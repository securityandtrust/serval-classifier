Document Title	Abstract
A Group Signature Based Secure and Privacy-Preserving Vehicular Communication Framework	We propose a novel group signature based security framework for vehicular communications. Compared to the traditional digital signature scheme, the new scheme achieves authenticity, data integrity, anonymity, and accountability at the same time. Furthermore, we describe a scalable role-based access control approach for vehicular networks. Finally, we present a probabilistic signature verification scheme that can efficiently detect the tampered messages or the messages from an unauthorized node.
Wired Equivalent Privacy (WEP) versus Wi-Fi Protected Access (WPA)	Wireless technology has been gaining rapid popularity for some years. Adaptation of a standard depends on the ease of use and level of security it provides. In this case, contrast between wireless usage and security standards show that the security is not keeping up with the growth paste of end userpsilas usage. Current wireless technologies in use allow hackers to monitor and even change the integrity of transmitted data. Lack of rigid security standards has caused companies to invest millions on securing their wireless networks. There are three major types of security standards in wireless. In our previous paper which was presented in ICFCC2009 Conference in Kuala Lumpur and published by IEEE Computer Society, we explained the structure of WEP as a first wireless security standard and discussed all its versions, problems and improvements. Now, we try to explain all of WPA versions and problems with the best solutions and finally make a comparison between WEP and WPA. Then we are in the next phase which is to explain the structure of last standard (WPA2) and we hope that we will publish a complete comparison among wireless security techniques in the near future and recommend a new proposal as a new protocol.
A Distortion-Based Approach to Privacy-Preserving Metering in Smart Grids	In this paper, we propose an efficient distortion-based privacy-preserving metering scheme that protects an individual customer's privacy and provides the complete power consumption distribution curve of a multitude of customers without privacy invasion. In the proposed scheme, a random noise is purposely introduced to distort customers' power consumption data at the smart meter so that data recovery becomes infeasible. Using the power consumption data and prior knowledge about added random noise, we develop an efficient algorithm for power consumption distribution reconstruction needed for power demand analysis and prediction. As a complete solution, our scheme also supports a privacy-preserving billing service. Using experimental results from real world single household power consumption data set and synthesized data of a large number of households, we demonstrate that the proposed scheme is robust against known attacks. Since it does not demand new facilities on existing smart grids, the proposed scheme offers a practical solution.
Privacy and security of features extracted from minutiae aggregates	This paper describes our recent analysis on the security and privacy of biometric feature vectors obtained from fingerprint minutiae. A large number of contiguous regions (cuboids) are selected at random in the minutiae space, and several new features are extracted from the minutiae inside each such cuboid. Specifically, the features are extracted from the average minutia coordinate within a cuboid, the standard deviation of the minutiae coordinates, and the aggregate wall distance, i.e., the sum of distance of each minutia from the boundary of the cuboids. In terms of matching performance on a public database, the feature vectors provide an equal error rate of 3 % even if the imposter is allowed to use the same local patches as the genuine user. Performance within a secure biometrics framework is evaluated by applying an LDPC code to the feature vectors and storing only the syndrome at the access control device, for use in authentication. The paper concludes with a discussion on methods to analyze security and privacy of biometric systems that use such local-aggregate-based feature vectors in a secure biometric recognition framework. This discussion highlights security attacks via template injection, spoofing, and cancelability compromises and also considers the difficulty of privacy attacks via template inversion.
Privacy-security tradeoffs in reusable biometric security systems	The performance of reusable biometric security systems in which the same biometric information is reused in several different locations is analyzed in this paper. The scenario in which the subsystems used at different locations are jointly designed is first considered. A fundamental limit of the privacy-security tradeoff is derived. Next, an incremental design approach is studied, in which the biometric measurements are reused while keeping the existing system intact. An achievable privacy-security tradeoff region for this design approach is derived. It is shown that under certain conditions, the incremental design approach can achieve the performance of the joint design approach. Finally, examples are given to illustrate the results.
Evaluating the robustness of privacy-sensitive audio features for speech detection in personal audio log scenarios	Personal audio logs are often recorded in multiple environments. This poses challenges for robust front-end processing, including speech/nonspeech detection (SND). Motivated by this, we investigate the robustness of four different privacy-sensitive features for SND, namely energy, zero crossing rate, spectral flatness, and kurtosis. We study early and late fusion of these features in conjunction with modeling temporal context. These combinations are evaluated in mismatched conditions on a dataset of nearly 450 hours. While both combinations yield improvements over individual features, generally feature combinations perform better. Comparisons with a state-of-the-art spectral based and a privacy-sensitive feature set are also provided.
Privacy preserving probabilistic inference with Hidden Markov Models	Alice possesses a sample of private data from which she wishes to obtain some probabilistic inference. Bob possesses Hidden Markov Models (HMMs) for this purpose, but he wants the model parameters to remain private. This paper develops a framework that enables Alice and Bob to collaboratively compute the so-called forward algorithm for HMMs while satisfying their privacy constraints. This is achieved using a public-key additively homomorphic cryptosystem. Our framework is asymmetric in the sense that a larger computational overhead is incurred by Bob who has higher computational resources at his disposal, compared with Alice who has limited computing resources. Practical issues such as the encryption of probabilities and the effect of finite precision on the accuracy of probabilistic inference are considered. The protocol is implemented in software and used for secure keyword recognition.
Smart meter privacy using a rechargeable battery: Minimizing the rate of information leakage	A rechargeable battery may be used to partially protect the privacy of information contained in a household's electrical load profile. We represent the system as a finite state model to make tractable the computation of the rate of information leakage. Specifically, we use a trellis algorithm to estimate the mutual information rate between the battery's input and output loads. We show that stochastic battery policies can leak 26% less information than a so-called best-effort algorithm (that holds the output load constant whenever possible). We finally describe the extension of the technique to more realistic models of the battery system.
Attacking a privacy preserving music matching algorithm	Secure multi-party computation based techniques are often used to perform audio database search tasks, such as music matching, with privacy. However, in spite of the security of individual components of the matching schemes, the overall scheme may still not be secure. This paper explains how such flaws may occur, using a privacy preserving music matching problem as a template, and provides a solution, and analyzes the resulting tradeoff between privacy and computational complexity. Although the paper focus on a music matching application, the principles can be easily adapted to perform other tasks, such as speaker verification and keyword spotting.
A novel eye region based privacy protection scheme	This paper introduces a novel eye region scrambling scheme capable of protecting privacy sensitive eye region information present in video contents. The proposed system consists of an automatic eye detection module followed by a privacy enabling JPEG XR encoder module. An object detection method based on a probabilistic model of image generation is used in conjunction with a skin-tone segmentation to accurately locate eye regions in real time. The utilized JPEG XR encoder effectively deteriorate the visual quality of privacy sensitive eye region at low computational cost. Performance of proposed solution is validated using benchmark face recognition algorithms on face image database. Experimental results indicate that the proposed solution is able to conceal identity by preventing successful identification at low computational costs.
Privacy-preserving speaker verification as password matching	We present a text-independent privacy-preserving speaker verification system that functions similar to conventional password-based authentication. Our privacy constraints require that the system does not observe the speech input provided by the user, as this can be used by an adversary to impersonate the user in the same system or elsewhere. We represent the speech input using supervectors and apply locality sensitive hashing (LSH) to transform these into bit strings, where two supervectors, and therefore inputs, are likely to be similar if they map to the same string. This transformation, therefore, reduces the problem of identifying nearest neighbors to string comparison. The users then apply a cryptographic hash function to the strings obtained from their enrollment and verification data, thereby obfuscating it from the server, who can only check if two hashed strings match without being able to reconstruct their content. We present execution time and accuracy experiments with the system on the YOHO dataset, and observe that the system achieves acceptable accuracy with minimal computational overhead needed to satisfy the privacy constraints.
On Privacy in Secure Biometric Authentication Systems	We focus here on two secure biometric systems (a common randomness based scheme and a fuzzy commitment scheme) and discuss their privacy preserving properties. We derive bounds on the privacy leakage in these schemes. We also show the relation between employed error-correction and leakage on biometric information, and between privacy and security for the fuzzy commitment scheme.
Capturing Spontaneous Conversation and Social Dynamics: A Privacy-Sensitive Data Collection Effort	The UW dynamic social network study is an effort to automatically observe and model the creation and evolution of a social network formed through spontaneous face-to-face conversations. We have collected more than 4,400 hours of data that capture the real world interactions between 24 subjects over a period of 9 months. The data was recorded in completely unconstrained and natural conditions, but was collected in a manner that protects the privacy of both study participants and non-participants. Despite the privacy constraints, the data allows for many different types of inference that are in turn useful for studying the prosodic and paralinguistic features of truly spontaneous speech across many subjects and over an extended period of time. This paper describes the new challenges and opportunities presented in such a study, our data collection effort, the problems we encountered, and the resulting corpus
Speech privacy for modern mobile communication systems	Speech privacy techniques are used to scramble clear speech into an unintelligible signal in order to avoid eavesdropping. Some analog speech-privacy equipments (scramblers) have been replaced by digital encryption devices (comsec), which have higher degree of security but require complex implementations and large bandwidth for transmission. However, if speech privacy is wanted in a mobile phone using a modern commercial codec, such as the AMR (adaptive multirate) codec, digital encryption may not be an option due to the fact that it requires internal hardware and software modifications. If encryption is applied before the codec, poor voice quality may result, for the vocoder would handle digitally encrypted signal resembling noise. On the other hand, analog scramblers may be placed before the voice encoder without causing much penalty to its performance. Analog scramblers are intended in applications where the degree of security is not too critical and hardware modifications are prohibitive due to its high cost. In this article we investigate the use of different techniques of voice scramblers applied to mobile communications vocoders. We present our results in terms of LPC and cepstral distances, and PESQ values.
Face recognition with enhanced privacy protection	This paper presents a novel approach for face based biometric recognition. The proposed method is based on the sorted index numbers (SIN) of appearance based facial features. A new algorithm is introduced to measure the similarity between SIN vectors. Due to the non-invertibility of the transformation from the original features to the SIN vectors, the proposed method can preserve the privacy of the users. The effectiveness of the proposed method is tested on a large generic data set, which contains images from several well known face databases. Experimental results demonstrate that the proposed solution may improve the recognition accuracy in both identification and verification scenarios.
The analog voice privacy system	The Analog Voice Privacy System is based on individual sample permutation of the output samples of a sub-band coder analysis filterbank. The system has a large number of digital keys, giving it the strength of a digital encryption system, but also retains the good quality characteristics of analog scramblers. It has been implemented in a real-time hardware prototype designed for evaluation in the field. The units work with any modular telephone and standard 120 volts AC electricity. The device contains two circuitry boards, one for analog and one for digital processing which contain four digital signal processors. There are 125! possible permutation keys. These prototypes were designed to be tested in real telephone environments. To date, the device has been successfully tested over long distance telephone connections, several different analog and digital PBXs and telephone switches, and a channel simulator. The quality of the decrypted speech is considered very natural, and in particular, speaker recognition is retained. This is a significant advantage over digital vocoders. This paper describes the underlying principles of the algorithm, the details of its implementation and laboratory test results.
Privacy control based on event elements in action logs	The privacy control is vitally discussed in context-aware environments. They focus on the static personal information gathered from many kinds of sensors. This research focuses on action logs. The action logs may be useful to provide context-aware services because they have much more implication than the static information. However, they may have a higher risk of privacy leak than the static information. This paper proposes a privacy control method in action logs.
An efficient distributed privacy-preserving recommendation system	Implementing a recommendation system on the data of mobile social networks exploits knowledge about behavior and preferences of its users and hence raises serious privacy concerns. Leveraging the wealth of aggregated information in these services promises an immense benefit by allowing suggestions for presumably appreciated, yet previously unseen restaurants, sights, and further types of locations. Privacy preserving recommenders based on homomorphic encryption have been proposed, which have a systematic draw-back: while recommender systems often store their information as real values, all homomorphic encryption schemes used today process only data from other algebraic structures, e.g., the ring of integers modulo some integer n. Therefore, we present a novel distributed recommender and a homomorphic encryption scheme, which works directly on real numbers and which possesses some remarkable properties: it is conceptually simple, efficient, and provably secure.
A pristine clean Cabalistic foruity strategize based approach for Incremental data stream privacy preserving data mining	Privacy has in recent times become an astounding akin to an oxymoron. It can either be embellished or marred with technology; confiscating more consideration in many data mining applications. We are focusing on information safety measures in order to preserve the individual's privacy, so that no personal information can be gained by the hacker from the data. Under the modern state of affairs of technological developments which has eradicated the distinction of domain data kept in private and public; we are inadequate in expertise of protecting the individual privacy. With today's scenario of data strewn globally, the records get incremented from various sources, which further masquerade a greater confrontation. In this paper we propose a new technique called Cabalistic fortuity strategize based approach for incremental data stream based PPDM. Our technique optimizes the privacy level by toughening the re-identification of original data without compromising the processing speed and data utility. Thus, it solves the re-identification predicament which is found in the conventional random projections. Here the encryption based random projection assigns secret keys to the positions of random matrix elements and not to the random numbers, (viz., where the random matrix is going to hold the random numbers). We have tackled two kinds of random sequences for generating the random sequences called determinist and indeterminist random sequences and encrypted it in a new way. And also we have proposed a projection based sketch for incremental data stream. We hope the proposed solution will tarmac way for investigation track and toil well according to the evaluation metrics including hiding effects, data utility, and time performance.
EMPPC-an evolutionary model based privacy preserving technique for cloud digital data storage	This paper spank out the enormity of unknown users hand on web service users' and their data protection level bump up as an issue in cloud users mind. Once hiring a data space in cloud it's the responsibility of both to accustomed the stored information's privacy and preserving it in a secret way. It is noticed by the academicians and researchers oodles and masses of privacy breaches relentlessly observable fact dealt globally. It is one of the hottest research topics. This work targets data privacy and its preservation by proposing an evolutionary approach to safeguard the confidential data stored in the cloud. It also focuses on prominent study of users' privacy need and to preserve data distorted from intermediate digital data thieves.
Impact of trust, security and privacy concerns in social networking: An exploratory study to understand the pattern of information revelation in Facebook	In the era of Internet technologies, social networking websites has witnessed thriving popularity. Computer mediated communication has changed the rules of social interaction and communication. Most social networking sites like Orkut, Facebook, Google+, Twitter etc. facilitates user's with the features like online interaction, sharing of information and developing new relationships etc. Online interaction and sharing of personal information in social networking sites has raised new privacy concerns. So, it requires an exploratory insight into user's behavioural intention to share information. This research aims to develop a research model, with security and privacy concerns conceptualized as an antecedent of trust in social networking site and moderator of information sharing. The study aims to understand the impact of security, trust and privacy concerns on the willingness of sharing information in social networking sites. Using an online questionnaire, empirical data were collected from 250 Facebook user's of different age group over the time period of 4 months. Reliability analysis, confirmatory factor analysis, structure equation modelling is used to validate the proposed research framework. This empirical study, based on an established theoretical foundation, will help the research community to gain a deeper understanding of the impacts of privacy concern in the context of Facebook. Practical implications: - The paper increases the understanding of user's willingness to reveal information on social networking site on their level of privacy, security and trust. The proposed ideas and discussion is equally applicable to social networking site operators with useful strategies for enhancing user's acceptance. Findings:-The privacy concerns of research respondents were found statistically significant and suggest that privacy concerns like security, trust has a positive effect on information sharing.
A privacy breach preventing and mitigation methodology for cloud service data storage	The present paper focuses on privacy preserving technique. Cloud computing is not a new technology more over it is a new way of delivering technology. Providers deliver it in the form of services, in computing field security is the main concern which blocks the tremendous growth of Cloud computing and became a huge debate area worldwide, due to security breach of user's valuable information. So we identified the week service bonding of cloud providers in maintaining, and preserving users' secrecy and failed to have a universal service level agreement. This paper focus on privacy mitigation methodology by proposing a privacy preserving algorithmic approach to congregate the privacy issue and preserve ones confidential data stored in the cloud.
Hiding sensitive association rules to maintain privacy and data quality in database	In this paper, we propose a heuristic based algorithm named MDSRRC (Modified Decrease Support of R.H.S. item of Rule Clusters) to hide the sensitive association rules with multiple items in consequent (R.H.S) and antecedent (L.H.S). This algorithm overcomes the limitation of existing rule hiding algorithm DSRRC. Proposed algorithm selects the items and transactions based on certain criteria which modify transactions to hide the sensitive information. Experimental result shows that proposed algorithm is highly efficient and maintains database quality.
ALP: An authentication and leak prediction model for Cloud Computing privacy	The current paper is an attempt to integrate privacy preservation with privacy leak detection in the context of text mining. This may be considered as extending the Storage as a Service feature of Cloud Computing wherein the user in the role of content creator submits the documents to be stored. There exists a facility to cluster these documents based on the concept-based mining algorithm. The clustered documents are usually available in the form a tree. When a user in the role of a subscriber requests to access a document, this request for access will have to go through an authentication procedure based on the Leakage Free Redactable Signature Scheme. Access control information is being maintained in the form of a Cloud user access control list. A privacy detection leak module which detects privacy leaks depending upon the pattern of previous privacy leaks is also being proposed. This information is then used to update the cloud user access control list and users responsible for privacy leaks are prevented from accessing the cloud service. The current document being requested by the user together with the information from the access control list is used to decide which part of the redacted trees have to be made available to the user as a response. Thus this combination of this authentication procedure and privacy leak detection can be used to ensure the privacy of the sensitive information stored by the user in the cloud.
An Improved Method for Privacy Preserving Data Mining	In the light of developments in technology to analyze personal data, public concerns regarding privacy are rising. Often a data holder, such as a hospital or bank needs to share person specific records in such a way that the identities of the individuals who are the subjects of data cannot be determined. The generalization techniques such as K-anonymous, L-diverse and t-closeness were given as solutions to solve the problem of privacy breach, at the cost of information loss. Also, a very few papers dealt with personalized generalization. But, all these methods were developed to solve the external linkage problem resulting in sensitive attribute disclosure. It is very easy to prevent sensitive attribute disclosure by simply not publishing quasi-identifiers and sensitive attributes together. But the only reason to publish generalized quasi identifiers and sensitive attributes together is to support data mining tasks that consider both types of attributes in the database. Our goal in this paper is to eliminate the privacy breach (how much an adversary learn from the published data) and increase utility (accuracy of data mining task) of a released database. This is achieved by transforming a part of quasi-identifier and personalizing the sensitive attribute values. Our experiment conducted on the datasets from the UCI machine repository demonstrates that there is incremental gain in data mining utility while preserving the privacy to a great extend.
Parallel Privacy Preserving Association rule mining on pc Clusters	Association rules discovered by association rule mining may contain some sensitive rules, which may cause potential threats towards privacy and security. In this paper, we address the problem of privacy preserving association rule mining by proposing a Knowledge Sanitization to prevent the disclosure of sensitive rules. We also present parallel approach to generate a non-sensitive and sensitive rule mining. Our proposed solution key issue is to provide a high degree of parallelism for privacy to the data owner.
A K-anonymity Based Semantic Model For Protecting Personal Information and Privacy	The proper protection of personal information is increasingly becoming an important issue in an age where misuse of personal information and identity theft are widespread. At times there is a need however for management or statistical purposes based on personal information in aggregated form. The k-anonymization technique has been developed to de-associate sensitive attributes and anonymise the information needed to a point where the identity and associated details cannot be reconstructed. The protection of personal information has manifested itself in various forms, ranging from legislation, to policies such as P3P and also information systems such as Hippocratic database. Unfortunately, none of these provide support for statistical data research and analysis. The traditional k-anonymity technique proposes a solution to this problem, but determining which information can be generalized and which information needs to be suppressed is potentially difficult to determine. In this paper we propose a new idea that integrates personal information ontology with the concept of k-anonymity, in order to overcome these problems. We demonstrate the idea with a prototype in the context of healthcare data management, a sector in which maintaining the privacy of individual information is essential.
Hiding of User Presence for Privacy Preserving Data Mining	Recently, it has been expected to realize privacy preserving data mining in order to acquire valuable knowledge from the combined information sources of several service providers. Therefore researches have been conducted on a distributed anonymization method, which combines the personal information and anonymize it to prevent identifying specific user records. However, in those researches, when sets of the users in the providers are not the same, there is a problem that users' presence in either provider may be revealed. Thus, this paper proposes a new indicator which represents the probability of the presence of users being revealed and introduces a modified distributed anonymization method to satisfy the proposed indicator. Also, we use U.S. census data for evaluation and calculate the relative error of its anonymized data. The results show that it is almost 10-25% in specific cases.
Privacy preserving associative classification on vertically partitioned databases	The growing needs of multiple parties interaction in corporate and financial sector emphasize the need of developing privacy preserving and efficient distributed data mining algorithms. Even though a lot of research work is progressing in this area to transform efficient centralized mining models to work on horizontal and vertical partitioned databases there is lack of associative classification model that can perform classification on vertically partitioned databases. In order to overcome such needs this paper proposes an associative classification model on vertically partitioned databases. By considering privacy requirements in case of data sharing among multiple parties a scalar product based third party privacy preserving model adopted for proposed model. The proposed model accuracy tested on UCI data bases given encouraging results.
Accountable privacy based on publicly verifiable secret sharing	As developing the internet a variety of services emerge and service providers serve services such as using users' private information. Service providers require many types of information related users even including sensitive private information to serve a service with high quality, but users are reluctant to disclose their private information. Because if the private information is leaked it will lead to an invasion of privacy of users and may arise some problems about users' life. Nevertheless, service providers want to collect the users' information because of increasing their efficiency of services. As a result, it brings about a conflict of the loss and gain between users and service providers. Anonymity is one of the solutions. Anonymity can get rid of linkability between transaction and users' private information. Therefore, users can provide their private information without concerns about leaking it and service providers can collect many types of information and serve services with high quality. However, anonymity may be abused, and used to undermine the protection goal of accountability. Namely, a person who is assured anonymity may serve information which is not related him/her. It may be reduced the quality of services. Revocation of anonymity can make up for weak point of anonymity. But when anonymity is revoked legal dispute may be arisen and there is a cost of time or money. In this paper, we propose a scheme for accountable privacy using secret sharing and some cryptographic methods. The scheme we propose reduces a cost of revocation of anonymity because there is maybe no legal dispute and keeps anonymity more secure against collusion between service provider and revocation authority.
An effective privacy protection scheme for cloud computing	With the rapid development of cloud computing, more cloud services are into our daily life, and thus security protection of cloud services, especially data privacy protection, becomes more important. However to perform privacy protection causes huge overhead. Thus it is a critical issue to perform the most suitable protection to decline performance consumption while provide privacy protection. In this paper, the Effective Privacy Protection Scheme (EPPS) is proposed to provide the appropriate privacy protection which is satisfying the user-demand privacy requirement and maintaining system performance simultaneously. At first, we analyze the privacy level users require and quantify security degree and performance of encryption algorithms. Then, an appropriate security composition is derived by the results of analysis and quantified data. Finally, the simulation results show that the EPPS not only fulfills the user-demand privacy but also maintains the cloud system performance in different cloud environments. The execution result of EPPS outperforms other security schemes by 35% to 50%.
Online advertising and its security and privacy concerns	Commercial advertising has greatly benefitted from Internet services and online advertising can even be considered as the foundation of web economy. However, despite the availability of many books on how to create, use and make profit from online advertisement; there is little in-depth study on its true nature, security and privacy concerns. Through this research, the authors were able to establish an in-depth understanding of online advertising by collecting and analyzing numerous data on online advertising, with the hope that it could serve as a basis for further study on the field. The authors have also examined the security and privacy concerns of online advertising and the various gimmicks used to victimize innocent people. On the positive side, the paper explains the attractiveness of free online advertising services and the mechanism though which website owners profit from hosting online advertisements despite the fact that neither advertisers nor users pay for the services. On the negative side, the paper shows how online advertising hosts could be victimized by some shroud users for their money making purposes by continuous clicking of online advertisements without any intention of purchase. It also cites cases in which some website owners have marketed users' private information behind the scene. The paper concludes by highlighting pros and cons of online advertising, i.e., despite its numerous advantages, such as efficiency and range, it presents many dangers to advertisers, providers, website owners, and users.
Session 5C: Information Security Technology (V) : Privacy & P2P	Start of the above-titled section of the conference proceedings record.
Review of Japan's privacy policy	The recent trend of growing breaches of personal privacy suggests the urgent need for privacy protection. Legislated by Japan's General Services Administration in May 2003, the Privacy Act applies to activities dealing with personal information in private industry sectors including the information telecommunications industry. The Privacy Act stipulates the basic policies for the general execution of personal information protection and roles and duties related to privacy management for information telecommunications companies. The Act take effect on April 1, 2005 for information telecommunications industries. This document reviews the contents of the Japanese Privacy Act and seeks to understand the Japanese policy direction regarding privacy protection to address strategic current issues for Korean privacy policies
On the study of service security model for privacy using global user management framework	GUMF (global user management framework) that is proposed in this research can be applied to next generation networks such as BcN (broadband convergence network), it's QoS guaranteed security framework for users can solve the present Internet's security vulnerability. GUMF offers anonymity for users of the service and uses the user's real-name or ID for management of service and it's technology can realize secure QoS. GUMF needs a management framework, UMS (user management system), VNC (virtual network controller) etc. UMS consists of a root UMS in country dimension and local UMS in each site dimension. VNC's network security equipment includes VPN, QoS and security functions etc., and it achieves the QoSS (quality of security service) and CLS (communication level switching) functions. GUMF can offer safety in bandwidth consumption attacks such as worm propagation and DoS/DDoS, IP spoofing attack, and most current attacks such as abusing of private information because it can offer the different QoS guaranteed network according to user's grades. User's grades are divided by 4 levels from Level 0 to Level 3, and the user's security service level is decided according to the level of the private information. Level 3 users that offer bio-information can receive secure network service where privacy is guaranteed. Therefore, GUMF that is proposed in this research can offer a profit model to ISP and NSP, and can be utilized by strategy for secure u-Korea realization
Privacy Protection based on User-defined Preferences in RFID System	Radio frequency identification, known as RFID, is fast becoming one of the most controversial technologies at present. Because the radio waves emitted from RFID reader are invisible, it's really hard to detect who reads a tag attached to or incorporated into products owned by a person. A significant concern to privacy threats in RFID system arises from this reason. Privacy threats are not just problem. Security is also another critical consideration. Many solutions have been proposed to address these fundamental problems and facilitate the benefits of RFID system. However, many of them are hard to implement in practice, even though their approaches are theoretically plausible in the literature. Keeping them in mind, we will design "preferences" oriented communication protocol rather than contrive new algorithm or hardware modules to prevent ill-intentioned uses of RFID technology. The concept "preferences" is originated on P3P
Design and Implementation of RDBAC Framework for Privacy on NEIS	In Korea, as concerns for protecting privacy is increased in developing e-government, digital era, it is needed to develop the more sophisticated mechanism for secure strategy. Research in the area of role-based access control (RBAC) has made fast progress over the last ten years and is well-known to effective techniques to reduce the complexity of role administration and ensure the security policy in large institutions or enterprises. However, we came to faced with two questions in adopting RBAC; how controls the access right of huge users in real world and how restricts the personal data access range of each user who takes the same role in organization. In RBAC model, the accessible data range is defined by role and its' system operation and it is needed to be extend it's model. In this paper we proposed new role and data based access control (RDBAC) platform, which was extended data access control mechanism and deployed in NEIS (National Education Information System). NEIS is a Web based centralized education administration system. It was developed as one of the 11 e-government projects by Ministry of Education and Human Resource Development (MOE&HRD) in Korea. Our approach of designing RDBAC model was successfully adopted in NEIS and it warrants our secure policy. Our contributions of RDBAC framework represented as three parts; simplifying complexity of user/role association, providing flexibility of role/operations association, and ensuring complete secure policies and principles by limiting access data range
RFID Authentication Protocol for Anti-Counterfeiting and Privacy Protection	RFID (radio frequency identification) is one of the most promising NFC (near field communication) technologies for pervasive and ubiquitous network societies in recent year. The main factor for more and more interests from both industry and academic institutes is due to the lower and lower costs, which may pose a threat to information security while RFID become part of our daily life because the lower cost, the weaker cryptographic algorithms provided by RFID tags. A feasible security mechanism for anti-counterfeiting and privacy protection is proposed that features mutual two-pass authentication and uses hash function and XOR operation to enhance the RFID tag's security but still with low cost.
Consumer's Privacy Concerns and Willingness to Provide Personal Information in Location-Based Services	Location-based services (LBS) are expected to provide more enhanced values utilizing consumer's personal information such as location information, and profile information. However, in contrast to existing mobile applications, LBS could raise more severe consumer's privacy concerns because of dynamically changing information such as location information could be more sensitive to consumer. In this context, this study proposes the research model that conceptualizes personal characteristics influencing consumer's privacy concerns and investigates the relationship between perceived privacy concerns and willingness to provide personal information. Finally, the model tests moderating effects that makes differences in the strength of relation between personal characteristics and consumer's privacy concerns. Data is collected by online survey and the model is verified by structural equation model.
Location privacy in sparse environment	Privacy of personal location information is becoming an increasingly important issue. This paper develops new methods for location privacy in sparse environment based on dummy users. The true user has been mixed with a set of dummy users in that LBSs can't distinguish the true user so as to protect user location privacy. We present two techniques, the first one is called ΓÇ£dummy user trigger algorithmΓÇ¥, which is able to achieve the balance of user's Location privacy and system performance, and the second one is named ΓÇ£dummy user generation algorithmΓÇ¥ based on the period density matrix which enhances the truthfulness of dummy user.
Privacy preserving based on association rule mining	Privacy has become an important issue in Data Mining. Many methods have been brought out to solve this problem. This paper deals with the problem of association rule mining which preserves the confidentiality of each database. In order to find the association rule, each participant has to share their own data. Thus, much privacy information may be broadcast or been illegal used. These issues can be divided into two categories: data hiding and knowledge hiding. This paper reviews the major method of privacy preserving on each category and choose some of them to complete our system. At the end, an improvement of sensitive rules hiding is proposed to make it more accuracy and security.
Privacy preserving clustering over distributed data	Data mining based on privacy preserving is the combination of information security technology and knowledge discovery technology. A simple and effective privacy-preserving distributed mining method of clustering (PPD-SMD) and (PPD-JD) is proposed to solve the issue about privacy preserving of cluster based on Binary and Nominal Attributes distance. This method brings the secure protocol and crypto-algorithm in the data models of the horizontal distributed. Using semi-trusted third party (STTP), PPD-SMD and PPD-JD do not transfer real data to other sites in clustering procedure. In the end, analysis in security, efficient and complexity are carried on.
Combined data distortion strategies for privacy-preserving data mining	The problem of privacy-preserving data mining has become more and more important in recent years. Many successful and efficient techniques have been developed. However, in collaborative data analysis, part of the datasets may come from different data owners and may be processed using different data distortion methods. Thus, combinations of datasets processed using different methods are of practical interests. In this paper, a class of novel data distortion strategies is proposed. Four schemes via attribute partition, with different combinations of singular value decomposition (SVD), nonnegative matrix factorization (NMF), discrete wavelet transformation (DWT), are designed to perturb submatrix of the original datasets for privacy protection. We use some metrics to measure the performance of the proposed new strategies. Data utility is examined by using a binary classification based on the support vector machine. Our experimental results indicate that, in comparison with the individual data distortion techniques, the proposed schemes are very efficient in achieving a good trade-off between data privacy and data utility, and provide a feasible solution for collaborative data analysis.
Location privacy in mobile environments using a secured anonymity server	With the advances in the growth of wireless technologies, the usage of cell phones (i.e.) mobile users and the location based services have been increasing. However the location privacy of an individual user has become the challenging problem in the location based service providers. Here we propose an Anonymity server which is enclosed within an authentication server and a security key generator. The authentication server authenticates the client and encrypts all the user data using block cipher in cipher block chaining mode and Advance Encryption standard which provides security for all the user data. Then for each encrypted data the security key generator generates a random number as a session key. The anonymity server now contacts the location based service server using the session key generated by the security key generator as user identity. Now the server is unknown of individual user data and the service information is provided to the user with location privacy through the anonymity server.
Privacy Preserving Cooperative Clustering Service	The growth of Internet has opened up new avenues for business and corporate model. Information sharing over Internet can help business houses in better cooperative strategic planning and growth. However despite such an impact, business houses are quite reluctant to share information because of the fear of information leakage. In this paper we study and propose an elegant, simple and practical solution for the problem of how can one party avail the data clustering service of another party without affecting each other's privacy. In our solution, we introduce the following two problems: (a) Secure multiparty computation of a depth of a query point, (b) Secure multiparty computation of whether a query point is a hull vertex. To the best of our knowledge this is the first time in literature that the aforementioned problems have been considered in privacy preserving framework.
Privacy Preserving Clustering-A Hybrid Approach	This paper presents a privacy preserving clustering technique using hybrid approach. The technique mainly exploits a combination of isometric transformations i.e. translation, rotation and reflection transformations along with a secure random function in order to provide secrecy of user-specified attributes without losing accuracy in results. The proposed method was tested and evaluated in terms of several synthetic as well as real-life data and the performance has been found satisfactory in comparison to its other counterparts.
Privacy-Preserving Collaborative Filtering Protocol Based on Similarity between Items	A recommendation system enables us to take information from huge datasets about tastes effectively. Many cryptographical protocols for computing privacy-preserving recommendation without leaking the privacy of users are proposed. However, the current issue is the large computational overhead depending the number of users. Hence, the application of the protocol is limited within small communities. In this paper, we address the issue of scalability by replacing the similarity between users by that of between items. Since the similarities between items can be publicly available, the recommendation steps are processed without dealing with confidential information such as the similarities between users. We propose an efficient scheme by using item-item similarities for providing a prediction of arbitrary values of rating. We show the performance and the accuracy evaluation of our proposed scheme based on a numerical experiment.
New Approach to Quantification of Privacy on Social Network Sites	Users may unintentionally reveal private information to the world on their blogs on social network sites (SNSs). Information hunters can exploit such disclosed sensitive information for the purpose of advertising, marketing, spamming, etc. We present a new metric to quantify privacy, based on probability and entropy theory. Simply by relying on the total leaked privacy value calculated with our metric, users can adjust the amount of information they reveal on SNSs. Previous studies focused on quantifying privacy for purposes of data mining and location finding. The privacy metric in this paper deals with unintentional leaks of information from SNSs. Our metric helps users of SNSs find how much privacy can be preserved after they have published sentences on their SNSs. It is simple, yet precise, which is proved through an experimental evaluation.
Privacy Protected Query Processing with Road Network Embedding	Location-based applications are becoming increasingly popular due to the wide spread of global positioning devices. One major concern in location-based applications is how to protect user privacy. A typical solution consists of three tiers: mobile users, trusted anonymizer, and service provider. The trusted anonymizer first needs to cloak the queries received from mobile users, then sends the cloaked queries to the service provider. The service provider then answers the cloaked query, which is a challenge if the underlying environment is a road network. In this paper, we propose to use Road Network Embedding (RNE) to answer cloaked queries in a road network environment. We first give an algorithm to answer k-nearest neighbor queries, then extend the algorithm to answer range queries and queries over private objects. Extensive simulation studies are preformed to show the effectiveness of the proposed technique.
Need for Symmetry: Addressing Privacy Risks in Online Social Networks	Private attributes of Online Social Network (OSN) users can be inferred from other information (which is usually from users' friends and group information). To address this, social networking sites allow users to hide their friend lists and group lists, so that general public cannot see them. However, if a user doesn't make his friend list public, but his friends have public friend list where we can find him, we can do reverse lookup to extend the friend lists of the user. Furthermore, many social networks allow non-group members to list the members of public groups (e.g., Face book). These are strong violations of OSN users' privacy, and can be considered as privacy risks caused by the asymmetric configuration of settings in OSNs. In this paper we present the privacy risks due to the lack of symmetric configurations, which exist in most of the OSNs. To make our idea more clear, we propose a inference attack and show that it can be used to infer users' private information, even users already made their friend list private. We theoretically analyze the risk of proposed privacy issues, and evaluate the risk using experiments based on real-world OSN data. We show that it is not sufficient to only disable friend list and group list to guarantee privacy, and propose methods to mitigate these privacy issues.
Privacy-Preserving Data Mashup	Data Mashup is a special class of mashup application that combines information on the fly from multiple data sources to respond to transient business needs. Mashing up data requires an important programming skill on the side of mashups' creators, and involves handling many challenging privacy and security concerns raised by data providers. This situation prevents non-expert users from mashing up data at large. In this paper, we propose a declarative approach for mashing-up data. The approach allows data mashup creators to create data mashups without any programming involved, they just need to specify "declaratively" their data needs. The approach will then build the mashups automatically while taking into account the data's privacy and security concerns.
Perfect Privacy Preserving in Automated Trust Negotiation	Automated Trust Negotiation aims to securely identify the consensus between two sets of policies consisting of certificates, with minimal disclosure of policies to each other. The paper proposes a new scheme that allows both parties to learn whether or not, both parties agree to transfer a given target certificate to the requesting party. No policy is revealed after performance of the protocol. No certificate is known to each other.
Privacy-Preserving Distributed Decision Tree Learning with Boolean Class Attributes	This paper studies a privacy-preserving decision tree learning protocol (PPDT) for vertically partitioned datasets. In the vertically partitioned datasets, a single class (target) attribute are shared by both parities or carefully treated by either party in the existing studies. The proposed scheme allows both parties to have independent class attributes in secure way and to combine multiple class attributes in arbitrary boolean function, which gives parties a flexibility in data-mining. Our proposed PPDT protocol reduces the CPU intensive computation of logarithm by approximating with the piecewise linear function defined by light-weight fundamental operations of addition and constant-multiplication so that information gain for attribute can be evaluated in the secure function evaluation scheme. Using the UCI Machine Learning dataset and the synthesized dataset, the proposed protocol is evaluated in terms of the accuracy and the size of tree.
A Privacy Preserving Prediction-based Routing Protocol for Mobile Delay Tolerant Networks	A prediction-based routing protocol for mobile delay tolerant networks functions by forwarding a message from one intermediate node to another if the latter has higher probability of encountering the destination node. However, this process compromises the privacy of the nodes by revealing their mobility patterns. In this paper, we propose a privacy preserving prediction-based routing protocol that forwards messages by comparing information about communities of nodes instead of individual nodes. Specifically, it compares the maximum probability that a node in the community of a potential intermediate node will encounter the destination node. We present theoretical security analyses as well as practical performance evaluations. Our simulations on a well established community-based mobility model demonstrate that our protocol has comparable performance to existing prediction-based protocols. Yet our protocol is the only one that preserves the privacy of nodes.
A Hybrid Sharing Control Model for Context Sharing and Privacy in Collaborative Systems	Complex Web-based information systems involving multiple entities and their dynamic mobile-based collaborations require efficient techniques for context information sharing. Sharing control is a requirement for preserving the privacy of personal context and shared context. Our sharing control mechanism is hybrid, based on sharing control rules defined by enterprise as well as by individuals users. Our complex scenario involves multiple entities which require prioritization and conflict handling mechanism for entities and their policy rules. This paper presents a sharing control model, Web services-based architecture and its implementation with a running example. The system is evaluated by comparing our hybrid sharing control policy with enterprise-defined role -based policy and shows effectiveness of our hybrid policy in collaborative information sharing environments.
Smart Blood Query: A Novel Mobile Phone Based Privacy-Aware Blood Donor Recruitment and Management System for Developing Regions	The growth in numbers and capacity of mobile devices such as mobile phones coupled with widespread availability of inexpensive range of services presents an unprecedented opportunity for mobile health care applications. Blood donation and transfusion service is one of the most complex management systems in health sector. Quality management of a Blood Transfusion Services (BTS) starts with safe blood donor recruitment (BDR) and donor care. In the South-East Asia Region (SEAR) almost all countries except Thailand depend heavily on replacement of blood from relatives and friends. In this paper, we present location-aware mobile phone based blood donor recruitment, information retrieval and management system that aims at ensuring the quality of the blood and increasing the efficiency of operation management. Here an attempt has been made to leverage the ubiquity and power of the standard mobile phone as a lifesaving mobile health care application, delivering more user convenience.
Towards a Pervasive Formal Privacy Language	The pervasive computing systems are weaving themselves in our daily life, collecting private user information invisibly, which made privacy a major issue in these environments. The huge number of interactions between users and pervasive devices necessitate the mapping of user defined privacy policies into data level privacy policies which can be used by pervasive devices. These data level policies should follow the original human language format so the resulted data privacy policies can be reviewed by non-technical users assuring that machine level policies are following user defined privacy requirements. On the other hand the resulted policies should be able to precisely describe events, components and operations in the context of pervasive environments and proper judgments can be made based on these policies. In this paper we review previous languages and formats for describing privacy policies and analyzing them in the context of pervasive systems. We introduce a PERvasive FORmal (PERFORM) privacy language to map user privacy policies into data level policies. The PERFORM is capable of describing events and characteristics of pervasive environments. The proposed model would follow human judgment process in checking operations against privacy policies.
Data Security and Information Privacy for PDA Accessible Clinical-Log for Medical Education in Problem-Based Learning (PBL) Approach	Data security and information privacy are the important aspects to consider for the use of mobile technology for recording clinical experience and encounter in medical education. Objective: This study aims to address the qualitative findings of the appropriate data security and information privacy for PDA accessible clinical-log in problem-based learning (PBL) approach in medical education. Method: The semi-structured interviews were conducted with the medical faculty members, honorary clinical academics and medical education technology specialists. Results: Data security and information access plan were determined for managing clinical-log data. The results directed the guideline for the future development and implementation of clinical-log and other functionalities on PDAs. Conclusion: The findings provide the understanding of aspects, concerns and appropriate strategy to safeguard data security and information privacy of PDA accessible clinical-log.
Privacy Preservation Through Process Views	Privacy and security are major concerns for partners in B2B and B2C applications. Service providers want on the one hand isolate their private process in order to protect their business logic and improve their privacy and on the other hand they have to expose (at least some parts of) their private process to other partners in order to enable communication, interaction and data exchange. Process Views are powerful mechanisms which serve several purposes: improvement of privacy and security, process abstraction, separation of public and private parts of business processes, interface definition for interorganizational workflows, loosening the coupling between process components, etc. Following an extensive survey of approaches for process views, we present a correctness criterion for views and a novel technique for the construction of process views which can be used for improvement of privacy and security. The formal definition of the view construction operators allows to prove that all views constructed with these operators are correct. In addition, by application of workflow views, changes in a private process can be kept local such that the interaction with other partners are not affected.
Some Thoughts on the Legal Background of the Continuously Increasing Privacy Risk in Information Systems and on How to Deal with It	This paper tries to give an overview of the rising concerns raised by the issue of privacy protection that is associated with the European Data Retention Directive. After relating this risk to the requirements as stated in the European Data Protection Directive, an approach for a security-integrated view on the design of information systems is discussed. The paper then finishes with an outlook on the possible impact on IT governance.
Privacy-Preserving Set Operations in the Presence of Rational Parties	Privacy-preserving set operations are useful for many data mining algorithms as building tools. Protocols for privacy-preserving set operations have considered semi-honest and malicious adversarial models in cryptographic settings, whereby an adversary is assumed to follow or arbitrarily deviate from the protocol. Semi-honest model provides weak security requiring small amount of computation, on the other hand, malicious model provides strong security requiring expensive computations like homomorphic encryption. However, efficient computation of such set operations are desirable for practical implementations. In this paper, we build efficient and private set operations avoiding the use of expensive tools like homomorphic encryption, zero knowledge proof, and oblivious transfer. Our protocol is constructed in game-theoretic model. In other words, instead of being semi-honest or malicious, the parties are viewed as rational and are assumed (only) to act in their self-interest. We show that our protocol satisfies computational Nash equilibrium.
Privacy Protection on Transfer System of Automated Teller Machine from Brute Force Attack	Currently, an authentication system used in banks is to protect assets of users. However, these systems are weak against the peeping attack. That is high risk. Therefore, we proposed that a user safely enters credentials and information to transfer money after launching Live CD on stand-alone in place without risk of peeping attack such as a home. The entered information is encrypted by common key crypto system and stored in a QR code. If the peeping attack occurred, this information were protected by using the QR code, also can be high-speed processing. However, if QR codes ware obtained by unauthorized users, they can find out privacy information of owner by reading QR code to a ATM. Therefore, we propose that the system is appended function for privacy protection to the previous method.
A Study of Efficiency and Accuracy of Secure Multiparty Protocol in Privacy-Preserving Data Mining	An analysis of the accuracy and efficiency of multiparty secured protocols is carried out so that both measures can be optimally exploited in the design of malicious party and semi-honest party. Finding efficient protocols of the Secure Multiparty Computation(SMC) is one active research area in the field of privacy preserving data mining (PPDM). The efficiency of privacy preserving data mining is crucial to many times-sensitive applications. In this paper, we study various efficient fundamental secure building blocks such as Fast Secure Matrix Multiplication(FSMP), Secure Scalar Product (SSP), and Secure Inverse of Matrix Sum (SIMS). They are supportively embedded the enhanced features into conventional data mining. We evaluate time/space efficiency on the different protocols. Experimental results are shown that there is a trade-off of accuracy and efficiency in the secured multiparty protocols targeted on semi honest party PPDM. It is therefore articulated that dimensionality reduction techniques such as Fisher Discriminant, Graph, Lapalician, and Support Vector Machine, should be used to preprocess the data. Key contributions of this paper include, besides providing some analyses of accuracy and efficiency, are commendation on further directions for computational efficiency improvement for multiparty online real data PPDM in cloud computing platforms (private and public).
How to Preserve Privacy in Services Interaction	In this paper, we present a formal model for preserving privacy in Web services. We define a Web service-aware privacy model that deals with the privacy of input data, output data, and operation usage. We introduce a matching protocol that caters for partial and total privacy compatibility. We propose also a negotiation model to reconcile clients' requirements with providers' policies in case of incompatibility.
Privacy-Preserving DRM for Cloud Computing	We come up with a digital rights management (DRM) concept for cloud computing and show how license management for software within the cloud can be achieved in a privacy-friendly manner. In our scenario, users who buy software from software providers stay anonymous. At the same time, our approach guarantees that software licenses are bound to users and their validity is checked before execution. We employ a software re-encryption scheme so that computing centers which execute users' software are not able to build user profiles - not even under pseudonym - of their users. We combine secret sharing and homomorphic encryption. We make sure that malicious users are unable to relay software to others. DRM constitutes an incentive for software providers to take partin a future cloud computing scenario. We make this scenario more attractive for users by preserving their privacy.
User-Side Personalization Considering Privacy Preserving in Cloud Systems	Cloud systems are in the list of the most recent technologies. It is expected that users move to these new systems rapidly, however, privacy issues make users doubtful to migrate to cloud. They need to give a guarantee that their data and processes are protected enough within the distributed cloud infrastructure, on the other hand, to get better and more special services they have to permit the hosts to access their personal data for personalization purposes. To solve this controversy, in this paper we introduce a new personalization framework and architecture conveys privacy issues. Our proposed architecture mostly involves user side processing and no personal data leaves the client. In this way, the users feel more comfortable to use the cloud system while the quality of service is promoted as well. This method embraces personal data processing agent in the client side through personalization techniques and queries are sent to the hosts in an anonymous format. What is more, our personalization system needs only light processing, able to be run on clients with minimum processing capability, one of the most important issues for cloud users. Another advantage of the proposed architecture is its technology independency that matches the modules with various implementation techniques. We explain our framework and architecture in a "location advising service case study."
A Client Privacy Preserving Discovery Service Scheme	The EPC global Network is a global information architecture for objects carrying RFID tags with Electronic Product Codes (EPC) in supply chains. Discovery Service (DS) is an important component storing large amounts of indices from EPCs to detailed information in EPCISes. However, to the client, DS is a third-party server which can easily get clients' privacy when they send queries. In this paper, using the policy of Private Information Retrieval (PIR), we propose a client privacy preserving DS scheme that can meet both basic functional requirement and client privacy requirement. Compared to existing privacy preserving DS schemes, our work is more concise in architecture and can completely guarantee the client privacy.
Privacy Enhanced and Computationally Efficient HSK-AKA LTE Scheme	In this paper, we propose a new Authentication and Key Agreement (AKA) scheme for the Long Term Evolution(LTE) technology. The scheme addresses mainly the privacy concerns related to the identity of mobile users and aims at protecting such users from malicious Mobile Management Entities (MME). In addition, the constraint of limited energy on mobile network elements is taken into consideration when developing the associated computational procedures. Accordingly, we propose a hybrid scheme that employs both symmetric and asymmetric encryption techniques.
Privacy Obfuscation with Bloom Filter for Effective Advertisement	Advertisements shown on web browser have been infiltrated into commerce on Internet. Especially, web sites with free contents such as news sites, shopping sites, game sites, etc. usually have advertisements instead of charge for users. Those sites have been evolved and have a method in which specific advertisements are effectively shown on users. Recent web sites collect personal information of users while storing logs of chosen items by the users on the sites, so that advertisements shown on browser will be related with favorites of users. Social Networking Service (SNS) is one of the best systems for collecting personal information for commercial use. However, personal information sometimes includes information of privacy. The information collected on the sites might be used for personal identification or identifying specific ideology. Therefore, I propose a method which obfuscates personal information for identification while keeping a certain accuracy of information for advertisement. It will act as a deterrent against elimination of people with specific ideology or against identification of a target for slandering.
Protecting Access Pattern Privacy in Database Outsourcing Service	The fact that the data owners outsource their data to external service providers introduces many security and privacy issues. Among them, the most significant research questions relate to data confidentiality and user privacy. Encryption was regarded as a solution for data confidentiality. The privacy of a user is characterized by the query he poses to the server and its result. We explore the techniques to execute the SQL query over the encrypted data without revealing to the server any information about the query such as the query type or the query pattern, and its result. By implementing all the relational operators by using the unique selection operator on the server-side database with a constant number of elements in each time of selection, our proposal can defeat against the statistical attacks of the untrusted server compromising data confidentiality and user privacy.
Integration of Privacy Protection Mechanisms in Location-Based Services	In the next few years, we will see the upcoming of location-based services. Such LBSs will be extremely heterogeneous. Protecting the privacy of the users in such a situation requires flexible approaches. A single privacy protection mechanism is often insufficient. The contribution of this paper is two-fold. First we present LbSprint, a middleware architecture for location-based services which integrates different privacy mechanisms by means of the standard XACML language. The system administrator can configure and extend the set of such mechanisms. To the best of our knowledge, this is the first proposal of an architecture which integrates many privacy mechanisms in an extensible way. Secondly, we present practical optimizations which considerably improves the performance of the XACML policy evaluation process.
Managing Privacy in LBAC Systems	One of the main challenges for privacy-aware location-based systems is to strike a balance between privacy preferences set by users and location accuracy needed by location-based services (LBSs). To this end, two key requirements must be satisfied: the availability of techniques providing for different degrees of user location privacy and the possibility of quantifying such privacy degrees. To address the first requirement, we describe two obfuscation techniques. For the second requirement, we introduce the notion of relevance as the estimator for the degree of location obfuscation. This way, location obfuscation can be adjusted to comply with both user preferences and LBS accuracy requirements.
Privacy Rights Management for Privacy Compliance Systems	The worldwide growth of e-services has brought to the forefront the importance of citizen privacy management. Korba and Kenny proposed a privacy rights management system in order to support the privacy principles derived from EU Data Directive 95/46/EC of the European Parliament and the Council of 24 October 1995. In this paper, we extend their system by proposing a privacy rights management framework for entity modeling and expression. The proposed framework manages and monitors the use of personal information. In addition, it provides interoperable mechanisms to support privacy compliance systems.
Privacy-Preserving Two-Party K-Means Clustering via Secure Approximation	K-means clustering is a powerful and frequently used technique in data mining. However, privacy breaching is a serious problem if the k-means clustering is used without any security treatment, while privacy is a real concern in many practical applications. Recently, four privacy-preserving solutions based on cryptography have been proposed by different researchers. Unfortunately none of these four schemes can achieve both security and completeness with good efficiency. In this paper, we present a new scheme to overcome the problems occurred previously. Our scheme deals with data standardization in order to make the result more reasonable. We show that our scheme is secure and complete with good efficiency.
Research Issues of Privacy Access Control Model for Mobile Ad Hoc Healthcare Applications with XACML	Information privacy is usually concerned with the confidentiality of protected health information (PHI) such as electronic medical records (EMR). To meet the needs of highly mobile patients in healthcare scenarios, mobile devices such as personal digital assistants (PDAs) are being used for storing entire patient histories and physicals, research data collection forms, the physician's reference desk, current care plans, and drug orders. Thus, the information access control mechanism for mobile ad hoc healthcare applications must be embedded with privacy- enhancing technologies. This paper presents the research issues of developing a privacy access control model for supporting mobile ad hoc healthcare applications. This paper also shows how extensible Access Control Markup Language (XACML) can protect confidential EMR in such a setting.
Privacy in Content-Based Opportunistic Networks	In this paper, we present security primitives required to achieve privacy in content-based opportunistic networks. We define three privacy models adapted to content-based networking and detail what are the requirements that the security primitives have to achieve in order to fit in each of these models. We also propose an original approach based on multiple layer commutative encryption that features full privacy content-based networking.
Privacy Protection in Passive Network Monitoring: An Access Control Approach	"On the Internet, nobody knows you are a dog" according to the famous Pat Steiner cartoon in The New Yorker, which has been very frequently cited in order to emphasize the potential for anonymity and privacy that the Internet was supposed to offer. However, the reality seems to be rather different. Among the several threats to personal privacy caused by the emerging Information and Communication Technologies, activities related to passive network monitoring hold an outstanding position. This paper discusses from an access control point of view the issue of privacy protection regarding data originating from passive network monitoring. It proposes a semantic information model, along with the underlying enforcement framework, for the real-time determination of access control provisions as stem from the personal data protection legislation and depending on the particular characteristics of every request for monitoring data disclosure.
Privacy-enhanced SPKI access control on PKIX and its application to Web server	Access control using PKIX (Public Key Infrastructure with X.509) may cause a privacy problem. It is caused mainly by the fact that a server can know a client's ID. To solve this problem, we proposed a restricted anonymous access control scheme using SPKI (Simple Public Key Infrastructure). It can make a server provide service to an authorized client. It still has another problem: SPKI is not so popular as PKIX. PKIX has many efficient technologies such like SSL (Secure Socket Layer), but SPKI can't directly use these technologies. In this paper our implementation utilizes the slightest extension of PKIX, namely, we use an X.509 Certificate as an Authorization Certificate and PKIX technologies, i.e. SSL. Therefore, our approach can make some proposed SPKI schemes practical and useful. In this paper the proposed scheme is applied to access control of the Web server. The system demonstrates that it succeeds in adding privacy-enhanced access control to SSL mutual authentication. We also describe and discuss the details of implementations.
Use of cryptographic technologies for privacy protection of watermarks in Internet retails of digital contents	In this paper, we propose an implementation of secure watermarking protocol using cryptographic technologies for use in real-life Internet retail market of digital contents, in which there is no trust assumption between a customer and a digital content provider. The blind RSA decryption algorithm is used in our scheme to doubly lock the information by the public key of the content provider and the secret numbers of the customer separately. The privacy of watermark pattern is maintained, while the digital rights of the contents provider are protected. This is achieved by allowing the customer to choose a secret pattern of watermark combination unknown to the content provider. Consequently, the quality of the watermarked digital contents can be guaranteed. We show that the protocol is secure against any possible attacks from the customer and the content provider. Moreover, the dispute resolution process becomes mechanical.
A secure wireless LAN system retaining privacy	We propose a secure wireless LAN system for casual users at event sites or Hotspots who want safer and easier access to the networks. It protects users' privacy by creating separated SSL sessions for each user, while the WEP shares one encryption key among all users. In the proposed system, in order to access the Internet, a user shows "SPKI-based authorization ticket" in SSL client-authentication phase instead of an ordinary X.509 certificate. The SPKI-based authorization ticket proves that the user has appropriate rights from the system while not showing his/her ID. A user can also access the Internet in another way that the user does not register his/her ID in contrast with existing secure wireless LAN systems. The proposed system restricts usable protocols and prevents unauthorized user from attacking to the Internet. By hiding user IDs from gateways, a user can retain his/her privacy. Moreover, the proposed system can be easily installed without modifying existing wireless LANs.
PrecePt: a privacy-enhancing license management protocol for digital rights management	One of the major issues raised by digital rights management (DRM) systems concerns the protection of the user's privacy and anonymous consumption of content. However, most existing DRM systems do not support the protection of each user's personal information. This paper suggests a privacy-enhancing license management protocol, named PrecePt (privacy-enhancing license management protocol), which is a more powerful protocol to protect personal information in DRM. To protect the exposure of user identifier, this protocol uses temporary ID and token to guarantee anonymity. The proposed scheme also uses a session key form ECDH cryptography and public-key so that it can protect the revelation of personal information and user privacy.
Security and privacy technologies for distance education applications	While there has been considerable development of tools for distance education, there has been relatively little work focused on how to offer users security and privacy during learning activities. This paper focuses on how tool development can combine with security to provide a safe, efficient, and effective learning environment. We present a number of distance education applications developed in our lab and show how security and privacy may be integrated into these applications.
An image authentication scheme considering privacy - a first step towards surveillance camera authentication	In this paper, we propose an authentication scheme considering privacy aimed for JPEG images. A picture from a surveillance camera must be authenticated when submitted to a third party, such as a legal organization, courts and so on. On one hand, privacy of objects in the picture must be considered. Therefore, mosaic and masking must be performed to the picture if needed. Our scheme authenticate JPEG picture, where parts are processed by mosaic and masking. Our scheme uses Merkle tree and Sandhu tree and achieves small overhead size needed to authenticate the processed picture.
Using privacy policies to protect privacy in UBICOMP	With the increasing deployment of sensors, intelligent devices of all sizes, and wireless networking, ubiquitous computing environments are getting closer and closer to reality. Research in UBICOMP has focused on enabling technologies, such as networking, data management, security, and user interfaces (Bodupalli et al., 2003). However, privacy for UBICOMP has been a contentious issue and the privacy concerns that have been raised suggest that privacy may be the greatest barrier to the long-term success of UBICOMP (Hong et al., 2004). In this paper, we propose that privacy in UBICOMP can be managed using privacy policies. We propose a UBICOMP model for protecting privacy using privacy policies and derive the content of a UBICOMP privacy policy.
An agent architecture for e-services privacy policy compliance	The growth of the Internet has been accompanied by the growth of e-services (e.g. e-commerce, e-health). This proliferation of e-services and the increasing regulatory and legal requirements for personal privacy have fueled the need to protect the personal privacy of e-service users. Approaches are needed to ensure that providers of e-services comply with the privacy policies of service users. In this paper, we examine privacy legislation to derive requirements for privacy policy compliance systems. We then propose an agent-based architecture for a privacy policy compliance system that satisfies many of the requirements and discuss the strengths and weaknesses of our proposed architecture.
Privacy preserving Web-based questionnaire	This paper proposes a secure protocol for Web-based questionnaire that preserves the privacy of responders and ensures the robustness. The proposed protocol is based on secure electronic voting protocol proposed by Cramer et al. confidentiality and efficiency, which are common requirements for both applications. This paper points out an issue particular in the secure questionnaire, that is, a requirement to deal with a multiple-choice question, and shows that the communication overhead grows exponentially with the number of choices n. To address the issue, the proposed protocol reduces the cost from ╬ÿ(2<sup>n</sup>) to ╬ÿ(n). The performance based on the experimental implementation is also shown.
Identity-based ring signcryption schemes: cryptographic primitives for preserving privacy and authenticity in the ubiquitous world	In this paper, we present a new concept called an identity based ring signcryption scheme (IDRSC,). We argue that this is an important cryptographic primitive that must be used to protect privacy and authenticity of a collection of users who are connected through an ad-hoc network, such as Bluetooth. We also present an efficient IDRSC scheme based on bilinear pairing. As a regular signcryption scheme, our scheme combines the functionality of signature and encryption schemes. However, the idea is to have an identity based system. In our scheme, a user can anonymously sign-crypts a message on behalf of the group. We show that our scheme outperforms a traditional identity based scheme, that is obtained by a standard sign-then-encrypt mechanism, in terms of the length of the ciphertext. We also provide a formal proof of our scheme with the chosen cipher-text security under the decisional bilinear Diffie-Hellman assumption, which is believed to be intractable.
A scheme for testing privacy state in pervasive sensor networks	More and more sensor networks will be deployed in the place where people are living, studying, and working. These sensor networks bring us the convenience of accessing information anytime and anywhere, whereas put our voice, motion, or even body temperature under surveillance. Under the circumstances of pervasively deployed sensor networks, people will have a dynamic concern about their privacy. At the same time, sensors will become invisible or should be hidden due to the privacy of themselves. This paper discusses privacy issues in pervasive sensor networks and proposes a general scheme for people in the environment of pervasive sensor networks, so that they can be aware of whether they should be alert on their privacy activities. Based on the protocol of secure two-party point-inclusion problem, the scheme has the characteristics of generality and confidentiality.
Privacy-enhanced Internet storage	One of the main important uses of Internet is its ability to connect people through the use of email or Internet storage. However, it is often desirable to limit the use of email or Internet storage clue to organization's restriction, avoiding spams, etc. In this paper, we propose cryptographic schemes that can be used to stop unwanted messages to be stored in the Internet server. We refer this technique as privacy enhancement for Internet storage, since the Internet server will not learn any information directed to its users, other than performing its task to deliver or stop the messages. Firstly, we describe a notion of non-interactive publicly verifiable 1-out-of-n encryption by proposing a model together with its security requirements. Then, we extend this notion to a publicly verifiable ring-to-1-out-of-n encryption, that provides sender anonymity. We note that the previously known interactive versions of the publicly verifiable 1-out-of-n encryption cannot be used to construct publicly verifiable ring-to-1-out-of-n encryption.
Agri-Food Traceability Management using a RFID System with Privacy Protection	In this paper an agri-food traceability system based on public key cryptography and Radio Frequency Identification (RFID) technology is proposed. In order to guarantee safety in food, an efficient tracking and tracing system is required. RFID devices allow recording all useful information for traceability directly on the commodity. The security issues are discussed and two different methods based on public cryptography are proposed and evaluated. The first algorithm uses a nested RSA based structure to improve security, while the second also provides authenticity of data. An experimental analysis demonstrated that the proposed system is well suitable on PDAs too.
Figurative Privacy Control of SIP-Based Narrowcasting	In traditional conferencing systems, participants have little or no privacy, as their voices are by default shared with all others in a session. Such systems cannot offer participants the options of muting and deafening other members. The concept of narrowcasting can be applied to make these kinds of filters available in multimedia conferencing systems. Our system treats media sinks (in the simplest case, listeners) as full citizens, peers of the media sources (con- versants' voices), and we defined therefore duals of mute & select : deafen & attend, which respectively block a sink or focus on it to the exclusion of others. In this article, we describe our prototyped system, which uses existing standard Session Initiation Protocol (SIP) methods to control fine-grained narrowcasting sessions. The design considers the policy configured by the participants and provides a policy evaluation algorithm for media mixing and delivery. We have integrated a "virtual reality"-style interface with this SIP backend to display and control articulated narrowcasting with figurative avatars.
A Secure Revised Simplex Algorithm for Privacy-Preserving Linear Programming	Linear programming is one of the most widely applied solutions to optimization problems. This paper presents a privacy-preserving solution to linear programming for two parties when the cost, or objective, function is known only to one party, and the constraint equations are known only to the other party. An algorithm based on revised simplex is given that ensures that neither party gains access to the otherpsilas private information. While this has been proposed before, our solution is significantly more efficient for the given data distribution. This enables collaboration among companies in many domains, enhancing efficiency while maintaining competitiveness.
Privacy-Aware Routing Approach for Mobile Applications	The advances in wireless communication and mobile computing make new types of applications possible. In this context, userspsila navigation becomes one of the most popular applications. The existing approaches to compute a route are either server- or client-based. The first one computes the route on a server and sends back the result to the mobile device. The second one computes it directly on the mobile device. Both approaches are related to some pros and cons.In this paper, we propose a new combined approach supporting the privacy of the user while maintaining the data accuracy at the same time.
Negotiated revealing of traders' credentials in e-marketplaces: dealing with trust and privacy issues	The rise of e-marketplaces on the Internet is going to bring a broad new set of business opportunities to enterprises and customers at a fraction of the physical-world costs. However, to be really successful, these e-marketplaces must be open, trusted, fair and transparent. They must be able to convey on-line the same feeling of trust, security and privacy that traditional marketplaces do. This has implication on three critical aspects: the decisions to be made about membership of traders; their admissibility to negotiations; the controls over the negotiation processes. In this paper we discuss trust and privacy problems related to admittance to negotiation within e-marketplaces and we introduce a novel method for automating the process consistently with traders' privacy requirements
A Novel Solution for Protecting Privacy in Ad Hoc Network	Communicating nodes in a wireless and mobile ad hoc network usually seek the help of other intermediate nodes to get communicate channels. In such an open environment, malicious intermediate nodes can be a threat to the security and/or anonymity of the exchanged data between the mobile nodes. The main purposes of this work are to define more strict requirements on the anonymity and security properties of the routing protocol in ad hoc network, and propose a solution of achieving the goal. Our solution includes a mechanism to establish a trusted relation between all neighboring nodes and a secure routing protocol of protecting privacy. The routing protocol based on the mechanism can avoid untrustworthy nodes during his route discovery process and resist the attack of DoS. We present our scheme, and report on its performance using an extensive set of simulation set of experiments using GloMoSim simulator. Our results indicate clearly that protecting privacy can be achieved in mobile ad hoc network.
A Study on User's Perception in E-learning Security and Privacy Issues	Researchers have proven with both theoretical and empirical studies that technologies could enhance learning. Meanwhile, technologies could also create barriers to the latter. Particularly, when the use of technologies causes security and privacy concerns, E-learning becomes less fruitful as the participants are too afraid to be exposed by what has been provided to help them learn in the first place. This paper presents a study on user's perception in using E-learning technologies and the relevant issues. The major contribution of this paper is the awareness-raising of security and privacy issues, which are often overlooked in the research efforts that implicate user tracking and personal data usage for instructional purposes.
Evaluation on security and privacy of Web-based learning systems	Web-based learning systems are becoming popular in the recent years. Many courses and lectures are now conducted online. Similar to other Web-based applications, security and privacy of Web-based learning systems should not be overlooked. We evaluate the security and privacy of general Web-based learning systems. We address the security and privacy requirements specific to them. Recommendations on design and implementation of a secure Web-based learning system are also presented. In particular, we have evaluated the security services of two popular Web-based learning tools.
Privacy issues of a smart space for learning	Personalized learning solutions typically involve learner profiles with sensitive information and activities that might breach learner's privacy, such as user profiling. In this paper we discuss privacy aspects of a smart space for learning that is being developed in the EU 1ST ELENA project. The paper presents threats and requirements, and describes several privacy-enhancing technology (PET) based solutions.
Quantum Security and Privacy	This chapter contains sections titled: <br> Introduction <br> Quantum Key Distribution <br> Private Communication over the Quantum Channel <br> Quantum Cryptographic Primitives <br> Further Reading
Biometrics Security Scheme for Privacy Protection	Recently much attention is paid to privacy issue in biometrics. In this paper, biometrics security technique using wavelet based watermarking is proposed. We present two kinds of methods that increase privacy protection level. First method is to embed ID watermark data to biometric image like fingerprint, face for backtracking when image missing. Second, as multi bio watermarking, fingerprint feature data are embedded to face image for hiding private biometric information. The proposed method for bio watermarking is based on the wavelet transform and minimizes recognition performance loss owing to watermark data embedding.
Privacy-Aware Object Representation for Surveillance Systems	Real-time object tracking, feature assessment and classification based on video are an enabling technology for improving situation awareness of human operators as well as for automated recognition of critical situations. To bridge the gap between video signal-processing output and spatio-temporal analysis of object behavior at the semantic level, a generic and sensor-independent object representation is necessary. However, in the case of public and corporate video surveillance, centralized storage of aggregated data leads to privacy violations. This article explains how a centralized object representation, complying with the Fair Information Practice Principles (FIP) privacy constraints, can be implemented for a video surveillance system.
TrustCAM: Security and Privacy-Protection for an Embedded Smart Camera Based on Trusted Computing	Security and privacy protection are critical issues for public acceptance of camera networks. Smart cameras, with onboard image processing, can be used to identify and remove privacy sensitive image regions. Existing approaches, however, only address isolated aspects without considering the integration with established security technologies and the underlying platform. This work tries to fill this gap and presents TrustCAM, a security-enhanced smart camera. Based on Trusted Computing, we realize integrity protection, authenticity and confidentiality of image data. Multiple levels of privacy protection, together with access control, are supported. Impact on overall system performance is evaluated on a real prototype implementation.
A track-based human movement analysis and privacy protection system adaptive to environmental contexts	This paper presents a track-based system for human movement analysis and privacy protection. Our system is adaptive to environmental contexts such as illumination variations, complex moving cast shadows, different camera perspectives, and diverse sue scenarios. Most of outdoor surveillance systems have been targeting at specific environmental situation: i.e., specific time, place, and activity scenarios. We address that more general human movement analysis systems should be able to handle multiple heterogeneous situations in an adaptive manner. We introduce the concept of "spatio-temporal personal boundary" to represent different grouping patterns of human tracks, and we incorporate the concept with various site models. Experimental evaluations with extensive outdoor data show our system's robustness to environmental changes and effectiveness to properly handle various environmental contexts.
Object-Video Streams for Preserving Privacy in Video Surveillance	This paper presents a framework for preserving privacy in video surveillance. Raw video is decomposed into a background and one or more object-video streams. Object-video streams can be combined to render the scene in a variety of ways: (1) The original video can be reconstructed from object-video streams without any data loss; (2) individuals in the scene can be represented as blobs, obscuring their identities; (3) foreground objects can be color coded to convey subtle scene information to the operator, again without revealing the identities of the individuals present in the scene; (4) the scene can be partially rendered, i.e., revealing the identities of some individuals, while preserving the anonymity of others. We evaluate our approach in a virtual train station environment populated by autonomous, lifelike virtual pedestrians.
Privacy-Enabled Object Tracking in Video Sequences Using Compressive Sensing	In a typical video analysis framework, video sequences are decoded and reconstructed in the pixel domain before being processed for high level tasks such as classification or detection.Nevertheless, in some application scenarios, it might be of interest to complete these analysis tasks without disclosing sensitive data, e.g. the identity of people captured by surveillance cameras. In this paper we propose a new coding scheme suitable for video surveillance applications that allows tracking of video objects without the need to reconstruct the sequence,thus enabling privacy protection. By taking advantage of recent findings in the compressive sensing literature, we encode a video sequence with a limited number of pseudo-random projections of each frame. At the decoder, we exploit the sparsity that characterizes background subtracted images in order to recover the location of the foreground object. We also leverage the prior knowledge about the estimated location of the object, which is predicted by means of a particle filter, to improve the recovery of the foreground object location. The proposed framework enables privacy, in the sense it is impossible to reconstruct the original video content from the encoded random projections alone, as well as secrecy, since decoding is prevented if the seed used to generate the random projections is not available.
Privacy Protection in Video Surveillance Systems Using Scalable Video Coding	Thanks to high-speed Internet access and feature-rich mobile devices, the demand for ubiquitous and secure surveillance systems has increased. In this paper, we propose a privacy-protected video surveillance system that makes use of scalable video coding (SVC). SVC can be used to fulfill the requirement of omnipresence. Further, to address privacy concerns, we detect face regions and subsequently scramble these regions-of-interest (ROIs) in the compressed domain. To demonstrate the feasibility of the proposed video surveillance system, simulation results are provided. The results show that our system is able to provide a good level of security, while offering access to surveillance video content in heterogeneous usage environments.
Privacy Adaptation for Secured Associations in a Social Cloud	Mobile social networks' (MSN) diverse security concerns have immensely compromised users' personal details leaving them vulnerable to cybercrimes. This paper proposes an adaptive privacy architecture which provides content, identity and location privacy against disclosure of information that the user intends to keep private. The architecture implements multiple servers with the global social graph cached in the front-end server and sub-graph of each user across several servers. Content privacy is enforced through a role based access control model (RBAC) that relies primarily on the relationship and the trust between the users. Identity privacy is preserved through pseudonym generation. Location obfuscation is performed to safeguard the mobile user's location information. This ensures that the privilege and control is given to the user rather than a central authority namely social network service provider as suggested in the existing systems.
Task Independent Privacy Preserving Data Mining on Medical Dataset	In this era of data digitization, data mining is essential for getting valuable information. However, privacy and security issues remain major barriers during this process. Since medical records are related to human subjects, privacy protection is taken more seriously than other data mining tasks. As required by the Health Insurance Portability and Accountability Act (HIPAA), it is necessary to protect the privacy of patients and ensure the security of the medical data. The privacy issues are handled by many algorithms and techniques in literature. But, always there exists a trade off between privacy and information. So, to preserve the accuracy of results and to reduce loss of information, task based privacy preserving techniques are developed. Our aim is to implement a task independent technique which preserves the information, privacy and utility of the data. Our algorithm is applied on the original data table to alter only the sensitive raw data before applying any mining methods. The experimental results prove that our simple technique yields excellent results as if worked on the original data set.
Enhancing privacy and security in multi hop wireless networks against traffic analysis using network codings	Wireless Access Networks, such as Wi-Fi, have been widely deployed due to their convenience, portability, and low cost. However, they still suffer inherent shortcomings such as limited radio coverage, poor system reliability, and lack of security and privacy. Privacy threat is one of the critical issues in Multi hop Wireless Networks, where attacks such as traffic analysis and flow tracing can be easily launched by a malicious adversary due to the open wireless medium. Network coding has the potential to thwart these attacks since the coding/mixing operation is encouraged at intermediate nodes. In this paper, we are giving the privacy and security in Multi hop Wireless Networks using Network Codings with the help of traffic analysis. We have shown the event reporting in wireless sensor networks, where flow tracing can help attackers to identify the location of concerned events, E.g., the appearance of an endangered animal in a monitored area, and then take subsequent actions to capture or kill the animals.
A pattern based framework for privacy preservation through association rule mining	Data mining extracts novel and useful knowledge from large repositories of data and has become an effective analysis and decision means in corporation. The sharing of data for data mining can bring a lot of advantages for research and business collaboration. The misuse of these techniques may lead to the disclosure of sensitive information. However, large repositories of data contain private data and sensitive rules that must be protected before published. Motivated by the multiple conflicting requirements of data sharing, privacy preserving and knowledge discovery, and privacy preserving data mining has become a research hotspot in data mining and database security fields. Researchers have recently made efforts at hiding sensitive association rules. This paper presents a novel based approach that strategically modifies a few transactions in the database. It modifies support or confidence values for hiding sensitive rules without producing many side effects. Nevertheless, undesired side effects such as nonsensitive rules falsely hidden and spurious rules falsely generated, may be produced in the rule hiding process.
Enhancing privacy and security in Multi Hop Wireless Networks against traffic analysis using network codings	Wireless Access Networks, such as Wi-Fi, have been widely deployed due to their convenience, portability, and low cost. However, they still suffer inherent shortcomings such as limited radio coverage, poor system reliability, and lack of security and privacy. Privacy threat is one of the critical issues in Multi hop Wireless Networks, where attacks such as traffic analysis and flow tracing can be easily launched by a malicious adversary due to the open wireless medium. Network coding has the potential to thwart these attacks since the coding/mixing operation is encouraged at intermediate nodes. In this paper, we are giving the privacy and security in Multi hop Wireless Networks using Network Codings with the help of traffic analysis. We have shown the event reporting in wireless sensor networks, where flow tracing can help attackers to identify the location of concerned events, E.g., the appearance of an endangered animal in a monitored area, and then take subsequent actions to capture or kill the animals.
A Privacy Service for Locator/Identifier-Split Architectures Based on Mobile IP Mechanisms	Concepts for a next generation Internet architecture quite often propose to decouple identifiers from locators. The so-called locator/identifier-split solves several problematic issues of today's Internet architecture. At the same time, however, a user's location is exposed within the whole network and any participant can be traced. Privacy considerations, therefore, need to be a key design element for any locator/identifier-split architecture. In this paper, we introduce a novel privacy service for locator/identifier-split architectures. The service is following Mobile IP's proxy idea and introduces mechanisms to overcome the unwanted side effects of such an approach. The concept decouples the privacy service from the network and leaves it open to the customer whether he wants to subscribe or not.
A Privacy-Enhanced M-Transactions Architecture for Awareness and Trust	Given the characteristics of the mobile phone market, the development of RFID technology in mobile phones (NFC) could grow quickly and importantly. This paper considers the possible impact of this evolution in term of privacy, and after a few examples, proposes a survey of technology and products of the PC-world intending to offer good privacy characteristics. Then it describes a model and technical architecture, which aims at enhancing privacy in many applications from the vast family of access control/right control applications.
GlobaliD - Privacy Concerns on a Federated Identity Provider Associated with the Users' National Citizen's Card	Personal information sharing is one of the most common online activities. Most of the times we feel forced to give up about some privacy in order to share a piece of information with others. This paper reflects on the anonymity, integrity, privacy of users' personal information and it's scattering across the Web by taking an approach to digital identity management concept. Consequently it also reflects on the users' information certification and accountability. In this paper we purpose a Federated Identity Management solution for the Web to decrease the privacy issues and avoid the lost of anonymity that may occur when users exchange their particular information within web contexts. We will use a collection of publicly available strong identification mechanisms, such as the users (Portuguese) National Electronic Citizen Identity Card, and a Federated Identity initiative to create the GlobaliD, a Federated Identity Provider to address the previously mentioned reflections. Our aim with the development of GlobaliD is to take a step further in the digital identity management and therefore in the privacy and anonymity safety of the users identity Online by making it more versatile, responsible, trustworthy, integrity and privacy safe, anonym and thus secure.
Ad Hoc Privacy Management in Ubiquitous Computing Environments	Privacy in ubiquitous computing is often discussed on a technical level with a focus on cryptography and anonymization. On the other side it is equally important to concentrate on user side aspects of privacy control, i.e., to enable users of ubicomp applications to practice privacy dynamically and in an intuitive way. In our work we review previous approaches on user side management of private information in smart environments and motive a new ad hoc based, semi-automatic privacy control. We present a privacy focused, data mining powered interaction model with ubicomp services and provide a prototype environment for evaluating this model. This environment can be used to perform and capture privacy related service interaction in a user study with real users as well as in a simulation with agents simulating users and their privacy related service interaction. Finally we show results of a first simulation which initially tests the proposed interaction model in the prototype environment.
Personalized Systems Need Adaptable Privacy Statements! How to Make Privacy-related Legal Aspects Usable and Retraceable	This paper presents a solution proposal for the design of usable privacy-enhancing practices in personalization-pertinent systems. In particular, the focus is set on two issues: (i) the design of an Adaptable Privacy Statement that complies with well-known privacy principles and legal demands, and (ii) the description of how to link such an adaptable statement with user interface functions that enhance the comprehension and control of the privacy-critical features of the system. Our proposal is part of our User-centric Privacy Framework, an integrative methodology that considers the main aspects of the three interrelated and highly relevant privacy points of view: legal compliance, technical feasibility, and user-centric design. Exemplarily, we present the applicability of our proposal by focusing on the field of Self-Directed Work-Integrated Learning systems.
Efficient Methods for Privacy Preserving Face Detection	Bob offers a face-detection web service where clients can submit their images for analysis. Alice would very much like to use the service, but is reluctant to reveal the content of her images to Bob. Bob, for his part, is reluctant to release his face detector, as he spent a lot of time, energy and money constructing it. Secure Multi- Party computations use cryptographic tools to solve this problem without leaking any information. Unfortunately, these methods are slow to compute and we introduce a couple of machine learning techniques that allow the parties to solve the problem while leaking a controlled amount of information. The first method is an information-bottleneck variant of AdaBoost that lets Bob find a subset of features that are enough for classifying an image patch, but not enough to actually reconstruct it. The second machine learning technique is active learning that allows Alice to construct an online classifier, based on a small number of calls to Bob's face detector. She can then use her online classifier as a fast rejector before using a cryptographically secure classifier on the remaining image patches.
Privacy Preservation Na├»ve Bayes Classification for a Vertically Distribution Scenario Using Trusted Third Party	Privacy preservation is an important area of research in recent years. Due to the advancement of technology, enormous digital data is being generated at various locations. There are many applications such as market basket analysis, medical research etc where the global results computation places a significant role. The collaborating parties are generally interested in finding the global results for their integrated data without revealing the personal details to the other party. There are few proposals which talk about privacy preservation of vertical partitioned distributed database. Our proposed novel approach preserves the privacy of the distributed databases, using Nai╠êve Bayes Classification along with the trusted third party and secure multiparty computation.
Preservation of Data Privacy Using PCA Based Transformation	Privacy-preserving data mining (PPDM) is one of the recent trends in privacy and security research. Recent advances in data collection, data dissemination and related technologies have inaugurated a new era of research where existing data mining algorithms should be reconsidered from a different point of view, this of privacy preservation. This paper explores all the aspects of privacy issues in datamining, especially related with clustering, and provides a technique for privacy preserving clustering with a hypothetical banking scenario. Here we propose a model for clustering horizontally partitioned or centralized data sets using a simple PCA based transformation approach. The proposed PPC method has been implemented using Matlab and evaluated using synthetic datasets. The proposed privacy preserving transformation preserved the nature of the data even in the transformed form. The classification accuracy while using the transformed data is almost equal to that of the original dataset.
Private Information Transmission on the Consumer Generated Media: Information Privacy in the Japanese Context	This study examined private information transmissions on CGM/UGM websites from the perspective of the Japanese sense of information privacy. The characteristics of Japanese private information transmission on the CGM are described and discussed.
Social Network Privacy for Attribute Disclosure Attacks	Increasing research on social networks stresses the urgency for producing effective means of ensuring user privacy. Represented ubiquitously as graphs, social networks have a myriad of recently developed techniques to prevent identity disclosure, but the equally important attribute disclosure attacks have been neglected. To address this gap, we introduce an approach to anonymize social networks that have labeled nodes, ╬▒-proximity, which requires that the label distribution in every neighbourhood of the graph be close to that throughout the entire network. We present an effective greedy algorithm to achieve ╬▒-proximity and experimentally validate the quality of the solutions it derives.
Processes View Modeling of Identity-related Privacy Business Interoperability: Considering User-Supremacy Federated Identity Technical Model and Identity Contract Negotiation	Federated identity is a distributed system that is deployed across multiple parties. Service providers still hold the absolute power over people identities. So, identity-related privacy is considered as a mean to entrench subjects' control over identities and foster trust among multiple involved parties. Thus, identity-related privacy should interoperable, which can be guaranteed through the capture of requirements from different polices related to identity. In this article, we provide and explain a BPMN processes view of the requirements allowing them to be ready to-implement, clear, easy to-understand by each party wishing to collaborate within or across federated identity systems. We highlight that present-day practitioners should be able to translate requirements with user-supremacy federated identity technical model concepts into a set of rules and take into consideration details of identity contract negotiation in order to successfully deliver processes view. BPMN collaboration and choreography diagrams are used to describe seven processes and a sub-process, which would provide a useful way to gain alignment between requirements and IT.
PROTOSS: A Run Time Tool for Detecting Privacy Violations in Online Social Networks	As online social networks are becoming part of both social and work life, preserving privacy of their users is becoming tremendously difficult. While these social networks are promising privacy through privacy agreements, everyday new privacy leakages are emerging. Ideally, online social networks should be able to manage and maintain their agreements through well-founded methods. However, the dynamic nature of the online social networks is making it difficult to keep private information contained. We have developed PROTOSS, a run time tool for detecting privacy leakages in online social networks. PROTOSS captures relations among users, their privacy agreements with an online social network operator, and domain-based inference rules. It then uses model checking to detect if an online social network will leak private information.
Privacy Preservation by k-Anonymization of Weighted Social Networks	Privacy preserving analysis of a social network aims at a better understanding of the network and its behavior, while at the same time protecting the privacy of its individuals. We propose an anonymization method for weighted graphs, i.e., for social networks where the strengths of links are important. This is in contrast with many previous studies which only consider unweighted graphs. Weights can be essential for social network analysis, but they pose new challenges to privacy preserving network analysis. In this paper, we mainly consider prevention of identity disclosure, but we also touch on edge and edge weight disclosure in weighted graphs. We propose a method that provides k-anonymity of nodes against attacks where the adversary has information about the structure of the network, including its edge weights. The method is efficient, and it has been evaluated in terms of privacy and utility on real word datasets.
A Guide to Differential Privacy Theory in Social Network Analysis	Privacy of social network data is a growing concern which threatens to limit access to this valuable data source. Analysis of the graph structure of social networks can provide valuable information for revenue generation and social science research, but unfortunately, ensuring this analysis does not violate individual privacy is difficult. Simply anonymizing graphs or even releasing only aggregate results of analysis may not provide sufficient protection. Differential privacy is an alternative privacy model, popular in data-mining over tabular data, which uses noise to obscure individuals' contributions to aggregate results and offers a very strong mathematical guarantee that individuals' presence in the data-set is hidden. Analyses that were previously vulnerable to identification of individuals and extraction of private data may be safely released under differential-privacy guarantees. We review two existing standards for adapting differential privacy to network data and analyse the feasibility of several common social-network analysis techniques under these standards. Additionally, we propose out-link privacy, a novel standard for differential privacy over network data, and introduce two powerful out-link private algorithms for common network analysis techniques that were infeasible to privatize under previous differential privacy standards.
An Analysis of Query Forwarding Strategies for Secure and Privacy-Preserving Social Networks	Decentralized Online Social Networks (OSNs) attempt to improve user privacy and security. One example is Vegas, a Peer-to-Peer (P2P) OSN which attempts to bring its users back into complete control of the data they share. Due to its decentralized characteristics, P2P OSNs cannot support social search functions in the same way users of centralized OSNs like Facebook are familiar with. Well-known and efficient P2P search algorithms cannot always be applied as knowledge about the structure of the social graph can be very limited. In this paper, we present an in-depth analysis of forwarding strategies to enable social search for secure and privacy preserving P2P OSNs. We compare well-known metrics from the field of unstructured P2P networks with metrics from the area of social network analysis and evaluate their applicability for P2P OSNs like Vegas. We simulate all metrics on four distinct datasets which were generated artificially from the ER- and the BA-model and from crawling data of Lastfm and Flickr. Our evaluation shows that prioritization based on knowledge from the ego network often yields the best results.
Privacy algorithm for cylindrical holographic weapons surveillance system	A novel personnel surveillance system has been developed to detect and identify threatening objects, which are undetectable by metal detectors, concealed on the human body. This new system can detect threats which are fabricated with plastic, liquid, metal, or ceramic. It uses millimeter-wave array technology and a cylindrical holographic imaging algorithm to provide full-body, 360-degree coverage of a person in near real-time. This system is ideally suited for mass transportation centers such as airport checkpoints that require high throughput rates and full coverage. Research and development efforts are underway to produce a privacy algorithm that removes the human features from the images while identifying the potential threats. This algorithm locates and segments the threats and places them on a wire-frame humanoid representation. The research areas for this algorithm development include artificial neural networks, image processing, edge detection, and dielectric measurements. This system is operational and results from this test and the privacy algorithm will be discussed in this paper.
Privacy issues on biometric systems	In the XXIst century, there is a strong interest on privacy issues. Technology permits obtaining personal information without individuals' consent, computers make it feasible to share and process this information and this can bring about damaging implications. In some sense, biometric information is personal information, so it is important to be conscious about what is true and what is false when some people claim that biometrics is an attempt to impinge upon an individual' privacy. In this paper, key points related to this matter are dealt with.
Industry and government DBMS security and privacy needs-a comparison	An overview of the database security requirements for both the private and government sectors is presented. It is concluded that both sectors require database management systems (DBMSs) capable of supporting secrecy and integrity policies. However, the government counts secrecy as the more important consideration because its data affects the lives and privacy of every citizen. The private sector considers integrity considerations more important because corrupt data undermines corporate strategies. The primary difference between the two sectors is that a global policy for secrecy in the government sector was well-established before computers came along, and that a similar global integrity policy has never truly existed. In the private sector, individual integrity policies for corporations are a fact of life. Corporate secrecy policies are enforced through physical security measures. The difference between the two sectors is one of scale, not requirements
Privacy enhanced electronic mail	The progress of work at University College of London in implementing a prototype model of a privacy-enhanced messaging (PEM) system is reported. The design of model is specified by the DARPANET IAB Privacy Task Force RFC 1040. The model is one which provides privacy, integrity, and authentication of messages transmitted in a typical electronic-mail system. The design and implementation experience of the prototype model is set out and several potential refinements to the model are suggested for future development
Privacy and Biometric Technology	This chapter contains sections titled: The Norms, Values, and Expectations of Privacy, Privacy, Normative Perceptions of Privacy, Personal Information as Property, Privacy as Social Freedom
Database nation: the death of privacy in the 21st century [Reviews]	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00948913.png" border="0">
Evolution of privacy-preserving data publishing	To achieve privacy protection better in data publishing, data must be sanitized before release. Research on protecting individual privacy and data confidentiality has received contributions from many fields. In order to grasp the development of privacy preserving data publishing, we discussed the evolution of this theme, focused on privacy mechanism, data utility and its metrics. The privacy mechanism, such as k-anonymity, l-diversity and t-closeness, provides formal safety guarantees and data utility preserve useful information while publishing data. Meantime, we discussed social network privacy and location based service. Finally, we made a conclusion with respect to privacy preserving data publishing, and given further research directions.
Privacy and Security Problems in RFID	Radio Frequency Identification (RFID) is noticeably shifting business methodologies towards more automated and ubiquitous techniques. The new amendment in the ISO 18000-6 RFID standard and successive adaptation of Gen 2 from Electronic Product Code (EPC) is driving research activities for secure and trustworthy systems around the globe. Data security and communication links are still vulnerable and there are certain loopholes that should be addressed to add this valuable communication for personal data processing to accounting systems. This paper investigates the ISO 18000-6 Type C and Gen2 standards and we will point out the security drawbacks and limitations of the existing air interface that should be addressed for widespread of this ubiquitous technology.
A New Privacy-Enhanced Authentication Scheme for Wireless Mesh Networks	In wireless mesh networks (WMNs), preserving users' privacy is an important but contradictory to security issue. To provide a new solution to the challenge, we propose an anonymous authentication scheme based on CPK and blind signature in the elliptic curve domain. The proposed scheme can not only provide fast and explicit mutual authentication between nodes, but also effectively preserve mesh users' privacy. The analyse result indicates that the proposed scheme successfully satisfies both security and privacy.
Towards wider cloud service applicability by security, privacy and trust measurements	Today large amounts of security and privacy-critical data are transferred, processed and stored in external cloud services. However, with many offerings, you need to be either an ignoramus or a daredevil to surrender such data. For the cautious, trustworthy, sufficient and credible evidence of the actual security, privacy and trust level is a prerequisite for considering cloud services for critical applications. We present results from an expert interview study investigating the needs of security, privacy and trust measurement in the cloud. Furthermore, research directions for metrics development are discussed based on the interviews.
Error tolerance and privacy enhancement in matching fingerprint templates	Biometric systems attempt to solve a matching problem through live measurements of human body features. However, two obstacles hinder the wider applications of biometrics: non-reproducibility and privacy concerns. In this paper we study fingerprint minutiae-based templates. Our testing results show templates can still match under some step-wised modification and therefore the biometric system can tolerate certain amounts of errors. Our testing results also show that partial fingerprint templates can still match successfully. Therefore, the security and privacy of fingerprint can be protected with these techniques.
Centralized Authentication System for Location Privacy Protection and Low Operational Cost of Large Scale WLAN Roaming	Recent proliferation of Wireless LAN devices has created a high demand for roaming systems that enable network connections at visited institutions using users' home accounts. We have been operating eduroam, the roaming system for international research and educational institutions. However, if the roaming system is to be introduced into more than a thousand of research and educational institutions in Japan, some operational and management difficulties arise at each institution as well as at the eduroam national operational body. In this paper, we propose a centralized delegate authentication system using pseudonymous ID for reducing operational cost and for protecting user's location privacy. A prototype system using Shibboleth is also presented.
Supporting Network Formation through Mining under Privacy Constraints	Single professionals and small companies come together and form virtual communities to compete with global players. In these collaboration networks, the actual business partners are discovered and alliances formed on demand. However, it is impossible for single members to keep track of the dynamics in large-scale networks. With the wide adoption of service-oriented architectures (SOA), interactions between partners have become observable. Monitoring collaborations enables the inference of social relations and the identification of successful partner compositions. Measuring the quality of social relations, such as the degree of trust based on the success of past interactions, are a powerful means to support the formation of alliances. However, by applying monitoring, also privacy concerns arise. In this paper we deal with concepts and tools to support group formations. We consider the trade-off between the benefits of sharing personal profiles and accounting for privacy concerns of the individual network members.
A Proposal of Privacy Management Architecture	Recent use of web services has spread over a wide variety of application areas. Users are requested to disclose private information for the use of web services. Such a disclosure is facing the risk of leaking private information. Privacy leakage is becoming one of the serious social problems. For the better use of web services, it is necessary to provide a reliable scheme for privacy management. There are many cases of private information leakage which are caused by user's misuse or unintended disclosure. In order to prevent users from unnecessarily leaking of private information, the users will be asked to clearly define information disclosure criteria. This paper discusses a privacy management architecture to prevent users from unnecessary leaking of private information. We demonstrate a prototype implementation how the proposed architecture effectively works in the initial setting of web services.
Toward Better Recommender System by Collaborative Computation with Privacy Preserved	Recommender systems are best known for the usage on E-commerce websites, with the aim of helping customers in the decision making and product selection process by providing a list of recommended items. Since most of the recommender systems of E-commerce websites suffer from data scarcity, joining recommender system databases is said to improve the prediction and recommendation results. However, there will be a risk of revealing the raw customer-product information by sharing the databases between websites. In this research, a new scenario of collaborative computation is proposed. A very preliminary result has shown the advantage of joining recommender systems. In addition, private user raw data is preserved while doing collaborative computation for better recommendations.
User Centric Privacy in Mobile Communication Scenarios	One common assumption when defining location privacy metrics is that one is dealing with attackers whose objective is to re-identify an individual out of an anonymized data set. However, today's communication scenarios are more diverse. For instance, there are several entities involved in mobile location sharing between individuals. Hence, in a communication relation with a service provider (e.g. SNS or network infrastructure) or with social contacts, an anonymity approach seems inadequate. Between each user and every single entity involved there is some level of trust and the identities are already known, at least to some extent. Hence, taking an anonymity approach for communication relations to peers or service providers (e.g. SNS or network infrastructure) seems to be inadequate. Therefore, we present an attacker model and propose a user-centric privacy metric to allow a user to uncover the extent of information disclosure and to evaluate autonomously his privacy level in a communication relation with semi-trusted listener groups. The goal of such a metric is to enable an individual to estimate the privacy loss caused by disclosing location information in a specific communication scenario and thus enabling the user to make informed choices, e.g. choose the right protection mechanism.
PIPER: A Framework for Exploring the Privacy Implications of Pervasive Computing Applications in Their Physical Environments	Pervasive computing presents profound privacy risks for end users because its capabilities to monitor, control, and interact with the physical world. As a first step to support early evaluation of potential privacy violations, we introduce PIPER, a framework for the systematic modeling, analysis, and exploration of Privacy Implications in PERvasive computing systems and their physical environments. UML/OCL is used to model important structures and behaviors of these systems as well as data flow properties and privacy requirements. This framework facilitates consideration and explicit specification of the effects of actions in the physical environment and the tracing of data flow through both cyber and physical components of the system. Using this framework, privacy analysts and software engineers can communicate more objectively about privacy-related issues, identify faults in application logic, and examine the impact that changes to either applications or physical environments have on personal privacy in pervasive systems.
Securing authentication and privacy in ad hoc partitioned networks	Security is a major concern in the design of modern communication systems. It is particularly challenging with wireless networks such as ad hoc networks. Ad hoc Networks are dynamically reconfigured. For this reason they are vulnerable to several major security threats. This paper focuses on authentication and privacy in partitioned ad hoc networks. We consider the problem of managing revocation lists and discuss privacy issues.
RFID-Based Location Information Management System with Privacy Awareness	Recently, many types of RFID products has been developed and used to tightly bind the ID tag to users┬Æ personal information in an application. This has brought up new social problems where RFID tags can be detected from other RFID readers without the user being conscious of the transaction. In this paper, we provide a location management system named Tachyon. Tachyon defines policy files which describe the privacy of the user┬Æs location information. In Tachyon, users can expose their location information with a privacy policy. Additionally, Tachyon can reduce the cost of building distributed location management system.
New Internet Security and Privacy Models Enabled by IPv6	This paper identifies some of the features of IPv6 technology that provide security and privacy benefits to Internet users and commercial network operators. It is clearly shown that deployment of IPv6 technology is a critical step on the path towards a more secure and trustworthy networking infrastructure for the future.
Privacy Assuring Video-Based Monitoring System Considering Browsing Purposes	We are trying to resolve privacy issues of monitoring cameras through the "Yaoyorozu Project," which is a research project based on a "transdisciplinary science and technology" approach. In this paper we describe technical issues that must be addressed to assure both privacy and monitoring availability. We describe the design and development of a system implementing a method that filters sensitive information in videos on the basis of data identifying the observers, camera locations, and the people observed by the cameras.
Privacy-Aware Context Discovery for Next Generation Mobile Services	We present a system that enables applications to discover and obtain information that describes the context of a particular entity (e.g., a user or a device). Our system revolves around the notion of a context agent, which is a service that represents an entity and provides access to context information about that entity. Context agents facilitate the enforcement of an entity's policies regarding the release of context information (e.g., to applications or visiting users), even while these entities roam across different administrative domains. Context agents form an overlay on top of traditional local area service discovery infrastructures (e.g., based on SLP or WS-discovery) and are enablers for more intelligent pervasive computing environments. In this extended abstract, we outline the architecture of our system based on a simple scenario
A Privacy Oriented Extension of Attribute Exchange in Shibboleth	In frameworks for Web services like SAML, liberty or Shibboleth, a user can get authentication by asking one's IdP (identity provider) to issue a security assertion by which one can get access to services at an SP (service provider). If the SP additionally requests some attributes of one's, the user is forced to reveal the immediate values of them. There are cases where users must present detailed privacy information which SPs don't actually require to authorize them. We focus on Shibboleth and propose an extension of the attribute exchange protocol between an IdP and an SP in Shibboleth. While in the conventional framework of Shibboleth attributes are exchanged in immediate value, in our extension an SP requests an IdP to test whether user's attributes are satisfied some conditions, then the IdP returns either "true", "false" or "unanswerable" to the SP. We specify a language to describe the conditions as a query at the SP. We also extend an attribute authority at the IdP to evaluate the conditions presented from the SP
Privacy Management for Context Transponders	While by now feasible solutions to protect privacy for complex ubiquitous applications are available, very small devices, called context transponders (CTP) still lack resources to run sophisticated full scale approaches like DRM and strong encryption. These devices however, play an important role in the success of ubiquitous computing as they support the idea of pervasiveness (small, mobile etc.). We propose a set of techniques outlined as the CTP-classmark that aims to introduce data avoidance and obfuscation strategies to enable information security in context aware applications. Using this classmark, the users' privacy can be protected even on low resource devices and hence the users' trust in ubicomp applications will rise
Privacy Oriented Attribute Exchange in Shibboleth Using Magic Protocols	We propose an extension of the attribute exchange between an identity provider (IdP) and an service provider (SP) in Shibboleth. While in the conventional framework of Shibboleth attributes are exchanged in immediate values, in our new extension an SP and an IdP exchange attributes according to so-called "magic protocols". This extension enables the SP to know whether user's attributes meet the requirement for authorization, without the SP and the IdP revealing their confidential information. We also show how we can detect cheating in execution of this protocol, e.g. the IdP tells another value instead of the true value to the SP in malice.
Privacy Disclosure: Personal Information and Images on Social Networking Sites in Taiwan	Social networking sites are well developing Internet applications that provide people to extend their real world social lives to a virtual social environment in the cyberspace. Social networking site is actually a double-edged sword, while providing enhanced social values, it also pose a risk of the dissemination of private information to outsiders. In Taiwan, leading social network Websites, such as Wretch.cc, has several privacy disclosures which result in damage of personal reputation or in other inconvenience. Since Taiwan might be still immature in the privacy point of view, we would like to discuss the network privacy environment in Taiwan, and try to make some suggestions to improve privacy protection.
Security Analysis on Privacy-Secure Image Trading Framework Using Blind Watermarking	We propose and evaluate a privacy-secure image trading framework using blind fingerprinting technique which embeds a user ID using watermark technique. The framework provides a privacy-secure trading even though there is no confidential relation between a content provider and a user. In a conventional fingerprinting scheme, a content provider offers a user ID embedded image to a user in order to trace a pirated piece and an illegal user when an image is pirated. In spite the fact that privacy protection becomes an important issue along with augmentation of digital content trading, it has not been well considered in a conventional fingerprinting scheme. Some blind fingerprinting techniques satisfy privacy protection by concealing user information using cryptography. Semi-blind fingerprinting is another type of blind technique that is proposed with a concept of blinding information within feasible processing cost. Feasibility is satisfied by avoiding use of cryptography which causes heavy overhead in computation. In our proposed image trading framework, we use semi-blind technique which is well optimized for our framework. In order to establish a robust framework, we carry out security analysis by specifying various kinds of incidents and solutions.
An Enhanced Location Privacy Framework with Mobility Using Host Identity Protocol	Location privacy is one of the problems involved in IP mobility. There are two proposed frameworks for this problem based on Host Identity Protocol (HIP); HIP Location Privacy Framework provides partial location privacy with mobility, while BLIND provides complete location privacy without mobility. In this paper, we integrate their strong points, i.e. complete location privacy with mobility. Our framework gives a way to decouple identifiers for mobility from identifiers for end-to-end communications. We construct an extensional mobility management protocol of BLIND, and discuss a trade-off in terms of efficiency and operational cost.
Secure remote matching with privacy: Scrambled support vector vaulted verification (S<sup>2</sup>V<sup>3</sup>)	As biometric authentication systems become common in everyday use, researchers are beginning to address privacy issues in biometric recognition. With the growing use of mobile devices, it is important to develop approaches that support remote mobile verification. This paper outlines the need for a mobile/remote SVM-based authentication system that does not compromise the privacy of the subject being recognized. We discuss limitations of earlier privacy-preserving authentication systems and present necessary privacy and security requirements that make a system attractive from both the server's security point of view and from the client's privacy-centric point of view. We then present a novel protocol we call ΓÇ£Vaulted VerificationΓÇ¥ that allows a server to remotely authenticate a client's biometric in a privacy preserving way. We conclude with a small evaluation of performance, discussion of security implications, and ideas for future work.
A privacy-aware, end-to-end, CFG-based regression test selection framework for web services using only local information	Web services are composable, interoperable, and autonomous which means that a single web service interaction could involve services written in several different languages provided by several different service providers. Such interactions hamper the development of RTS techniques because RTS techniques generally require some form of implementation details which service providers in separate autonomous systems are unlikely to expose. In this work, a privacy-aware, end-to-end regression testing framework employing a RTS technique using Control-Flow Graphs (CFGs) built using only locally available information at each service and a publish/subscribe mechanism will be presented. The proposed framework is unique because it does not require service providers to expose private and sensitive implementation details in order to participate in the regression testing framework. Also, a case study will be presented to highlight the approach and be used in an empirical study to evaluate the cost-effectiveness of the approach.
E-commerce privacy and trust: Overview and foundation	The proliferation of the Internet has given rise to electronic commerce or e-commerce. Each year consumer privacy becomes more of an issue. There are a number of actions that online merchants can take to give a sense of security to their customers in addition to actions that consumers can take to ensure their own privacy. This review is an overview of the issues found in the e-commerce literature and is provided as a foundation for future research regarding the issues of privacy and trust in e-commerce.
Privacy-Preserving Musical Database Matching	In this paper we present an illustratory process which allows privacy-preserving transactions in the context of musical databases. In particular we address the problem of matching a piece of music audio to a service database in such a way such that the database provider will not directly observe the query, nor its result, thereby preserving the privacy of the inquirer. We formulate this process within the field of secure multiparty computation and show how such a transaction can be achieved once we derive secure versions of basic signal processing operations.
Privacy and security for RFID Access Control Systems: RFID Access Control Systems without back-end database	Radio Frequency Identification (RFID) is one of the most popular Automatic Identification and Data Capture (AIDC) technologies that facilitate objects identification and information exchange over relatively small and widely separated entities. In this paper, the main aim is to address the privacy and security challenges that RFID Access Control Systems face and solve these challenges without relying on back-end database but only the RF subsystem.
Introducing privacy-awareness in remote healthcare monitoring	The creation of smart spaces for remote healthcare monitoring is a very prominent example of patients' life improvement by healthcare ICT, eliminating in certain cases the need for hospitalization of patients that require monitoring. On the other hand, services as such create concerns and are characterized by implications with respect to personal privacy. In order to limit the disclosure and misuse of patients' personal data, this paper discusses the access control solution considered by the inCasa project for the enforcement of fair information practices in the context of remote healthcare monitoring.
Privacy and security in biomedical applications of wireless sensor networks	Wireless sensor network applications in healthcare and biomedical technology have received increasing attention, while associated security and privacy issues remain open areas of consideration. The relevance of this technology to our growing elderly population, as well as our increasingly over-crowded and attention-drained healthcare systems, is promising. However, prior to the emergence of these systems as a ubiquitous technology, healthcare providers and regulatory agencies must determine an acceptable level of security and privacy. This paper will review biomedical applications of wireless sensor networks, identify security and privacy issues to be addressed, and note some of the proposed methods for securing these systems.
Privacy Preserving Attribute Reduction for Vertically Partitioned Data	Traditional attribute reduction algorithms based on rough set theory assume free access to data. Increasingly, privacy and security constraints may prevent the parties from directly sharing the data and some types of information about the data, thus derailing attribute reduction projects. Distributed attribute reduction, if done correctly, can alleviate this problem. The key is to obtain globally valid attribute reduction result, while providing guarantees on the (non) disclosure of data. In this paper, we consider the problem of computing the attribute reduction of private datasets of two parties, and present a privacy preserving attribute reduction algorithm for vertically partitioned data. The algorithm incorporates secure two-party computation protocol using commutative encryption to minimize the information shared for both semi-honest and malicious environments, while adding little overhead to the relative reduct task.
A Privacy-Preserving Distributed Method for Mining Association Rules	In order to improve the privacy preservation and the mining efficiency, an effective privacy preserving distributed mining algorithm of association rules is proposed in this paper. Combining the advantages of both RSA public key cryptosystem and homomorphic encryption scheme, a model of hierarchical management on the cryptogram is put forward in the algorithm. By introducing cryptogram management server and data mining server in the process of mining, the algorithm quickly generates global K-frequent itemsets using similarity matrix of transactions as well as effectively protects security of sensitive data. As shown in the theoretical analysis and the experimental results, the algorithm can achieve improvements in terms of privacy, accuracy, and efficiency.
Privacy concern toward using social networking services: A conceptual model	The success of social networking services (SNS) largely depends on the targeted users' adoption and usage behavior. However, privacy concern is one of the important barriers to SNS services application. A better understanding of online privacy concern and its general effect on users' intention toward using social networking services is an important research issue. This paper initiates discussion of this issue by proposing a conceptual model which places privacy concern as the focal point for SNS acceptance.
Data aggregation with privacy-preserving for wireless sensor networks	In-network data aggregation presents a critical challenge for data privacy in resource constraint wireless sensor networks. We propose a PAPF scheme, in which a novel p-function set taking advantage of the algebraic properties of modular operation is constructed. Thanks to the p-functions, nodes can perturb their privacy data without extra data exchange, and the aggregation result can be recovered from the perturbed data in the cluster head. Due to the flexible generation of the p-function set, PAPF scheme is adapted to node periodical reporting and sink in query response reports. Extensive analysis and simulations show that PAPF scheme is able to preserve privacy more efficiently while consuming less communication overhead, and has a good resistance to data loss.
Computer-Aided Privacy Requirements Elicitation Technique	The legislative penalties and economic penalties for privacy violations are more serious for a service provider these days. In spite of demonstrating that it is willing and able to protect the privacy of information, a service provider developing a privacy-compliant system faces two challenges; technical complexities and legal complexities. In this paper, we propose a computer-aided privacy requirements elicitation technique (PRET) that helps software developers elicit privacy requirements more efficiently in the early stages of software development. The goal of the PRET tool is to accelerate the elicitation process and prevent privacy requirements leaks by using a general privacy requirements database derived from privacy laws and empirical privacy requirements. We also show the results of integrating the PRET tool with the security quality requirements engineering (SQUARE) methodology and provide evidence of the efficacy of the resultant tool.
Privacy Concealments: Detective Strategies Unveiling Cyberstalking on Internet	Cyber world is developing with substantial advancement to enter into glorious future, but cybercrime has always been a disaster to this dream. Recent advancement in internet technologies has lead stalking to become cyber. Cyberstalking offenses have become diversified and technological advance. It creates social and mental disorders among victims. In order to improve the privacy of internet users against cyberstalking, a novel examination of action research is evaluated from a former event. With the guidance of this case study, we can discriminate normal social networking friends from the possible offenders. The initial results show that our approach is highly helpful. Curbing cyberstalking is a baffling task because of its newness and technological furtherance. It is believed that this study will clarify the obscure technological and social aspects of cyberstalking. In this paper, the proposed solutions can prohibit users from the risk of getting hurts, facilitate to cut down its roots and remove its foundation.
Privacy Sensitivity: Application in Arabic	Personal Identifiable Information (PII) describes a relationship between information and a uniquely identifiable person. Sensitive PII refers to a category of PII that contains significant information about individuals. In general, sources of sensitivity of PII can be tracked by partitioning the basic unit of linguistic information into three parts: identity, verb, and the reminder of the linguistic construct. In this paper, we analyze the anatomy of PII with respect to its sensitivity and apply it to Arabic. The paper reports on an experimental system that uses such a method.
Privacy-Sensitive Audio Features for Speech/Nonspeech Detection	The goal of this paper is to investigate features for speech/nonspeech detection (SND) having low linguistic information from the speech signal. Towards this, we present a comprehensive study of privacy-sensitive features for SND in multiparty conversations. Our study investigates three different approaches to privacy-sensitive features. These approaches are based on: 1) simple, instantaneous feature extraction methods; 2) excitation source information based methods; and 3) feature obfuscation methods such as local (within 130 ms) temporal averaging and randomization applied on excitation source information. To evaluate these approaches for SND, we use multiparty conversational meeting data of nearly 450 hours. On this dataset, we evaluate these features and benchmark them against standard spectral shape based features such as Mel frequency perceptual linear prediction (MFPLP). Fusion strategies combining excitation source with simple features show that comparable performance can be obtained in both close-talking and far-field microphone scenarios. As one way to objectively evaluate the notion of privacy, we conduct phoneme recognition studies on TIMIT. While excitation source features yield phoneme recognition accuracies in between the simple features and the MFPLP features, obfuscation methods applied on the excitation features yield low phoneme accuracies in conjunction with SND performance comparable to that of MFPLP features.
Wordless Sounds: Robust Speaker Diarization Using Privacy-Preserving Audio Representations	This paper investigates robust privacy-sensitive audio features for speaker diarization in multiparty conversations: i.e., a set of audio features having low linguistic information for speaker diarization in a single and multiple distant microphone scenarios. We systematically investigate Linear Prediction (LP) residual. Issues such as prediction order and choice of representation of LP residual are studied. Additionally, we explore the combination of LP residual with subband information from 2.5 kHz to 3.5 kHz and spectral slope. Next, we propose a supervised framework using deep neural architecture for deriving privacy-sensitive audio features. We benchmark these approaches against the traditional Mel Frequency Cepstral Coefficients (MFCC) features for speaker diarization in both the microphone scenarios. Experiments on the RT07 evaluation dataset show that the proposed approaches yield diarization performance close to the MFCC features on the single distant microphone dataset. To objectively evaluate the notion of privacy in terms of linguistic information, we perform human and automatic speech recognition tests, showing that the proposed approaches to privacy-sensitive audio features yield much lower recognition accuracies compared to MFCC features.
Privacy-Preserving Speaker Verification and Identification Using Gaussian Mixture Models	Speech being a unique characteristic of an individual is widely used in speaker verification and speaker identification tasks in applications such as authentication and surveillance respectively. In this article, we present frameworks for privacy-preserving speaker verification and speaker identification systems, where the system is able to perform the necessary operations without being able to observe the speech input provided by the user. In a speech-based authentication setting, this privacy constraint protect against an adversary who can break into the system and use the speech models to impersonate legitimate users. In surveillance applications, we require the system to first identify if the speech recording belongs to a suspect while preserving the privacy constraints. This prevents the system from listening in on conversations of innocent individuals. In this paper we formalize the privacy criteria for the speaker verification and speaker identification problems and construct Gaussian mixture model-based protocols. We also report experiments with a prototype implementation of the protocols on a standardized dataset for execution time and accuracy.
Special Issue on Intelligent Video Surveillance for Public Security & Personal Privacy	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Distributed Architectures for High Performance and Privacy-Aware Content Generation and Delivery	The current trend in the evolution of the Web is towards an every increasing demand for personalized Web contents. Tailoring Web resources to the characteristics of heterogeneous client devices and user preferences opens two main novel issues in the research area of content generation and delivery. First, the high computational cost characterizing most adaptation services requires efficient and scalable support systems. Second, adaptation services typically rely on user information that may include sensitive data. When system scalability is achieved through architectures that are distributed over a geographical area, privacy issues concerning the user profiles management become particularly critical. In this paper, we propose a distributed architecture for the ubiquitous Web access that guarantees high performance and privacy of sensitive user information by splitting the adaptation services over the nodes of a two-level topology. We evaluate the performance and the overheads of the proposed architecture in order to understand to which extent it is convenient to distribute adaptation services over multiple nodes that are geographically distributed
User-aware privacy control via extended static-information-flow analysis	Applications in mobile-marketplaces may leak private user information without notification. Existing mobile platforms provide little information on how applications use private user data, making it difficult for experts to validate applications and for users to grant applications access to their private data. We propose a user-aware privacy control approach, which reveals how private information is used inside applications. We compute static information flows and classify them as safe/unsafe based on a tamper analysis that tracks whether private data is obscured before escaping through output channels. This flow information enables platforms to provide default settings that expose private data only for safe flows, thereby preserving privacy and minimizing decisions required from users. We built our approach into TouchDevelop, an application-creation environment that allows users to write scripts on mobile devices and install scripts published by other users. We evaluate our approach by studying 546 scripts published by 194 users.
Caprice: a tool for engineering adaptive privacy	In a dynamic environment where context changes frequently, users' privacy requirements can also change. To satisfy such changing requirements, there is a need for continuous analysis to discover new threats and possible mitigation actions. A frequently changing context can also blur the boundary between public and personal space, making it difficult for users to discover and mitigate emerging privacy threats. This challenge necessitates some degree of self-adaptive privacy management in software applications. This paper presents Caprice - a tool for enabling software engineers to design systems that discover and mitigate context-sensitive privacy threats. The tool uses privacy policies, and associated domain and software behavioural models, to reason over the contexts that threaten privacy. Based on the severity of a discovered threat, adaptation actions are then suggested to the designer. We present the Caprice architecture and demonstrate, through an example, that the tool can enable designers to focus on specific privacy threats that arise from changing context and the plausible category of adaptation action, such as ignoring, preventing, reacting, and terminating interactions that threaten privacy.
Face recognition with renewable and privacy preserving binary templates	This paper considers generating binary feature vectors from biometric face data such that their privacy can be protected using recently introduced helper data systems. We explain how the binary feature vectors can be derived and investigate their statistical properties. Experimental results for a subset of the FERET and Caltech databases show that there is only a slight degradation in classification results when using the binary rather than the real-valued feature vectors. Finally, the scheme to extract the binary vectors is combined with a helper data scheme leading to renewable and privacy preserving facial templates with acceptable classification results provided that the within-class variation is not too large.
A survey on various privacy and security features adopted in MANETs routing protocol	Mobile AdHoc Networks (MANETs) has a wide range of applications, ranging from everyday mobile phone application to mission critical military applications. MANETs have proved their necessity and the ease of setting up networks. Thus MANETs are very popular for scenarios which are sensitive and urgent like disaster relief, military applications, etc. As the application of MANETs increases, the attacks on MANETs also increase. A vast range of research is being conducted to keep routing in MANETs robust and secure. One of the major research area is routing privacy. Many routing solutions are proposed to maintain privacy. Location aided routing is a novel idea; in which routing is done based on location information, therefore node identity is not revealed. This paper outlines few of the routing algorithms in MANETs.
(Im)possibility of unconditionally privacy-preserving auctions	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01373597.png" border="0">
The effect of policies for selecting the solution of a DisCSP on privacy loss	
Privacy-aware and distributed system design for personalised alerting	This paper presents a concept for the privacy-friendly generation and distribution of personalized emergency alert messages. Based upon a discussion of possible benefits of alert personalization in disaster situations, relevant target groups for personalized alerting and their respective information requirements are identified. Subsequently, different system design approaches will be discussed, with emphasis on client-centric versus server-centric personalization, ansynchronicity and interoperability. A design concept will be presented which also facilitates the integration of additional alerting functionalities on smart phones.
Enforcing Privacy Using Symmetric Random Key-Set in Vehicular Networks	Vehicular networks have attracted extensive attentions in recent years for their promises in improving safety and enabling other value-added services. Security and privacy are two integrated issues in the deployment of vehicular networks. Privacy-preserving authentication is a key technique in addressing these two issues. We propose a random keyset based authentication protocol that preserves user privacy under the zero-trust policy, in which no central authority is trusted with the user privacy. We show that the protocol can efficiently authenticate users without compromising their privacy with theoretical analysis. Malicious user identification and key revocation are also described
LiDSec- A Lightweight Pseudonymization Approach for Privacy-Preserving Publishing of Textual Personal Information	Sharing personal information benefits both data providers and data consumers in many ways. Recent advances in sensor networks and personal archives enable users to record personal information including emails, social networking activities, or life events (life logging). These information objects are usually privacy sensitive and thus need to be protected adequately when being shared. In this work, we present a lightweight pseudonymization framework which allows users to benefit from sharing their personal information while still preserving their privacy. Furthermore, this approach increases the data owners' awareness of what information they are sharing, thus rendering data publishing more transparent.
A Server-side Approach to Privacy Policy Matching	With the increasing use of online services that require sharing of information there is a need for Privacy Enhancing Technology tailored for personal information control. Commonly, web privacy is handled through matching of privacy policies and user preferences using software agents on the client side. In this paper, we propose a new approach to privacy policy matching we denote server-side matching. By moving the matching logic from the client to the server, the client is alleviated from the resource consuming process of obtaining and matching policies and the service provider is able to adapt services to users' privacy preferences. We describe the architecture of a general solution and a prototype implementation of selected parts. The solution has only been subject to rudimentary testing, but our initial evaluation is promising.
Bulletin Boards in Voting Systems: Modelling and Measuring Privacy	Transparency is crucial to ensuring fair, honest elections. Transparency is achieved by making information (e.g. election result) public. In e-voting literature, this publication is often described in terms of a bulletin board. While privacy of voting systems has been actively studied in recent years, resulting in various analysis frameworks, to date there has not been an explicit modelling of bulletin board in any such framework. Privacy implications of bulletin boards are thus understudied. In this paper, we extend the semantics of the framework of Jonker, Mauw and Pang to model a bulletin board and capture coercion-resistance. The usage of the extended framework is illustrated by an application to the Pret a Voter voting system. Moreover, we present an information-theoretical measure of privacy loss in elections.
Enhance Data Privacy in Service Compositions through a Privacy Proxy	Web services are loosely coupled Web-enabled applications that can be dynamically invoked to facilitate business interactions through well-defined interfaces over the Internet. However, since personal data will be exchanged between nested Web services, the question how to preserve a user's data privacy becomes a challenging issue. In this paper we aim to minimize personal data disclosure in service composition that consists several nested Web services. To do so, we propose a practical, scalable and light-weight privacy-enhanced design that uses a privacy proxy to achieve data privacy. We furthermore show that by utilizing the privacy proxy in combination with advertising its capabilities and requirements as service level agreements (SLA's), it is possible to enhance data privacy in existing service infrastructure in a minimal invasive manner.
Optimization of Privacy Preserving Mechanisms in Homogeneous Collaborative Association Rules Mining	This article focuses on optimization of cryptographic mechanisms used in association rules multiparty mining algorithms with preserving data privacy. The major part of attention is focused on increasing the performance because the computation expense can be prohibitive when applying to large databases. We introduce how to use a Common Decrypting Key for commutative encryption in Secure Set Union to improve performance. As an example of the above mentioned mechanism application, the article presents a new algorithm of mining association rules on horizontally partitioned data with preserving data privacy-CDKSU (Secure Union with Common Decrypting Key). CDKSU is an application of the Common Decrypting Key for a commutative encryption in a Secure Set Union. This algorithm is compared to the KCS scheme (referenced as HPSU also) since they are both based on FDM. As far as the performance optimization is concerned, the application of Elliptic Curve Cryptography versus Exponential Cryptography is presented as well. We believe that this is the first description of application of the Elliptic Curve Pohlig-Hellman Cipher. The system implementing given algorithms is described and subjected to performance tests. Finally, the results of these tests are presented and analyzed.
Privacy Frost: A User-Oriented Data Anonymization Tool	A challenging task in privacy protection for public data is to realize an algorithm that generalizes a table according to requirements of a data user. In this paper, we propose an anonymization scheme for generating a k-anonymous and l-diverse table, and show evaluation results using three different tables. Our scheme is based on both top-down and bottom-up approaches for full-domain and partial-domain generalization, and the requirements are automatically incorporated into the generated table. The generated table meets user's requirements and can be employed in the services provided by users without any modification or evaluation.
Support Access to Distributed EPRs with Three Levels of Identity Privacy Preservation	The emergence of e-health has put an enormous amount of sensitive data in the hands of service providers or other third parties, where privacy risks might exist when accessing sensitive data stored in electronic patient records (EPRs). EPRs support efficient access to patient data by multiple healthcare providers and third party users, which will consequently, improve patient care. However, the sensitive nature of patient data requires access restrictions to only those `who needs to know'. How to achieve this without compromising patient privacy remains an open issue that needs further consideration. This paper, therefore, presents a novel method to support access to distributed EPRs with three levels of patient identity privacy preservation. The method makes use of cryptographic primitives. In comparison with related work, the method supports three levels of access requirements while preserving data owner's privacy on a single platform.
Security and Privacy in Companies: State-of-the-art and Qualitative Analysis	Privacy and security are relevant topics in both -- research and practice. Although they are often used together, implicitly assuming that they represent the same concept, they actually represent different concepts that are closely related. First, this paper presents a way to differentiate between these two topics from a conceptual point of view. Furthermore, it depicts some commonly accepted privacy regulations that exist in the OECD, EU and US. Second, we show how privacy and security are defined and implemented in practice, based on three interviews, conducted in different Austrian companies. The interviews picture the specific situation in the companies. Similarities and differences between the three interviews as well as between the interviews as a whole and the conceptual considerations were found and are described. To explain the maturity of these companies in terms of their understanding of privacy and security, we analyzed and visualized the interviews.
Privacy Verification Using Ontologies	As information systems extensively exchange information between participants, privacy concerns may arise from its potential misuse. A Privacy by Design (PbD) approach considers privacy requirements of different stakeholders during the design and the implementation of a system. Currently, a comprehensive approach for privacy requirement engineering, implementation, and verification is largely missing. This paper extends current design methods by additional (formal) steps which take advantage of ontologies. The proposed extensions result in a systematic approach that better protects privacy in future information systems.
Learning Privacy Preferences	This paper suggests a machine learning approach to preference generation in the context of privacy agents. With this solution, users are relieved from the complex task of specifying their preferences beforehand, disconnected from actual situations. Instead, historical privacy decisions are used as a basis for providing privacy recommendations to users in new situations. The solution also takes into account the reasons why users act as they do, and allows users to benefit from information on the privacy trade-offs made by others.
Privacy Policy Preferences Enforced by SPARQL Query Rewriting	When specifying privacy preferences, the data owner can control who may access its personal data, for which purpose and under which accuracy. In this paper we present an approach that enforces the privacy policy preferences by query transformation. We present also how to instrument this rewriting query algorithm using a privacy-aware model like PrivOrBAC. We take into account various dimensions of privacy preferences through the concepts of consent, accuracy, purpose and recipient.
Comparing Privacy Requirements Engineering Approaches	Several privacy requirements engineering approaches exist, which differ in notions and terminology. We extended a conceptual framework originally designed to compare security requirements engineering approaches with concepts and notions used in privacy requirements engineering. Furthermore, we apply our conceptual framework to compare and evaluate current privacy requirements engineering approaches, e.g., the PriS and LINDDUN approaches. We discuss how these methods are related to the conceptual framework. We compare the terminology and notions of these methods with the clear-cut vocabulary of the conceptual framework.
Design and Implementation of a CBR-based Privacy Agent	This paper presents Privacy Advisor; a software which uses machine-learning techniques to help the users make online privacy decisions. Privacy Advisor is based on Case Based Reasoning (CBR), which relies on the ability to identify similar situations from the past and use these to provide recommendations in new situations. This paper focuses on the algorithms necessary to calculate the similarity of privacy policies. In addition, we provide results from a focus group study on the perceived similarity of data items and data handling purposes from a privacy point of view.
A Privacy preserving Approach to Call Detail Records Analysis in VoIP Systems	Attacks on Voice-over-IP calls happen frequently. A specific type of these attacks are toll-fraud attacks. The prevention of these attacks depends on understanding the attack patterns. These can be derived from communication records. However, these records contain privacy relevant information of the call participants. These records are also protected by a number of laws and regulations. To make an analysis privacy compliant, relevant laws and regulations need to be considered. We propose a method for changing communication records in such a way that the forensic analysis in VoIP attacks is possible and the privacy of the call participants is preserved. We define privacy requirements for communication records from laws, regulations and concerns of call participants. We also present patterns of communication records based upon real world examples. We further show a framework for privacy attack identification and privacy data minimisation for a structured analysis of communication records. Moreover, an analysis pattern for toll-fraud attacks states which relations in the communication records have to survive the data minimisation.
Ensuring privacy for e-health services	The growth of the Internet has been accompanied by the growth of e-health services (e.g. online medical advice, online pharmacies). This proliferation of services and the increasing regulatory and legal requirements for personal privacy have fueled the need to protect the personal privacy of service users. Existing approaches for privacy protection such as access control are predicated on the e-service provider having possession and control over the user's personal data. In this paper, we propose a new approach to protecting personal privacy for e-health services: keeping possession and control over the user's personally identifiable information in the hands of the user as much as possible. Our approach can also be characterized as distributing personally identifiable information only on a "need to know" basis.
Privacy threats and issues in mobile RFID	Radio frequency identification (RFID) technology that is used to identify objects and users and automatically takes advantage of contextual information such as user's location is expected to become an important and a core technology of ubiquitous infrastructure. This technology has been applied to many applications such as retail and supply chain. At recent, there are an increasing number of researches related to mobile RFID that provides RFID service to user with a reader embedded in the mobile device as the one of RFID applications. However, there are an increasing number of concerns, and even some resistance, related to user tracking and profiling using RFID technology. Therefore, in this paper, we review privacy threats that have been reported in various RFID applications and bring up some additional privacy threats in mobile RFID, impeding the deployment of mobile RFID. And we analyze whether various privacy protecting measures that have been proposed to address privacy problems in RFID can also apply to mobile RFID.
A reference model for Authentication and Authorisation Infrastructures respecting privacy and flexibility in b2c eCommerce	Authentication and Authorisation Infrastructures (AAIs) are gaining momentum throughout the Internet. Solutions have been proposed for various scenarios among them academia, grid computing, company networks, and above all eCommerce applications. Products and concepts vary in architecture, security features, target group, and usability containing different strengths and weaknesses. In addition security needs have changed in communication and business processes. Security on the Internet is no longer defined as only security measures for an eCommerce provider against an untrustworthy customer but also vice versa. Consequently, privacy, data canniness, and security are demands in this area. The authors define criteria for an eCommerce provider federation using an AAI with a maximum of privacy and flexibility. The criteria is derived concentrating on b2c eCommerce applications fulfilling the demands. In addition to best practices found, XACML policies and an attribute infrastructure are deployed. Among the evaluated AAIs are Shibboleth, Microsoft Passport, the Liberty Alliance Framework, and PERMIS.
Access control in a privacy-aware eLearning environment	Access control is necessary to prevent illegal accesses to shared resources. Within eLearning, access control is required in order to protect provided contents and services as well as user data. Usually, access rights are assigned to users of a system. However, in a system that applies privacy-enhancing identity management (PIM) common approaches cannot be directly utilized since users do not act under fix login names. Within this paper, we want to discuss how protection of contents as well as of user data can be realized in such an environment. The context of our work is the eLearning application BluES'n which additionally aims at providing users a flexible working environment. All functionality needed for realizing access control is provided by a PIM-aware platform which is currently developed within the European project PRIME.
Using Privacy Process Patterns for Incorporating Privacy Requirements into the System Design Process	In the online world every person has to hold a number of different data sets so as to be able to have access to various e-services and take part in specific economical and social transactions. Such data sets require special consideration since they may convey personal data, sensitive personal data, employee data, credit card data etc. Recent surveys have shown that people feel that their privacy is at risk from identity theft and erosion of individual rights. The result is that privacy violation is becoming an increasingly critical issue in modern societies. To this end, PriS, a new security requirements engineering methodology, has been introduced aiming to incorporate privacy requirements early in the system development process. In this paper, we extend the PriS conceptual framework by introducing privacy process patterns as a way for describing the effect of privacy requirements on business processes. In addition, privacy process patterns facilitate the identification of the system architecture that best supports the privacy-related business processes, thus providing a holistic approach from business goals to `privacy-compliant' IT systems
A Privacy Enhancing Service Architecture for Ticket-based Mobile Applications	Network operators gradually open their interfaces to formerly hidden services. This fosters the development of a new class of mobile applications that take into account user's location and presence information. However, this development also raises problems especially the lack of protection of privacy in location-based services. This paper proposes a service architecture that is aimed at overcoming some of the shortages of currently existing context-aware applications that make use of network providers services as well as existing mobile payment systems. We therefore introduce the combination of tickets together with a novel privacy enhancing mechanism that is based on the notion of pseudonyms. Compared to other privacy enhancing solutions our pseudonym mechanism can also be implemented on mobile devices that have some restrictions regarding resources like memory or processing power. Due to their flexibility tickets can be used for many different kinds of applications. One important aspect in this respect is the highly postulated pay-as-you-go model. We give an example of a transport ticket application and explain the message interaction patterns for the basic functionalities of the systems, regarding aspects like data and privacy protection. This example further shows how 3rd party application providers can build meaningful mobile applications that are accepted by users
The Cost of Preserving Privacy: Performance Measurements of RFID Pseudonym Protocols	The purpose of RFID tags is to provide identifying information; the problem is that tags may radiate identifying information to any RFID reader anywhere. Encryption alone does not help: even encrypted IDs are static, and can be identified as unique to a particular object, and are thus vulnerable to tracking. To preserve privacy, pseudonym protocols have been proposed. Using cryptography and pseudonyms, unauthorized entities cannot even link two sightings of the same tag. In this paper, we measure the cost of running tree-based pseudonym protocols. Pseudonym protocols require random numbers, cryptographic operations and writing to onboard memory (in case time-limited delegation is enabled), which we implement using TinyOS system software. For MicaZ hardware, we measure voltage drop with an oscilloscope. Our results show that one Skipjack block cipher (part of the pseudonym encryption process) costs more energy than generating ten random numbers. Therefore, when configuring the tree of secrets, it is more energy-efficient to have a wider rather than a deeper tree
Privacy in Pervasive Computing and Open Issues	Privacy appears as a major issue for pervasive computing applications. Several models have been proposed to address privacy challenges. Successful design requires awareness of the technology's users and that their desires and concerns are understood. This is difficult as few empirical researches exist about potential pervasive users that designers can use. Complicating design further is the fact that pervasive systems are typically embedded or invisible, making it difficult for users to know when these devices are present and collecting data. As users have a limited understanding of the technology several privacy, design, and safety issues are raised. This paper discusses how privacy might be preserved in a pervasive computing environment. It presents some research developments in these areas to address privacy concerns. Open issues and challenges are also examined
Experimental Demonstration of a Hybrid Privacy-Preserving Recommender System	Recommender systems enable merchants to assist customers in finding products that best satisfy their needs. Unfortunately, current recommender systems suffer from various privacy-protection vulnerabilities. We report on the first experimental realization of a theoretical framework called ALAMBIC, which we had previously put forth to protect the privacy of customers and the commercial interests of merchants. Our system is a hybrid recommender that combines content-based, demographic and collaborative filtering techniques. The originality of our approach is to split customer data between the merchant and a semi- trusted third party, so that neither can derive sensitive information from their share alone. Therefore, the system can only be subverted by a coalition between these two parties. Experimental results confirm that the performance and user-friendliness of the application need not suffer from the adoption of such privacy-protection solutions. Furthermore, user testing of our prototype show that users react positively to the privacy model proposed.
NFC Devices: Security and Privacy	The aim of this paper is to show security measures for NFC (Near Field Communication) use cases and devices. We give a brief overview over NFC technology and evaluate the implementation of NFC in devices. Out of this technology review we derive different use cases and applications based on NFC technology. Based on the use cases we show assets and interfaces of an NFC device that could be a possible target of an attacker. In the following we apply different attacks against the operation modes to show how applications and devices could be protected against such attacks. The information collected is consolidated in a set of threats giving guidelines on how to improve security and overcome privacy issues. This allows integrating NFC technology in a secure way for the end consumer.
Privacy Aspects of eHealth	A central aspect of eHealth is the electronic healthcare record (EHR) which integrates all relevant medical information of a person and represents a lifelong documentation of the medical history. By virtue of their sensitive character it is crucial that medical data can only be accessed by the patient herself and persons who are directly involved in the treatment of the patient. Since eHealth portals can be accessed via the Internet, security and privacy issues arise that have to be considered carefully. Besides traditional security properties, we mainly focus on additional threats, namely the trivial disclosure attack and the statistical analysis of metadata. Thereby a disclosure attack takes place if a person enforces another person to present her EHR, e.g. during a job interview. Additionally, by applying statistical analysis on the metadata of an eHealth portal, it is possible to determine relevant information (e.g. psychological treatment) which could have negative effects on the patient. In this paper we present a concept including pseudonymization of medical data, identity management, obfuscation of metadata and anonymous authentication to prevent disclosure attacks and statistical analysis.
Privacy-Preserving Recommendation Systems for Consumer Healthcare Services	Advances in e-health bring new challenges with regard to the protection of sensitive patient data; an increasing number of applications require to share data with consumer healthcare services. Typically the providers of those services reside outside the traditional health care domain, where medical data protection laws (such as HIPAA) do not apply. Instead, technical means of protection should safeguard critical health data that is shared with third parties. In this paper, we show that cryptographic privacy- enhancing protocols are a key tool to protect the privacy of patients in upcoming consumer e-health services. In particular we focus on services offering health advice, allowing to locate specialists and supporting the formation of patient communities.
Bayesian Additive Regression Trees-Based Spam Detection for Enhanced Email Privacy	Spam is considered an invasion of privacy. Its changeable structures and variability raise the need for new spam classification techniques. The present study proposes using Bayesian additive regression trees (BART) for spam classification and evaluates its performance against other classification methods, including logistic regression, support vector machines, classification and regression trees, neural networks, random forests, and naive Bayes. BART in its original form is not designed for such problems, hence we modify BART and make it applicable to classification problems. We evaluate the classifiers using three spam datasets; Ling-Spam, PU1, and Spambase to determine the predictive accuracy and the false positive rate.
Cluster-Specific Information Loss Measures in Data Privacy: A Review	Data protection mechanisms need to find a trade-off between information loss and disclosure risk. To this end, information loss and disclosure risk measures have been developed. Due to the fact that when data is published it is usual to ignore which kind of analyses a user will pursue with the data, generic information loss measures are used to analyse the impact of the perturbation method onto the data. Such generic information loss measures are defined in terms of a few general-enough statistics. Nevertheless, a more fine-grained analysis is needed for particular data uses. In this paper we provide the reader with a review of a few results on cluster-specific information loss measures. More specifically, we consider the case of using fuzzy clustering to the perturbated data.
A New Scheme for Distributed Density Estimation based Privacy-Preserving Clustering	The sensitive information leakage and security risk is a problem from which both individual and enterprise suffer in massive data collection and the information retrieval by the distrusted parties. In this paper, we focus on the privacy issue of data clustering and point out some security risks in the existing data mining algorithms. Associated with cryptographic techniques, we initiate an application of random data perturbation (RDP) which has been widely used for preserving the privacy of individual records in statistical database for the distributed data clustering scheme. Our scheme applies linear transformation of Gaussian distribution perturbed data and general additional data perturbation (GADP) schemes to preserve the privacy for distributed kernel density estimation with the help of any trusted third party. We also show that our scheme is more secure against the random matrix-based filtering attack which is based on analysis of the distribution of the eigenvalues by using two RDP methods.
Privacy-preserving Protocols for Finding the Convex Hulls	Secure Multi-party Computation (SMC) has been a research focus in international cryptography community in recent years. SMC deals with the following situation: Two (or many) parties want to jointly perform a computation without disclosing their private inputs. Privacy-preserving convex hulls problem is a special case of SMC and it can be applied in many fields such as military and commercial fields. In this paper, we first present two privacy-preserving protocols to solve the convex hulls problem by using Yao 's millionaire protocol. We also discuss the security, correctness and performance of the two protocols. Based on the Euclid-distance Measure Protocol, an approximate solution to the convex hulls problem is proposed for fairness, which conceals more private information.
Privacy Preserving Support Vector Machines in Wireless Sensor Networks	It is important to achieve energy efficient data mining in Wireless Sensor Networks (WSN) while preserving privacy of data. In this paper, we present a privacy preserving data mining based on Support Vector Machines (SVM). We review the previous approach in privacy preserving data mining in distributed system. And we also review energy efficient data mining in WSN. We then propose an energy efficient privacy preserving data mining in WSN. We use SVM because it has been shown best classification accuracy and sparse data presentation using support vectors. We show security analysis and energy estimation of our proposed approach.
Towards an Architecture for Balancing Privacy and Traceability in Ubiquitous Computing Environments	Privacy preservation has been identified as an important factor to the success and acceptance of ubiquitous computing systems. Traceability, i. e. attributing events and actions to those who caused them, seems to be a directly contradicting goal. However, harnessing sensitive data collected by ubiquitous computing infrastructures for traceability applications in a privacy-respecting manner may clearly bring further benefits, for different concerned parties. Automated working hours recording and personalized insurances are first examples of such applications. To contribute to this matter, this paper presents an architecture that allows for balancing between privacy and traceability in ubiquitous computing environments. We describe its foundations and components and illustrate its benefits. Moreover, we discuss important existing research approaches on privacy protection and traceability applications in ubiquitous computing settings.
Privacy-Preserving Distributed Set Intersection	With the growing demand of databases outsourcing and its security concerns, we investigate privacy-preserving set intersection in a distributed scenario. We propose a one-round protocol for privacy-preserving set intersection based on a combination of secret sharing scheme and ho- momorphic encryption. We then show that, with an extra permutation performed by each contacted server, the cardinality of set intersection can be computed efficiently. All protocols constructed in this paper are provably secure against an honest-but-curious adversary under the Decisional Diffie-Hellman assumption.
haplog: A Hash-Only and Privacy-Preserved Secure Logging Mechanism	A secure logging mechanism named haplog is proposed. In essence, haplog uses only one-way hash functions to achieve the security and functional requirements of logging. This makes haplog more concise and efficient than schemes previously proposed. In addition, haplog considers that all events logged as log entries should be private and only the system can decide what event information the verifier can obtain. Even the trusted center, who helps to initialize the log mechanism and possesses shared secret with the system, should not be able to learn event information when verifying the integrity of the log.
Secure and Privacy-Friendly Logging for eGovernment Services	In this paper we present a scheme for building a logging- trail for processes related to eGovernment services. A citizen can reconstruct the trail of such a process and verify its status if he is the subject of that process. Reconstruction is based on hand-overs, special types of log events, that link data stored by multiple logging servers, which are not necessarily trusted. Our scheme is privacy-friendly in the sense that only the authorised subject, i.e. the citizen, can link the different log entries related to one specific process. The scheme is also auditable; it allows logging servers to show that they behave according to a certain policy.
Privacy Protected ELF for Private Computing on Public Platforms	Private computing on public platforms (PCPP) is a new technology designed to enable secure and private execution of applications on remote potentially hostile public platforms. PCPP uses a host assessment to validate a host's hardware and software configuration and then uses 4 active security building blocks which together allow an application to remain unaltered, unmonitored, and unrecorded before, during, and after execution on the public platform. Privacy protected ELF (PPELF) is the building block used by PCPP to protect application executable code while it is stored on the public platform and to provide a secure binary load mechanism. PPELF is an encrypted binary executable format and methodology which uses just in time decryption during the executable load procedure. In this paper we describe the PPELF file format, our new PPELF binary format loader, and our updates to the GLIBC ELF interpreter to support PPELF. We also provide experimental results detailing the initial load-time and run-time penalty associated with the use of PPELF.
A Comprehensive Approach for Context-dependent Privacy Management	Disclosing personal and contextual information enables a widespread use of services in the internet in a comfortable working environment adapted to individual user needs and preferences. On the other hand, information disclosure raises serious privacy issues. In this paper, we propose a novel integrated approach for achieving a good balance between convenience and privacy. We integrate privacy- enhancing identity management (PIM) with extended role- based access control mechanisms (RBAC) in an extended concept and architecture. In combination, both mechanism enable a fine grained control of what private and contextual information is disclosed to whom in what situation. We have implemented a privacy-enhanced adaptive communicator application (PEAC) to validate our approach.
Privacy Preserving Shortest Path Computation in Presence of Convex Polygonal Obstacles	Shortest path computation in presence of obstacles has been a subject of study since long and so has been the study of privacy preserving algorithms. In this paper we design efficient privacy preserving algorithms for computing the shortest path circumventing convex polygonal obstacles. Specifically, we assume that a party A has source s and destination d while another party B has the list of convex polygonal obstacles and A wishes to find the shortest path from s to d without compromising each others' privacy. That is, at the end of the protocol, A must not know anything else about the obstacles other that what may be revealed by the shortest path that is output and B must not know anything about A's source/destination.
Privacy-Preserving Collaborative Filtering Schemes	The privacy-preserving recommendation system enables us to evaluate the recommended value without leaking the private information of users to service providers. The large overhead in performing cryptographical operations in proportion to the number of users and the number of items is the current issue. In this article, we propose some efficient schemes reducing the preference matrix of the sets of items and users.
Patterns to Support the Development of Privacy Policies	This paper presents patterns for privacy policies to be used in web sites, in particular e-commerce and e-business sites. Because of their financial aspects, the users accessing those sites need to provide personal information, and expect integrity, security, and privacy. The patterns are derived from a study of the 33 most accessed e-commerce sites in Brazil, where it was possible to observe that they do not use a systematic approach to develop privacy policies which are clear, friendly, and with relevant contents.
A System of Privacy Preserving Distributed Spatial Data Warehouse Using Relation Decomposition	The article presents relation decomposition as a method of preserving data confidentiality in new distributed spatial data warehouse architecture that we proposed. Each node in new architecture has its own privacy preserving module which can communicate with other modules. It enables parallel query processing through all privacy preserving modules and as a result it shortens the time of query processing in DSDW. Procedures processing basic SQL as well as typical OLAP queries for protected data were also implemented. Those procedures realize execution of queries in such a way so that the greatest possible number of processing stages could be executed parallel. Additionally the privacy preserving module was designed to enable spatial data mining in DSDW. In order to do those two density-based algorithms of distributed clustering were used. First of those is applied if data warehouse nodes and privacy preserving modules are placed on internal servers of a corporation, second one is used if nodes and modules are on external servers of third party companies. Tests of effectiveness of executing queries as well as data mining, both using privacy preserving based on relation decomposition are finally presented.
Linking Privacy Solutions to Developer Goals	Privacy is gaining importance since more and more data becomes digitalized. There is also a growing interest from the security community because of the existing synergy between security and privacy. Unfortunately, the privacy development life cycle is less advanced than the security one. A clear classification into different objectives is not available yet. This paper attempts to scope the privacy landscape for software engineering by proposing an operational definition for privacy and by describing a privacy taxonomy. The taxonomy is rooted in the definition and presents a classification of privacy objectives, which correspond to the developer's goals. Each objective can be achieved by one or more strategies. As a validation for the taxonomy, existing privacy solutions are matched to each strategy.
Generating User-Understandable Privacy Preferences	Making use of the World Wide Web's numerous services increasingly requires the disclosure of personal user data. While these data represent an important value for service providers, users are increasingly concerned about growing privacy threats, as more and more of their personal and private information is released to a rising number of parties. Privacy-enhancing technologies, like the P3P specification, assist users in protecting their privacy. P3P provides means to express a machine-readable P3P privacy policy of a Web site and allows the interpretation of a dedicated P3P user agent that recommends a certain disclosure behavior. The agent's recommendation, however, is based on the quality of pre-defined privacy preferences of the user. Accordingly, the creation of these disclosure rules requires tools that accurately record individual privacy preferences in an understandable way. This paper introduces a novel, user-friendly privacy preference generator that allows the definition of privacy preferences for twelve different Internet service types, allowing for more precise and practical user preferences. Addressing the needs of users with different levels of experience, we present a multi-level user interface. Our solution includes a user-friendly P3P-based wizard as well as a clear and understandable configuration summary. The resulting privacy preferences of this tool will allow moreaccurate recommendations of future privacy agents.
On Privacy Preserving Convex Hull	Computing convex hull for a given set of points is one of the most explored problems in the area of computational geometry (CG). If the set of points is distributed among a set of parties who jointly wish to compute the convex hull, each party can send his points to every other party, and can then locally compute the hull using any of the existing algorithms in CG. However such an approach does not work if the parties wish to compute the convex hull securely, i.e., no party wishes to reveal any of his input points to any other party apart from those that are part of the answer. The problem of secure computation of convex hull for two parties was first introduced by Du and Atallah (NSPW '01). The first solution to the problem was given by Wang et. al(ARES '08). However, the proposed solution was based on well known algorithms for computing convex hull in CG which are proven to be sub-optimal. We propose a new solution for secure computation of convex hull with a considerable improvement in computational complexity. We further show how to extend our two-party protocol for the case of any number of parties.
Measuring Voter-Controlled Privacy	In voting, the notion of receipt-freeness has been proposed to express that a voter cannot gain any information to prove that she has voted in a certain way. Receipt-freeness aims to prevent vote buying, even when a voter chooses to renounce her privacy. In this paper, we distinguish various ways that a voter can communicate with the intruder to reduce her privacy and classify them according to their ability to reduce the privacy of a voter. We develop a formal framework combining knowledge reasoning and trace equivalences to formally model voting protocols and define vote privacy for the voters. Our framework is quantitative, in the sense that it defines a measure for the privacy of a voter. Therefore, the framework can precisely measure the level of privacy for a voter for each of the identified privacy classes. The quantification allows our framework to capture receipts that reduce, but not nullify, the privacy of the voter. This has not been identified and dealt with by other formal approaches.
A Test Framework for Assessing Effectiveness of the Data Privacy Policy's Implementation into Relational Databases	The growing migration of business transactions toward the web made data privacy a critical issue to cope with. Many technologies have been proposed in order to preserve sensitive data from illegal disclosure, also known as privacy enhancing technology (PET). Unfortunately, under certain conditions, sensitive data could be obtained by leveraging different malicious mechanisms which exploit actions permitted to the user. Thus, it is needed to face the problem also at the system design level, and not only by integrating a specific PET into the final system. We propose a framework for testing the software systempsilas capability of respecting established data privacy policy. Our test framework aims at detecting the sequence of legal actions which could allow a user to breach the mechanisms for preserving data privacy. The test output helps designers to properly modify those usage scenarios which could compromise data privacy. Experimentation has been carried out in order to make a preliminary assessment of the method.
An Automatic Privacy Policy Agreement Checker for E-services	An effective way of managing privacy for an e-service user is to make use of user and service provider privacy policies. The user privacy policy expresses the user's privacy preferences for personal information that is to be shared with the e-service provider. The provider privacy policy expresses the privacy requirements of the providerpsilas service, in terms of what personal information the service requires and how the information will be used. The e-service may proceed only if the user privacy policy "agrees" with the provider privacy policy. However, checking for policy agreement needs to be relatively fast in an e-services environment. How can this checking be automated? This paper defines user and provider privacy policies based on legal considerations. It then proposes a privacy policy agreement checker that can automatically determine if the user privacy policy agrees with the corresponding provider privacy policy. An example application of the checker is included.
P2F: A User-Centric Privacy Protection Framework	In this paper, we present an end-user tool called the privacy protection framework (P<sup>2</sup>F) which aims to support users in protecting their privacy when obtaining Web-based services. P<sup>2</sup>F acts as a recommendation tool that analyzes the user's transaction history and privacy preferences in addition to real-world privacy guidelines to prevent undesirable disclosure of personal data. The framework is based on a novel qualitative privacy compromise risk assessment approach designed to support decision-making in settings where server-side support for user-centric privacy protection frameworks is minimal or unkown. Our risk assessment model uses service provider properties, likelihood of collusion between providers, the sensitivity of the personal data to be released, and undesirable transaction linkability to determine the privacy compromise potential of a transaction.
Binomial-Mix-Based Location Anonymizer System with Global Dummy Generation to Preserve User Location Privacy in Location-Based Services	We propose a binomial-mix-based location anonymizer system with global dummy generation to protect user location privacy in location-based services in the face of attacks from a global active adversary and even with untrusted location-based service providers. Our proposed system overcomes the disadvantages of high latency in general-purpose mix-net systems when they are applied to location-based services, and the imprecision of query result or inefficiency due to large number of candidates in query result of existing obfuscation or spatial cloaking techniques. In our system, dummies (false locations) are generated globally in order to reduce the latency of requests to location-based services. A centralized dummy generation mechanism exploits all users' activities to optimize the system's behavior and performance. Because of the randomness provided by a binomial mix, our system prevents an adversary from determining with certainty whether a user is at a specific location. Our system also lets users define and update their personal location privacy maps and satisfies a probabilistic real-time condition that ensures delivery of any request within a predefined duration with high probability.
Model-Driven Application-Level Encryption for the Privacy of E-health Data	We propose a novel model-driven application-level encryption solution to protect the privacy and confidentiality of health data in response to the growing public concern about the privacy of health data. Domain experts specify sensitive data which are to be protected by encryption in the application's domain model. Security experts specify the cryptographic parameters used for the encryption in a security configuration. Both specifications are highly flexible to support different granularities of data to be encrypted and appropriate security levels. Based on the domain model, our code generator for Model-Driven Software Development generates code and configuration artifacts to control the encryption and decryption logic in the application and perform database schema modifications. Our encryption infrastructure outside the database (hence, application-level encryption) utilizes the security configuration to perform encryption and decryption.The generator relieves application developers from a significant amount of migration work required by application-level encryption. Hence, our approach combines the flexibility, security and independence from database vendors of application-level encryption and the transparency of database-level encryption. Our model-driven application-level encryption has been integrated into our eHealth Framework, a comprehensive platform for the development of electronic health care solutions. Our approach can be applied to other domains as well.
Towards a Privacy-Enhanced Social Networking Site	Social Networking Sites (SNS), such as Facebook and LinkedIn, have become the established place for keeping contact with old friends and meeting new acquaintances. As a result, a user leaves a big trail of personal information about him and his friends on the SNS, sometimes even without being aware of it. This information can lead to privacy drifts such as damaging his reputation and credibility, security risks (for instance identity theft) and profiling risks. In this paper, we first highlight some privacy issues raised by the growing development of SNS and identify clearly three privacy risks. While it may seem a priori that privacy and SNS are two antagonist concepts, we also identified some privacy criteria that SNS could fulfill in order to be more respectful of the privacy of their users. Finally, we introduce the concept of a Privacy-enhanced Social Networking Site (PSNS) and we describe Privacy Watch, our first implementation of a PSNS.
U-healthcare system protecting privacy based on cloaker	Recently, u-healthcare system has been widely used. Therefore many people are able to manage their health at anytime and anywhere. Especially, implantable device is used to care untreatable diseases. In u-healthcare environment with implantable device, privacy protection and secure access control mechanism support are important. When a patient wants to care at another hospital, implantable devices have to be accessed by doctor easily. However, these objectives are difficult to reconcile. To solve this problem, we propose u-healthcare system which provides a secure access control and protects the privacy of patient who uses implantable device.
PSSTΓÇª privacy, safety, security, and trust in health information websites	Various newsworthy incidents typically include breaches of security, invasion of privacy, and harm caused by false information. In the e-health domain, there has been a lot of focus on ethical issues when dealing with electronic health records (EHRs) and patient medical records (PMRs). However, equally important are the myriad of health information websites that are being used to formally or informally get medical advice online. This study surveys related work on three popular and pertinent issues in health information websites: privacy, security, and trust. Our contributions include a succinct survey of different categories of popular health information websites (WebMD.com, MayoClinic.com, KidsHealth.org, PatientsLikeMe. com) to gauge existing methods for handling these issues. Moreover, an agenda is proposed for understanding the three issues orthogonally via access control. Other outcomes of the study include recommendations for open problems identified in health websites, including the need for fine-grained privacy, security and trust controls.
Research on Privacy Protection Based on K-Anonymity	With the rising of data mining technology and the appearances of data stream and uncertain data technology etc, individual data, the enterprise data are possibly leaked at any moments, so the data security has become nowadays the main topic of information security. The common way to protect privacy is to use K-anonymity in data publishing. This paper will analyse comprehensively the current research situation of K-anonymity model used to prevent privacy leaked in data publishing, introduce the technology of K-anonymity, generalization and suppression, illustrate K-anonymity evaluation criterion, and assess many different algorithms used currently. Finally, the future directions in this field are discussed.
Recoverable concealed data aggregation for privacy preserving in wireless sensor networks	Data aggregation is one of the key technologies in the wireless sensor networks (WSNs). Moreover, the privacy of data must be preserved in WSNs. A privacy preserving data aggregation scheme is designed in the energy efficient manner in this paper. Based on the reflexivity property of the XOR operation, the original data obtained from sensor is sliced into several segments. Further, these slices are aggregated and transmitted to the sink node with the aid of nodes in the same region. Finally, the data can be reconstructed by the sink node according to the relation between slices. With our simple integrity check method, the accuracy of reconstructed data can be enhanced. We evaluate the performance of our proposed scheme in terms of communication overhead, computation overhead and privacy preservation, and these performances are compared with the typical data aggregation scheme, CPDA and iPDA respectively. Results show that the overhead can be reduced effectively by our proposed mechanism, and the scalability can also be guaranteed.
Protection of Patient's Privacy and Data Security in E-Health Services	E-Health involves new forms of patient-physician interaction and poses new ethical challenges and threats to patient privacy. This paper reviews Health On the Net Foundation Code of Conduct (HONcode) accredited e-Health websites that provide online appointment services in the U.S.A for compliance with basic principles of security and privacy. We found that 20 of 30 HON sites we reviewed are secure sites but only 8 of 20 secure sites state that it is secure. Most HON sites require patients to submit confidential data. 12 of 30 websites do not display privacy notice on the web appointment request page. The reading level might be a problem for the patients who have lower educational background to understand the privacy notice. Regulations and guidelines do not ensure that privacy protection and data security is done appropriately or well. More attention to security methods and procedures is needed to safeguard patients 'privacy rights.
Efficient Privacy of Message Encryption Algorithm for Anonymous Receivers in E-Commerce	Protecting the privacy of message receivers is an important issue in pay services of e-commerce and the distribution of digital contents on the Internet. This paper proposes an efficient privacy of message encryption algorithm called PMEA for pay services of e-commerce. In PMEA, each of the receivers only needs to perform constant times of pairing computation to decrypt the received message. PMEA adopts bilinear pairings on elliptic curves to protect the privacy of message receivers, to ensure that an attacker or any other message receiver can not derive the identity of a message receiver such that the privacy of every receiver can be guaranteed. Detailed theoretical analysis proves that PMEA is secure and anonymous for message receivers.
Privacy issues in publishing cancer-related stories in Cancer Patient Portal	This research investigated the privacy issues in publishing cancer stories among the public. Survey via questionnaires and interviews were conducted to help to understand the privacy concerns of the users especially among the cancer patients. Privacy in publishing is one of the key factors that will determine the success or failure of publishing service via Cancer Patient Portal. A good privacy for publishing service can be managed to attract and encourage the user to utilize the publishing service, raise user satisfaction levels and increase the return of investment of the service. The results of questionnaires and interviews after analysis reflect that users are willing to publish their experiences via publishing service in Cancer Patient Portal. We found that privacy factors have influenced on the willingness of users especially cancer patient using publishing service in Cancer Patient Portal.
Quantifying privacy and security of biometric fuzzy commitment	Fuzzy commitment is an efficient template protection algorithm that can improve security and safeguard privacy of biometrics. Existing theoretical security analysis has proved that although privacy leakage is unavoidable, perfect security from information-theoretical points of view is possible when bits extracted from biometric features are uniformly and independently distributed. Unfortunately, this strict condition is difficult to fulfill in practice. In many applications, dependency of binary features is ignored and security is thus suspected to be highly overestimated. This paper gives a comprehensive analysis on security and privacy of fuzzy commitment regarding empirical evaluation. The criteria representing requirements in practical applications are investigated and measured quantitatively in an existing protection system for 3D face recognition. The evaluation results show that a very significant reduction of security and enlargement of privacy leakage occur due to the dependency of biometric features. This work shows that in practice, one has to explicitly measure the security and privacy instead of trusting results under non-realistic assumptions.
RFID: Importance, privacy / security issues and implementation	RFID technology can be truly called old wine in new bottle as it is around the globe since 1940 but mainly in military domain. Lately high expectancy of users in automatic identification data collection, enormous gain and avenues offered by RFID attracted scientists, researcher and vendors to revamp this technology. Out of myriad of technologies emerging, RFID has attracted people from all walks of life. The objective of this research study is two fold; first and the foremost is to analyze this technology in depth and secondly propose its implementation in Pakistan's environment through the phase deployment of RFID systems. Cost of the equipment has not been worked out.
Addressing biometrics security and privacy related challenges in China	There has been significant advancement improvement in the capabilities of biometrics and data protection technologies in last decade. The significant reduction in cost, improvements in speed and accuracy has resulted in increased deployment of such technologies in day-to-day business and public utilities. The increasing use of biometrics and data protection technologies has also raised concern on the unethical use of personal information. There are increasing number of incidents and concerns in the public over the infringement of personal privacy in China. This paper has investigated such emerging privacy related concerns in the deployment of biometrics and data protection technologies in China. This paper also includes a study on public attitudes toward such technologies and attempts to make comparison with the same in the difference with such emerging concerns in other developed countries. This paper has developed an online survey to ascertain people's understanding on the various aspects of privacy and thus willingness to tradeoff with the benefits of increased security. The online survey was conducted in February - March 2012 and revealed great deal of information from the 305 Hong Kong people. We have attempted to analyze the survey results which illustrate interesting findings on the use of CCTV, biometrics technologies, social networking, disclosure of personal information and recent (2012) privacy policy adjustments in popular websites.
Face Based Biometric Authentication with Changeable and Privacy Preservable Templates	Changeability, privacy protection, and verification accuracy are important factors for widespread deployment of biometrics based authentication systems. In this paper, we introduce a method for effective combination of biometrics data with user specific secret key for human verification. The proposed approach is based on discretized random orthonormal transformation of biometrics features. It provides attractive properties of zero error rate, and generates revocable and non-invertible biometrics templates. In addition, we also present another scheme where no discretization procedure is involved. The proposed methods are well supported by mathematical analysis. The feasibility of the introduced solutions on a face verification problem is demonstrated using the well known ORL and GT database. Experimentation shows the effectiveness of the proposed methods comparing with existing works.
Towards Unattended and Privacy Protected Border Control	Biometric data have been integrated in all new European passports, since the member states of the European Union started to implement the EU Council Regulation No 2252/2004 on standards for security features and biometrics in passports. The additional integration of three-dimensional facial models promises significant performance enhancements for border control applications. By combining the geometry-and texture-channel information of the face, 3D face recognition systems provide improved robustness while being able to handle variations in poses and problematic lighting conditions during image acquisition. To assess the potential of three-dimensional face recognition, the 3D Face Integrated Project was initiated as part of the European Framework Program for collaborative research in April 2006. This paper outlines the research objectives and the approach of this project: Not only shall the recognition performance be increased but also a new, fake-resistant acquisition system is to be developed. In addition, methods for protection of the stored template data in the biometric reference are under development to enhance the privacy and security of the overall system. The use of multi-biometrics is also a key feature of the 3D Face project addressing the performance, robustness and flexibility targets of the system.
Dynamic biometrics: The case for a real-time solution to the problem of access control, privacy and security	From a certain perspective, security is broken. The security authorization triangle (possession, knowledge, identity) has in some cases been reduced to a single point (knowledge) because of the limitations to possession attributable to virtualization, and because of the limitations to identity attributable to the use of static biometrics. This paper makes the case for a stronger security rights triangle-privacy, security and access control-underpinned by the resurrection of possession and identity through the use of dynamic biometrics. New technologies in mobile and cloud computing, pattern recognition and user interaction provide a potential path forward for an identity-matching ecosystem in which both privacy and security needs can be accommodated.
Operational bio-hash to preserve privacy of fingerprint minutiae templates	The storage of fingerprints is an important issue as this biometric modality is more and more deployed for real applications. Considering minutiae templates as sensitive information, a key question concerns the secure and privacy management of this digital identity. Indeed, if an attacker obtains the minutiae template of a subject, he/she will be able to generate a fingerprint having the same characteristics. Instead of directly storing the minutiae templates, the authors propose in this study a new adaptation of BioHashing to generate a cancellable template in the context of un-ordered set of noisy minutiae features. To the authors knowledge, little interest has been paid in the literature to the question of protecting minutiae template by BioHashing until now. Using the FVC2002 benchmark database, they show the effectiveness of the proposed approach in term of privacy preservation. They show how the proposed method copes with irreversibility and diversity properties and therefore can be efficient in a realistic context.
Biometrics: Privacy and Social Acceptance	This tutorial will cover the ethics, privacy and security of biometrics. The first part, will address the concept of identity and its ethical implications. The concept of personal identity is important from several perspectives. From a cultural perspective, the more the world converges, the more individual cultures wish to maintain their separate identities. From an individual perspective, the greater the population and the tendency to reduce people to stereotypes, the greater the desire to establish an individual identity. There is, however, another level where identity and the verification of identity, is becoming increasingly important in relation to all manner of transactions, from those related to mobility, to those related to legal, and political, rights and obligations, finally to financial and economical transactions. The intrusion of technology into these areas is not new, but their heightened visibility and ubiquity can create anxiety. This holds particularly true for biometrics. The tutorial will then present the security and privacy issues with traditional biometrics, introduce the Biometrics Dilemma, various threats it poses and a model for biometric DB risk highlighting the problem with standard large-scale biometrics. The tutorial will explain why standard encryption does not solve the key problems, but also explore best practices in using standard encryption, which can improve security. Moving to security, the tutorial will examine security system architectures, the role of authentication in such systems and the standard architectures for authentication using biometrics. It will examine the advantages that biometrics bring, how biometrics can improve security and even privacy in such systems, and then discuss their weakness in both security and privacy. The tutorial will briefly discusses the Nobel Prize winning Economic theory of asymmetric information, Akerlof's market for lemons and Kerckhoffs' principles for security, and their implications for biometrics systems, especially large scale deployments. The last component the tutorial is an in-depth review of the state of the art in what is sometimes called biometric template protection, including biometric encryption, fuzzy vaults, fuzzy extractors, biometric hashing, and cancelable biometrics. The tutorial will walk through a security analysis of these technologies including the published attacks.
A privacy-compliant fingerprint recognition system based on homomorphic encryption and Fingercode templates	The privacy protection of the biometric data is an important research topic, especially in the case of distributed biometric systems. In this scenario, it is very important to guarantee that biometric data cannot be steeled by anyone, and that the biometric clients are unable to gather any information different from the single user verification/identification. In a biome╠ütrie system with high level of privacy compliance, also the server that processes the biome╠ütrie matching should not learn anything on the database and it should be impossible for the server to exploit the resulting matching values in order to extract any knowledge about the user presence or behavior. Within this conceptual framework, in this paper we propose a novel complete demonstrator based on a distributed biome╠ütrie system that is capable to protect the privacy of the individuals by exploiting cryptosystems. The implemented system computes the matching task in the encrypted domain by exploiting homomorphic encryption and using Fingercode templates. The paper describes the design methodology of the demonstrator and the obtained results. The demonstrator has been fully implemented and tested in real applicative conditions. Experimental results show that this method is feasible in the cases where the privacy of the data is more important than the accuracy of the system and the obtained computational time is satisfactory.
Slice-based architecture for biometrics: Prototype illustration on privacy preserving voice verification	This research investigates slice-based architecture for biometrics. A service slice is an aggregation of resources for a specific biometric objective; e.g., speaker verification. Slice-based architecture is attractive as a framework for modeling service-oriented biometric applications. In order for it to be usable, slice-based architecture must adequately address privacy, security, and standard based interoperability. We propose to incorporate secure computation mechanism and BioAPI standard into slice-based architecture. We discuss why secure computation is information-theoretic secure, and how it can be used to realize a private computation for the exchange of biometric data between two parties in slice-based architecture. For proof-of-concept, open source software is developed for realizing a privacy preserving voice verification prototype based on slice-based architecture, and will be released for experimentation by the public. The result of our initial experimentation is reported.
Privacy in Biometrics	This chapter contains sections titled: <br> Introduction <br> Biometric Traits and Privacy <br> Biometric Templates Protection <br> Privacy in Multimodal Systems <br> An Exemplifying Scheme <br> Conclusions <br> References
Conflict and Overlap in Privacy Regulation: National, International, and Private	This chapter contains sections titled: Introduction, Jurisdictional Conflicts, Tentative Steps toward International Coordination, Practical Problems of National Privacy Regulation, Conclusion, Notes
A new method of networked video surveillance with privacy area protection	Privacy area protection has become more important than before in networked video surveillance. In this paper, we address privacy area protection related issues. First, the characteristics of security camera with pan/tilt rotation mechanism are introduced and the privacy problems of video surveillance in public areas are analyzed. Then, a new method of protecting privacy areas is proposed to automatically adapt the panning rotation and tilting rotation of security camera. This method contains two steps to calculate the masked area matrix from predetermined privacy area matrix and some static/dynamic basic parameters. Experimental results have shown that the proposed method could work well in real-systems and protect the privacy areas efficiently.
The privacy-aware access control system using attribute-and role-based access control in private cloud	Cloud is a relatively new concept and so it is unsurprising that the information assurance, data protection, network security and privacy concerns have yet to be fully addressed. The cloud allows users to avoid upfront hardware and software investments, gain flexibility, collaborate with others, and take advantage of the sophisticated services. However, security is a huge issue for cloud users especially access control, user profile management and accessing services offered by the private cloud environment. A privacy enhancement system on Academic-based private cloud system using Eucalyptus open source cloud infrastructure has been proposed in this paper. This system provides the cloud users to improve the privacy and security of the private personal data. Two approaches (Role-based Access Control and Attribute-based Access Control model) are combined as a new approach (ARBAC). This means that they are applied to improve the privacy which supports both mandatory and discretionary access control needs on the target private cloud system.
An identity-based personal location system with protected privacy in IOT	The internet of things (IOT) has the same security requirements as traditional network, but according to the characteristics of its own, the internet of things also has some specific security features. Among these features, the flexibility of the network requires nodes to apply corresponding measures when scene changes. For example, in emergency situations (e.g. an accident occurs, and a doctor is needed), the location of the user is available, while under normal circumstances, the user's location information is confidential. This paper is in the background of the above scene to present an identity based system for personal location in emergency situations. The proposed system consists of registration subsystem, user authentication subsystem, policy subsystem and client subsystem. The system confirms the identity of the user through the user authentication subsystem and gets the level of the emergency through the policy subsystem. Then it can make sure that user's location information can be accessed only by some authorized user, and only when necessary. The proposed system strengthens the protection of the user's privacy while providing the location of the user, and prevents the disclosure of the users' information.
Privacy enhanced access control in pervasive computing environments	Privacy and security are two important but seemingly contradict objectives in pervasive computing environments (PCEs). On the one hand, service providers want to authenticate service users and make sure they are accessing only authorized services in a legitimate way. On the other hand, users want to maintain necessary privacy without being tracked down for wherever they are and whatever they are doing. In this paper we propose a novel privacy enhanced authentication and access control scheme to secure the interactions between mobile users and services in PCEs. The proposed scheme seamlessly integrates two underlying cryptographic primitives, blind signature and hash chain, into a highly flexible and lightweight authentication and key establishment protocol. It provides explicit mutual authentication between a user and a service, while allowing the user to anonymously interact with the service. Differentiated service access control is also enabled in the proposed scheme by classifying mobile users into different service groups.
Towards a Common Notion of Privacy Leakage on Public Database	Two different approaches to defining a notion of database privacy, the generalization method and the perturbation method, have been independently studied. These two approaches are significantly different, making it hard to compare related research. In this paper, we propose a unified model that is based on the perturbation method, but which is applicable to generalized data sets. In particular, this model applies the notion of differential privacy to data sets that satisfy k-anonymity. We demonstrate this approach through a simple case study. This is a first step towards a common notion for protecting database privacy.
Who Refuses to Wash Hands? Privacy Issues in Modern House Installation Networks	Modern buildings are often equipped with universal bus systems. The purpose of these bus systems is to control the functions of houses such as lighting, climate control, and heating. In this paper we present a case study that shows how privacy issues evolve out of an untypical utilization of those control systems. As a controversial example, we show that we are able to tell, who does not perform proper hand washing by sampling data from the control network and applying an old-fashioned Monte-Carlo simulation to the problem.
Privacy Preservation for Detecting Malicious Web Sites from Suspicious URLs	Some criminals and malcontents attempt to take advantage of others by using malicious web sites. As a result, many systems were developed to prevent the end user from visiting such malicious sites. A lot of approaches were used in these systems, e.g., blacklists were constructed by a range of techniques including manual reporting, honey pots, and Web crawlers. Inevitably, not all the malicious sites are blacklisted. Aim to this problem, some client-side systems were developed to analyze the content or behavior of a Web site as it is visited. But, the run-time overhead can not be avoided. Compared with these approaches, there has an efficient approach to detect malicious web sites. Whereas this approach can obtain 95-99% accuracy, the private information is needed. In this paper, a new strategy for detecting malicious web sites based on privacy preservation is proposed. We use structural partition and Singular Value Decomposition (SVD) technique to protect the private information. Then the Support Vector Machine (SVM) is used for evaluation. Our experimental results indicate that, in comparison with original method, the new strategy has the similar accuracy in detecting large numbers of malicious Web sites from their URLs.
Customizing Privacy Protection in Data Publishing	Distortion of data prior to publishing is one of the primary approaches to make sensitive data free of any illegal access or malicious use. Privacy customization has not been emphasized and well-studied in related literature. In this paper, data owners' preferences and data attributes' characteristics are taken into consideration. A privacy customization strategy is proposed and accomplished via a group distortion technique based on matrix decomposition. Several privacy and utility measures are studied. The performance of the proposed strategy is evaluated and compared to a conventional full distortion method. Our evaluation demonstrates that the proposed strategy has some attractive properties including an improved utility. In this way, a tradeoff between privacy and utility becomes more feasible.
Impact of privacy and security on users' trust in ubiquitous commerce	This paper investigates the factors that influencing the adoption of ubiquitous commerce (u-commerce) focusing on users' trust in privacy and security. Specifically, a framework is developed to show the interrelationships among users' trust, privacy and security on the adoption of u-commerce. The precedent factors that affecting privacy and security are also analyzed, including technology familiarity, social presence, and legislation and policy. A survey method is developed in order to quantitatively measure these factors. A pilot study shows that the majority of these measurements are important to the adoption of ubiquitous commerce. The results will be beneficial to managers and ubiquitous commerce developers when make decisions on the development of the system; and thereby, accelerate the adoption of ubiquitous commerce.
Adaptive binary mask for privacy region protection	Privacy region protection in video surveillance systems is an active topic at present. In previous research, a binary mask mechanism has been developed to indicate the privacy region; however this incurs a significant bitrate overhead. In this paper, an adaptive binary mask is proposed to represent the privacy region. In a practical privacy region protection application, in which the privacy region typically occupies less than half of the overall frame and is rectangular or approximately rectangular, the proposed adaptive binary mask can effectively reduce the bitrate overhead. The proposed method can also be easily applied to the FMO mechanism of H.264/AVC, providing both error resilience and a lower bitrate overhead.
Privacy Protection in Video Surveillance Systems: Analysis of Subband-Adaptive Scrambling in JPEG XR	This paper discusses a privacy-protected video surveillance system that makes use of JPEG extended range (JPEG XR). JPEG XR offers a low-complexity solution for the scalable coding of high-resolution images. To address privacy concerns, face regions are detected and scrambled in the transform domain, taking into account the quality and spatial scalability features of JPEG XR. Experiments were conducted to investigate the performance of our surveillance system, considering visual distortion, bit stream overhead, and security aspects. Our results demonstrate that subband-adaptive scrambling is able to conceal privacy-sensitive face regions with a feasible level of protection. In addition, our results show that subband-adaptive scrambling of face regions outperforms subband-adaptive scrambling of frames in terms of coding efficiency, except when low video bit rates are in use.
Scrambling for Privacy Protection in Video Surveillance Systems	In this paper, we address the problem of privacy protection in video surveillance. We introduce two efficient approaches to conceal regions of interest (ROIs) based on transform-domain or codestream-domain scrambling. In the first technique, the sign of selected transform coefficients is pseudorandomly flipped during encoding. In the second method, some bits of the codestream are pseudorandomly inverted. We address more specifically the cases of MPEG-4 as it is today the prevailing standard in video surveillance equipment. Simulations show that both techniques successfully hide private data in ROIs while the scene remains comprehensible. Additionally, the amount of noise introduced by the scrambling process can be adjusted. Finally, the impact on coding efficiency performance is small, and the required computational complexity is negligible.
Privacy Protected Surveillance Using Secure Visual Object Coding	<para> This paper presents the Secure Shape and Texture SPIHT (SecST-SPIHT) scheme for secure coding of arbitrarily shaped visual objects. The scheme can be employed in a privacy protected surveillance system, whereby visual objects are encrypted so that the content is only available to authorized personnel with the correct decryption key. The secure visual object coder employs shape and texture set partitioning in hierarchical trees (ST-SPIHT) along with a novel selective encryption scheme for efficient, secure storage and transmission of visual object shape and textures. The encryption is performed in the compressed domain and does not affect the rate-distortion performance of the coder. A separate parameter for each encrypted object controls the strength of the encryption versus required processing overhead. Security analyses are provided, demonstrating the confidentiality of both the encrypted and unencrypted portions of the secured output bit-stream, effectively securing the entire object shape and texture content. Experimental results showed that no object details are revealed to attackers who do not possess the correct decryption key. Using typical parameter values and output bit-rates, the SecST-SPIHT coder is shown to require encryption on less than 5% of the output bit-stream, a significant reduction in computational overhead compared to ΓÇ£whole contentΓÇ¥ encryption schemes. </para>
Privacy preserving data mining with unidirectional interaction	Privacy concerns over the ever-increasing gathering of personal information by various institutions led to the development of privacy preserving data mining. Two main approaches to privacy preserving data mining have emerged in recent years. The first approach protects the privacy of the data by perturbing the data through a random process. The second approach uses cryptographic techniques to perform secure multi-party computation. While the second approach is generally viewed as superior due to its strong assurance of privacy, there are reasons why it might not be appropriate in certain applications. For instance, in some cases, the data collection phase usually does not allow for complicated processing, such as ballots cast via the short message service. In other cases, such as paper surveys, the data flow is unidirectional from the survey taker to the survey collector. The requested data is sent once with no further interaction. In both these cases, the complicated computations and iterative interaction between data originators and data collectors that are required for secure multi-party computation cannot be used. We show how, in these cases, random perturbation of data can be a useful approach to privacy preserving data mining. In particular, we study a data perturbation scheme which was shown to have asymptotically small privacy loss and information loss. We illustrate the ideas using an example of a privacy preserving paper-based survey where no computation is done by the users. Finally, we apply this method to privacy preserving association rules mining.
A new model for privacy preserving multiparty collaborative data mining	Due to the increasing use of internet, the privacy of sensitive data in multiparty collaborative mining is a major issue. The group of participants contribute their own datasets and collaboratively involved to find quality model in multiparty collaborative mining. In this approach, each participant has sensitive and non-sensitive data in their local database. Therefore, an important challenge of privacy preserving collaborative data mining (PPCDM) is how multiple parties efficiently conduct data mining without exposing each participant's sensitive information. This paper proposes a new Binary Integer Programming model for multiparty collaborative data mining, which provide solutions to investigated problem of disclosure of sensitive data. In addition to that, maintaining confidentiality of the newly created pooled data by semantically secured ElGamal Encryption Scheme. Finally, Artificial Neural Network is used by the service provider in order to predict the patterns for data providers to identify the risk factors of colorectal cancer.
Key Research Issues for Privacy Protection and Preservation in Cloud Computing	Cloud computing promises an open and promising environment where customers or users can utilise and deploy IT services in a pay-as-you-go style while saving huge capital investments on their own IT infrastructure. The openness and virtualisation features in cloud environments make privacy protection and preservation be a challenging issue. Currently, in existing privacy protection and preservation fields, many approaches and methods have been investigated and presented to withstand different kinds of attackers and risks. On the basis of this, many researchers start to consider these in cloud environments. But current work is still at the early stage. Therefore, a systematic investigation and an overall classification of key issues in cloud privacy protection and preservation are necessary to keep current research on the right track while reducing unnecessary work as much as possible. Hence, in this paper, we investigate and classify various privacy issues in cloud environments. Especially, we focus on some key areas of cloud privacy protection and preservation from the perspective of cloud roles and cloud service levels. This paper can help to provide an overall picture of cloud privacy protection and preservation and point out potential key areas in cloud privacy protection and preservation.
A Consent-patienship Based Privacy Model for Healthcare	Managing privacy in healthcare is a difficult task. There are many needs conflicting each other and different groups have different opinions how information should be accessed. Information processing must be fluent and there is no room for steps to assure informed consent in every situation. In this paper we present a model how to manage privacy in healthcare. The model is based on consent and patient relationship. Originally it was created in 2006 but it has been modified after some experiences.
Privacy-Preserving Layer over MapReduce on Cloud	Cloud computing provides powerful and economical infrastructural resources for cloud users to handle ever-increasing Big Data with data-processing frameworks such as MapReduce. Based on cloud computing, the MapReduce framework has been widely adopted to process huge-volume data sets by various companies and organizations due to its salient features. Nevertheless, privacy concerns in MapReduce are aggravated because the privacy-sensitive information scattered among various data sets can be recovered with more ease when data and computational power are considerably abundant. Existing approaches employ techniques like access control or encryption to protect privacy in data processed by MapReduce. However, such techniques fail to preserve data privacy cost-effectively in some common scenarios where data are processed for data analytics, mining and sharing on cloud. As such, we propose a flexible, scalable, dynamical and costeffective privacy-preserving layer over the MapReduce framework in this paper. The layer ensures data privacy preservation and data utility under the given privacy requirements before data are further processed by subsequent MapReduce tasks. A corresponding prototype system is developed for the privacy-preserving layer as well.
Towards Privacy Preserving Mining over Distributed Cloud Databases	Due to great advances in computing and Internet technologies, organizations have been enabled to collect and generate a large amount of data. Most of these organizations tend to analyze their data to discover new patterns. Usually, analyzing such amount of data requires huge computational power and storage facilities that may not be available to these organizations. Cloud computing offers the best way to solve this problem. Storing the private data of different organizations in the same cloud server enhances the mining process, but at the same time, raises privacy concerns. Therefore, it is highly recommended to support privacy preserving data mining algorithms in the cloud environment. This paper introduces an efficient and accurate cryptography-based scheme for mining the cloud data in a secure way without loss of accuracy. Specifically, we address the problem of K-nearest neighbor (KNN) classification over horizontally distributed databases without revealing any unnecessary information. We have utilized the recently developed cryptography primitive, order preserving symmetric encryption (OPSE), to integrate securely the local classifications at a lower cost than the previously presented privacy preserving data mining schemes. Empirical results on real datasets demonstrate that the proposed scheme has similar performance with the naive mining systems in terms of classification accuracy.
A privacy-protecting file system on public cloud storage	With the development of cloud-based systems and applications, a number of major technical firms have started to provide public cloud storage services, and store user data in datacenters strategically positioned across the Internet. However, when users store private data in shared datacenters, they lose control over how the data are stored and accessed. Multiple classes of personnel may access the physical storage media and potentially read the data. While strong cryptographic methods can protect user files from unauthorized accesses, they incur computational overhead, and make it difficult for the infrastructure provider to optimize the storage space with effective compression and deduplication. To provide strong protection on user data, we design a new file system called BIFS (Bit-Interleaving File System). Focusing on the privacy protection of the on-disk state, BIFS re-orders data in user files at the bit level, and stores bit slices at distributed locations in the storage system. While providing strong privacy protection, BIFS still retains part of the regularity in user data, and thus enables the infrastructure provider to perform a certain level of space optimization (e.g., compression). We implement BIFS on the Amazon Simple Storage Service (S3), and examine its performance characteristics. The comparison with several existing network or Internet-based file systems shows that BIFS provides robust file system functions with satisfactory throughput on S3.
A Fast Privacy-Preserving Multi-keyword Search Scheme on Cloud Data	Nowadays, more and more people outsource their data to cloud servers for great flexibility and economic savings. Due to considerations on security, private data is usually protected by encryption before sending to cloud. How to utilize data efficiently while preserving user's privacy is a new challenge. In this paper, we focus on a efficient multi-keyword search scheme meeting a strict privacy requirement. First, we make a short review of two existing schemes supporting multi-keyword search, the kNN-based MRSE scheme and scheme based on bloom filter. Based on the kNN-based scheme, we propose an improved scheme. Our scheme adopt a product of three sparse matrix pairs instead of the original dense matrix pair to encrypt index, and thus get a significant improvement in efficiency. Then, we combine our improved scheme with bloom filter, and thus gain the ability for index updating. Simulation Experiments show proposed scheme indeed introduces low overhead on computation and storage.
Privacy Enhancing Framework on PaaS	Platform as a service (PaaS) is a cloud computing service model that provides a computing platform and a solution stack as an on-demand service, allowing users to create, deploy and control their own cloud services without building and managing their own computing platforms. PaaS providers provide the networks, servers and storages alongside with the PaaS platform. Though cloud computing is getting prevalence in IT, security, in particular privacy, has incurred the most concerns from users. Using a cloud service, a user has no privilege in managing the underlying computing platform nor the underlying resource and infrastructure, leading to the situation that a user has no way to monitor cloud services' behavior to protect the user's privacy. This paper proposes a privacy enhancing framework on PaaS for detecting the privacy violating behavior and protecting user's information instantly by enforcing related protection actions. The proposed framework allows customized security policies and behavior analysis models, enabling users to impose application oriented privacy monitoring mechanisms.
Efficient Query Processing on Outsourced Encrypted Data in Cloud with Privacy Preservation	Data outsourcing on to the public cloud faces several security challenges. Ensuring the confidentiality of the outsourced sensitive data is of paramount importance for the adoption of public cloud for data outsourcing. Often the cloud storage servers are untrusted. Encryption method is used for maintaining the confidentiality of the outsourced data. Performing the queries on the encrypted data is a challenging task. Adversary should not gain any significant information other than the minimal information by observing the queries and the query responses. In this work, we provide two solutions which are efficient in processing the queries on the encrypted data. We focus on improving the performance of the query processing without compromising the privacy of the data and the queries. We show that adversary can gain no significant information about the data other than the minimal information which cannot be avoided. We conduct the empirical performance evaluations and compare with the scheme available in the literature. Our experiments show that the proposed schemes are efficient in comparison with the existing scheme.
Ensuring Privacy in Data Storage as a Service for Educational Institution in Cloud Computing	Cloud computing is an emerging computing technology that allows us to implement their own services using on-demand IT infrastructures.1 The idea behind this approach is to provide a new model of infrastructure provisioning which can create elastic on-demand IT infrastructures according to the changing requirements. In our work we have proposed to use this on-demand service for data storage typically in an Educational Institution. But, this new technology suffers security issues. To solve this problem we have proposed to incorporate public audit ability and data dynamics for Data Storage as a Service with a Trusted Third Party auditor. Thus making the owners of the data to store their data remotely in the cloud data storage and thereby making them to enjoy on-demand high-quality data storage service from the shared pool of data storage.
My Private Cloud Overview: A Trust, Privacy and Security Infrastructure for the Cloud	Based on the assumption that cloud providers can be trusted (to a certain extent) we define a trust, security and privacy preserving infrastructure that relies on trusted cloud providers to operate properly. Working in tandem with legal agreements, our open source software supports: trust and reputation management, sticky policies with fine grained access controls, privacy preserving delegation of authority, federated identity management, different levels of assurance and configurable audit trails. Armed with these tools, cloud service providers are then able to offer a reliable privacy preserving infrastructure-as-a-service to their clients.
An Analysis of Security and Privacy Issues in Smart Grid Software Architectures on Clouds	Power utilities globally are increasingly upgrading to Smart Grids that use bi-directional communication with the consumer to enable an information-driven approach to distributed energy management. Clouds offer features well suited for Smart Grid software platforms and applications, such as elastic resources and shared services. However, the security and privacy concerns inherent in an information-rich Smart Grid environment are further exacerbated by their deployment on Clouds. Here, we present an analysis of security and privacy issues in a Smart Grids software architecture operating on different Cloud environments, in the form of a taxonomy. We use the Los Angeles Smart Grid Project that is underway in the largest U.S. municipal utility to drive this analysis that will benefit both Cloud practitioners targeting Smart Grid applications, and Cloud researchers investigating security and privacy.
A Home Healthcare System in the Cloud--Addressing Security and Privacy Challenges	Cloud computing is an emerging technology that is expected to support Internet scale critical applications which could be essential to the healthcare sector. Its scalability, resilience, adaptability, connectivity, cost reduction, and high performance features have high potential to lift the efficiency and quality of healthcare. However, it is also important to understand specific risks related to security and privacy that this technology brings. This paper focuses on a home healthcare system based on cloud computing. It introduces several use cases and draws an architecture based on the cloud. A comprehensive methodology is used to integrate security and privacy engineering process into the software development lifecycle. In particular, security and privacy challenges are identified in the proposed cloud-based home healthcare system. Moreover, a functional infrastructure plan is provided to demonstrate the integration between the proposed application architecture with the cloud infrastructure. Finally, the paper discusses several mitigation techniques putting the focus on patient-centric control and policy enforcement via cryptographic technologies, and consequently on digital rights management and attribute based encryption technologies.
Oruta: Privacy-Preserving Public Auditing for Shared Data in the Cloud	With cloud storage services, it is commonplace for data to be not only stored in the cloud, but also shared across multiple users. However, public auditing for such shared data - while preserving identity privacy - remains to be an open challenge. In this paper, we propose the first privacy-preserving mechanism that allows public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute the verification information needed to audit the integrity of shared data. With our mechanism, the identity of the signer on each block in shared data is kept private from a third party auditor (TPA), who is still able to verify the integrity of shared data without retrieving the entire file. Our experimental results demonstrate the effectiveness and efficiency of our proposed mechanism when auditing shared data.
CloudProtect: Managing Data Privacy in Cloud Applications	This paper describes the CloudProtect middleware that empowers users to encrypt sensitive data stored within various cloud applications. However, most web applications require data in plaintext for implementing the various functionalities and in general, do not support encrypted data management. Therefore, CloudProtect strives to carry out the data transformations (encryption/decryption) in a manner that is transparent to the application, i.e., preserves all functionalities of the application, including those that require data to be in plaintext. Additionally, CloudProtect allows users flexibility in trading off performance for security in order to let them optimally balance their privacy needs and usage-experience.
Security & Privacy Architecture as a service for Small and Medium Enterprises	This paper focuses on Security and Privacy for Small and Medium Enterprises pertaining to their dependency on small clouds to carry out their business activities. They lack the knowledge pertaining to the security to be applied to safeguard their data and services due to lack of in-house expert technical resources, security architects or less budgets to carry out the vulnerability study for them and to safeguard their data. Customers can rely on the services offered by the SMEs only if the hired services are secured. SMEs should have a proper understanding of the threats pertaining to the security aspect of the Software as a Service which they undertake. They should be able to investigate and asses the risk involved in showcasing their services on a cloud via the internet. The aim of this paper is to design a framework that brings out a Security & Privacy Architecture as a service for SMEs (SPAaaS) pertaining to Web Applications which can be offered by various security vendors. SPAaaS will assist the SMEs to evaluate the security requirements pertaining to host their data and services on cloud.
Security and privacy in cloud computing	After decades of engineering development, Internet connectivity has become a commodity product in many countries. The rapid adoption of Web 2.0 technologies such as blogging, online media sharing, social networking, and web-based collaboration has moved enormous quantities of data onto Internet servers. Along with this migration to web services has come a push for companies to adopt utility computing. Much like traditional infrastructure utilities, such as gas and electricity, utility or cloud computing seeks to abstract the supply of computing services from concerns of everyday users. Today, security and privacy concerns may represent the biggest hazards to moving services to external clouds. With cloud computing, data is stored and delivered over the Internet. The owner of the data does not control, and typically does not even know, the location of the data. There is a real chance that the owner's data could rest on the same resources as a competitor's application and data. In this paper I focus on how to secure cloud computing in terms of security and privacy.
SafeVanish: An Improved Data Self-Destruction for Protecting Data Privacy	In the background of cloud, self-destructing data mainly aims at protecting the data privacy. All the data and its copies will become destructed or unreadable after a user-specified period, without any user intervention. Besides, anyone cannot get the decryption key after timeout, neither the sender nor the receiver. The Washington's Vanish system is a system for self-destructing data under cloud computing, and it is vulnerable to ΓÇ£hopping attackΓÇ¥ and ΓÇ£sniffer attackΓÇ¥. We propose a new scheme in this paper, called Safe Vanish, to prevent hopping attacks by way of extending the length range of the key shares to increase the attack cost substantially, and do some improvement on the Shamir Secret Sharing algorithm implemented in the Original Vanish system. We present an improved approach against sniffing attacks by using the public key cryptosystem to protectt from sniffing operations. In addition, we evaluate analytically the functionality of the proposed Safe Vanish system.
A Privacy Impact Assessment Tool for Cloud Computing	In this paper, we present a Privacy Impact Assessment (PIA) decision support tool that can be integrated within a cloud computing environment. Privacy is an important consideration in cloud computing, as actual or perceived privacy weaknesses will impact legal compliance, data security, and user trust. A PIA is a systematic process for evaluating the possible future effects that a particular activity or proposal may have on an individual's privacy. It focuses on understanding the system, initiative or scheme, identifying and mitigating adverse privacy impacts and informing decision makers who must decide whether the project should proceed and in what form. A PIA, as a proactive business process, is thus properly distinguished from reactive processes, such as privacy issue analysis, privacy audits and privacy law compliance checking, applied to existing systems to ensure their continuing conformity with internal rules and external requirements.
Privacy, Security and Trust Issues Arising from Cloud Computing	Cloud computing is an emerging paradigm for large scale infrastructures. It has the advantage of reducing cost by sharing computing and storage resources, combined with an on-demand provisioning mechanism relying on a pay-per-use business model. These new features have a direct impact on the budgeting of IT budgeting but also affect traditional security, trust and privacy mechanisms. Many of these mechanisms are no longer adequate, but need to be rethought to fit this new paradigm. In this paper we assess how security, trust and privacy issues occur in the context of cloud computing and discuss ways in which they may be addressed.
Social Impact of Privacy in Cloud Computing	Cloud computing is emerging as a serious paradigm shift in the way we use computers. It relies on several technologies that are not new. However, the increasing availability of bandwidth allows new combinations and opens new IT perspectives. The data storage and processing power are being moved to more efficient and centralized structures over the web. Costs are being reduced with the loss of our data control as a trade-off. It will almost be inevitable for companies not to follow this trend. Yet, there are some important challenges to overcome. This paper discusses Cloud Computing concept concerning privacy and how it may affect our freedom of speech.
Privacy-preserving Collaborative Filtering for the Cloud	Rating-based collaborative filtering (CF) enables the prediction of the rating that a user will give to an item, based on the ratings of other items given by other users. However, doing this while preserving the privacy of rating data from individual users is a significant challenge. Several privacy preserving schemes have, so far been proposed in prior work. However, while these schemes are theoretically feasible, there are many practical implementation difficulties on real world public cloud computing platforms. In this paper, we approach the generalised problem of privacy preserving collaborative filtering from the cloud perspective and propose an efficient and secure approach that is built for the cloud. We present our implementation experiences and experimental results based on the Google App Engine for Java (GAE/J) cloud platform.
A study on the data privacy and operation performance for cloud collaborative editing systems	This paper deals with the problem of collaboratively secure document editing in cloud environment. Using cloud document editing service, several users can create and edit a document collaboratively. However, as the cloud service provider is not trusted to guarantee the confidentiality of these documents, existing methods encrypt the documents before uploading them to the cloud. While these approaches can be inefficient for collaborative editing, we propose to organize the content of a document using a Red-Black tree and encrypt each block of data separately, so as to improve the performance of collaborative editing systems. Although creating and maintaining the Red-Black tree introduces extra cost, compared to the whole document encryption strategy the experimental results show that for text editing operations, such as insertion and removal, the use of Red-Black tree algorithm improves efficiency by 31.04% if 3DES encryption is applied and by 23.94% if applying AES encryption.
Integrating OpenID with proxy re-encryption to enhance privacy in cloud-based identity services	The inclusion of identity management in the cloud computing landscape represents a new business opportunity for providing what has been called Identity Management as a Service (IDaaS). Nevertheless, IDaaS introduces the same kind of problems regarding privacy and data confidentiality as other cloud services; on top of that, the nature of the outsourced information (users' identity) is critical. Traditionally, cloud services (including IDaaS) rely only on SLAs and security policies to protect the data, but these measures have proven insufficient in some cases; recent research has employed advanced cryptographic mechanisms as an additional safeguard. Apart from this, there are several identity management schemes that could be used for realizing IDaaS systems in the cloud; among them, OpenID has gained crescent popularity because of its open and decentralized nature, which makes it a prime candidate for this task. In this paper we demonstrate how a privacy-preserving IDaaS system can be implemented using OpenID Attribute Exchange and a proxy re-encryption scheme. Our prototype enables an identity provider to serve attributes to other parties without being able to read their values. This proposal constitutes a novel contribution to both privacy and identity management fields. Finally, we discuss the performance and economical viability of our proposal.
Towards privacy-preserving image template matching in the clouds	Template matching is a fundamental building block for image search operations. In this paper, we present a scheme that allows privacy-preserving template matching operations on images that are stored on clouds. Our scheme uses ΓÇ£ambient image dataΓÇ¥ (images that are found in social media sites such as Flickr) as well as a privacy-preserving encoding technique to encode a given image before it is stored in a cloud. We show a particular encoding strategy that allows template matching to take place in the cloud while not revealing any information about the image or queried template to the cloud. A simplified prototype of the image processing system was implemented and the experimental results are presented in this paper. Our prototype shows the feasibility of performing privacy-aware template matching on encoded images.
Privacy control in the cloud based on multilevel policy enforcement	The cloud computing paradigm is revolutionizing the delivery of information services as it offers several advantages in terms of cost reduction, time-to-market and flexibility. However, such flexibility raises many concerns related to security and privacy which are strong obstacles for the large adoption of the cloud by users who have to delegate too much control to the cloud provider. In this paper, we propose a new privacy control approach notably based on multilevel privacy policies bound to user data and enforced in the cloud at different levels (application and infrastructure). This approach allows the cloud users to control their data stored, processed and moved in the cloud.
Limited Negative Surveys: Privacy-preserving participatory sensing	Participatory sensing is a crowd-sourcing technique that relies on participants' active contribution. By aggregating data sets from each participant, we can collect statistical information of the environment or phenomenona in the cloud. To promote use of participatory sensing in healthcare, research, and other useful applications, the protection of privacy is important to consider. The invasion of privacy in participatory sensing would have dire consequences because mobile phone used by these applications have sensitive data about users daily life. In this paper, we suggest a privacy-preserving participatory sensing scheme for real-world data sets with large numbers of categories by using Limited Negative Surveys. By using our method described in this paper, the server can reconstruct the probability distributions of the original distributions of sensed values without knowing the personal information of citizens. Furthermore, our research has the capablity to change, according to the features of data, especially the number of categories. We evaluate how this scheme of aggregate information can be still useful while protecting the privacy of users' original data.
Privacy-preserving association rule mining in large-scale distributed systems	Data privacy is a major concern that threatens the widespread deployment of data Grids in domains such as health-care and finance. We propose a unique approach for obtaining knowledge, by way of a data mining model, from a data Grid, while ensuring that the data is cryptographically safe. This is made possible by an innovative, yet natural generalization for the accepted trusted third party model and a new privacy-preserving data mining algorithm that is suitable for Grid-scale systems. The algorithm is asynchronous, involves no global communication patterns, and dynamically adjusts to changes in the data or to the failure and recovery of resources. To the best of our knowledge, this is the first privacy-preserving mining algorithm to possess these features. Simulations of thousands of resources prove that our algorithm quickly converges to the correct result while using reasonable communication. The simulations also prove that the effect of the privacy parameter on both the convergence time and the number of messages, is logarithmic.
Using Policy-Based Management for Privacy-Enhancing Data Access and Usage Control in Grid Environments	Preventing the misuse of personally identifiable information and preserving user privacy are key issues in the management of IT services, especially when organizational borders are crossed. In this paper, we first present an analysis of the differences between grid environments and previous models of inter-organizational collaboration. Based on requirements derived thereof, we demonstrate how existing policy-based privacy management architectures can be extended to provide grid-specific functionality and can be integrated into existing infrastructures. Special emphasis is put on privacy policies which can be configured by users themselves, and distinguishing between the initial data access and the later data usage control phases. We also discuss the application of this approach to a XACML-based privacy management system.
Privacy Preserving Access Control with Authentication for Securing Data in Clouds	In this paper, we propose a new privacy preserving authenticated access control scheme for securing data in clouds. In the proposed scheme, the cloud verifies the authenticity of the user without knowing the user's identity before storing information. Our scheme also has the added feature of access control in which only valid users are able to decrypt the stored information. The scheme prevents replay attacks and supports creation, modification, and reading data stored in the cloud. Moreover, our authentication and access control scheme is decentralized and robust, unlike other access control schemes designed for clouds which are centralized. The communication, computation, and storage overheads are comparable to centralized approaches.
A Time-Series Pattern Based Noise Generation Strategy for Privacy Protection in Cloud Computing	Cloud computing promises an open environment where customers can deploy IT services in a pay-as-you-go fashion while saving huge capital investment in their own IT infrastructure. Due to the openness, various malicious service providers may exist. Such service providers may record service information in a service process from a customer and then collectively deduce the customer's private information. Therefore, from the perspective of cloud computing security, there is a need to take special actions to protect privacy at client sides. Noise obfuscation is an effective approach in this regard by utilising noise data. For instance, it generates and injects noise service requests into real customer service requests so that service providers would not be able to distinguish which requests are real ones if their occurrence probabilities are about the same. However, existing typical noise generation strategies mainly focus on the entire service usage period to achieve about the same final occurrence probabilities of service requests. In fact, such probabilities can fluctuate in a time interval such as three months and may significantly differ than other time intervals. In this case, service providers may still be able to deduce the customers' privacy from a specific time interval although unlikely from the overall period. That is to say, the existing typical noise generation strategies could fail to protect customers' privacy for local time intervals. To address this problem, we develop a novel time-series pattern based noise generation strategy. Firstly, we analyse previous probability fluctuations and propose a group of time-series patterns for predicting future fluctuated probabilities. Then, based on these patterns, we present our strategy by forecasting future occurrence probabilities of real service requests and generating noise requests to reach about the same final probabilities in the next time interval. The simulation evaluation demonstrates that our strateg- can cope with these fluctuations to significantly improve the effectiveness of customers' privacy protection.
Protect mobile RFID location privacy using dynamic identity	To protect data and location privacy of an RFID user, the transmitted sensitive information of RIFD tags must be encrypted and unpredictable. The previous approaches to protect user privacy for RFID are classified into authentication-based schemes, encryption-based schemes, and dynamic identity schemes. However, authentication-based schemes are easily broken. Because low-cost RFID tags are not tamper-resistant, the key for the authentication protocol cannot be well protected. Encryption-based schemes can protect data privacy but location privacy is still vulnerable due to fixed cipertext. Although dynamic identity schemes have chance to overcome the previous problems, but dynamic identity schemes are limited by exhaustive search problem. And, the cost of RFID tags is very limited. In this paper, we proposed a lightweight dynamic identity based RFID authentication scheme to protect both data privacy and location privacy. And we use the GNY logic analysis to show the proposed scheme can against threats of replay attacks, spoofing, man-in-the-middle, and message loss.
Privacy-preserving collaborative filtering based on horizontally partitioned dataset	Nowadays, recommender systems have been increasingly used by companies to improve their services. Such systems are employed by companies in order to satisfy their existing customers and attract new ones. However, many small or medium companies do not possess adequate customer data to generate satisfactory recommendations. To solve this problem, we propose that the companies should generate recommendations based on a joint set of customer data. For this purpose, we present a privacy-preserving collaborative filtering algorithm, which allows one company to generate recommendations based on its own customer data and the customer data from other companies. The security property is based on rigorous cryptographic techniques, and guarantees that no company will leak its customer data to others. In practice, such a guarantee not only protects companies' business incentives but also makes the operation compliant with privacy regulations. To obtain precise performance figures, we implement a prototype of the proposed solution in C++. The experimental results show that the proposed solution achieves significant accuracy difference in the generated recommendations.
Method for privacy-protecting display and exchange of emergency information on Mobile devices	First responders and emergency care providers make life or death decisions with little to no information about patient's medical problems. Access to a person's medical record could greatly improve the medical care they receive. Challenges to proving this information include finding the correct platform and protecting the patient's privacy. Current solutions are lacking in both these areas. Here we propose leveraging smartphone sensor and matrix barcode technology to allow users to securely encode sensitive information using the widely accepted Quick Response code standard. Placing this code on the phone's lock-screen removes the need to unlock the phone and search for it. Our solution lets users decode information, automatically notify authorized contacts of the nature of the emergency, and location where the patient is being cared for. Future research work will explore utilizing near field communication interfaces to augment the app's features for ease of use.
Cryptographic framework for analyzing the privacy of recommender algorithms	Recommender algorithms are widely used, ranging from traditional Video on Demand to a wide variety of Web 2.0 services. Unfortunately, the related privacy concerns have not received much attention. In this paper, we study the privacy concerns associated with recommender algorithms and present a cryptographic security model to formulate the privacy properties. We propose two privacy-preserving content-based recommender algorithms and prove their properties. Moreover, we show the potential weakness in some existing collaborative filtering algorithms which claim to provide privacy protection.
Protecting patient privacy in distributed collaborative healthcare environments by retaining access control of shared information	Access control and privacy policies change during the course of collaboration. Information is often shared with collaborators outside of the traditional ΓÇ£perimeterizedΓÇ¥ organizational computer network. At this point the information owner (in the legal data protection sense) loses persistent control over their information. They cannot modify the policy that controls who accesses it, and have that enforced on the information wherever it resides. However, if patient consent is withdrawn or if the collaboration comes to an end naturally, or prematurely, the owner may be required to withdraw further access to their information. This paper presents a system that enhances the way access control technology is currently deployed so that information owners retain control of their access control and privacy policies, even after information has been shared.
Global privacy and transportation mode homogeneity anonymization in location based mobile systems with continuous queries	A major concern for deployment of location-based mobile systems is the ill-usage of mobile client's location data, which may imply sensitive and private personal information. Also, even if the location is exposed willingly by the mobile client the query should not be linked to the mobile client. Still, many location based systems (store finders, transit itinerary systems, and social networks) are created with a different focus and have little concern for end user privacy. We focused on location based mobile systems where the location of the mobile user may be available; however, an adversary should not be able to link a query to a specific mobile user. Two key contributions of this work are the introduction and experimental evaluation of a novel concept called transportation mode homogeneity anonymization that adds another dimension to privacy in mobile location based systems. Also, a novel dynamic layered approach on achieving K-anonymity by separating the local privacy requirement on each snapshot and global privacy requirement across snapshots with different privacy goals is proposed to exploit the local privacy anonymization group as candidates to obtain global anonymization group candidates.
A collaborative framework for privacy protection in online social networks	With the wide use of online social networks (OSNs), the problem of data privacy has attracted much attention. Several approaches have been proposed to address this issue. One of privacy management approaches for OSN leverages a key management technique to enable a user to simply post encrypted contents so that only users who can satisfy the associate security policy can derive the key to access the data. However, the key management policies of existing schemes may grant access to unauthorized users and cannot efficiently determine authorized users. In this paper, we propose a collaborative framework which enforces access control for OSN through an innovative key management focused on communities. This framework introduces a community key management based on a new group-oriented convergence cryptosystem, as well as provides an efficient privacy preservation needed in a private OSN. To prove the feasibility of our approach, we also discuss a proof-of-concept implementation of our framework. Experimental results show that our construction can achieve the identified design goals for OSNs with the acceptable performance.
Patient-Centric Privacy: Envisioning collaboration between payers, providers & patients with the patient at the core	Protection of personal healthcare information (PHI) has been as a significant hindrance to the acceptance, adoption and continued use of healthcare information technology (HIT). As nations and corporations encourage innovation in the healthcare sector for better outcomes for all its stakeholders, they are proceeding under a latent assumption - the equation of data stewardship with data ownership. This notion relegates the patient to the role of information provider and empowers infrastructure owners with data ownership rights. In this paper, we introduce Patient-Centric Privacy, which refers to 1) the recognition that patients are a fundamental and integral part of the disclosure, access and use processes, and 2) to the ability of the patient to control the release of their healthcare information.
m-Privacy for collaborative data publishing	In this paper, we consider the collaborative data publishing problem for anonymizing horizontally partitioned data at multiple data providers. We consider a new type of "insider attack" by colluding data providers who may use their own data records (a subset of the overall data) in addition to the external background knowledge to infer the data records contributed by other data providers. The paper addresses this new threat and makes several contributions. First, we introduce the notion of m-privacy, which guarantees that the anonymized data satisfies a given privacy constraint against any group of up to m colluding data providers. Second, we present heuristic algorithms exploiting the equivalence group monotonicity of privacy constraints and adaptive ordering techniques for efficiently checking m-privacy given a set of records. Finally, we present a data provider-aware anonymization algorithm with adaptive m- privacy checking strategies to ensure high utility and m-privacy of anonymized data with efficiency. Experiments on real-life datasets suggest that our approach achieves better or comparable utility and efficiency than existing and baseline algorithms while providing m-privacy guarantee.
PrIvacy Risks And Countermeasures In Publishing And Mining Social Network Data	As interests in sharing and mining social network data continue to grow, we see a growing demand for privacy preserving social network data publishing. In this paper, we discuss privacy risks in publishing social network data and the design principles for developing countermeasures. The main contributions of this study are three folds. First, to the best of our knowledge, we make the first attempt to define the utility of released data in terms of exposure levels and query types, assuming queries are the most fundamental operations in social network analysis. We argue that using information exposure levels to characterize the utility of anonymized data can be used as a general and usage-neutral metric and query types can be used as the baseline usage driven utility metric. Second, we identify two types of background knowledge based inference attacks that can break some of most representative graph permutation based anonymization techniques in terms of anonymity violations. Third but not the least, we describe some design considerations for developing countermeasures in privacy preserving social network data publishing.
Towards privacy preserving access control in the cloud	It is very costly and cumbersome to manage database systems in-house especially for small or medium organizations. Data-as-a-Service (DaaS) hosted in the cloud provides an attractive solution, which is flexible, reliable, easy and economical to operate, for such organizations. However security and privacy issues concerning the storage of the data in the cloud and access via the Internet have been major concerns for many organizations. The data and the human resources are the life blood of any organization. Hence, they should be strongly protected. In this paper, we identify the challenges in securing DaaS model and propose a system called CloudMask that lays the foundation for organizations to enjoy all the benefits of hosting their data in the cloud while at the same time supporting fine-grained and flexible access control for shared data hosted in the cloud.
Privacy through web-traveler policies in social network environments	Social networking sites are ingrained in the fabric of our day-to-day lives, with these sites being widely used to exchange personal information and content. Some forms of access control are provided by the sites themselves to protect the user-uploaded content. However, these types of control are limited in that they require the user's input for the effective protection, otherwise a default policy which provides minimal protection is often applied. Towards providing extended content protection, in this paper we propose an approach for automated user-uploaded content control. Automatic enforcement allows us to extend the protection of content for unprotected files, preventing underage viewers from accessing adult content, tracking stolen or misused copyright-free images. This work builds upon the notion of `Web-Traveler policies', previously introduced as a new class of content control policies. In the paper, we also provide a proof of concept implementation of our algorithms for automatic propagation for images in order to prove the applicability and strength of our approach.
Privacy-preserving assessment of social network data trustworthiness	Extracting useful knowledge from social network datasets is a challenging problem. To add to the difficulty of this problem, privacy concerns that exist for many social network datasets have restricted the ability to analyze these networks and consequently to maximize the knowledge that can be extracted from them. This paper addresses this issue by introducing the problem of data trustworthiness in social networks when repositories of anonymized social networks exist that can be used to assess such trustworthiness. Three trust score computation models (absolute, relative, and weighted) that can be instantiated for specific anonymization models are defined and algorithms to calculate these trust scores are developed. Using both real and synthetic social networks, the usefulness of the trust score computation is validated through a series of experiments.
L2TAP+SCIP: An audit-based privacy framework leveraging Linked Data	We describe a framework designed to facilitate privacy auditing while accommodating a variety of privacy scenarios and policies that involve multiple participants. Our proposal is based on two ontologies, L2TAP and SCIP, designed for deployment in a Linked Data environment. L2TAP provides provenance enabled logging of events. SCIP synthesizes contextual integrity concepts and enables query based solutions for two important privacy processes (compliance and obligation derivation). We include an experimental validation of the scalability of our approach.
Sensor source location privacy based on random perturbations	Sensor source location privacy, which means to protect source sensors' locations of network traffic, is an emerging topic in wireless sensor networks, because it cannot be fully addressed by traditional cryptographic mechanisms, such as encryption and authentication. Current source location privacy schemes, assuming either a local attack model or a global attack model, have limitations. For example, schemes under a global attack model are subject to a so called `01' attack. Targeting on solving this attack under a global attack model, we propose two perturbation schemes, one based on Uniform distribution and the other based on Gaussian distribution. We analyze the security properties of these two schemes. We also simulate them and compare them with previous schemes, with the results showing that the proposed perturbation schemes can improve the source location privacy significantly.
Automatic social group organization and privacy management	With the dramatic increase of users on social network websites, the needs to assist users to manage their large number of contacts as well as providing privacy protection become more and more evident. Unfortunately, limited tools are available to address such needs and reduce users' workload on managing their social relationships. To tackle this issue, we propose an approach to facilitate online social network users to group their contacts into social circles with common interests. Further, we leverage the social group practice to automate the privacy setting process for users who add new contacts or upload new data items. We conducted a user study to evaluate the effectiveness of our solution.
An architecture and key management approach for maintaining privacy in location based group services	Location based services are becoming increasingly important to the success and attractiveness of next generation wireless systems. Service providers will use location information to introduce new services and greatly enhance many existing services. Maintaining location privacy is an important requirement that must be met for these services to be widely deployed. It is a challenge to maintain location privacy while still providing the flexible access to location information required to enable a rich set of location based services. In this paper we define a high-level architecture for providing LBS and classify services according to several basic criteria. To support these services we propose a hierarchical key distribution method. Four methods are proposed to deliver hierarchical location information while maintaining privacy. We evaluate the efficiency of the system in terms of message delivery and key management overhead
Information Security, Privacy and Confidentiality National Science Foundation's Past and Current Funding Profile and Future Opportunities	Summary form only given. National Science Foundation (NSF) has a long-standing interest in protecting, enhancing and evaluating information security, privacy and confidentiality in information systems. The interest is broad including new architectures, algorithms, data collection and evaluation methods. All these are in recognition of newly emerging environments and applications (e.g. pervasive computing, mobile, sensor and distributed databases, discovery and handling of future threats), newly emerging requirements and increasing public interest in this topic. This paper discusses NSF's past and current funding profile and future funding opportunities for secure information systems research
Controlled sharing of identity attributes for better privacy	In recent years user centricity has drawn a lot of attention as a promising component to advance federated identity management (FIM) systems. The basic notion is to give users a larger degree of control over their attribute data that comprises digital identities on a federated network, thus providing an ideal mechanism for upholding user privacy. One of the fundamental problems facing user centricity in this context is how a user can selectively share her identity attributes certified by an identity provider (IdP) to a service provider (SP). In this paper we present an approach to addressing the problem, which allows a user to share only selected attributes from a larger set of attributes that form his digital identity credential for better privacy. Our approach enables such sharing to occur without IdPpsilas intervention in every transaction.
CollaborateCom 2007 Yuecel Karabulut, SAP research - Security & privacy in collaboration	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04553843.png" border="0">
User-centric privacy management for federated identity management	We have witnessed that the Internet is now a prime vehicle for business, community, and personal interactions. The notion of identity is the important component of this vehicle. Identity management has been recently considered to be a viable solution for simplifying user management across enterprise applications. The network identity of each user is the global set of personal credentials and preferences constituting the various accounts. The prevalence of business alliances or coalitions necessitates the further evolution of identity management, named federated identity management (FIM). The main motivation of FIM is to facilitate the federation of identities among business partners emphasizing on ease of user management. In this paper, we propose systematic mechanisms to specify privacy preferences in FIM, attempting to help users facilitate preferences for managing their private information across domains.
The TLC-PP framework for delivering a Privacy Augmented Collaborative Environment (PACE)	In order to preserve privacy in electronic collaborative environments a comprehensive multidimensional privacy protecting framework is required. Such information privacy and personal data management solutions for collaborations must incorporate a number of factors and influences in order to provide a holistic information privacy solution. Our technical, legal, and community privacy protecting (TLC-PP) framework addresses the problems associated with the multi-facetted notion of privacy. The three key components of the TLC-PP framework are merged together to provide robust privacy solutions for collaborative environment stakeholders and users alike. The application of the TLC-PP framework provides a significant contribution to the delivery of a privacy augmented collaborative environment (PACE).
CollaborateCom 2007 Track titleSession Chair: Yuecel Karabulut, SAP Research - Privacy & trust in collaboration	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04553828.png" border="0">
Privacy protection on sliding window of data streams	In many applications, transaction data arrive in the form of high speed data streams. These data contain a lot of information about customers that needs to be carefully managed to protect customerspsila privacy. In this paper, we consider the problem of preserving customerpsilas privacy on the sliding window of transaction data streams. This problem is challenging because sliding window is updated frequently and rapidly. We propose a novel approach, SWAF (sliding window anonymization framework), to solve this problem by continuously facilitating k-anonymity on the sliding window. Three advantages make SWAF practical: (1) Small processing time for each tuple of data steam. (2) Small memory requirement. (3) Both privacy protection and utility of anonymized sliding window are carefully considered. Theoretical analysis and experimental results show that SWAF is efficient and effective.
Enforcing relationships privacy through collaborative access control in web-based Social Networks	Web-based social networks (WBSNs) are today one of the hugest data source available on the Web and therefore data protection has become an urgent need. This has resulted in the proposals of some access control models for social networks. Quite all the models proposed so far enforce a relationship-based access control, where the granting of a resource depends on the relationships established in the network. An important issue is therefore to devise access control mechanisms able to enforce relationship-based access control by, at the same time, protecting relationships privacy. In this paper, we propose a solution to this problem, which enforces access control through a collaboration of selected nodes in the network. We exploit the ElGamal cryptosystem to preserve relationship privacy when relationship information is used for access control purposes.
Towards automatic privacy management in Web 2.0 with semantic analysis on annotations	Sharing personal information and documents is pervasive in Web 2.0 environments, which creates the need for properly controlling shared data. Most existing authorization and policy management systems are for organizational use by IT professionals. Average Web users, however, do not have the sophistication to specify and maintain privacy policies for their shared content. In this paper, we aim to utilize personal and social annotations to develop automatic tools for managing content sharing, and demonstrate a new application of social annotations in access control. We use annotation data to predict privacy preferences of users and automatically derive policies for shared content. We carry out a series of user studies to evaluate the accuracy of our predicted techniques. We also perform extensive analysis on static and dynamic approaches of analyzing semantic similarities of tags, which is of independent interest. Our analysis gives encouraging results on the feasibility of using annotations for privacy management in Web 2.0.
A collaborative k-anonymity approach for location privacy in location-based services	Considering the growth of wireless communication and mobile positioning technologies, location-based services (LBSs) have been generating increasing research interest in recent years. One of the critical issues for the deployment of LBS applications is how to reconcile their quality of service with privacy concerns. Location privacy based on k-anonymity is a very common way to hide the real locations of the users from the LBS provider. Several k-anonymity approaches have been proposed in the literature, each with some drawbacks. They need either a trusted third party or the users (or providers) to trust each other in collaborative approaches. In this paper, we propose a collaborative approach that provides k-anonymity in a distributed manner and does not require a trusted third party nor the users (or providers) to trust each other. Furthermore, our approach integrates well with the existing communication infrastructure. A user's location is known to only his/her location provider (e.g., cell phone operator). By using cryptographic schemes, user with the help of location providers determines whether the k-anonymity property is satisfied in a query area or not. We start with a simple scenario where user and location providers are honest-but-curious and then we progressively extend our protocol to deal with scenarios where entities may collude with each other. Moreover, we analyze possible threats and discuss how our proposed approach defends against such threats.
Payment and privacy: A key for the development of NFC mobile	This paper first introduces a possible evolution of secure personal identification devices, based on RFID technology in the mobiles phones (NFC). Given the characteristics of the mobile phone market, this trend could grow quickly and importantly. This paper considers the possible impact of this evolution in term of privacy, focusing on a typical and important case: payment transactions. This paper sticks to the general approach and role of ΓÇ£card payment systemΓÇ¥. Yet, it demonstrates that it is possible to improve some of the privacy characteristics of this kind of application. It also outlines the way payment protocol should be designed in order to reach this goal.
Research issues in Privacy-preserving Record Linkage	Record linkage from multiple, independent and heterogeneous databases is a major area of database research. However, little attention has been paid to the privacy concerns of colluding databases. Activities such as sharing data for scientific research, monitoring disease symptoms over a region or developing large e-commerce market place, all require large scale data integration among different organizations. Legitimate concerns over data security and privacy have caused organizations to be reluctant to collaborate in any data sharing protocol; thus a data integration protocol applicable for private databases is needed. Privacy-preserving Record Linkage (PRL) deals with the development of such a protocol. This paper presents the PRL key ideas and research challenges.
Personal data anonymization for security and privacy in collaborative environments	Nowadays, more and more applications use sensitive and personal information. Subsequently, hiding identities and respecting citizens' privacy are becoming extremely important. Dedicated to this issue, this paper is organized as follows: after defining the topic through an example of collaborative complex and heterogeneous system, this paper analyzes the most typical anonymization procedures. Afterwards it proposes a rigorous approach to define anonymization requirements, as well as how to characterize, select and build solutions. Finally, a new generic procedure to anonymize and link identities is proposed. We suggest that a critical part of this procedure is carried out in a smart card. According to needs, anonymized data are processed through cryptographic transformations in several organizations. Our solution is suitable to collaborative environments; guarantees the user's consent; resists dictionary attacks; respects the least privilege principle and thus fulfils the legislation requirements. Moreover, it remains flexible, adaptable to different fields, and supports some organizational changes like the merging of several systems
A collaborative distributed privacy-sensitive decision support system for monitoring heterogeneous data sources	This paper introduces MCDS, a multi-organizational collaborative decision support system that makes an effort to support seamless integration of humans and software agents for collaborative emergency preparedness and threat management in a distributed multi-party environment with heterogeneous social and organizational cultures. MCDS offers mechanisms for systematic detection, tracking, and management of emerging threat-structures in the context of the existing assets, algorithms for mining distributed multi-party data in a privacy-sensitive manner, archival and retrieval of case histories, and relevance feedback-based personalization. The paper provides an overview of a few modules and describes two ongoing applications of this collaborative problem solving technology
Role-based consistency verification for privacy-aware Web services	Web services collaborative environments are highly automatic, dynamic, heterogeneous, and full of cheating. These characteristics always lead to high risks of the services for the interaction participants. Hence, to guarantee that the private data in Cross-Organizational collaborative applications are not illegally collected and disclosed becomes a key for implementing the security services collaboration. In order to improve the reliability of the system, it is necessary in privacy-aware Web services collaboration systems to verify whether the implementation of a set of services satisfies the requirement specification of the system. This paper proposes a role-based privacy-aware Web services collaborative model, which delegates the privacy authorization based on trust relationships of services and then presents algorithms to make the consistency verification between the requirement specification and the implementation services. Finally, this paper verifies the correctness and efficiency of the role-based approach through an application example.
Privacy in Service Oriented Architectures: SOA Boundary Identity Masking for Enterprises	Sensitive data is increasingly proliferating due to outsourcing, application service provisioning, cloud computing and so on. The control of such data is increasingly crucial for enterprises, because of regulatory scrutiny, data privacy concerns, and so on. One approach to confine storing and processing sensitive data is our Boundary Identity Masking approach [1], in which a key-value token substitution ensures that sensitive data in its clear-text representation is available only within a well-defined boundary. However, the governance of these boundaries and substitution rules is not defined in [1]. This paper introduces a model for defining boundaries for sensitive data in the context of an enterprise. Next, the paper describes how to govern data privacy of services given the boundary model and a Service Oriented Architecture (SOA). Furthermore, we describe how the data structures of our Boundary Identity Masking approach are governed at an enterprise level. This addresses the scaling of our approach with respect to a large number of services and many boundaries.
Privacy-Preserving Outsourced Profiling	Personalized services attract high-value customers. Knowing the preferences and habits of an individual customer, it is possible to offer to that customer well customized and adapted services, matching his needs and desires. This is advantageous for the entity offering the service (e.g., a retailer) as well, as it helps in creating additional sales or improve customer retention. The main unsolved problem today is that the profile of each individual customer would be necessary in order to create such services, posing severe risks regarding privacy and data protection. This paper proposes efficient encryption schemes that allow profiling to be outsourced while preserving privacy. The schemes ensure that the customer is always in control of his profile data, at the same time making shopping data across multiple retailers available to third party service providers to be able to provide targeted services.
Privacy Application Infrastructure: Confidential Data Masking	Handling of confidential and sensitive data is an important issue facing any professional service provider that wishes to use services from a third party company. This paper describes an infrastructure, the privacy infrastructure appliance that was designed to protect confidential information when outsourcing service fulfillment. A comparison is made with an embedded solution that does not use an infrastructure.There are two use cases to consider, one use case is the outsourcing of back-end service fulfillment, such as executing foreign exchange trade orders and the second use case is the outsourcing of back-office activities, such as non-core competence office work. In considering back-end service delivery, we look at the use of computer systems and processes, which are not privy to confidential information. In considering back-office clerical activities, we look at the human component of service fulfillment, the clerical office worker. The clerical office worker that is outsourced, will still use the applications of the outsourcing company, but he is no longer privy to confidential information. This paper describes and contrasts two solutions. An infrastructure that was built to meet confidential information requirements for doing outsourcing of solution delivery systems and an application approach to mask confidential information from outsourced back office workers.
Privacy preserving data mining based on association rule- a survey	Data mining is the process of extracting hidden information from the database. Data mining is emerging as one of the key features of many business organizations. The current trend in business collaboration shares the data and mined results to gain mutual benefit. The problem of privacy-preserving data mining has become more important in recent years because of the increasing ability to store personal data about users, and the increasing sophistication of data mining algorithms to leverage this information. Apart from classification and regression, one of the most important tasks of data mining is to find patterns in data. In particular, new advances in data mining and knowledge discovery that allow for the extraction of hidden knowledge in enormous amount of data impose new threats on the seamless integration of information. In this paper, we consider the problem of building privacy preserving algorithms for one category of data mining techniques, the association rule mining.
Analysis of privacy preserving K-anonymity methods and techniques	Many applications employing the data mining techniques involve mining the data that includes private and sensitive information about the subjects. K-anonymity is a property that models the protection of released data against possible re-identification of the respondents to which the data refers. One of the interesting aspects of k-anonymity is its association with protection techniques that preserve the truthfulness of the data. It is however evident that the collection and analysis of data that include personal information may violate the privacy of the individuals to whom information refers. To guarantee the k-anonymity requirement, k-anonymity requires each quasi-identifier value in the released table to have at least k occurrences. In this paper, we present a survey of recent approaches that have been applied to the k-Anonymity problem.
Cross-layer Privacy Enhancement and Non-repudiation in Vehicular Communication	We propose a security architecture that provides two fundamental security services for VANETS: i) non-repudiation and ii) privacy enhancement. Due to a new PKI concept, referred to as PKI+, users are autonomous in deriving public keys, certificates and pseudonyms which minimizes the communication to the certificate authority. Security techniques are supported on all layers of the protocol stack. In particular we show how to link the PKI+ concepts to solutions for routing in vehicle-to-vehicle and vehicle-to-infrastructure communication.
Evaluation Framework of Location Privacy of Wireless Mobile Systems with Arbitrary Beam Pattern	Position localization of transmitters can be carried out by an adversary owning a network of pervasive receivers, which can pinpoint the victim mobile nodes' locations with high temporal and spatial accuracy, such that pseudonym changing and higher-layer obfuscation are insufficient to protect their location privacy. Our contribution is to consider covert beam patterns, generated using multiple antennas to do adaptive beamforming, and so reducing radio signature. We architect such a privacy-enhancing system, give an informal security analysis, and develop an evaluation framework to analyze its location privacy. We performed simulations using wireless LAN parameters, and found that signal-to-noise-ratios for successful direction-finding are more stringent than those required for mere communications. We composed an end-to-end integrated radio and mobility simulation, and compared location privacy performance of omnidirectional versus adaptive beamforming antennas. Our proposal is shown to perform better. In addition, our evaluation framework is flexible and extensible.
Analyzing reputation concept in privacy-invasive software	Nowadays computers are integrated with daily life increasing and people entrust them to store data and share their personal information with them. As the concept of personal information is implied in this context, the privacy issues will be so important. There are lots of definitions about privacy but in this work, privacy is the ability for individuals to control how personal data are stored or in other word "Privacy is the right to be alone". And with the developments going in the computer field we are becoming more vulnerable to threats and hence we should be really careful in choosing the right type of software for protecting our privacy, and in this context, it is shown that the related work which is dealing with some of the software that are really good and helpful in building such a system that we need.
Privacy preserving computation of trust-value in wireless sensor networks	The traditional cryptographic mechanisms are not enough for wireless sensor networks (WSNs) when the control of sensor nodes are taken by an interior adversary. Trust management system can solve this problem efficiently, and enhance the security and reliability of WSNs. One of the key problems in trust management system is computing trust values of nodes. However, previous works pay little attention to preserving data privacy during computing trust values. This paper focus on the problem that how to protect the data privacy while computing trust values, and proposes a privacy preserving trust value computation (PPTC) protocol to solve this problem. We develop a new private distributed scalar product protocol based on semi-honest third party to achieve the PPTC protocol. A great advantage of PPTC protocol is that it does not need any encryption or decryption operations, and the computation and communication overheads is low to 0(n). What's more, we analyze the correctness and security of the PPTC protocol and prove that the protocol can resist to collusion of up to n -1 users.
Privacy preserving research based on association rule algorithm	Privacy protection based on association rules aim is to find a data set of the original approach, making the mining of sensitive rules is to implement a data mining process is not to be found. To efficiently achieve privacy protection, this article combine the PPARM algorithm and IMBA algorithm, through the operation of sensitive items to do less, it will hidden sensitive rules more greater degree. It is making little effect on non-sensitive rules at the same time. That is making loss rate of the rules of the original database smaller. Theoretical and experimental results show that the algorithm is highly efficient, is a better method related to privacy protection.
The conflict between privacy and self-disclosure in Social Networking Services	The Social Networking Services (SNS) allow users with similar interests to build relationship on online network, and community activities via information sharing, networking, self-disclosure. To participate in SNS, people provide personal data. This study focuses on whether the personal needs of privacy and the one of self-disclosure have a one-dimensional relationship with each other or are independent from each other. Authors review research articles both on information privacy and on self-disclosure. This research also focuses on the dynamic relations between the needs for self-disclosure and privacy attitudes among SNS users.
Using students' tracking data in E-learning: Are we always aware of security and privacy concerns?	This paper presents a study on security and privacy concerns in E-learning. The study has been conducted along with our research effort that focuses on tracking students' activities on Computer-Mediated Communication tools (e.g. discussion forum, blog, wiki, etc.). It aims to express our attention on technical and ethical aspects of using tracking approach in the learning process. While the study covers an analysis of some existing research data of security in E-learning and user privacy protection provisions, it helps us gain a broader perspective of utilizing the tracking approach in our research. The major contribution of this paper is that it raises an awareness of the relevant issues, which are often neglected in the research efforts that implicate user tracking and personal data usage for instructional purposes.
State-of-the-art in distributed privacy preserving data mining	Privacy preserving data mining has become an important research problem. The chief research is how to mine the potential knowledge and not to reveal the sensitive data. In reality, large amounts of data are stored in distributed sites, so the DPPDM (Distributed Privacy Preserving Data Mining) is very important. This paper gave a survey on the DPPDM. Based on different underlying technologies, there are three kinds of techniques: perturbation, secure multi-party computation and restricted query. It provides a detailed description of the research in this area, compares the advantages and disadvantages of each method, foucs on the hot topic in this field, points out the future research directions.
Latent Dirichlet Conditional Naive-Bayes Models for Privacy-Preservation Clustering	The paper introduces a model for privacy preservation clustering which can handle the problems of privacy preservation, distributed computing. First, the latent variables in latent Dirichlet conditional Naive-Bayes models (LDCNB)are redefined and some terminologies are defined. Second, Variational approximation inference for LD-CNBis stated in detail. Third, base on the variational approximation inference, we design a distributed EM algorithm for privacy preservation clustering. Finally, some datasets from UCI are chosen for experiment, Compared with the distributed k-means algorithm, the results show LD-CNB algorithm does work better and LD-CNB can work distributed,so LD-CNB can protect privacy information.
Dynamic Privacy Management in Ubiquitous Computing Environments	Ubiquitous computing environment pursues context-aware in order words personalized service by collecting contexts through sensors located over wide area and presenting the service automatically depending not on the user's request but on the situations that are needed. But in order to provide the personalized service, contexts collected through various sensors are needed and they include private information. Therefore, it is important to keep a balance between the convenience by presenting service and protecting private information. In this paper, we classify and grade user's various contexts requested in ubiquitous computing environment. Based on these, we make decisions on whether to present the service or not by profile-matching between user profile and privacy requirements for providing service.
A User-Centered Context-Sensitive Privacy Model in Pervasive Systems	With emerging of pervasive computing, computers have increasingly become a part of in our life routines. Ubiquitous computing (also known as pervasive computing) is known as the age of calm technology where technology becomes as necessity and tends to be virtually invisible in our daily life without realizing. Privacy is a major problem in an individual's daily routine and being a treat in a pervasive computing system. The proposed system to solve individual's privacy problems is called ├é┬┐User-Centered Context-Sensitive Privacy Model in Pervasive Systems├é┬┐. Implementation of this system wills emphasize on managing user's context privacy concern.
Utilizing Network Features for Privacy Violation Detection	Privacy, its violations and techniques to circumvent privacy violation have grabbed the centre-stage of both academia and industry in recent months. Corporations worldwide have become conscious of the implications of privacy violation and its impact on them and to other stakeholders. Moreover, nations across the world are coming out with privacy protecting legislations to prevent data privacy violations. Such legislations however expose organizations to the issues of intentional or unintentional violation of privacy data. A violation by either malicious external hackers or by internal employees can expose the organizations to costly litigations. In this paper, we propose PRIVDAM; a data mining based intelligent architecture of a privacy violation detection and monitoring system whose purpose is to detect possible privacy violations and to prevent them in the future. This paper elaborates on the use of network characteristics for differentiating between normal network traffic and potential malicious attacks. These attacks are usually hidden in common network services like http, ftp, udp etc. Experimental evaluations illustrate that our approach is scalable as well as robust and accurate in detecting privacy violations
WLAN Location Sharing through a Privacy Observant Architecture	In the last few years, WLAN has seen immense growth and it will continue this trend due to the fact that it provides convenient connectivity as well as high speed links. Furthermore, the infrastructure already exists in most public places and is cheap to extend. These advantages, together with the fact that WLAN covers a large area and is not restricted to line of sight, have led to developing many WLAN localization techniques and applications based on them. In this paper we present a novel calibration-free localization technique using the existing WLAN infrastructure that enables conference participants to determine their location without the need of a centralized system. The evaluation results illustrate the superiority of our technique compared to existing methods. In addition, we present a privacy observant architecture to share location information. We handle both the location of people and the resources in the infrastructure as services, which can be easily discovered and used. An important design issue for us was to avoid tracking people and giving the users control over who they share their location information with and under which conditions
Privacy in machine-to-machine communications A state-of-the-art survey	With the rapid deployment of M2M services, countless smart ΓÇ£thingsΓÇ¥ with sensing and communication capabilities are collecting data about the physical world we live in. These data can be used by various service providers to make their services more customized with high quality. On the other hand the availability of personal information raises serious concerns over individual privacy. In order to prevent unauthorized identification, localization and tracking of humans and things, privacy preserving mechanisms must be an integral part of M2M based systems. This survey gives an overview of existing approaches to information privacy, focusing on technical solutions.
The Evolution of RFID Security and Privacy: A Research Survey	This paper presents the recent technical research on the problems of privacy and security for radio frequency identification (RFID). RFID technology is already used widely and is increasingly becoming a part of daily life. However, issues regarding security and privacy with respect to RFID technology have not been resolved satisfactorily. There are huge number of challenges, which must be overcome to resolve RFID security and privacy issues. It is because of the many constraints attached to the provision of security and privacy in RFID systems. These challenges are chiefly technical and economic in nature but also include ethical and social issues. Along with meeting the security and privacy needs of RFID technology, solutions must be inexpensive, practical, reliable, scalable, flexible, inter-organizational, and long lasting. This paper reviews the approaches which had been proposed by scientists for privacy protection and integrity assurance in RFID systems, and treats the social and technical context of their work. This paper can be useful as a reference for non specialist, as well as for specialist readers.
Issues of Privacy and Security in the Role of Software in Smart Cities	Throughout the evolution of cities, the very structure of what defines a city has been changing. There has been a huge amount of advancement from the ancient settlements to modern metropolitans and now the next step in the evolution of cities is here - smart cities. Smart cities have come up to counter act the ills of the industrial cities that produce a many bad side effects. Smart cities have been known to be environment friendly, better organized, have better mobility, and a more competent economy. In meeting these necessary objectives, the role of software can make the smart city more integrated and functional as a whole. But the use of smart software, as we call it, can pose problems pertaining to the security and integrity of the smart city's data and privacy. Therefore the need arises to understand and evaluate the concerns of security and privacy that come up with smart software before they can be used in full scale. This paper concentrates on these issues.
Cluster Based Anonymization for Source Location Privacy in Wireless Sensor Network	In many real life applications, the locations of events monitored by the network are required to remain anonymous. Preserving source location privacy becomes important, and also difficult to implement in case of wireless sensor networks (WSN) given their operating constraints. The privacy threats that exist for sensor networks may be categorized broadly into content privacy and context privacy. Context based privacy protection in WSN aims to hide the location information of the sensor nodes. This paper proposes a source location privacy scheme for WSN through cluster based anonymization. The scheme hides the real node identities during communication, by replacing them with random identities generated by the cluster heads. The degree of privacy of WSN is analyzed using entropy based method. The simulation results show that the scheme improves the degree of privacy compared to a method which does not have any provision of anonymity for sensor nodes.
Security and privacy of future aircraft wireless communications with offboard systems	Modern global aviation must rise up to the challenge of safely, securely and efficiently managing increasingly crowded skies under growing passenger, business and societal demands. The ΓÇ£e-enabled aircraftΓÇ¥ plays a central role in overcoming this grand challenge. Aeronautical-specific and commercial wireless data links as well as Internet standards will tightly integrate this aircraft with off-board systems in space, air and ground for revolutionizing air traffic control, flight operations and passenger services. However, potential vulnerabilities of these new technologies present risks to performance, user acceptance and deployment cost of future airspace systems. In this paper, we focus on these vulnerabilities and their mitigation. We discuss security and privacy threats and challenges that emerge with wireless-enabled air traffic control and flight operations.
Vis-├á-Vis: Privacy-preserving online social networking via Virtual Individual Servers	Online social networks (OSNs) are immensely popular, but their centralized control of user data raises important privacy concerns. This paper presents Vis-a╠Ç-Vis, a decentralized framework for OSNs based on the privacy-preserving notion of a Virtual Individual Server (VIS). A VIS is a personal virtual machine running in a paid compute utility. In Vis-a╠Ç-Vis, a person stores her data on her own VIS, which arbitrates access to that data by others. VISs self-organize into overlay networks corresponding to social groups. This paper focuses on preserving the privacy of location information. Vis-a╠Ç-Vis uses distributed location trees to provide efficient and scalable operations for sharing location information within social groups. We have evaluated our Vis-a╠Ç-Vis prototype using hundreds of virtual machines running in the Amazon EC2 compute utility. Our results demonstrate that Vis-a╠Ç-Vis represents an attractive complement to today's centralized OSNs.
A threat taxonomy for mHealth privacy	Networked mobile devices have great potential to enable individuals (and their physicians) to better monitor their health and to manage medical conditions. In this paper, we examine the privacy-related threats to these so-called mHealth technologies. We develop a taxonomy of the privacy-related threats, and discuss some of the technologies that could support privacy-sensitive mHealth systems. We conclude with a brief summary of research challenges.
Effects of network trace sampling methods on privacy and utility metrics	Researchers choosing to share wireless-network traces with colleagues must first anonymize sensitive information, trading off the removal of information in the interest of identity protection and the preservation of useful data within the trace. While several metrics exist to quantify this privacy-utility tradeoff, they are often computationally expensive. Computing these metrics using a sample of the trace could potentially save precious time. In this paper, we examine several sampling methods to discover their effects on measurement of the privacy-utility tradeoff when anonymizing network traces. We tested the relative accuracy of several packet and flow-sampling methods on existing privacy and utility metrics. We concluded that, for our test trace, no single sampling method we examined allowed us to accurately measure the tradeoff, and that some sampling methods can produce grossly inaccurate estimates of those values. We call for further research to develop sampling methods that maintain relevant privacy and utility properties.
Reconciling bitter rivals: Towards privacy-aware and bandwidth efficient mobile Ads delivery networks	The use of free mobile services and applications (commonly referred as apps) are becoming increasingly popular. Such services and apps are generally monetized by means of third party advertising. The app developers and ad networks which provide the advertisements to be displayed within apps use every means to maximize their revenue, most often at the expense of the end user. These means of maximizing revenue impact the user in three ways: 1) Through the loss of privacy and control over their data; 2) through the increase in monetary cost due to communications overheads introduced by ad traffic; and 3) by the increase of battery usage. The introduction of rich media advertisements will have even greater implications with respect to the aforementioned bandwidth and battery consumption concerns. In this paper, we propose a novel architecture, called MASTAds, that combines the concepts of opportunistic networks, network intermediaries and predictive regularity of human behavior which enable both cost and energy-efficient ads delivery. In addition, MASTAds allows ad networks to obtain only the necessary information to provide targeted advertisements and high Ads revenues, whilst still preserving the user privacy.
Privacy-preserving domain-flux botnet detection in a large scale network	In a large scale network, the privacy of the users and the performance are critical issues when conceiving a detection system, precisely for botnet detection where we need to differentiate between benign and malicious traffic. In this paper, we propose a new approach which conciliates these two requirements in order to detect domain-flux botnets and malicious servers controlling them. It relies on two successive steps: (1) it identifies communities of bots, infected by the same malware and showing similar behaviour in a defined interval; (2) it identifies malicious servers controlling these bots by correlating the traffic within each community. Our approach takes advantage of Bloom filters to represent information during the analysis, which allows us to comply with the constraints of privacy preservation and performance of a large scale implementation. We implemented our system and fed it with anonymised DNS traffic coming from an operator network. It detected several hundreds of malicious domain names with few false positives. Our system was able to process the capture faster than the injection rate, indicating that it can be scaled for real-time detection in a production environment. Our detection system is a first step into a fully privacy conservative botnet detection system.
Security analysis of the Louis protocol for location privacy	Many location-based services for alerting persons of nearby friends have been deployed in practice. A drawback of most approaches to providing such services is that friends always learn each other's location even when they are not actually nearby. The Louis protocol proposed by Zhong, Goldberg and Hengartner aims to ensure that a friend's location is revealed to another friend if and only if the friends are actually nearby. The protocol lets a third party learn whether the friends are nearby, without the third party learning their location. The third party communicates the answer to the person who invokes the service. A key feature of the protocol is that a person can detect misbehavior by the third party or the person's friend. This paper reveals a flaw in the way the protocol handles the detection of the misbehaving party, leading to an unauthorized disclosure of a person's location. Two alternatives for fixing the flaw in the protocol are proposed and a heuristic analysis is given.
A plain type of mobile attack: Compromise of userΓÇÖs privacy through a simple implementation method	An easy way to determine the state of a cell phone without the ownerpsilas knowledge is presented in this paper. The described method, combined with a form of patterning mobile userpsilas behavior (in terms of evaluating the mobile phonepsilas state in a tactical way) could lead to privacy compromise revealing his whereabouts. The technical part of the paper is based on the Short Messaging Service and the offered service of Receipt Report, manipulated in such a way as not to reveal any information to the targeted user. In addition, this method can provide known plain texts for an attack on A5.
A platform for the development of location-based mobile applications with privacy protection	Network operators gradually open their interfaces to formerly hidden services which fosters the development of a new class of mobile applications that take into account context information such as the users location. However, this development also raises problems. Especially the lack of protection of privacy in location-based services. In this work we propose a service architecture that is aimed at overcoming some of the shortages of currently existing context-aware applications that make use of network providers services. It makes use of a novel privacy enhancing mechanism that is based on the notion of pseudonyms that are applicable even on mobile devices with restrictions regarding resources like memory or processing power. Due to the flexibility of the privacy enhancing mechanism many different kinds of applications are conceivable. The most important aspect in this respect is the highly postulated pay-as-you-go model. To illustrate our approach we demonstrate a transport ticket application that is extended by location-tracking functionality and discuss a management module which allows 3<sup>rd</sup> party application developers to test complex interaction patterns even for a huge number of notional users prior to the realization of full mobile applications and by confirming obligatory requirements regarding data and privacy protection legislation.
Privacy-preserving set intersection in outsourcing environments	We propose two privacy-preserving set intersection protocols in outsourcing environments. First, we propose a secure protocol (namely Protocol 1) for privacy-preserving set intersection using Mignotte's secret sharing scheme. The data owner outsources a dataset A to w third-party service providers by Mignotte's secret sharing scheme. Then, the user interacts with any k (k <; w) service providers to determine whether some elements of the user's dataset B belong to the dataset A without disclosing any useful information to all parties. Furthermore, we also construct a privacy-preserving cardinality computation protocol (namely Protocol 2) of set intersection which has no disclosure about the result of set intersection by improving Protocol 1. In the semi-honest model, we prove the security of these protocols.
A security and privacy model for mobile RFID systems in the internet of things	For the security and privacy of mobile radio frequency identification (RFID) systems in the internet of things, a novel security and privacy model is proposed in this paper. The model not only takes into account the privacy of tags and readers, but also supports tag corruption, reader corruption, multiple readers and mutual authenticated key exchange (AKE) protocols. We then propose a new AKE protocol for mobile RFID systems. Security analysis shows that the protocol is correct, secure and tag-forward private in our model. Furthermore, our protocol is efficient in terms of computation, communication rounds and functions.
Privacy-preserving multi-set operations	We consider several multiset operations in secure two-party setting where Alice and Bob each have a multiset and they want to perform some private computations over the two multisets without revealing and private information which means no one of them would learn more information than what can be deduced from the result. We design some methods to compute union, intersection and element reduction operations effectively and securely and apply these techniques to solve the multiset operations problems in semi-honest setting and consider their extension to the malicious setting.
A wew remote data integrity checking scheme for cloud storage with privacy preserving	Cloud storage services enable users to enjoy high-capacity and high-quality storage with less overhead. However, the fact that users no longer have physical possession of the data makes the data integrity protection in cloud storage a very challenging and formidable task. In this paper, we propose a new remote integrality checking scheme for cloud storage that integrate correct checking, dynamic update and privacy preserving. The security and performance analysis shows that this new scheme is provably secure, and can check mass remote file's integrality with constant storage and communication resource for cloud storage users.
A privacy enhanced DNS scheme for the Internet Of Things	In the environment of Internet of Things (IoT), smart devices' privacy protection is a significant issue in several security problems. When a static domain name was assigned to a specified IoT terminal smart device, the risk of the existing privacy will be raised. In this article we proposed a privacy protection enhanced DNS scheme for smart devices, which can authenticate the original user's identity, reject illegal access to the smart device. The scheme is compatible with widely used DNS and DNSSEC protocol.
Security and Privacy in the Computer Forensics Context	Today computers are used in numerous day- to-day activities as a communications tool. In this regard several different applications are used to generate and store important documents. These documents contain vital data to the user and at times to an investigator in the event a crime is committed using that computer. The user would expect reasonable security precautions to be in place to protect the data on the computer, especially when the computer is connected to the Internet. The user with deceptive goals in mind would want to hide information where as a Computer Forensics investigator would want to find out the hidden information for evidence. In this paper we examine several security features that are commonly used and how such precautions are thwarted by Computer Forensics tools and their impact on privacy.
An Anti-Collusion Solution for Privacy-Preserving Data Mining	In distributed data mining with privacy preserving, the algorithms which adopt data obscurity method are sometimes vulnerable facing collusion. In this research, such stream of collusion challenge is defined. Since previously suggested methods would cause multiple orders magnitude of communication or partial security covering among parties, we have proposed a method (adjacency permutation) for the colluding problem and integrated it in establishment of RPA (ring polling for association rules) platform. The proposed solution is: (1) lightweight for only increasing linear communication; (2) effective for all sites are covered by suggested protection. In synthetic simulation, RPA is compared with other two representative DDM (distributed data mining) algorithms (FDM and CER); the results show good performance of RPA on efficiency and effectivity.
Toward User-Centric Privacy-Aware User Profile Ontology for Future Services	Personalization is one of the key features of the future Internet. However, the success of personalized services mostly relies on user profiles. Therefore, a generic, shareable, and reusable user profile is crucial for service providers for the uptake of personalized services. This paper proposes a user-centric personalization approach. The core of this approach is a user-centric user profile where user is in the center and experience perceived control over his information. We use Ontology Web Language (OWL-DL) to formally represent user relevant information in ontology. We present profile and privacy enhancement mechanism to increase profile applicability and user privacy respectively. The paper also offers a policy based approach to ensure authorized access of user profiles among third parties. Furthermore, we formally represent authorization policies by exploiting Semantic Web Rule Language (SWRL) and evaluate policies by employing Semantic Query Enhanced Web Rule Language (SQWRL).
Supervisory control strategies for enhancing system security and privacy	Enhancing the security and reliability of automated systems that control vital national infrastructures, such as energy and water distribution systems, has recently emerged as a critical aspect of maintaining, protecting, and securing such infrastructures against interference or possibly malicious activity. Examples of such automated systems include Supervisory Control and Data Acquisition (SCADA) systems, Distributed Control Systems (DCS), and networks of embedded sensors and actuators, most of which were designed without anticipating the security threats that arise due to increasing reliance on common software, public telecommunication networks, and the Internet. In this paper, we discuss how state-based notions of opacity in finite automata models can be used to capture security properties of interest in automated systems that can be modeled as controlled finite automata subject to external disturbances.We also describe when and how control objectives can be achieved while enforcing desirable security and/or privacy objectives.
An information-theoretic approach to privacy	Ensuring the usefulness of electronic data sources while providing necessary privacy guarantees is an important unsolved problem. This problem drives the need for an overarching analytical framework that can quantify the safety of personally identifiable information (privacy) while still providing a quantifable benefit (utility) to multiple legitimate information consumers. State of the art approaches have predominantly focused on privacy. This paper presents the first information-theoretic approach that promises an analytical model guaranteeing tight bounds of how much utility is possible for a given level of privacy and vice-versa.
One-to-n scrip systems for cooperative privacy-enhancing technologies	Scrip is a generic term for any substitute for real currency; it can be converted into goods or services sold by the issuer. In the classic scrip system model, one agent is helped by another in return for one unit of scrip. In this paper, we present an upgraded model, the one-to-n scrip system, where users need to find n agents to accomplish a single task. We provide a detailed analytical evaluation of this system based on a game-theoretic approach. We establish that a nontrivial Nash equilibrium exists in such systems under certain conditions. We study the effect of n on the equilibrium, on the distribution of scrip in the system and on its performance. Among other results, we show that the system designer should increase the average amount of scrip in the system when n increases in order to optimize its efficiency. We also explain how our new one-to-n scrip system can be applied to foster cooperation in two privacy-enhancing applications.
Privacy preserving data aggregating with multiple access channel	We consider the scenario in which a set of users want to compute an aggregate function of their messages at a message center. The users communicate with the message center over a multiple access channel with fading, where the fading states of the channels from individual receivers are unknown a priori to the message center. For privacy reasons, the users do not want disclose their message information to the message center. No computational limitations on the message center are assumed, and the message center may collude with a set of hidden eavesdroppers to retrieve the message information of the users. This paper proposes a scheme called MacPDA that leverages the multiple access properties of wireless signals to achieve privacy. It relies on fairly loose synchronization and does not require secret channels. MacPDA is shown to reveal no message information of the users other than the required function value. The estimation performance of MacPDA is investigated with numerical experiments, and theoretical bounds are given on the asymptotic performance.
The price of privacy in untrusted recommendation engines	Recent increase in online privacy concerns prompts the following question: can a recommendation engine be accurate if end-users do not entrust it with their private data? To answer this, we study the problem of predicting user-ratings under local or `user-end' differential privacy, a powerful, formal notion of data privacy. We develop a systematic approach for lower bounds on the complexity of learning item structure from privatized user inputs, based on mutual information. Our results identify a sample complexity separation between learning in the scarce information regime and the rich information regime, thereby highlighting the role of the amount of ratings (information) available to each user. In the information-rich regime (where each user rates a constant fraction of items), a spectral clustering approach is shown to achieve optimal sample complexity. However, the information-scarce regime (where each user rates only a vanishing fraction of the total item set) is found to require a fundamentally different approach. We propose a new algorithm, MaxSense, and show that it achieves optimal sample complexity in this setting. The techniques we develop for bounding mutual information may be of broader interest. To illustrate this, we show their applicability to (i) learning based on 1-bit sketches (in contrast to differentially private sketches), and (ii) adaptive learning, where queries can be adapted based on answers to past queries.
A game theory model for electricity theft detection and privacy-aware control in AMI systems	We introduce a model for the operational costs of an electric distribution utility. The model focuses on two of the new services that are enabled by the Advanced Metering Infrastructure (AMI): (1) the fine-grained anomaly detection that is possible thanks to the frequent smart meter sampling rates (e.g., 15 minute sampling intervals of some smart meter deployments versus monthly-readings from old meters), and (2) the ability to shape the load thanks to advanced demand-response mechanisms that leverage AMI networks, such as direct-load control. We then study two security problems in this context. (1) In the first part of the paper we formulate the problem of electricity theft detection (one of the use-cases of anomaly detection) as a game between the electric utility and the electricity thief. The goal of the electricity thief is to steal a predefined amount of electricity while minimizing the likelihood of being detected, while the electric utility wants to maximize the probability of detection and the degree of operational cost it will incur for managing this anomaly detection mechanism. (2) In the second part of the paper we formulate the problem of privacy-preserving demand response as a control theory problem, and show how to select the maximum sampling interval for smart meters in order to protect the privacy of consumers while maintaining the desired load shaping properties of demand-response programs.
Privacy against statistical inference	We propose a general statistical inference framework to capture the privacy threat incurred by a user that releases data to a passive but curious adversary, given utility constraints. We show that applying this general framework to the setting where the adversary uses the self-information cost function naturally leads to a non-asymptotic information-theoretic approach for characterizing the best achievable privacy subject to utility constraints. Based on these results we introduce two privacy metrics, namely average information leakage and maximum information leakage. We prove that under both metrics the resulting design problem of finding the optimal mapping from the user's data to a privacy-preserving output can be cast as a modified rate-distortion problem which, in turn, can be formulated as a convex program. Finally, we compare our framework with differential privacy.
Privacy-security tradeoffs in biometric security systems	Biometric security systems are studied from an information theoretic perspective. A fundamental tradeoff between privacy, measured by the normalized equivocation rate of the biometric measurements, and security, measured by the rate of the key generated from the biometric measurements, is identified. The scenario in which a potential attacker does not have side information is considered first. The privacy-security region, which characterizes the above-noted tradeoff, is derived for this case. The close relationship between common information among random variables and the biometric security system is also revealed. The scenario in which the attacker has side information is then considered. Inner and outer bounds on the privacy-security region are derived in this case.
Privacy leakage in biometric secrecy systems	Motivated by Maurer [1993], Ahlswede and Csiszar [1993] introduced the concept of secret sharing. In their source model two terminals observe two correlated sequences. It is the objective of both terminals to form a common secret by interchanging a public message (helper data), that should contain only a negligible amount of information about the secret. Ahlswede and Csiszar showed that the maximum secret key rate that can be achieved in this way is equal to the mutual information between the two source outputs. In a biometric setting, where the sequences correspond to the enrollment and authentication data, it is crucial that the public message leaks as little information as possible about the biometric data, since compromised biometric data cannot be replaced. We investigate the fundamental trade-offs for four biometric settings. The first one is the standard (Ahlswede-Csiszar) secret generation setting, for which we determine the secret key rate - privacy leakage region. Here leakage corresponds to the mutual information between helper data and biometric enrollment sequence conditional on the secret. In the second setting the secret is not generated by the terminals but independently chosen, and transmitted using a public message. Again we determine the region of achievable rate - leakage pairs. In setting three and four we consider zero-leakage, i.e. the public message contains only a negligible amount of information about the secret and the biometric enrollment sequence. To achieve this a private key is needed which can be observed only by the terminals. We consider again both secret generation and secret transmission and determine for both cases the region of achievable secret key rate - private key rate pairs.
Preserving privacy with anonymity for customer collaboration in smart grid	The interconnection among all the components in Smart Grid may expose the customer information that are collected and processed in the smart meter or EMS. The privacy issue becomes more serious when customers collaborated on the power consumption. Even though many research efforts have been focused on enhancing the privacy in both the smart metering infrastructure and the interaction between the customer and the other domains, the privacy on the information exchange among customers has been neglected. In this paper, we propose the security framework of supporting the privacy with anonymity based on a hybrid identity based cryptography scheme, when customers exchange their information to trade their contracted power.
TESP2: Timed Efficient Source Privacy Preservation Scheme for Wireless Sensor Networks	Source privacy preservation against global eavesdroppers' traffic analysis attack is one of the most challenge issues in wireless sensor networks. In this paper, we present a new timed efficient source privacy preservation (TESP<sup>2</sup>) scheme. In the TESP<sup>2</sup> scheme, each sensor node broadcasts timed data collection request to its upstream nodes, and then each upstream node will return the real data's ciphertext if it has detected something, or a dummy data's ciphertext if it hasn't. After receiving ciphertexts from upstream nodes, the sensor node will filter the dummy data, re-encrypt and forward the real data's ciphertexts to its downstream node to achieve the source privacy preservation. Security analysis and extensive simulation results demonstrate the proposed TESP<sup>2</sup> scheme can resist the traffic analysis attack and achieve high source privacy preservation with some tolerant latency.
Secure Data Downloading with Privacy Preservation in Vehicular Ad Hoc Networks	In this paper, we propose a secure data downloading protocol with privacy preservation in vehicular ad hoc networks (VANETs). In the data downloading application, vehicles send requests, such as where is the nearest gas station, at a road side unit (RSU) and receive the corresponding responses from application servers via current or the following RSUs. It would be easy for eavesdroppers to get vehicles' private information if semi-trust RSUs are compromised because both request and response messages are forwarded by them. Therefore, we develop a protocol which enables vehicles to download data securely from RSUs with their privacy under protection even when one or multiple RSUs are compromised. Our protocol guarantees vehicles exclusive access to their requested data while eavesdroppers can not obtain any private information of the vehicles. Possible attacks and the corresponding solutions as well as privacy evaluation are discussed to demonstrate the performance of the proposed protocol.
Efficient and Spontaneous Privacy-Preserving Protocol for Secure Vehicular Communication	This paper introduces an efficient and spontaneous privacy-preserving protocol for vehicular ad-hoc networks based on revocable ring signature. The proposed protocol has three appealing characteristics: First, it offers conditional privacy-preservation: while a receiver can verify that a message issuer is an authorized participant in the system only a trusted authority can reveal the true identity of a message sender. Second, it is spontaneous: safety messages can be authenticated locally, without support from the roadside units or contacting other vehicles. Third, it is efficient: it offers fast message authentication and verification, cost-effective identity tracking in case of a dispute, and has low storage requirements. We use extensive analysis to demonstrate the merits of the proposed protocol and to compare it with previously proposed solutions.
HyberLoc: Providing Physical Layer Location Privacy in Hybrid Sensor Networks	In many hybrid wireless sensor networks' applications, sensor nodes are deployed in hostile environments where trusted and un-trusted nodes co-exist. In anchor-based hybrid networks, it becomes important to allow trusted nodes to gain full access to the location information transmitted in beacon frames while, at the same time, prevent un-trusted nodes from using this information. The main challenge is that un-trusted nodes can measure the physical signal transmitted from anchor nodes, even if these nodes encrypt their transmission. Using the measured signal strength, un-trusted nodes can still tri-laterate the location of anchor nodes. In this paper, we propose HyberLoc, an algorithm that provides anchor physical layer location privacy in anchor-based hybrid sensor networks. The idea is for anchor nodes to dynamically change their transmission power following a certain probability distribution, degrading the localization accuracy at un-trusted nodes while maintaining high localization accuracy at trusted nodes. Given an average power constraint, our analysis shows that the discretized exponential distribution is the distribution that maximizes location uncertainty at the un-trusted nodes. Detailed evaluation through analysis, simulation, and implementation shows that HyperLoc gives trusted nodes up to 3.5 times better localization accuracy as compared to un-trusted nodes.
A Novel Attack Tree Based Risk Assessment Approach for Location Privacy Preservation in the VANETs	Even though emerging as a promising approach to increase road safety, efficiency and convenience, Vehicular Ad hoc Networks (VANETs) pose many new research challenges, especially on the aspect of location privacy. The existing literatures focus on preventive techniques to achieve location privacy protection, however the location privacy risk assessment receives less attention. In this paper, we introduce a novel risk assessment method to evaluate the security risk of VANET's privacy based on attack tree. The proposed scheme provides a general analysis framework to estimate the degree that a certain threat might bring to the VANETs. We also use the constructed attack tree to identify possible attack scenarios that an attacker may launch towards the privacy preserving system in VANETs, which is expected to further improve the system security.
Anonymity Analysis on Social Spot Based Pseudonym Changing for Location Privacy in VANETs	Location privacy is one of the Quality of Privacies (QoP) in vehicular ad hoc network (VANET) and imperative for the VANET's full flourish. Frequent pseudonym changing can provide a promising solution to achieve location privacy, however if the pseudonyms are changed in an improper occasion, the solution is ineffective. In this paper, to improve the effectiveness of this kind of solution, we first introduce the social spot where many vehicles could aggregate, e.g., a road intersection when the traffic light is red or a free parking lot near a shopping mall. We then propose a social spot based pseudonyms changing technique to achieve the location privacy. By taking the anonymity set size as the privacy metric, we develop two anonymity analytic models to quantitatively investigate the location privacy achieved in the technique. The analytical results show that better location privacy can be achieved when a vehicle changes its pseudonyms at some highly social spots, and as a result, the proposed models can be used to assist vehicles to change their pseudonyms for better location privacy at the right moment and place.
Game Theoretic Modeling and Evolution of Trust in Autonomous Multi-Hop Networks: Application to Network Security and Privacy	Future applications will require autonomous devices to be interconnected to form a network. Such networks will not have a central manager; each node will manage itself and will be free to decide participation in any network function. As with traditional networks, these networks need to be secured to authenticate the nodes, prevent misuse, detect anomalies and protect user privacy. Network security and privacy protection without a central manager will be challenging. Several security mechanisms and privacy protections will require the cooperation of several nodes to defend the network from malicious attacks. We particularly investigate when for each node it is cost-effective to freely participate in the security mechanism or protect its privacy depending if that node believes or trusts that all other nodes or at least a minimum number of other nodes will do the same. In this case, each node will be involved in a trust dilemma that we will model using the mathematical framework of game theory and evolutionary game theory. The well known stag hunt game will be our basic game model. This paper will clearly present the interconnection between cooperation, trust, privacy and security in a network.
A Location-Privacy-Protected RFID Authentication Scheme	RFID is popular to be used in plenty of applications with its capability of remote automatic identification. However, information transmitted wirelessly is under the treats of eavesdropping, interception, or modification because of the nature of the transmission media. Thus, Yeh et al. proposed an RFID authentication scheme based on quadratic residues by improving Chen et al.'s. However, we find that the server needs to maintain the obsolete shared secret key to resist DoS (Denial of Service) attack in both schemes. To overcome this drawback and improve the computation load, an improvement will be given with simple operations, one-way hash function and XOR operations. The proposed scheme can defend against possible attacks and be suitable for applications requiring efficiency and security at the same time.
PEKSrand: Providing Predicate Privacy in Public-Key Encryption with Keyword Search	Recently, Shen, Shi, and Waters introduced the notion of predicate privacy, and proposed a scheme that achieves predicate privacy in the symmetric-key settings. In this paper, we propose two schemes. In the first scheme, we extend PEKS to support predicate privacy based on the idea of randomization. To the best of our knowledge, this is the first work that ensures predicate privacy in the public-key settings without requiring interactions between the receiver and potential senders, the size of which may be very large. Moreover, we identify a new type of attacks against PEKS, i.e., statistical guessing attacks. Accordingly, we introduce a new notion called statistics privacy, i.e., the property that predicate privacy is preserved even when the statistical distribution of keywords is known. The second scheme we proposed makes a tradeoff between statistics privacy and storage efficiency (of the delegate). Compared to PEKS, both schemes introduce reasonable communication and computation overheads and can be smoothly deployed in existing systems.
Distributed Data Mining with Differential Privacy	With recent advances in communication and data storage technology, an explosive amount of information is being collected and stored in the Internet. Even though such vast amount of information presents great opportunities for knowledge discovery, organizations might not want to share their data due to legal or competitive reasons. This posts the challenge of mining knowledge while preserving privacy. Current efficient privacy-preserving data mining algorithms are based on an assumption that it is acceptable to release all the intermediate results during the data mining operations. However, it has been shown that such intermediate results can still leak private information. In this work, we use differential privacy to quantitatively limit such information leak. Differential privacy is a newly emerged privacy definition that is capable of providing strong measurable privacy guarantees. We propose Secure group Differential private Query (SDQ), a new algorithm that combines techniques from differential privacy and secure multiparty computation. Using decision tree induction as a case study, we show that SDQ can achieve stronger privacy than current efficient secure multiparty computation approach, and better accuracy than current differential privacy approach while maintaining efficiency.
EVSE: An Efficient Vehicle Social Evaluation Scheme with Location Privacy Preservation for Vehicular Communications	Social-aware data diffusion can improve the dissemination performance in vehicular ad hoc networks (VANETs). However, if some vehicles lie their social claims and vehicle location information is not protected, social-aware data diffusion may not work well. In this paper, to tackle the security and privacy challenges existing in social-aware data diffusion, we propose an efficient vehicle social evaluation (EVSE) scheme, which enables each vehicle to show its authentic social evaluation to others while without disclosing its past location information. As a result, it can meet the prerequisites for the success of social-aware data diffusion in VANET.
Joint Privacy and Reputation Assurance for VANETs	Privacy protection and reputation management, both indispensible to Vehicular Ad Hoc Networks (VANETs), impose conflicting requirements: privacy protection makes it challenging to maintain the reputation history of any node; reputation management requires real-time reputation manifestation at risk of easier vehicle tracking. Here, a novel Joint Privacy and Reputation Assurance (JPRA) scheme is proposed to solve these conflicting requirements. To make reputation aggregation secure and efficient in face of high node mobility and privacy protection, JPRA adopts a localized reputation management approach. A reputation relay procedure ensures that the complete reputation information of any node is always maintained by itself and its 1-hop neighbors in face of network topology changes. Neighbor-assisted reputation update, with partially blind signature, allows each node to securely update its reputation without harming its privacy in JPRA. Eventually, to make reputation manifestation privacy-preserving, a conditional reputation discretization algorithm is proposed to allow the honest nodes to manifest a common reputation value. Analysis and simulations show that JPRA efficiently and synergistically supports the coexistence of reputation schemes and privacy schemes in VANETs.
An efficient handover authentication scheme with location privacy preserving for EAP-based wireless networks	In this paper, we propose a handover authentication scheme with location privacy preserving based on the proxy ring signature scheme for EAP-based wireless networks. First, we integrate an efficient ring signature and a proxy signature into a proxy ring signature scheme, which allows the mobile node (MN) to be authenticated without revealing its identity and location privacies due to the inherent anonymity of the proxy ring signature. Second, our scheme only requires point multiplication operations on the resource-constraints MN, thus, it is suitable for low-power mobile devices in the wireless networks. Finally, an extensive simulation is given to validate the performance of the proposed scheme. The results demonstrate that our scheme is relatively efficient in terms of computation and communication overhead.
Enabling pervasive healthcare with privacy preservation in smart community	Smart community is an emerging Internet of Things application. It supports a variety of high-value automated services such as pervasive healthcare through a multi-hop community network of smart homes in a local residential region. In this paper, we study privacy preserving data communication between patients and an online healthcare provider (referred to as vendor) for efficient remote healthcare monitoring (RHM) in a smart community environment. We adopt patients' attribute structures instead of their identities for authentication and preserve identity privacy during patient-to-vendor communication, and we build a receiver chain among smart homes to enable vendor-to-patient communication and achieve location privacy. The privacy preserving properties of the proposed data communication scheme are analyzed, and its effectiveness and efficiency are demonstrated through extensive simulations.
Low-latency privacy-enabled Context Distribution Architecture	As personal information and context sharing applications gain traction more attention is drawn to the associated privacy issues. These applications address privacy using an unsatisfactory ΓÇ£whitelistΓÇ¥ approach, similar to social networks ΓÇ£friendsΓÇ¥. Some of them also link location publishing with user interaction which is also a form of privacy control - the user has to explicitly say where he is. There are a few automatic location based-services (LBS) that track the user, but without more adequate privacy protection mechanisms they enable even bigger threats to the user. On previous work, an XMPP-based Context Distribution Architecture was defined, more suitable for the distribution of frequently changing context than other systems because it is based on the publish-subscribe pattern. In this paper the authors present an extension to this architecture that allows for the introduction of a complex degree of access control in context distribution. The devised changes enable the system to consider a number of interesting context privacy settings for context distribution control. Also, this control must be enforced in a way that it doesn't interfere with the real-time nature of the distribution process. After describing the enhancements to the architecture, a prototype of the system is presented. Finally, the delivery latency and additional processing introduced by the access control components is estimated by testing it against the existing system.
Privacy-preserving PKIs with reduced server trust	Motivated by vehicular networking applications, we study a novel type of privacy-preserving public-key infrastructures where the server that distributes public and private keys to clients need not be trusted by clients to protect its secret data against intruders. We target three main requirements for these public-key infrastructures: privacy preservation of the client's identity (or, anonymity), traceability of malicious messages to clients corrupted by an attacker rather than honest clients (or, traceability) and communication and computation time constant with respect to the number of users (or, efficiency). This combination of properties was not achieved in previously studied areas such as broadcast or multicast encryption, group signatures and ring signatures. This paper designs a public key infrastructure that achieves satisfactory performance on all three requirements, based on key pools and a novel probabilistic key revocation and update strategy. Perhaps surprisingly, we use a careful design of our revocation protocol to achieve a combination of properties for public-key infrastructures that was not previously achieved.
Privacy-preserving location and mobility management to support tether-free patients in ad-hoc networks	A major driver of healthcare cost is the inefficiencies associated keeping less-critical patients overnight in the hospital when these patients could be treated as outpatients and received comparable quality of care. To this end, we propose the concept of tether-free patient to support patient mobility and ensure privacy-preserving healthcare. The paper addresses issues related to the design of a ubiquitous architectures to support tetherless care and proposes a robust, scalable and secure framework to location management of tether-free patients in mobile, wireless environments. The main building blocks and functionalities of the proposed architecture are described, and the algorithms used for secure registration and discovery, as the patient roams around, are presented. The complexity analysis of the proposed schemes is discussed.
A formal taxonomy of privacy in voting protocols	Privacy is one of the main issues in electronic voting. We propose a family of symbolic privacy notions that allows to assess the level of privacy ensured by a voting protocol. Our definitions are applicable to protocols featuring multiple votes per voter and special attack scenarios such as vote-copying or forced abstention. Finally we employ our definitions on several existing voting protocols to show that our model allows to compare different types of protocols based on different techniques, and is suitable for automated verification using existing tools.
A privacy-preserving proximity friend notification scheme with opportunistic networking	Recently, smartphones have revolutionized mobile and pervasive computing around the world, and many smartphone-based applications have been developed to enrich our daily lives, such as location-based application which offers various useful services to its users based on users' current locations like Google Latitude. However, the attractive features of smartphone-based applications inevitably incur higher risks for abuse if such applications and services do not take security and privacy consideration into account prior to it being widely deployment. In this paper, to simultaneously find the proximity friends and protect smartphone users' identity privacy, we utilize the opportunistic networking to propose an efficient privacy-preserving proximity friend notification (PFN) scheme. Specifically, by combining the Bluetooth and 3G techniques of smartphones, a smartphone user can first send his privacy-preserving friend notification packet in a physical proximity area, then once a friend nearby receives and identifies the packet with opportunistic networking, the friend can directly phone back to the user. Detailed security analysis with provable security technique demonstrates the security of the proposed PFN scheme. In addition, extensive simulations have also been conducted to examine its effectiveness in terms of friend notification delay.
Utilizing social links for location privacy in opportunistic delay-tolerant networks	This paper is concerned with improving location-privacy for users accessing location-based services in opportunistic DTNs. We design a protocol that offers location privacy through request/reply location obfuscation technique that uses the nodes' own social network to drive the forwarding heuristic. We propose a fully distributed social-based location privacy protocol (SLPD) that utilizes social ties between nodes to ensure K-Anonymity, i.e. the requesting node's locations cannot be determined from at least k-1 other nodes in its social network. We evaluate SLPD using extensive simulations and real connectivity data traces. We compare our results to a benchmark protocol that requires centralized trusted server. We show that our distributed protocol is applicable to DTNs with various mobility patterns, and provides the user with the required privacy at less than 30% of the privacy range we define. SLPD achieves success ratios similar to the ones obtained using centralized benchmark solutions up to 15% privacy requirements.
Secure and efficient source location privacy-preserving scheme for wireless sensor networks	In this paper, we propose a novel scheme for efficiently and securely preserving source nodes' location privacy. Our scheme uses efficient cryptographic operations to change the packets' appearance at each hop to prevent packet correlation. It also creates a cloud with irregular shape of fake traffic to enable the real source node to send its data anonymously to a fake source node to send to the sink and to camouflage the real source node in the nodes creating the cloud. To reduce the energy cost, clouds are active only during data transmission and the intersection of clouds creates a larger merged cloud to reduce the number of fake packets and boost privacy preservation. Simulation and analytical results demonstrate that our scheme can provide stronger privacy preservation than routing-based schemes and requires much less energy cost than global-adversary-based schemes.
Evaluation of Location Obfuscation techniques for privacy in location based information systems	In recent years, smart-phones and GPS-enabled devices have been a critical factor in the popularization and increasing demand of location based information systems. However, at the same time, the concern of privacy has also increased on users who would like to protect their exact location from attackers or from the service provider. One technique to protect the location is called Location Obfuscation, which consists in non reversible ways to slightly alter the location such that it does not reflect the real location of the user, but still contains enough information to provide a satisfactory service. In this work, the N-Rand, N-Mix and the N-Dispersion techniques are introduced and compared with other two existing techniques, Rand and Distortion, in terms of distance-based metrics. The results show that the N-Rand and N-Dispersion techniques produce a larger minimum distance to the original location, and the greatest average distance to the original path.
Privacy preservation in Location-Based Services (LBS) through Trusted Computing technology	Location privacy in Location Based Services (LBS) is the ability to protect the association between user's identity, query sources, servers and database, thereby preventing an imminent attacker from easily linking users of LBS to certain locations. This paper studies recent schemes designed to offer location privacy and anonymity to LBS users. The main idea is to solve current practical problem by proposing a new framework of LBS Middleware called Trusted Anonymizer (TA) secured by Trusted Computing (TC) technologies. Firstly, we propose an architecture of Clustered Trusted Anonymizer (CTA) to mitigate bottlenecks as well as preventing TA from becoming a single point of failure. Secondly, we focus on a concrete efficient Direct Anonymous Attestation (DAA) scheme with the main functionalities adopted by TCG-compliant platforms in attestation environments. Each party involved in the LBS chain will be equipped with security platforms namely Trusted Platform Module (TPMs) and Mobile Trusted Module (MTMs). Hence, links and services form a trusted infrastructure for mobile and wireless networks.
Opportunistic routing for enhanced source-location privacy in wireless sensor networks	Wireless sensor networks are designed for a plethora of applications, such as unattended event monitoring and tracking. Source-privacy is one of the looming challenges that threaten successful deployment of these sensor networks, especially when they are used to monitor sensitive objects. In order to enhance source-location privacy in wireless sensor networks, we propose the use opportunistic routing schemes. In opportunistic routing, each sensor transmits the packet over a dynamic path to the destination. Every packet from the source can follow a different path toward the destination, making it difficult for an adversary to backtrack hop-by-hop to the origin of the sensor data. In the context of providing source location privacy for wireless sensor networks, the obtained simulation results demonstrate the efficiency and suitability of opportunistic routing in practical applications.
A model for privacy policy agreement in online services	Today, several online services are provided for free in exchange for the users private information/interaction online. It is common for these services on the internet to also act as data warehouse, gathering the usage information and all interaction of its users. The collection and dissemination of the data is governed by the service provider's privacy policy, which users must agree to prior to using the service. Once agreed to the policy, the user no longer has any say in regard to how the service provider uses the data. In this paper, we propose a model for 3 parties policy architecture that allows the consumer, the data warehouse, and a 3rd party service provider that want to use the data stored by the data warehouse to negotiate the privacy policy and the need to access the data. We propose an application architecture utilizing this policy model, and discuss how it can be used. Lastly, we discuss the dataset we perform simulation experiment on, and our findings.
Analysis of location privacy risk in a plain-text communication based Participatory Sensing System using subset coding and mix network	Success of participatory sensing, where participants share information of their environment to an application server using readily available mobile sensor devices such as smart phones, depends on mitigating the location privacy risk as identity of the participants need to be relayed to facilitate rewards. Recently, we proposed a plain-text communication based location anonymization scheme for participatory sensing without compromising data integrity at the application server using our novel subset coding technique. To improve decoding efficiency, instead of using any random k-anonymization, the scheme has to rely on an anonymization server to which an observer communicates via HP3-based mix network so that the identity of the observer can be protected. Introduction of such a network, however, may increase the risk of location privacy when an adversary within the mix network colludes with other types of existing adversaries. This paper presents a detail analysis of such risk with extensive analytical and simulation results to confirm that the risk depends on a number of system parameters and, more importantly, by increasing the network-friends per user in the HP3-based mix network, the risk can be mitigated without increasing the computational overhead or compromising other goals of participatory sensing such as high data integrity at the application server.
RPINA- Network Forensics Protocol Embedding Privacy Enhancing Technologies	Although privacy is considered to be the ultimate right for every user to enjoy intercommunications with security and anonymity, the provision for such a service could easily be adapted as a hiding cover by malicious users. Privacy enhancing technologies (PETs) should not only hide the identity of legitimate users but also provide means by which evidence of malicious activity can be gathered and revealed when necessary. This paper proposes a network forensics protocol called RPINA (respect private information, not abuser) which may operate over PETs, without violating the privacy of innocent users, but only the privacy of abusers. This approach introduces a new dimension in the relation between these two opposite-goal technologies, which enhances their viability in the global network environment
A Personalized Location Privacy Protection Solution in Wireless Network	In this paper we present a novel personalized location privacy protection solution based on AC-tree, we construct a Permission Access Control Center (PACC) in the wireless network, and each target in the wireless network have an AC-tree which store all the rules of user's location privacy. when a user request a target's location information, PACC determine the privacy level according to AC-tree of target, and Location Server (LS) return the corresponding location service to user.
Privacy Preserving Density-Based Outlier Detection	Outlier detection can find its tremendous applications in areas such as intrusion detection, fraud detection, and image processing. Among many outlier detection algorithms, LOF is a very important density-based algorithm in which one critical step is to find the k-distance neighbors. In some privacy preserving circumstances, the cooperation between data holders is necessary while the privacy of the participators should be guaranteed. In this paper, we focus on privacy preserving LOF. We propose a novel algorithm for privacy preserving k-distance neighbors search. Combining it with other secure multiparty computation techniques, we detect outliers by LOF in a privacy preserving way.
A Practical Solution for Privacy-Preserving Approximate Convex Hulls Problem	Convex Hulls Problem is a special case of Privacy-preserving Geometry problems in the inquiry of Secure Multi-Party Computation (SMC). It can be applied in military, commercial and many other fields. However, because of the definition's inherent defect, current schemes will inevitably disclose the points on the vertices. In this paper, we proposed the concept of privacy-preserving approximate convex hulls problem and provide a practical protocol which is more secure and efficient than previous convex hulls protocols. We also show that it can be applied to finding the approximate intersection area of two private convex hulls.
XPACML eXtensible Privacy Access Control Markup Langua	Privacy in the digital world is a critical problem which is becoming even more imperious with the growth of the Internet, accompanied by the proliferation of e-services (e.g. e-commerce, e-health). One research track for efficient privacy management is to make use of user's and service provider's (SP) privacy policies, and to perform an automatic comparison in between to help any (skilled or unskilled) users preserving their privacy.
Cloud computing privacy & security global issues, challenges, & mechanisms	Cloud computing is a developing archetype with marvelous momentum, but its exceptional aspects worsening the security and privacy challenges. This article provides an overview of the security and privacy challenges pertinent to public cloud computing and points out considerations organizations should take when outsourcing data, applications, and infrastructure to a public cloud environment. We have also proposed a security mechanism ΓÇ£security as a serviceΓÇ¥ for cloud computing. It also explores the roadblocks and solutions to providing a trustworthy cloud computing environment.
BCE: A privacy-preserving common-friend estimation method for distributed online social networks without cryptography	Distributed online social networks (DOSN) have emerged recently. Nevertheless, recommending friends in the distributed social networks has not been exploited fully. We propose BCE (Bloom Filter based Common-Friend Estimation), a scalable and privacy-preserving common-friend estimation scheme that estimates the set of common friends without the need of cryptography techniques. First, BCE denotes each user using the identifiers created by the Peer-to-Peer underlay that are robust against the dictionary attacks. Second, BCE uses a Bloom filter to represent a friend list for scalability. Third, BCE estimates common friends of two users using the intersection of Bloom filters computed by one of their common friends, which ensures the privacy of friend lists against unknown users. Our privacy analysis shows that BCE hides the privacy of each user with a high probability. Simulations over real-world social-network data sets confirms that BCE is both accurate and scalable.
Adaptive Privacy-Preserving Authentication in Vehicular Networks	Vehicular networks have attracted extensive attentions in recent years for their promises in improving safety and enabling other value-added services. Most previous work focuses on designing the media access and physical layer protocols. Privacy issues in vehicular systems have not been well addressed. We argue that privacy is a user-specific concept, and a good privacy protection mechanism should allow users to select the degrees of privacy they wish to have. To address this requirement, we propose an adaptive privacy-preserving authentication mechanism that can trade off the privacy degree with computational and communication overheads (resource usage). This mechanism, to our knowledge, is the first effort on adaptive privacy-preserving authentication. We present analytical and preliminary simulation results to show that the proposed protocol is not only adaptive but also scalable.
Uni-Access: A secure location aware communication system providing user privacy	In this working paper, we propose a location determination system, uni-access, which provides location information while still respecting the location privacy of the user. The uni-access system takes into account legislation, corporate policies and user input to define a set of rules for location privacy. In addition to location determination services, uni-access incorporates an intrusion detection system (IDS) for security purposes. The uni-access IDS uses location information to improve its detection capabilities.
A Privacy Enabled Service Authorization Based on a User-centric Virtual Identity Management System	User trust and empowerment (in terms of their personal data control) are areas that must be addressed thoroughly when talking about identity and business models for distributed communication systems. Protecting the privacy of users is a challenging problem for identity management systems, which can only be achieved if it gives users complete control over their identity data. However, none of the existing solutions offers this possibility. Based on a user-centric virtual identity defined by EU IST project Daidalos, this paper proposes an effective infrastructure to authorize the privacy-enabled pervasive service, which protects the context-driven access policies for online services in order to avoid attacks by malicious eavesdroppers. In the proposed infrastructure, SMAL and Diameter are used to securely protect and deliver authenticated and authorized entities and XACML is used to authorize the user-level privacy policy. The proposed infrastructure is partially integrated into the Daidalos demonstration platform.
Routing for enhancing source-location privacy in wireless sensor networks of multiple assets	In wireless sensor networks, a node that reports information gathered from adjacent assets should relay packets appropriately so that its location context is kept private, and thereby helping ensure the security of the assets that are being monitored. Unfortunately, existing routing methods that counter the local eavesdropping-based tracing deal with a single asset, and most of them suffer from the packet-delivery latency as they prefer to take a separate path of many hops for each packet being sent. In this paper, we propose a routing method, greedy perimeter stateless routing-based source-location privacy with crew size w (GSLP-w), that enhances location privacy of the packet-originating node (i.e., active source) in the presence of multiple assets. GSLP-w is a hybrid method, in which the next-hop node is chosen in one of four modes, namely greedy, random, perimeter, and retreat modes. Random forwarding brings the path diversity, while greedy forwarding refrains from taking an excessively long path and leads to convergence to the destination. Perimeter routing makes detours that avoid the nodes near assets so that they cannot be located by an adversary tracing up the route path. We study the performance of GSLP-w with respect to crew size w (the number of packets being sent per path) and the number of sources. GSLP-w is compared with phantom routing-single path (PR-SP), which is a notable routing method for source-location privacy and our simulation results show that improvements from the point of the ratio of safety period and delivery latency become significant as the number of source nodes increases.
A beacon-based trust management system for enhancing user centric location privacy in VANETs	In recent years, more and more researches have been focusing on trust management of vehicle ad-hoc networks (VANETs) for improving the safety of vehicles. However, in these researches, little attention has been paid to the location privacy due to the natural conflict between trust and anonymity, which is the basic protection of privacy. Although traffic safety remains the most crucial issue in VANETs, location privacy can be just as important for drivers, and neither can be ignored. In this paper, we propose a beacon-based trust management system, called BTM, that aims to thwart internal attackers from sending false messages in privacy-enhanced VANETs. To evaluate the reliability and performance of the proposed system, we conducted a set of simulations under alteration attacks, bogus message attacks, and message suppression attacks. The simulation results show that the proposed system is highly resilient to adversarial attacks, whether it is under a fixed silent period or random silent period location privacy-enhancement scheme.
PEC: A privacy-preserving emergency call scheme for mobile healthcare social networks	In this paper, we propose a privacy-preserving emergency call scheme, called PEC, enabling patients in life-threatening emergencies to fast and accurately transmit emergency data to the nearby helpers via mobile healthcare social networks (MHSNs). Once an emergency happens, the personal digital assistant (PDA) of the patient runs the PEC to collect the emergency data including emergency location, patient health record, as well as patient physiological condition. The PEC then generates an emergency call with the emergency data inside and epidemically disseminates it to every user in the patient's neighborhood. If a physician happens to be nearby, the PEC ensures the time used to notify the physician of the emergency is the shortest. We show via theoretical analysis that the PEC is able to provide fine-grained access control on the emergency data, where the access policy is set by patients themselves. More- over, the PEC can withstand multiple types of attacks, such as identity theft attack, forgery attack, and collusion attack. We also de- vise an effective revocation mechanism to make the revocable PEC (rPEC) resistant to inside attacks. In addition, we demonstrate via simulation that the PEC can significantly reduce the response time of emergency care in MHSNs.
User authentication scheme with privacy-preservation for multi-server environment	New user authentication schemes for multiple-servers environment were proposed by Liao-Wang and Tsai. In their schemes, application servers do not need to maintain a verification table and this admired merit is not addressed by previous scholarship. Besides, the privacy of users is also addressed in Liao-Wang's scheme. In this article, we show that their schemes are not secure against the server spoofing and the impersonation attacks. Then we propose a robust user authentication scheme to withstand these attacks and keep the same merits.
A Novel Group-Based Handover Authentication Scheme with Privacy Preservation for Mobile WiMAX Networks	This letter proposes an efficient group-based handover authentication scheme for mobile WiMAX networks. When the first Mobile Station (MS) of the handover group moves from the service Base Station (BS) to a target BS, the service BS transmits all the handover group members security context to the target BS. Thus the rest of the MSs in the same handover group can bypass the Extensible Authentication Protocol (EAP) and the security context transfer phases to directly perform the handover authentication, which obviously reduces handover latency. Moreover, the proposed scheme not only meets the essential security requirements in handover authentication semantics (such as mutual authentication and resisting the domino effect) but also achieves privacy preservation.
An Efficient Privacy Preserving Data Aggregation Scheme with Constant Communication Overheads for Wireless Sensor Networks	Providing efficient data aggregation while preserving data privacy in wireless sensor networks (WSNs) is a challenging problem. Existing security schemes either incur high communication and computational overheads or simply fail to counter attacks when nodes are compromised. In this paper, we present a multidimensional privacy preserving data aggregation scheme for WSNs which is efficient and provides strong security. The scheme not only provides efficient countermeasure against passive and active privacy compromising attacks, coalition attacks from malicious base station and captured sensor nodes, but also is robust to data loss. In addition, the proposed scheme provides data aggregation with constant communication overheads, so that the transmission cost can be significantly reduced which makes it suitable to be used in large scale WSNs. To the best of our knowledge, our scheme is the first one that addresses the privacy and efficiency issues in WSNs all at once.
Mitigation of Compromising Privacy by Transmission Range Control in Wireless Sensor Networks	Wireless sensor networks (WSNs) are used to obtain information from the surrounding areas and collected data is reported to the base station through wireless links. In certain scenarios ongoing transmissions within the network need to be concealed so that no information is leaked beyond a vulnerable area. Such a concealment effort necessitates transmit ranges of radios to be limited. However, limiting transmit ranges results in sub-optimal routing patterns within the network, which results in lower network lifetime. In this paper, through a Linear Programming (LP) framework, we analyze lifetime limits of WSNs improving contextual privacy by transmit range control.
Building a decentralized, cooperative, and privacy-preserving monitoring system for trustworthiness: the approach of the EU FP7 DEMONS project [Very Large Projects]	The aim of DEMONS is to significantly improve the trustworthiness of today's Internet by empowering the operators' ability to detect and react to global-scale incidents and malicious activity. To this end, DEMONS follows an integrated approach to network monitoring whose key elements are the distribution of programmable monitoring tasks across cooperative monitoring nodes, and the deployment of inter-domain collaborative mechanisms that preserve the privacy of customers' and operators' data.
Security and privacy in RFID and applications in telemedicine	Radio frequency identification systems have many applications in manufacturing, supply chain management, inventory control, and telemedicine. In an RFID system, products and objects are given RFID tags to identify themselves. However, security and privacy issues pose significant challenges on these systems. In this article we first briefly introduce RFID systems. Then two RFID applications in telemedicine are proposed: studying supply and demand of doctors, nurses, and patients in hospitals and healthcare, and developing mobile telemedicine services. The security and privacy issues of RFID, and their solutions are discussed as well.
Policy management for ENUM system enabling privacy and security	ENUM (telephone number mapping) is a key enabler in the convergence between IP-based networks and the traditional PSTNs that may result in additional complexity in commercial relationships and regulation of the telecommunications sector. In particular, the current ENUM may significantly increase the risk of unscrupulous use of the information managed (e.g., public user identifiers and user/service reachability). The aim of this article is to describe a new functional reference model for ENUM, and provide some new requirements that enable user privacy and security.
Do not snoop my habits: preserving privacy in the smart grid	The recent deployment of smart grids has proven to bring numerous advantages in terms of energy consumption reduction in both homes and businesses. A more accurate measurement of up-to-date electricity necessities through smart meters utilization leads to an enhancement in the ability of monitoring, controlling and predicting energy use. Nevertheless, it has associated drawbacks related to the privacy of customers as well, since such management might reveal their personal habits and behavior, which electrical appliances they are using at each moment, whether they are at home or not, and so on. In this article we present a privacy enhanced architecture for smart metering aimed to tackle this threat by means of a new and novel protocol encrypting individual measurements while allowing the electricity supplier to access the aggregation of the corresponding decrypted values. The technique being used is named additively homomorphic encryption, and enables the direct connection and exchange of data between electricity suppliers and final users, while preserving the privacy of the latter.
The quest for personal control over mobile location privacy	How to protect location privacy of mobile users is an important issue in ubiquitous computing. However, location privacy protection is particularly challenging: on one hand, the administration requires all legitimate users to provide identity information in order to grant them permission to use its wireless service; on the other hand, mobile users would prefer not to expose any information that could enable anyone, including the administration, to get some clue regarding their whereabouts; mobile users would like to have complete personal control of their location privacy. To address this issue, we propose an authorized-anonymous-ID-based scheme; this scheme effectively eliminates the need for a trusted server or administration, which is assumed in the previous work. Our key weapon is a cryptographic technique called blind signature, which is used to generate an authorized anonymous ID that replaces the real ID of an authorized mobile device. With authorized anonymous IDs, we design an architecture capable of achieving complete personal control over location privacy while maintaining the authentication function required by the administration.
Giving notice: why privacy policies and security breach notifications aren't enough	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01497545.png" border="0">
SlotSwap: strong and affordable location privacy in intelligent transportation systems	Public acceptance, and thus the economic success, of an ITS is highly dependent on the quality of deployed privacy mechanisms. In general, neither users nor operators should be able to track a given individual. One approach to facilitate this is the usage of pseudonym pools, which allow vehicles to autonomously switch between different identities. We extend this scheme with that of a time-slotted pseudonym pool of static size, reducing the storage and computation needs of the envisioned ITS while further improving users' privacy. In addition, we allow the exchange of pseudonyms between vehicles, eliminating the mapping between vehicles and pseudonyms even for the ITS operator. We support the exchange of both current and future pseudonyms, further enhancing users' privacy. We evaluate the feasibility of our approach and back up privacy claims by performing a simulative study of the system using the entropy of nodes' anonymity sets as the primary metric.
Privacy enhancements for mobile and social uses of consumer electronics	Today's consumer electronics feature marvelous capabilities. From smartphones to in-car navigators to media players, all benefit from advances in underlying components such as RAM, GPS chips, and fast communications networks. Buddy-mapping applications, now possible and deployed on smartphones and personal navigation systems, are a meld of communications, instant messaging, location-aware service, and map mash-up. These kinds of applications can be incredibly useful and fun; at the same time, their feature creep can threaten user privacy. For example, the ability to map all buddies on a mobile smartphone via a mobile buddymapping application (e.g., Google Latitude) also makes it necessary to manage one's visibility with respect to a large number of buddies. As we explain in this article, this is of key importance since once one is seen on another's map, one's intent can sometimes be inferred; and even if intent is not something one is hiding per se, it is still desirable to know "Who can see me now?" and to be forewarned of impending visibility. Today's consumer communications applications and devices do not handle these requirements well. This article presents middleware architecture and methodology that can help give users of buddy-mapping services greater awareness of who is about to see them before they are actually seen.
The pursuit of citizens' privacy: a privacy-aware smart city is possible	Cities are growing steadily, and the process of urbanization is a common trend in the world. Although cities are getting bigger, they are not necessarily getting better. With the aim to provide citizens with a better place to live, a new concept of a city was born: the smart city. The real meaning of smart city is not strictly defined, but it has gained much attention, and many cities are taking action in order to be considered 'smart'. These smart cities, founded on the use of information and communication technologies, aim at tackling many local problems, from local economy and transportation to quality of life and e-governance. Although technology helps to solve many of these local problems, their ability to gather unprecedented amounts of information could endanger the privacy of citizens. In this article we identify a number of privacy breaches that can appear within the context of smart cities and their services. We leverage some concepts of previously defined privacy models and define the concept of citizens' privacy as a model with five dimensions: identity privacy, query privacy, location privacy, footprint privacy and owner privacy. By means of several examples of smart city services, we define each privacy dimension and show how existing privacy enhancing technologies could be used to preserve citizens' privacy.
Safebook: A privacy-preserving online social network leveraging on real-life trust	Online social network applications severely suffer from various security and privacy exposures. This article suggests a new approach to tackle these security and privacy problems with a special emphasis on the privacy of users with respect to the application provider in addition to defense against intruders or malicious users. In order to ensure users' privacy in the face of potential privacy violations by the provider, the suggested approach adopts a decentralized architecture relying on cooperation among a number of independent parties that are also the users of the online social network application. The second strong point of the suggested approach is to capitalize on the trust relationships that are part of social networks in real life in order to cope with the problem of building trusted and privacy- preserving mechanisms as part of the online application. The combination of these design principles is Safebook, a decentralized and privacy- preserving online social network application. Based on the two design principles, decentralization and exploiting real-life trust, various mechanisms for privacy and security are integrated into Safebook in order to provide data storage and data management functions that preserve users' privacy, data integrity, and availability. Preliminary evaluations of Safebook show that a realistic compromise between privacy and performance is feasible.
Privacy-preserving advance power reservation	Smart grid is considered to be the next generation power system. Integrating information and communication technology, power electronics, and power system technologies, smart grid reduces excess power generation by better matching power generation with customer demands, and facilitates renewable power generation by closely monitoring renewable energy source status. Such a large-scale network may be subject to various attacks. In particular, authentication and user privacy preservation are considered two major security concerns. In this article, we first highlight the importance of smart grid security. Next we introduce a new power request paradigm in which a customer is allowed to submit a power usage plan in advance. We then propose a secure and privacy-preserving power request scheme as a solution to this problem. To achieve the privacy-preserving property, our scheme employs two cryptographic techniques: anonymous credential and blind signature. We conclude this article by discussing the security and performance issues of our proposed scheme.
Editorial - Communications privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01089773.png" border="0">
Host Identity Protocol (HIP): Connectivity, Mobility, Multi-Homing, Security, and Privacy over IPv4 and IPv6 Networks	The Host Identity Protocol (HIP) is an inter-networking architecture and an associated set of protocols, developed at the IETF since 1999 and reaching their first stable version in 2007. HIP enhances the original Internet architecture by adding a name space used between the IP layer and the transport protocols. This new name space consists of cryptographic identifiers, thereby implementing the so-called identifier/locator split. In the new architecture, the new identifiers are used in naming application level end-points (sockets), replacing the prior identification role of IP addresses in applications, sockets, TCP connections, and UDP-based send and receive system calls. IPv4 and IPv6 addresses are still used, but only as names for topological locations in the network. HIP can be deployed such that no changes are needed in applications or routers. Almost all pre-compiled legacy applications continue to work, without modifications, for communicating with both HIP-enabled and non-HIP-enabled peer hosts. The architectural enhancement implemented by HIP has profound consequences. A number of the previously hard networking problems become suddenly much easier. Mobility, multi-homing, and baseline end-to-end security integrate neatly into the new architecture. The use of cryptographic identifiers allows enhanced accountability, thereby providing a base for easier build up of trust. With privacy enhancements, HIP allows good location anonymity, assuring strong identity only towards relevant trusted parties. Finally, the HIP protocols have been carefully designed to take middle boxes into account, providing for overlay networks and enterprise deployment concerns. This article provides an in-depth look at HIP, discussing its architecture, design, benefits, potential drawbacks, and ongoing work.
Providing Source Location Privacy in Wireless Sensor Networks: A Survey	Wireless sensor networks (WSNs) consist of numerous small nodes that can sense, collect, and disseminate information for many different types of applications. One of these applications is subject tracking and monitoring, in which the monitored subjects often need protection. For instance, a WSN can be deployed to monitor the movement of a panda in a national park. The panda needs protection from different adversaries, such as hunters and poachers. An adversary might trace the messages in the WSN to find the source node that sensed the panda, with the final aim of killing the panda. Hence the question is: how do we hide the location of the source node from the adversary? This question is relevant in several of the scenarios related to this application, such as patient monitoring and battlefield surveillance. In other words, the problem is to provide privacy to the source node: source location privacy. In this paper, we provide a survey of the state of the art in source location privacy. We first discuss the key concepts in source location privacy, such as anonymity, unobservability, safety period, and capture likelihood. Then, we present an overview of the solutions that provide source location privacy within a WSN, in relation to the assumptions about the adversary's capabilities. In particular, we summarize the concepts and solutions, which are categorized based on the core techniques used to provide source location privacy. We mention the limitations of the algorithms as found in the literature, classify the solutions based on their approach, and provide an overview of the assumptions on the adversarial capabilities related to each solution.
Security and Privacy in Cloud Computing	Recent advances have given rise to the popularity and success of cloud computing. However, when outsourcing the data and business application to a third party causes the security and privacy issues to become a critical concern. Throughout the study at hand, the authors obtain a common goal to provide a comprehensive review of the existing security and privacy issues in cloud environments. We have identified five most representative security and privacy attributes (i.e., confidentiality, integrity, availability, accountability, and privacy-preservability). Beginning with these attributes, we present the relationships among them, the vulnerabilities that may be exploited by attackers, the threat models, as well as existing defense strategies in a cloud scenario. Future research directions are previously determined for each attribute.
Cyber Security and Privacy Issues in Smart Grids	Smart grid is a promising power delivery infrastructure integrated with communication and information technologies. Its bi-directional communication and electricity flow enable both utilities and customers to monitor, predict, and manage energy usage. It also advances energy and environmental sustainability through the integration of vast distributed energy resources. Deploying such a green electric system has enormous and far-reaching economic and social benefits. Nevertheless, increased interconnection and integration also introduce cyber-vulnerabilities into the grid. Failure to address these problems will hinder the modernization of the existing power system. In order to build a reliable smart grid, an overview of relevant cyber security and privacy issues is presented. Based on current literatures, several potential research fields are discussed at the end of this paper.
Evaluating the Security and Privacy Protection Level of IP Multimedia Subsystem Environments	In complex environments like the IP multimedia Subsystem (IMS), state of the art security solutions cannot always provide satisfactory protection against any type of attack. This paper addresses the security mechanisms utilized by IMS with respect to their susceptibility to SIP based attacks that have been described in the literature. This analysis also studies the effects of 3GPP's security directions (i.e., IMS architectures) on limiting the attack chances. The protection mechanisms involved are evaluated considering three distinct and crucial factors: (i) whether the attacker is an insider or an external one, (ii) the time frame of the attack and (iii) how these attacks affect the messages' confidentiality, authenticity and integrity as well as architecture's availability and users' privacy. A thorough review of the recently proposed protection frameworks is also provided together with an evaluation of the protection level they offer to the IMS architecture.
A Privacy Model for Smart Metering	Electricity suppliers have started replacing traditional electricity meters with so-called smart meters, which can transmit current power consumption levels to the supplier within short intervals. Though this is advantageous for the electricity suppliers' planning purposes, and also allows the customers a more detailed look at their usage behavior, it means a considerable risk for privacy. The detailed information can be used to judge whether persons are in the household, when they come home, which electric devices they use (e.g. when they watch TV), and so forth. In this work, we introduce the "smart metering privacy model" for measuring the degree of privacy that a smart metering application can provide. Moreover, we present two design solutions both with and without involvement of trusted third parties. We show that the solution with trusted party can provide "perfect privacy" under certain conditions.
To Add or Not to Add: Privacy and Social Honeypots	Online Social Networks (OSNs) have become a mainstream cultural phenomenon in the past years, where million of people connect to each other and share memories, digital media and business relations. Many users also publish personal information about their activities, relationships, locations and interests on these sites, seemingly unaware of how these data can be used by other parties. Sites typically attempt to restrict data-sharing to members of a user''s social network, but this is only effective if these social networks cannot be exploited by malicious users. In this paper we perform an experiment in order to assess the vulnerability and privacy awareness of users when engaging in online relations with random unknown users, or those pretending to be a famous character. We find that usually users do not accept random friendship requests, but some aggressively search for celebrities, making a perfect case for spammers to form honeypots using such fake profiles. We present a set of suggestions for enhancing privacy on social networks which could reduce the threats of identity theft in such environments.
Preserving Privacy in Assistive Technologies	Assistive technologies enable individuals to perform a function that might be difficult or they otherwise are unable to do. However, the provision of context-awareness interfaces and accessible information everywhere bring with them the potential for data violations, with concomitant privacy issues such as spying and exploitation. Privacy preservation can thus constrain deployment. The aim of this paper is to promote user sensitiveness in privacy policy and tackle malicious data extraction and selling, with the focus on assistive technologies for a diverse mix of services for use in applications ranging from healthcare to smart shopping.
Network impacts of privacy and authentication protocols for PCS	This paper describes the message flow due to authentication, voice privacy, and signaling message encryption of two schemes that are expected to be incorporated in the EIA/TIA's cellular industry Interim Standard IS 41 Revision C. We compare the two schemes with the use of a simple mobility model for users and study their impact on the traffic to network databases. Defining user mobility rate as the number of registrations per hour per user, we show that as the user mobility rate increases from roughly 0.5 to 15, the effectiveness of one of the schemes (the one that shares the shared secret data or SSD with the visited system) as compared to the other (the one that does not share it with the visited system) varies from about 66% improvement to about 30% degradation, clearly implying that the mobility characteristics of the user population dictate the choice of the authentication scheme
Providing privacy without encryption in multichannel systems	We introduce a new randomized distributed protocol designed to detect unauthorized reads in multichannel-communication systems, such as wavelength division multiplexed optical networks. We describe a method for modifying any available scheduling protocol for channel sharing, so that the new protocol does not use cryptography, yet it prevents eavesdropping by third parties. Our approach uses the tunability delay of optical transmitters and receivers as well as a special challenge-response scheme to guarantee privacy of communication. We provide two solutions to deal with different levels of attacks: (1) eavesdroppers working alone, and (2) eavesdroppers working in collaboration
RFID System for User's Privacy Protection	Recently, the RFID system has been studied actively in ubiquitous computing environments as a main technology. While the RFID system has much advantage, however it may create new problems to the user's privacy. In this paper, we present a description of previously proposed mechanisms for protecting user's privacy and these problems. Then, we propose the RFID system providing privacy protection in ubiquitous computing environments. The proposed system provides a method of protecting user's privacy from unwanted scanning and tracking by an adversary
A Practical Approach to provide Communication Privacy	Privacy and security are important features for the future mobile wireless Internet since users expect a privacy level comparable to that of today's cellular networks. Separating identifiers from locators is a current practice in today's new network protocols and is a small step on the right direction. However, the separation must be maintained in the presence of an intruder who eavesdrops or manipulates the traffic. In this paper we present a generic framework that targets these problems at the network layer. We further instantiate this framework with an example architecture using well-known protocols which support mobility.
Distributed Privacy-Preserving Policy Reconciliation	Organizations use security policies to regulate how they share and exchange information, e.g., under what conditions data can be exchanged, what protocols are to be used, who is granted access, etc. Agreement on specific policies is achieved though policy reconciliation, where multiple parties, with possibly different policies, exchange their security policies, resolve differences, and reach a consensus. Current solutions for policy reconciliation do not take into account the privacy concerns of reconciliating parties. This paper addresses the problem of preserving privacy during security policy reconciliation. We introduce new protocols that meet the privacy requirements of the organizations and allow parties to find a common policy rule which maximizes their individual preferences.
An Architecture for Network Layer Privacy	We present an architecture for the provision of network layer privacy based on the SHIM6 multihoming protocol. In its basic form, the architecture prevents on-path eavesdroppers from using SHIM6 network layer information to correlate packets that belong to the same communication but use different locators. To achieve this, several extensions to the SHIM6 protocol and to the HBA (Hash Based Addresses) addressing model are defined. On its full-featured mode of operation, hosts can vary dynamically the addresses of the packets of on-going communications. Single-homed hosts can adopt the SHIM6 protocol with the privacy enhancements to benefit from this protection against information collectors.
Distributed ONS and its Impact on Privacy	The EPC Network is an industry proposal to build a global information architecture for objects carrying RFID tags with electronic product codes (EPC). A so-called object naming service (ONS) is used to locate information sources for these objects in the EPC Network. But ONS is based on DNS, which suffers from well-studied weaknesses in robustness, configuration complexity and security. There are promising approaches to enhance the performance and robustness of DNS by using structured P2P systems based on distributed hash tables (DHT) that have a high potential as a replacement for ONS as well. We investigate if and how a decentralized alternative to ONS based on DHT could additionally offer data access control and enhance the privacy of its clients. As it turns out, the strength of privacy protection will slightly increase by using DHT compared to DNS, but strong protection will depend on the feasibility of secure out- of-band key distribution mechanisms.
PPGCV: Privacy Preserving Group Communications Protocol for Vehicular Ad Hoc Networks	Vehicular communications (VC) have many applications with multicast nature such as cooperative driving and platooning. The multicast nature implies that secure group communication is important to guarantee the security in vehicular networks. One of the main security concerns for vehicular networks is preserving the privacy of the network users. In this paper, we propose privacy preserving group communication protocol for vehicular ad hoc networks (PPGCV). The PPGCV preserves the privacy of the users and provides conditional full statelessness property. By conducting detailed analysis and simulation, PPGCV is demonstrated to be reliable, efficient, and scalable.
A Source-Location Privacy Protocol in WSN Based on Locational Angle	In environments where sensor networks are used to monitor sensitive objects or valuable assets, attackers may use the method of hop-by-hop backtracking to find out the protected objects. This paper proposes a new source protected protocol in WSN, the phantom routing with locational angle (PRLA). In PRLA, inclination angles are introduced and used to direct random walks, which avoids choosing paths harmful to the privacy of source location. Simulation results show that, compared to the phantom single-path routing protocol proposed in the literature, PRLA improves the safety period by up to 50% with minor increase in energy overhead.
Wireless Location Privacy Protection in Vehicular Ad-Hoc Networks	Advances in mobile networks and positioning technologies have made location information a valuable asset in vehicular ad-hoc networks (VANETs). However, the availability of such information must be weighted against the potential for abuse. In this paper, we investigate the problem of alleviating unauthorized tracking of target vehicles by adversaries in VANETs. We propose a vehicle density-based location privacy (DLP) scheme which can provide location privacy by utilizing the neighboring vehicle density as a threshold to change the pseudonyms. We derive the delay distribution and the average total delay of a vehicle within a density zone. Given the delay information, an adversary may still be available to track the target vehicle by a selection rule. We investigate the effectiveness of DLP based on extensive simulation study. Simulation results show that the probability of successful location tracking of a target vehicle by an adversary is inversely proportional to both the traffic arrival rate and the variance of vehicles' speed. Our proposed DLP scheme also has a better performance than both Mix-Zone scheme and AMOEBA with random silent period.
Privacy-Enhanced User-Centric Identity Management	User-centric identity management approaches have received significant attention for managing private and critical identity attributes from the user's perspective. User-centric identity management allows users to control their own digital identities. Users are allowed to select their credentials when responding to an authentication or attribute requester and it gives users more rights and responsibility over their identity information. However, current user-centric approaches mainly focus on interoperable architectures between existing identity management systems and privacy issues have not been considered in depth. In this paper, we propose a category-based privacy preference approach to enhance the privacy of user-centric identity management systems. In addition, we present our proof- of-concept prototype of our approach in the Identity Metasystem.
Routing-Based Source-Location Privacy in Wireless Sensor Networks	Wireless sensor networks (WSN) have the potential to be widely used in many areas for unattended event monitoring. Mainly due to lack of a protected physical boundary, wireless communications are vulnerable to unauthorized interception and detection. Privacy is becoming one of the major issues that jeopardize the successful deployment of wireless sensor networks. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address the source-location privacy. For WSN, source-location privacy service is further complicated by the fact that the sensor nodes consist of low-cost and low-power radio devices, computationally intensive cryptographic algorithms (such as public-key cryptosystems) and large scale broadcasting-based protocols are not suitable for WSN. In this paper, we propose a scheme to provide both content confidentiality and source-location privacy through routing to a randomly selected intermediate node (RRIN). While being able to provide source-location privacy for WSN, our simulation results also demonstrate that the proposed scheme is very efficient and can be used for practical applications.
Protecting Location Privacy in Large-Scale Wireless Sensor Networks	In a wireless sensor network, an adversary equipped monitoring antenna can easily overhear packets, which may facilitate identifying the directions of packet flows and trace to the sink or source nodes. In order to defend the location privacy of the sink and source nodes, we propose a location privacy support scheme (LPSS). We prove that, with the increase in distance between sink and source node, the protection strength of the LPSS increases exponentially. Theoretical and simulation results show that LPSS can provide strong location privacy protection for both the sink and source nodes under different attacks. Under the similar delivery delay (or energy consumption), the safe time provided by LPSS is much longer than other approaches. Facilitated by the study on LPSS, we further investigate that the correlation between sink and source nodes. We find that if one source node is exposed to a sophisticated adversary, conventional fake packet injection mechanisms for protecting sink node tend to be useless.
Preserving Privacy for Location-Based Services with Continuous Queries	Location-based service (LBS) is gaining momentum as GPS-equipped mobile devices become increasingly affordable and popular. One of the potential obstacles faced by LBS is that users may raise concerns about their personal privacy when location data are sent to a distrusted LBS provider. A well-known solution is to render the location data less accurate through spatial or temporal cloaking. In this paper, we show that by combining consecutive location data including speed, heading direction, and cloaked locations, an adversary can obtain more accurate estimation of the actual location. We propose a solution to prevent such inferences by cloaking speed and direction. Since the cloaking is based on estimated future locations, we devise methods for tolerating errors caused by the estimation process. We report simulation results on the tradeoff between the capability of tolerating errors and the degree of cloaking.
On measuring the privacy of anonymized data in multiparty network data sharing	This paper aims to find a practical way of quantitatively representing the privacy of network data. A method of quantifying the privacy of network data anonymization based on similarity distance and entropy in the scenario involving multiparty network data sharing with Trusted Third Party (TTP) is proposed. Simulations are then conducted using network data from different sources, and show that the measurement indicators defined in this paper can adequately quantify the privacy of the network. In particular, it can indicate the effect of the auxiliary information of the adversary on privacy.
Privacy prevention based on trust model for P2P streaming systems	In P2P streaming networks, the main sources of illegal media contents sharing are streaming clients who ignore copyright laws and provide contents deliver services. To stop illegally media contents sharing activities with the boundary of a P2P streaming network, we propose a time-space dynamic trust model for legalizing peers' content delivery services. We incorporate time dimension using time-frame, which captures experience and recommendation's time-sensitivity. At the same time, we introduce space dimension using IP addresses, which reflects the peers' physical locations and relations. Together, these two dimensions are adjusted using positive feedback control mechanism, thus, trust valuation can reflect the dynamics of the trust environment. Theoretical analysis and simulation results show that, out proposed trust model has advantages in modeling time-space dynamic trust relationship. It is capable to detect and penalize the illegally media contents sharing peers, as well as those that exhibit malicious behavior. Moreover, the trust model can filter out dishonest peers effectively.
GRIP - a profile control mechanism for user privacy protection and quality of personalization services	In an era in which customization is a growing feature of online services, personalization services are invented to provide users a single portal where they can access selected contents. Designed to reduce information overload, improve efficiency, and increase the use of certain contents, these services must first obtain users' personal information in order to provide tailor-made benefits. However, users are commonly deterred by this request due to privacy concerns, and thus are unable to enjoy the benefits these services have to offer. In this paper we propose a profile control mechanism GRIP (granularity control mechanism based on person identification probability) to manage the number and granularity of personal information disclosed to services. By increasing user privacy protection while ensuring quality of service, this mechanism allows personalization services to better serve their users and users to better enjoy the services.
Privacy in Bidirectional Relay Networks	In this work, the bidirectional broadcast channel (BBC) with confidential messages is studied. The problem is motivated by the concept of bidirectional relaying in a three-node network, where a half-duplex relay node establishes a bidirectional communication between two other nodes using a decode-and-forward protocol and thereby transmits additional confidential information to one of them in the broadcast phase. The corresponding confidential message is transmitted at a certain secrecy level which characterizes the amount of information that can be kept secret from the non-legitimate node. The capacity-equivocation and secrecy capacity regions of the BBC with confidential messages are established where the latter characterizes the communication scenario with perfect secrecy, which means that the confidential information is completely hidden from the non-legitimate node. Thereby, it is shown that the optimal processing exploits ideas and concepts of the BBC with common messages and of the classical broadcast channel with confidential messages.
A Comparison of Four Methods for Analog Speech Privacy	Four well-known procedures for analog speech privacy have been compared in terms of residual intelligibility, bandwidth expansion, and encoding delay. Intelligibility scores have been determined from a perceptual experiment where about 70 untrained listeners were given the task of recognizing each of 200 spoken digits that occurred in a balanced set of 50 encrypted four-digit utterances, and by averaging resulting probabilities of correct digit recognition. Bandwidth expansion has been expressed in terms of a new segmental measure that is more sensitive to short-time bandwidth manipulations than a conventional, long-time-averaged power spectrum measurement. Encoding delay is a straightforward function of analog scrambler parameters. The scrambling procedures that have been compared are sample permutation (<tex>S</tex>), block permutation (<tex>B</tex>), frequency inversion (<tex>F</tex>), and a combination of methods<tex>B</tex>and<tex>F</tex>, denoted by [<tex>BF</tex>]. Sample permutations involved a contiguous set of L<inf>S</inf>(2 to 128) 8 kHz samples, while block permutations operated on a contiguous set of N<inf>B</inf>(4 to 128) speech segments each of which was L<inf>B</inf>(8 to 256) samples long. Frequency inversion is obtained by simply inverting the sign of every other Nyquist (8 kHz) sample. The parameters,<tex>L_{s},N_{B}</tex>, and L<inf>B</inf>, determine residual intelligibility as well as transmission properties such as encoding delay and bandwidth. The comparisons in our study provide a quantitative justification for the popular approach [<tex>BF</tex>]. For example, with<tex>N_{B} = 8</tex>and<tex>L_{B} =128</tex>, although the encoding delay is as much as 128 ms, the bandwidth expansion is only about 100 Hz (using the new segmental measure), and the digit intelligibility<tex>I</tex>is 20 percent. Note that in the specific problem of recognizing ten digits, purely random (input-independent) listener responses correspond to<tex>I = 10</tex>percent.
Analysis of location privacy solutions in wireless sensor networks	Extensive work has been done on the protection of wireless sensor networks (WSNs) from the hardware to the application layer. However, only recently, the privacy preservation problem has drawn the attention of the research community because of its challenging nature. This problem is exacerbated in the domain of WSNs owing to the extreme resource limitation of sensor nodes. In this study the authors focus on the location privacy problem in WSNs, which allows an adversary to determine the location of nodes of interest to him. The authors provide a taxonomy of solutions based on the power of the adversary and the main techniques proposed by the various solutions. In addition, the authors describe and analyse the advantages and disadvantages of different approaches. Finally, they discuss some open challenges and future directions of research.
Privacy-preserving range set union for rare cases in healthcare data	Hospitals have to use a large amount of medical data from individuals while protecting their privacy to execute medical data mining. It is important to find `rare` cases among medical data of individuals in many healthcare applications. Therefore hospitals need privacy-preserving mining techniques to find rare cases among medical data of individuals. However, previous privacy-preserving data-mining techniques cannot be used to find rare cases. In this study, they suggest a privacy-preserving `range set union` protocol that can be used to find rare cases in the private medical datasets of individuals.
Privacy-enhancing technologies for the Internet	The increased use of the Internet for everyday activities is bringing new threats to personal privacy. The paper gives an overview of existing and potential privacy enhancing technologies for the Internet, as well as motivation and challenges for future work in this field.
Threats to privacy and public keys for protection	Public-key cryptography is discussed with respect to the rights of individuals to electronic privacy. The RSA Public-Key Cryptosystem is described, and digital signatures and certificates are discussed. Applications of public-key cryptography are reviewed, and standards and future prospects in this field are considered.<<ETX>>
Computers and privacy in the pivotal decade	The author discusses information privacy, the right to control data about individuals that is kept by governmental and corporate institutions. He notes that the 1990s promises to be the decade that determines the course of information and privacy policies for many decades to come. He argues that what must be confronted is the fact that the necessary laws have not been passed because certain sectors of the American business community, along with government, have formed an antiprivacy lobby which, due to lack of focus and little effective pressure on lawmakers, has been able to derail most proposals that politicians generally could not oppose in a highly visible context. He further argues that the challenge now is to raise the visibility of the campaign for privacy protection and to focus its energies on obtainable, constructive solutions that do not get so watered down along the way that they do more harm than good.<<ETX>>
A Peer-to-Peer Recommender System with Privacy Constraints	A recommender system can be used to suggest users potentially interesting content based on their previous consumption behavior. Such services already became common in centralized systems, such as Amazon, and approaches exist for decentralized recommender systems. However, common P2P recommender systems expose the userpsilas preferences in the whole system. This is not desirable if privacy is required.Realization of a recommender system in a private P2P environment is not a trivial task, since we cannot gather the user data at central servers or just spread them in the community. In this work we propose a private file sharing application based on social contacts. Instead of gathering all the information about users at one place the users exchange information only with their social contacts. We show how a personalized recommender system can be built in such an environment.
Ontology Alignment in RFID Privacy Protection	RFID technology has been widely spread. Many business players and consumers will take advantage of RFID system. On the other hand, it is important to protect the RFID userpsilas privacy information. RFID stakeholders have published the privacy protection guidelines to control to obtain, use and manage the privacy information for RFID system. In this article, we analyze four guidelines which are published by four various RFID stakeholders. As a result of our analysis, we propose RFID privacy protection ontology. This ontology consists of goal ontology, function ontology and technology ontology. This article shows features of each ontology and relationship among them, and also discusses the stepwise ontology alignment to design method of RFID system.
The SHIELD framework: How to control Security, Privacy and Dependability in complex systems	The purpose of this paper is to present the SHIELD holistic approach: an innovative methodology to address Security, Privacy and Dependability (SPD) in the context of Embedded Systems (ES) by means of control science theory. The SHIELD methodology consider the SPD functionalities offered by the generic atomic component of a complex system at 3 different levels: node, network and middleware. Then these technologies are enhanced with a fourth vertical layer named overlay that provides composability functionality, thus creating a framework able to dynamically reconfigure to satisfy the user needs in terms of SPD, in different scenarios. In order to achieve this objective, the use of specific SPD metrics (derived from recognized standards for security, like the ISO/IEC 15408), is proposed. The results presented in this work have been developed in the scope of the pSHIELD ARTEMIS-JU project and are currently under investigation in the nSHIELD project.
Hashing on strings, cryptography, and protection of privacy	Summary form only given. The issues of privacy and reliability of personal data are of paramount importance. If L is a list of people carrying some harmful defective gene, we want questions as to whether a person is in L to be reliably answered without compromising the data concerning anybody else. Reliability means that once the list is formed, nobody can play with the answer. Thus the answer should be checkable by the agent posing the question. We present an efficient protocol for this task. Our solution has very strong privacy protection properties
A privacy-preserving framework for distributed clinical decision support	We propose a framework for distributed knowledge-mining that results in a useful clinical decision support tool in the form of a decision tree. This framework facilitates knowledge building using statistics based on patient data from multiple sites that satisfy a certain filtering condition, without the need for actual data to leave the participating sites. Our information retrieval and diagnostics supporting tool accommodates heterogeneous data schemas associated with participating sites. It also supports prevention of personally identifiable information leakage and preservation of privacy, which are important security concerns in management of clinical data transactions. Results of experiments conducted on 8 and 16 sites with a small number of patients per site (if any) satisfying specific partial diagnostics criteria are presented. The experiments coupled with restricting a fraction of attributes from sharing statistics as well as applying different constraints on privacy at various sites demonstrate the usefulness of the tool.
SVD-Based Factorization Technique for Dual Privacy Protection Data Mining	Singular value decomposition (SVD) method is a very important matrix decomposition method in linear algebra. It is widely used in signal processing, statistics, data compression and other fields. The paper introduces a SVD method to reduce dimension of original dataset and makes use of the attribute of LSA technique to combine SVD method with LSA technique, and then presents new methods for dual private protection data mining. Finally we conduct experiments to test and verify the proposed approach and get good results.
The Privacy Protection for Shapley Value	We propose issues of privacy protection currently viewed in terms of Shapley value be re-conceptualized in terms of reasonable allocations of the resources of the grand coalition in this paper. We use the Paillier homomorphic encryption system to re-design the Shapley value algorithm which is under the privacy protection, and to ensure that the sensitive information of participants will not be disclosed in determining the income distribution alliance programs at the same time. We present a technology infrastructure on the transferable utility of game participants, which can be configured to support the allocation of resources between the grand alliances by the use of Shapley value.
Security and Privacy Issues within the Cloud Computing	Cloud Computing has been regarded as evolutionary paradigm recently. It has much strength, such as large storage, ubiquitous network access, cost effective and so on. However it also faces security and privacy concerns. In this paper, we discussed several major security and privacy issues. And we also proposed four effective methods to handle such issues. According to the features of issues, we investigated the feasible solutions and finally found four methods. Such methods can be applied to the generalized Cloud Computing. This paper is original that we consider the characteristics of Cloud Computing adequately, so the methods are well functioned and can be developed further to solve other problems.
Privacy, How Can I Protect You? How to Construct Safe Data Security System in E-commerce Transaction	There has been increasing challenges in the effective structure of crucial information for effectual information security, personal privacy and data protection. Especially, when in an age of e-commerce, risks and threats from e-commerce transaction have been keeping rising up. Both new ways of cyber information security and security breach, which have affected people's life in some particular aspects, are stated and renewed all the time. Because of the specific characteristics of carrying out online transaction, data transition plays a very heavy role in personal information security, and also, it incurs security breaches.
Preserving Sensor Location Privacy in Internet of Things	Internet of Things (IoT) links uniquely identifiable objects (things) to their virtual representations in the internet. Meanwhile, wireless sensor networks are widely used in IoT and various sensors which collect different information containing the identity, status, location of a object or any other business, social or privately relevant information. But some issues related to sensor's location privacy will be paid attention to. In this paper, we focus on protecting the sensor's location by introducing suitable modifications to sensor routing to make it difficult for an eavesdropper to find the original location. And we propose a flexible routing strategy, called Multi-routing Random Walk, which protects the sensor's location. Our strategy can efficiently reduce the chance of packets being detected.
Privacy-preserving profile matching using the social graph	We present a privacy-preserving protocol for users to test a match with potential new friends in an environment where all users cryptographically encrypt their private information. The following scenario is considered. Suppose that user Alice thinks that Bob might be a good new friend. So, Alice and the Online Social Network (representing Bob) engage in a two-party matching protocol. In this protocol no work from Bob is required, Bob can be offline. The matching protocol is designed to give Alice an indication if Bob is similar to her based on their profiles. We show that the process does so without revealing the private information of Alice and Bob to one another and to the Online Social Network.
Enabling fine-tuned relationship and privacy in social networks	In this article, we suggest a mechanism to ease privacy management in social networks. This mechanism is based on a relationship model which renders the asymmetry and the diversity of real-life relationships between peers. This model defines attributes that are used in an attribute-based encryption system which protects both user information and exchanged data within the social network. This project is currently a work in progress and the ideas developed here will be confirmed during an extensive implementation and testing phase.
Non-malleable Extractors with Short Seeds and Applications to Privacy Amplification	Motivated by the classical problem of privacy amplification, Dodis and Wichs [9] introduced the notion of a non-malleable extractor, significantly strengthening the notion of a strong extractor. A non-malleable extractor is a function nmExt : {0, 1}<sup>n</sup> ├ù {0, 1}<sup>d</sup> ΓåÆ {0, 1}<sup>m</sup> that takes two inputs: a weak source W and a uniform (independent) seed S, and outputs a string nmExt(W, S) that is nearly uniform given S as well as nmExt(W, S) for any seed S' Γëá S that is determined as an arbitrary function of S. The first explicit construction of a non-malleable extractor was recently provided by Dodis, Li, Wooley and Zuckerman [7]. Their extractor works for any weak source with min-entropy rate 1/2+╬┤, where ╬┤ >; 0 is an arbitrary constant, and outputs up to a linear number of bits, but suffers from two drawbacks. First, the length of its seed is linear in the length of the weak source (which leads to privacy amplification protocols with high communication complexity). Second, the construction is conditional: when outputting more than a logarithmic number of bits (as required for privacy amplification protocols) its efficiency relies on a longstanding conjecture on the distribution of prime numbers. In this paper we present an unconditional construction of a non-malleable extractor with short seeds. For any integers n and d such that 2.01 ┬╖ log n Γëñ d Γëñ n, we present an explicit construction of a non-malleable extractor nmExt: {0, 1}<sup>n</sup> ├ù {0, 1}<sup>d</sup> ΓåÆ {0, 1}<sup>m</sup>, with m = ╬⌐(d), and error exponentially small in m. The extractor works for any weak source with min-entropy rate 1/2 + ╬┤, where ╬┤ >; 0 is an arbitrary constant. Moreover, our extractor in fact satisfies an even more general notion of non-malleability: its output nmExt(W, S) is nearly uniform given the seed S as well as the values nmExt(W, S<sub>1</sub>),- .., nmExt(W, S<sub>t</sub>) for several seeds S<sub>1</sub>,..., St that may be determined as an arbitrary function of S, as long as S Γêë {S<sub>1</sub>,..., S<sub>t</sub>}. By instantiating the framework of Dodis and Wichs with our non-malleable extractor, we obtain the first 2-round privacy amplification protocol for min-entropy rate 1/2 + ╬┤ with asymptotically optimal entropy loss and poly-logarithmic communication complexity. This improves the previously known 2-round privacy amplification protocols: the protocol of Dodis and Wichs whose entropy loss is not asymptotically optimal, and the protocol of Dodis, Li, Wooley and Zuckerman whose communication complexity is linear.
Prior entanglement, message compression and privacy in quantum communication	Consider a two-party quantum communication protocol for computing some function f : {0, 1}<sup>n</sup> ├ù {0, 1}<sup>n</sup> ΓåÆ Z. We show that the first message of P can be compressed to 0(k) classical bits using prior entanglement if it carries at most k bits of information about the sender's input. This implies a general direct sum result for one-round and simultaneous quantum protocols. It also implies a new round elimination lemma in quantum communication, which allows us to extend recent classical lower bounds on the cell probe complexity of some data structure problems, e.g. approximate nearest neighbor searching on the Hamming cube {0, 1}<sup>n</sup>, to the quantum setting. We then show an optimal tradeoff between the privacy losses of Alice and Bob in computing f in terms of the one-round quantum communication complexity of f with prior entanglement. This tradeoff is independent of the number of rounds of communication. The above message compression and privacy tradeoff results use a lot of qubits of prior entanglement, leading one to wonder how much prior entanglement is really required by a quantum protocol. We show that Newman's [1991] technique of reducing the number of public coins in a classical protocol cannot be lifted to the quantum setting. We do this by defining a general notion of black-box reduction of prior entanglement that subsumes Newman's technique. Intuitively, a black-box reduction does not change the unitary transforms of Alice and Bob; it only decreases the amount of entanglement of the prior entangled state. We prove that such a black-box reduction is impossible for quantum protocols by exhibiting a particular one-round quantum protocol for the equality function where the black-box technique fails to reduce the amount of prior entanglement by more than a constant factor.
Analysis of RFID security and privacy by means of identification and authentication protocols	When analyzing the Radio Frequency Identification applications, one might think of two essential hierarchies: the structures aiming to offer security to an RFID system and the structures aiming to offer functionality means, with no security issues. One should know precisely the significance of these notions. Radio Frequency Identification represents an advanced wireless technology, which integrates an essential solution within the fields of intelligent chips and automation technologies. In this paper, four protocols based on updating the tags' identifiers by means of RFID readers will be compared, in order to carry out an analysis over the jeopardizing points that threaten the security and privacy of RFID systems. Cryptography signifies a way of creating RFID systems more secure. A chaotic matter is brought into discussion, by the following situations: to find out if it is a protocol of identification or authentication that is necessary, depending on various RFID applications or systems. Such analysis over RFID security has carried out wide thoughts.
A review on privacy preserving data mining	The information is rich: but the knowledge is poor. To gain a better knowledge from available information, number of techniques and methods has been developed in the area of data mining so far. On the other hand privacy is one of the most important properties of information that any system should satisfy. The secrecy of the information must be maintained while sharing the information among different un-trusted parties. Thus privacy plays a major role and also an important issue in most of the data mining applications. Best suited Privacy Preserving Data Mining (PPDM) algorithm for different levels of mining which minimizes the information loss and improves accuracy of the mined data are identified based on this survey.
Verification of Privacy Preserving Authentication Protocol for VANETs	The paper presents verification of privacy preserving authentication protocol for VANETs using SPIN tool. The authentication process involves authentication of the moving vehicle and the corresponding road side unit (RSU) by a fixed infrastructure from (CTA) through RSU. The whole process needs only one request and reply between different entities. The work described the impact of known attack on the protocol, graphically specification, its behavior in terms of reliability and its correctly verification using the integrated specification verifying JSPIN tool.
Architecture for Discovery of Context-Aware Web Services Based on Privacy Preferences	With the rise of information and communication technologies, along with commencement of context - aware web services, the whole internet platform has inclined towards pervasiveness, exploring the way for the brand new world of the "future internet". However, they bring the issue of personal privacy to the picture, as context-awareness not only natively depends upon the collection and processing of the context information, but also the loose architectural concepts of web services increase the leakage-proneness of the data flows. This paper aims at contributing privacy management layer to the context-aware web service architecture, encouraging the concept of privacy awareness in this class of services. The described architecture provides means for privacy in context targeting the user privacy preferences to discover the most secure and flexible web services. An effective and efficient technique is proposed which generates the ranking order of web services on the basis of user's privacy preferences.
Privacy Preserving in Data Mining Using Hybrid Approach	Data sharing between two organizations is common in many application areas like business planning or marketing. When data are to be shared between parties, there could be some sensitive data which should not be disclosed to the other parties. Also medical records are more sensitive so, privacy protection is taken more seriously. As per requirement by the Health Insurance Portability and Accountability Act (HIPAA), it is necessary to protect the privacy of patients and ensure the security of the medical data. we propose a method called Hybrid approach for privacy preserving. First we randomizing the original data. Then we apply generalization on randomized or modified data. This technique protect private data with better accuracy, also it can reconstruct original data and provide data with no information loss, makes usability of data.
Efficient Privacy-Preserving Association Rule Mining: P4P Style	In this paper we introduce a new practical framework, called P4P (peers for privacy), for privacy-preserving data mining. P4P features a hybrid architecture combining P2P and client-server paradigms and provides practical private protocols for user data validation and general computation. The architecture is guided by the natural incentives of the participants and allows the computation to be based on verifiable secret sharing (VSS) where arithmetic operations are done over small fields (e.g. 32 or 64 bits), so that private arithmetic operations have the same cost as normal arithmetic. Verification of user data, which uses large-field public-key arithmetic (1024 bits or more) and homomorphic computation, only requires a small number (constant or logarithmic in the size of user data) of large integer operations. The solution is extremely efficient: In experiments with our implementation, verification of a million-element vector takes a few seconds of server or client time on commodity PCs (in contrast, using standard techniques takes hours). This verification can be used in many privacy-preserving data mining tasks to detect cheating users who attempt to bias the computation by submitting exaggerated values as their inputs. As an example, we demonstrate how association rule mining can be done in the P4P model with near-optimal efficiency and provable privacy
Quantifying Privacy for Privacy Preserving Data Mining	Data privacy is an important issue in data mining. How to protect respondents' data privacy during the data collection and mining process is a challenge to the security and privacy community. In this paper, we describe two schemes for privacy preserving naive Bayesian classification which is one of data mining tasks. More importantly, for each scheme, we present a method to measure data privacy. We finally compare these two methods
Privacy Preserving Burst Detection of Distributed Time Series Data Using Linear Transforms	In this paper, we consider burst detection within the context of privacy. In our scenario, multiple parties want to detect a burst in aggregated time series data, but none of the parties want to disclose their individual data. Our approach calculates bursts directly from linear transform coefficients using a cumulative sum calculation. In order to reduce the chance of a privacy breech, we present multiple data perturbation strategies and compare the varying degrees of privacy preserved. Our strategies do not share raw time series data and still detect significant bursts. We empirically demonstrate this using both real and synthetic distributed data sets. When evaluating both privacy guarantees and burst detection accuracy, we find that our percentage thresholding heuristic maintains a high degree of privacy while accurately identifying bursts of varying widths
Using Homomorphic Encryption For Privacy-Preserving Collaborative Decision Tree Classification	To conduct data mining, we often need to collect data from various parties. Privacy concerns may prevent the parties from directly sharing the data. A challenging problem is how multiple parties collaboratively conduct data mining without breaching data privacy. The goal of this paper is to provide solutions for privacy-preserving decision tree classification which is one of data mining tasks. Our goal is to obtain accurate data mining results without disclosing private data
A Randomization Approach to Mining Sequential Pattern with Privacy Preserving	Data mining is to discover previously unknown, potentially useful and nontrivial knowledge, patterns or rules. Because databases may have some sensitive information that should not to be leaked out, we should study how to make data mining without leaking sensitive information, i.e., privacy-preserving data mining. We propose a randomization approach for privacy-preserving mining of sequential patterns in this paper.
Privacy Parallel Algorithm for Mining Association Rules and its Application in HRM	Parallel association rules mining has been improved the efficiency of data mining, and meanwhile concerned with the privacy preserving problem. A simple and effective method of parallel association rules mining which based on privacy protection----parallel association rules mining algorithm with privacy preserving (PARMA-P) has been introduced in this paper. It could achieve effective concealment of frequent item-set and then the association rules by the means of using imported hash assignment strategy in frequent item sets of FP sub tree could be protected. It has been used in HRM of an enterprise and experiments show that the algorithm can be simple and effective in protection of data privacy.
Privacy Preserving Classification Algorithm Based on Random Multidimensional Scales	A privacy preserving classification algorithm based on random Multidimensional Scales (MDS) is presented in this paper. We first alter the selection of the parameter embedded dimension d for satisfying the security of privacy preserving classification. Further the sensitive attributes are embedded into random (even higher) dimension feature space using random MDS algorithm, thus the sensitive attributes are transformed and protected. Because the transformed space dimension d is stochastic, this algorithm is not easily be breached. In addition, MDS can keep Euclidean distance of points, so the classification precision after encryption are kept well. The experiment shows that the present method can provide sensitive information enough protection without loss of the classification precision.
RFID and E-commerce Privacy Protection	The implementation of radiofrequency identification (RFID) technology in e-commerce provides an intelligent and dynamic technical solution for all kinds of online transactions. RFID system relies on wireless transmission technology which may easily cause the leakage of personal or business private information. The violation of privacy protection in the e-commerce activities becomes one major part of RFID research. This paper demonstrated that we can protect information privacy in the following aspects: technology, management, and regulation and consumers education.
Research on Security for Personal Information and Privacy Under Network Environment	With the development of the Internet, the security of personal information privacy has been widespread concern, from "Yan Zhao Men Incidentrdquo to "human search", personal information and privacy has become an urgent need for China to resolve. The paper described the concept of privacy, analyzed the insecurity of privacy under current network environment, and gives the effective protection of privacy at the end.
Privacy-Preserving Classification on Horizontally Partitioned Data	With the appearance of large-scale database and people's increasing concern about individual privacy, privacy-preserving data mining becomes a hot study area, to which the support vector machine(SVM) belongs. In this paper, a novel privacy-preserving SVM for horizontally partitioned data is given. It has comparable accuracy to that of an ordinary SVM as we obtain the SVM by using the distinct property of the orthogonal matrices.
A Neural Network Clustering Based Algorithm for Privacy Preserving Data Mining	The increasing use of fast and efficient data mining algorithms in huge collections of personal data, facilitated through the exponential growth of technology, in particular in the field of electronic data storage media and processing power, has raised serious ethical, philosophical and legal issues related to privacy protection. To cope with these concerns, several privacy preserving methodologies have been proposed, classified in two categories, methodologies that aim at protecting the sensitive data and those that aim at protecting the mining results. In our work, we focus on sensitive data protection and compare existing techniques according to their anonymity degree achieved, the information loss suffered and their performance characteristics. The l-diversity principle is combined with k-anonymity concepts, so that background information can not be exploited to successfully attack the privacy of data subjects data refer to. Based on Kohonen Self Organizing Feature Maps (SOMs), we firstly organize data sets in subspaces according to their information theoretical distance to each other, then create the most relevant classes paying special attention to rare sensitive attribute values, and finally generalize attribute values to the minimum extend required so that both the data disclosure probability and the information loss are possibly kept negligible. Furthermore, we propose information theoretical measures for assessing the anonymity degree achieved and empirical tests to demonstrate it.
Improving Privacy of Property-based Attestation without a Trusted Third Party	Aiming at improving the Property-Based Attestation without Trusted Third Party, some modifications were put forward. The attestation model was modified, and the Pedersen Commitment Scheme was used again to hide the configuration of platform, so that the privacy leakage problem which then brings the computing complexity can be solved. The protocol is applicable to the case without Property Certification Authority, and can provide security and privacy of high level with higher usability and lower computing complexity.
Research on Privacy-preserving in Distributed Mining Based on the Attribute Similarity	It's of profound significance to preserve privacy in the distributed data mining process. Based on the NDTree's attribute similarity algorithm and combined with the HES homomorphism encryption algorithm, this paper constructs the HE-NDT which is a privacy-preserving distributed database of decision tree mining algorithm. The theory and experimental results indicates that this algorithm can achieve improvements in terms of privacy, accuracy, and efficiency.
A Protocol of Privacy-Preserving Closest Pair in Two Dimensional Space	The problem of closest pair is a basic problem of computational geometry. This paper investigates the problem of privacy-preserving closet pair and designs a protocol. This protocol bases on Euclid-distance measure protocol and private comparison protocol. The main idea of this protocol is using the Euclid-distance measure protocol to respectively compute the distances of one party's one point and the other party's two points. Then the private comparison protocol is called for comparing the two distances. This paper analyzes the security and complexity. The protocol doesn't need the third party and can be easily extended to multi-dimensional space.
Privacy Preserving Na├»ve Bayesian Classifier Based on Transition Probability Matrix	Recently, lots of researchers pay attention to privacy preserving data mining, which can discover useful knowledge and concurrently preserve the data privacy. In this paper, we propose a Nai╠êve Bayesian classifier based on transition probability matrix, NBCTPM, which uses transition probability matrix to generate the private data. Different from existing techniques, transition probability matrix can also be used for processing non-char data. NBCTPM firstly adopts transition probability matrix to generate private dataset from the original one. Then it builds a Bayesian classifier based on it, and classifies test datasets. Finally, we make some experimental tests on some benchmark datasets. The experimental results show the efficiency of the presented classifier.
On the Representation and Querying of Sets of Possible Worlds in the K-anonymity Privacy Protecting Model	We represent a set of possible worlds using a k-anonymity privacy protection model. We introduce kpro-anonymity model, a space-efficient and complete representation system for finite sets of worlds. We study the problem of efficiently evaluating queries on sets of possible worlds represented by kpro-anonymity model.
Traitor Tracing and Revocation Mechanisms with Privacy-Preserving	Content distribution systems are vulnerable to the attack of rebroadcasting: pirate publishes the content or the decoding key in violation of the licensing agreement. Traitor tracing and revocation mechanisms can trace the traitors and revoke malicious users. We argue that privacy is another important feature in digital rights management technologies, and the proper balance between DRM and user privacy is an important question in its own right. Our scheme adds this important privacy-preserving feature into the existing content distribution system, and with the help of a trusted third party it can efficiently trace and revoke the pirate users while still preserve the privacy of honest users.
Modeling the Uncertain Data in the K-anonymity Privacy Protection Model	Modeling is the basis for data management of uncertainty. The Specificity in the uncertainty of the data in the k-anonymity privacy protection model is found, namely, its uncertainty is caused by human with generalization, the probability that each instance after generalization is reduced to the original tuple is equal. The past modeling approaches of uncertainty data are not suitable for this kind of uncertainty data simply. In order to describe it, several new modeling methods are proposed in this paper: K<sub>attr</sub> model uses attribute-ors ways to describe the uncertainty of the quasi-identifier attribute values, K<sub>tuple</sub> model takes the quasi-identifier attribute values as nest relations and use tuple-ors ways to describe the relations, K<sub>upperlower</sub> model separates a quasi-identifier attribute to two fields: upper and lower, K<sub>tree</sub> model converts each quasi-identifier attribute into a tree. The completeness and closure of these models are discussed later.
A Novel Biometric Authentication Scheme with Privacy Preserving	In this paper, a novel biometric authentication scheme is proposed, which combines zero-knowledge proof, ╬ú - protocols and bit commitment scheme. The remote server compares biometric template using committed values, this can keep privacy of user's biometrics. To the best knowledge of us, this is the first scheme which uses ╬ú - protocols as a basic tool to implement biometric authentication. Compared with the previous schemes, this scheme has advantages as higher security, lower computation complexity and privacy keeping of biometric template.
Security and Privacy on Authentication Protocol for Low-cost RFID	The radio frequency identification (RFID) is an automatic identification system, relying on storing and remotely retrieving data about objects we want to manage using devices called RFID tag. Even though RFID system is widely used for industrial and individual applications, RFID tag has a serious privacy problem, i.e., traceability. To protect the users from tracing and also to support low-cost RFID, we propose an authentication protocol which can be adopted for read-only RFID tag using XOR computation and partial ID concept. The proposed protocol is secure against reply attacking, eavesdropping, and spoofing attacking so that avoiding the location privacy exposure
A Biometric Verification System Addressing Privacy Concerns	Biometric techniques are more and more exploited in or- der to fasten and make more reliable the identification pro- cess. Recently, many proposals have been formulated com- bining cryptography and biometrics in order to increase the confidence in the system when biometric templates are stored for verification. In this work we present a biometric authentication tech- nique based on the combination of multiple biometric read- ings. The authentication control can be performed offline and the stored identifier does not disclose any information on the biometric traits of the identified person, so that even in case of loss or steal of the document, privacy is guaran- teed. Keywords: Biometric identification, Privacy, Secure sketch.
Pairing-Based Proxy Signature Scheme with Proxy Signer's Privacy Protection	Based on bilinear pairings, a proxy signature scheme with proxy signer's privacy protection is proposed, in which a proxy signer signs messages on behalf of the original signer while the proxy signer is anonymous to anyone but the original signer. If necessary, the anonymity can be revoked by the original signer to identify the proxy signer. Neither this scheme needs any trusted third party nor the proxy signers need publish the extra public keys corresponding to their alias. On the other hand, both the original signer and the proxy signers can open the identities of the proxy signers from a valid proxy signature. Then, neither the original signer nor the proxy signer can deny the identity of a valid proxy signature. So, the proposed scheme can be used in e- voting, e-auction and other environment where individual privacy needs careful protection.
Formal Privacy Analysis of an Electronic Voting Scheme	We present the formalization of a recent electronic voting scheme using GSM mobile technology (GVS) in the applied pi calculus and analyze its privacy property. A refined threat model considering not only the attacks from outsiders but also from the insiders and the collusion between them, is defined to represent the hostile voting environment, in which the privacy property is analyzed.
A Role-Based Model for Web Services Privacy Delegation	Web services collaborations are highly automatic, dynamic, heterogeneous, and lack protection against corruption of the process. These characteristics impose high levels of risk on the interacting parties. In order to improve the reliability of the system, it is very necessary to make sure the privacy authorization of each service in system designing. This paper proposes a role-based Web services privacy delegation model, which delegates the privacy authorization based on trust relationships of services, then it gives corresponding algorithms to check the validity of privacy delegation of services.
Measuring users' privacy payoff using intelligent agents	As many people are now taking advantages of on-line services, the value of the private data they own comes into sight as a problem of fundamental concern. This paper takes the position that, individuals are entitled to secure control over their personal information, disclosing it as part of a transaction only when they are fairly compensated. To make this a concrete possibility, users require technical instruments to be able to measure their privacy payoff and track the use of their private data. In this paper, we propose an intelligent agent-based framework for privacy payoff measurements and negotiation. Intelligent agents in our system collaboratively work on behalf of users for the goal of maximizing their benefit and protect the use of their private data. The overall framework is described, and a particular simulation experiment is presented to evaluate our approach.
Assessment of privacy enhancing technologies for biometrics	Biometric privacy-enhancing technologies (PET) include two major groups: Biometric Encryption and Cancelable Biometrics. They enhance both privacy and security of a biometric system, thus embodying the Privacy by Design principles in a way that benefits the individual and minimizes the privacy risks. In this paper, the results of independent third-party evaluation of a commercial biometric PET product are presented. The GenKey ΓÇ£BioCryptic┬« ID Management SystemΓÇ¥ is evaluated against a benchmark commercial product, Neurotechnology VeriFinger version 6.3. The database contained approximately 20,000 flat fingerprint images from 1,200 subjects. For a two-finger, two images per finger enrollment, the best results are: at FMR = 0.1%, FNMR = 1.54% for the PET System and FNMR = 1.74% for the benchmark system; at FMR = 0.01%, FNMR = 2.41% for the PET System and FNMR = 1.74% for the benchmark system. The results also suggest that specific subjects are substantially more likely than others to cause false matches. Security issues of the PET system are briefly discussed but no security evaluation is performed. The study demonstrates the viability of fingerprint-based PETs from a matching accuracy perspective.
Location privacy protection on social networks	Location information is considered as private in many scenarios. Location information protection on social networks has not been paid much attention. In this paper, we extend our previous proposed location privacy protection approach on the basis of user messages in social networks. Our approach grants flexibility to users by offering them multiple protecting options. The extension includes performance evaluation towards our approach.
Finding the state sequence maximizing P(O; I|╬╗) on distributed HMMs with Privacy	Hidden Markov models (HMMs) are widely used by many applications for forecasting purposes. They are increasingly becoming popular models as part of prediction systems in finance, marketing, bio-informatics, speech recognition, signal processing, and so on. Given an HMM, an application of HMMs is to choose a state sequence so that the joint probability of an observation sequence and a state sequence given the model is maximized. Although this seems an easy task if the model is given, it becomes a challenge when the model is distributed between various parties. Due to privacy, financial, and legal reasons, the model owners might not want to integrate their split models. In this paper, we propose schemes to select a state sequence so that the joint probability of an observation sequence and a state sequence given the model is maximized when the model is horizontally or vertically distributed between two parties while preserving their privacy. We then analyze the proposed schemes in terms of privacy, accuracy, and additional overhead costs. Since privacy, accuracy, and performance are conflicting goals, our proposed methods are able to achieve an equilibrium among them.
An intelligent agent-based framework for privacy payoff negotiation in virtual environments	With the rapid development of applications in open distributed virtual environments, such as e-Business and virtual games, privacy is becoming a critical issue. This paper presents an intelligent agent-based framework for privacy payoff in virtual environments, with special focus on capability-based negotiation services. These services take into consideration users' entitlement to benefit from revealing their personal information. In such model, users of the virtual environment who share same interests have the opportunity to form personal information lists that can be used later for group bargaining. The intelligent negotiation agent acts on their behalf to maximize their benefit. The overall framework is described, and a particular example is presented to show the interaction among the agents.
Privacy-preserving collaborative data mining	Data collection is a necessary step in data mining process. Due to privacy reasons, collecting data from different parties becomes difficult. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties collaboratively conduct data mining without breaching data privacy presents a challenge. The objective of this paper is to provide solutions for privacy-preserving collaborative data mining problems. In particular, we illustrate how to conduct privacy-preserving naive Bayesian classification which is one of the data mining tasks. To measure the privacy level for privacy- preserving schemes, we propose a definition of privacy and show that our solutions preserve data privacy.
An Agent-Based Secure Transaction Protocol with Fair Privacy	To reduce mobile users' dependence on effective network availability, this paper proposes mobile agent technology in mobile computing applications. This allows mobile users to perform data collection and electronic transactions in a wireless network environment. In an agent-based transaction protocol, mobile agents carry information provided by the user and are able to migrate between hosts to execute tasks. The issue of safety i.e. ensuring the information carried by mobile agents is not modified or eavesdropped on becomes important and cannot be ignored. This paper proposes a secure transaction protocol; mobile agents help users gather information on goods. Since the protocol is tailored to the user's needs, the security of the application system is comprehensively enhanced. The issues addressed include preserving the privacy of the user's identity, the integrity of transaction information, non-repudiation and fairness of transactions, and the confidentiality of information exchange.
Pseudonym Based Mechanism for Sustaining Privacy in VANETs	This paper addresses the problem of sustaining the privacy of a vehicle in a vehicular ad hoc network (VANET). In a VANET, vehicles broadcast information as they move on the road. The location of a vehicle can estimated using localization techniques and its identity can be read from its messages. A link can be established between the physical vehicle through localization and its identity is a threat to privacy. This localization is not accurate and a vehicle can hide in the crowd of neighborhood vehicles. Further to avoid getting tracked, vehicles use pseudonyms and update these pseudonyms as they transmit. To avoid depletion of pseudonym pool, pseudonym update must be performed only when required. In this work, a strategy has been formulated for pseudonym update to sustain privacy when a vehicle is being observed by an adversary with different capabilities. Results indicate that updating pseudonyms in accordance to the strategy maximizes the privacy of a vehicle.
Schematize Trust Overlays and Management for Privacy Preservation in MANET	Mobile ad hoc Networks refers to the infrastructure less, resource poor wireless networks whose interaction is unplanned in such a way that location of participating nodes and parties can not be identifiable. The mobile devices are used by people to access services in various environments. Before two or more mobile networks ready to interact, they must trust that each will satisfy the security and privacy requirements of the other. In this paper, we schematize the role of trust overlays and its management, a systematic approach to build such trust overlay in MANET for privacy preservation. Our solution exploits the increasing availability of trusted computing hardware on open systems, including portable computers and mobile devices. Our proposal has emphasized that key pieces of these solutions are coming into a common place, as all mobile devices provide distributed mandatory access control. We also point out that tremendous challenges remain, such as how to set compatible security policies across administrative domains and how to derive a trust coefficient to build trust in MANET.
Protecting Privacy of User Information in Continuous Location-Based Services	The widespread diffusion of mobile devices integrating location capabilities makes the location of users yet another type of sensitive information used by service providers in the provision of accurate and personalized services (location-based services -- LBSs). A major problem in this context is that the privacy of users is increasingly at risk, calling for solutions balancing the benefits provided by LBSs and the privacy guarantees. In this paper, we study a novel privacy problem related to inferences of sensitive information caused by the release of consecutive positions to LBS providers. We provide an approach based on Markov chains that allows the user to continuously release her location information in a privacy-preserving way. We then define an approach to counteract different inference channels, addressing users' preferences in terms of both privacy requirements and quality of service.
A Web Service Privacy Framework Based on a Policy Approach Enhanced with Ontologies	The Web service technology facilitates the automated use of electronic services on the Web. It offers benefits, mainly the system interoperability support, but it also raises privacy concerns on the handling of sensitive data about service consumers. For instance, in electronic commerce applications, privacy protection is frequently a major consumer requirement. It includes concerns such as, how sensitive data are used and who has access to them. These concerns have been increasingly discussed. However, there is not a standard privacy framework for Web services. This paper proposes a Web service privacy framework based on a policy approach enhanced with ontologies. It uses different Web standards for supporting privacy protection, including the platform for privacy preferences (P3P), the Web services policy framework (WS-Policy) and the Web ontology language (OWL).
Noise Injection for Search Privacy Protection	To protect user privacy in the search engine context, most current approaches, such as private information retrieval and privacy preserving data mining, require a server-side deployment, thus users have little control over their data and privacy. In this paper we propose a user-side solution within the context of keyword based search. We model the search privacy threat as an information inference problem and show how to inject noise into user queries to minimize privacy breaches. The search privacy breach is measured as the mutual information between real user queries and the diluted queries seen by search engines. We give the lower bound for the amount of noise queries required by a perfect privacy protection and provide the optimal protection given the number of noise queries. We verify our results with a special case where the number of noise queries is equal to the number of user queries. The simulation result shows that the noise given by our approach greatly reduces privacy breaches and outperforms random noise. As far as we know, this work presents the first theoretical analysis on user side noise injection for search privacy protection.
All Friends Are Not Created Equal: An Interaction Intensity Based Approach to Privacy in Online Social Networks	Recent research identifies a growing privacy problem that exists within online social networks (OSNs). Several studies have shown how easily strangers can extract personal data about users from the network. Other studies have shown that an extremely small percentage of OSN users change their permissive default privacy settings. Complementary systems have been proposed to provide privacy for OSN users but many of them seem to be costly in terms of simplicity or management overhead. Furthermore, several of these approaches seem to violate the social aspect of online social networks by reducing the problem to manual access management with cryptography. Under this setting, instead of freely sharing onepsilas data with its friends, a user will share data only with those friends possessing allowed cryptographic keys. While these systems will indeed provide additional privacy for user data, they will not address a more fundamental problem that exists within OSNs: the inability of the network to easily and automatically distinguish relationship quality between a user and its friends. This distinction may be critical in providing a simple, automatic privacy mechanism for OSNs. We propose a unique approach utilizing interactions between friends as the currency for data access. This model operates within the bounds of social networks while incurring minimum additional management overhead for the user. As a first step, we consider interaction intensity as a proxy for relationship quality for the purpose of making privacy decisions. Although we present our ideas from the privacy perspective we also discuss how our approach can be used to support the development of more secure social network based applications.
Enabling Privacy as a Fundamental Construct for Social Networks	The current set of social networking platforms, e.g. Facebook and MySpace, has created a new class of Internet applications called social software. These systems focus on leveraging the real life relationships of people and augment them with the facilities and the richness of the Web. The large number of social applications and the even larger user populations of these social networks are proving that this new class of software is useful and complements modern life. However, social platforms and software are not without drawbacks and significant concerns. One of the most important considerations is the need to allow strong security and privacy protections. In addition, these protections need to be easy to use and apply uniformly across platforms and applications. While most of the leading social platforms have primitives for providing privacy in the platform and the applications, we argue that they are insufficient. In particular, the privacy primitives lack ease of use, are too plentiful, do not fully apply to third party applications, and do not take full advantage of the social graphs that users implicitly build on these platforms. This paper provides a first step in resolving these issues.
Privacy-Preserving Bayesian Network for Horizontally Partitioned Data	Construction of learning structures for Bayesian networks is considered in this work when data is securely maintained by different parties, not willing to reveal their individual private data to each other. We propose a privacy-preserving protocol for Bayesian network from data which is homogeneously partitioned among two or more parties by using K2 algorithm, a heuristic algorithm typically used to construct Bayesian network. Three secure building blocks are also presented to use inside the main protocol; Secure Exponentiation, Secure Multi-party Factorial and Secure Product Comparison. We have also modified two existing building blocks which are used in this paper, Secure Multi-Party Addition and Multiplication, to improve their resistance against colluding attack. These protocols have the added advantage that they can even be used over public channels. That is, channels over which any party is able to see any messages exchanged between any two or more parties.
Solutions to Security and Privacy Issues in Mobile Social Networking	Social network information is now being used in ways for which it may have not been originally intended. In particular, increased use of smartphones capable of running applications which access social network information enable applications to be aware of a user's location and preferences. However, current models for exchange of this information require users to compromise their privacy and security. We present several of these privacy and security issues, along withour design and implementation of solutions for these issues. Our work allows location-based services to query local mobile devices for users' social network information, without disclosing user identity or compromising users' privacy and security. We contend that it is important that such solutions be acceptedas mobile social networks continue to grow exponentially.
Visible Flows: Contextual Integrity and the Design of Privacy Mechanisms on Social Network Sites	Social Network Sites have a number of well publicized privacy issues stemming from the over disclosure of personal information. On one hand, users seem oblivious to their privacy, doing little to protect their personal data. On the other hand, there have been a number of privacy uproars and backlashes due to certain site features or behaviors. In this paper, we explore the privacy issues in social network sites using contextual integrity, a recently proposed privacy framework. We use the framework to highlight a number of privacy issues on social network sites, and to propose a set of design guidelines and potential solutions.
Privacy Management, the Law & Business Strategies: A Case for Privacy Driven Design	This paper explores the adage that good privacy is good business. Businesses, like social networks, often seek to create value from personal information and monetize it. Unlocking and harvesting value embedded in personal information can lead to disclosure of private and sensitive information, and subsequent harm. Personal information management practices can be a means to competitive and strategic advantage, however they are also subject to privacy law. We explore the underlying tension between transparency and disclosure in the privacy verses business strategy in the pursuit of innovation arena, and argue that in order achieve sustained innovation next generation applications and services will require a fresh imaginative and strategic privacy by design approach. Personal information management is a complex task and cannot be adequately achieved without significant attention and commitment to privacy requirements in systems analysis and design. Due to the potential power, magnitude, complexity and scope of web technologies there is a pressing need to understand privacy requirements better, and to invest in developing tools and techniques for modeling, analyzing, designing and building more effective personal information management systems that seek consent where appropriate and that offer users natural choices and sophisticated mechanisms for controlling their personal information.
Privacy-Enhanced Event Scheduling	Event schedulers, well-known from groupware and social software, typically share the problem that they disclose detailed availability patterns of their users. This paper distinguishes event scheduling from electronic voting and proposes a privacy-enhanced event scheduling scheme. Based on superposed sending and Diffie-Hellman key agreement, it is designed to be efficient enough for practical implementations while requiring minimal trust in a central entity. Protocols to enable dynamic joining and leaving of participants are given.
A Lattice-Based Privacy Aware Access Control Model	As the amount of data being collected by service providers increases, privacy concerns increase for the data owners that must provide private data to get services. Legislative acts require enterprises protect the privacy of their customers and privacy policy frameworks such as P3P assist enterprises in demonstrating their privacy policies to customers (i.e. publishing privacy policy on Websites). Unfortunately, defining these standards does not guarantee that the privacy policies are actually enforced since privacy is not central to conventional access control models. Furthermore, a privacy-preserving model should consider the privacy preferences of both data provider and data collector. This paper presents a lattice-based privacy aware access control (LPAAC) model. The key contribution is providing a privacy preserving model that enforces privacy policies and facilitates customization of privacy agreements and preferences of both data providers and organizations that collect data.
Practical Values for Privacy	Whether or not consumers realistically value their private information, why should businesses? This article examines the preconceived notions of the importance of collecting and using consumers' private information with regard to price discrimination and targeted advertising to determine that modern efforts to harness private information in achieving these goals has little long-term value and can be replaced with simpler, cheaper, and safer practices.
Privacy-Preserving Integrity-Assured Data Aggregation in Sensor Networks	Data aggregation in sensor network can improve both efficiency and privacy of network traffic.Recent work in integrity-assured data aggregation has considered aggregation as only an efficiency primitive. In this work, we address for the first time the problem of integrity-assured data aggregation with efficiency and privacy as a joint objective. Our solutions show the inherent tension between privacy-preservation and integrity-assurance of data aggregation.
Privacy-Preserving Multi-agent Constraint Satisfaction	Constraint satisfaction has been a very successful paradigm for solving problems such as resource allocation and planning. Many of these problems pose themselves in a context involving multiple agents, and protecting privacy of information among them is often desirable. Secure multiparty computation (SMC) provides methods that in principle allow such computation without leaking any information. However, it does not consider the issue of keeping agents' decisions private from one another. In this paper, we show an algorithm that uses SMC in distributed computation to satisfy this objective.
User-centric Privacy Framework: Integrating Legal, Technological and Human Aspects into User-Adapting Systems	This paper summarizes our most relevant results of research and development work regarding a solution proposal for a privacy concept called user-centric privacy framework (UPF). In particular, our work focuses on user-adapting systems and follows three objectives: elaborate an adaptable privacy statement that complies with well-known privacy practices and with legal regulations; utilize privacy-enhancing technologies for single-user and group-based activities; provide user-controlled privacy concerns. UPF is an integrative solution proposal that considers main aspects of the three interrelated and highly relevant points of view: legal aspects (lawyerpsilas language); technological aspects (technicianpsilas language); user-centric design aspects (userpsilas language). To give a practical example, we present the applicability of UPF focusing on the field of self-directed work-integrated learning systems.
Designing Privacy for Scalable Electronic Healthcare Linkage	A unified electronic health record (EHR) has potentially immeasurable benefits to society, and the current healthcare industry drive to create a single EHR reflects this. However, adoption is slow due to two major factors: the disparate nature of data storage facilities of current healthcare systems, and the security ramifications of accessing, using, and potential misuse of that data. To attempt to address these issues this paper presents the VANGUARD (Virtual ANonymisation Grid for Unified Access of Remote Data) system which supports adaptive security-oriented linkage of distributed clinical data-sets to support a variety of virtual EHRs avoiding the need for a single schematic standard and the natural concerns of data owners and other stakeholders on data access and usage. VANGUARD has been designed explicitly with security in mind and supports clear delineation of roles for data linkage and usage.
Examining the Shifting Nature of Privacy, Identities, and Impression Management with Web 2.0	A common focus of internet privacy research has been on allowing users to maintain their anonymity in order that they may freely reveal personal aspects of themselves. However, with Web 2.0 and the increasing popularity of social networking sites, it has become increasingly commonplace for users to reveal their identities in order to advertise their on-line presence to their real-life associates. This position paper explores the changing nature of on-line identities, as the norm of anonymity shifts to a more accurate representation of self. The applicability of earlier on-line, information sharing privacy research findings to this new state is discussed.
An Efficient Privacy Preserving Keyword Search Scheme in Cloud Computing	A user stores his personal files in a cloud, and retrieves them wherever and whenever he wants. For the sake of protecting the user data privacy and the user queries privacy, a user should store his personal files in an encrypted form in a cloud, and then sends queries in the form of encrypted keywords. However, a simple encryption scheme may not work well when a user wants to retrieve only files containing certain keywords using a thin client. First, the user needs to encrypt and decrypt files frequently, which depletes too much CPU capability and memory power of the client. Second, the service provider couldn't determine which files contain keywords specified by a user if the encryption is not searchable. Therefore, it can only return back all the encrypted files. A thin client generally has limited bandwidth, CPU and memory, and this may not be a feasible solution under the circumstances. In this paper, we investigate the characteristics of cloud computing and propose an efficient privacy preserving keyword search scheme in cloud computing. It allows a service provider to participate in partial decipherment to reduce a client's computational overhead, and enables the service provider to search the keywords on encrypted files to protect the user data privacy and the user queries privacy efficiently. By proof, our scheme is semantically secure.
Anonymity, Privacy, Onymity, and Identity: A Modal Logic Approach	In this paper, we propose a taxonomy of privacy-related information-hiding/disclosure properties in terms of the modal logic of knowledge for multi-agent systems. The properties considered here are anonymity, privacy, onymity, and identity. Intuitively, anonymity means the property of hiding who performed a certain specific action, privacy hiding what was performed by a certain specific agent, onymity disclosing who performed a certain specific action, and identity disclosing what was performed by a certain specific agent. Building on Halpern and O'Neill's work, we provide formal definitions of these properties and study the logical structure underlying them. In particular, we show that some weak forms of anonymity and privacy are compatible with some weak forms of onymity and identity, respectively. We also discuss relationships between our definitions and existing standard terminology, in particular Pfitzmann and Hansen's consolidated proposal.
Limiting Private Data Exposure in Online Transactions: A User-Based Online Privacy Assurance Model	Privacy conscious online shoppers find themselves forced to disseminate and share private data with new entities when engaging in online transactions. This paper provides a solution that limits private data exposure to entities that already have it. First, we provide a high-level classification of current privacy assurance practices. We identify three categories that are based on who is responsible for the protection of private data access and usage. Next, we present a detailed classification based on the degree of user anonymity and the degree of transaction traceability a privacy assurance model provides. Finally, we propose a new online shopping model that limits private data sharing to the userpsilas bank, which we argue does not constitute a new exposure of the userpsilas data.
Privacy in Online Social Networking at Workplace	Employees using social network sites (SNS) at workplace is a fact. As companies are further embracing social media, how if at all does this practice affect the work dynamics? While privacy has been a hot topic in online social network research in general, there is little work investigating the privacy aspect of this practice at workplace. This paper aims at starting the groundwork towards filling the gap. Based on a review of existing literature in social networks and workplace studies, we hypothesize a number of potential privacy issues in this work practice and suggest future research directions in this area.
FaceCloak: An Architecture for User Privacy on Social Networking Sites	Social networking sites, such as MySpace, Facebook and Flickr, are gaining more and more popularity among Internet users. As users are enjoying this new style of networking, privacy concerns are also attracting increasing public attention due to reports about privacy breaches on social networking sites. We propose FaceCloak, an architecture that protects user privacy on a social networking site by shielding a user's personal information from the site and from other users that were not explicitly authorized by the user. At the same time, FaceCloak seamlessly maintains usability of the site's services. FaceCloak achieves these goals by providing fake information to the social networking site and by storing sensitive information in encrypted form on a separate server. We implemented our solution as a Firefox browser extension for the Facebook platform. Our experiments show that our solution successfully conceals a user's personal information, while allowing the user and her friends to explore Facebook pages and services as usual.
Emergency Privacy Measures	In the past, only the security and confidentiality of data in medical information systems was a contentious issue, and privacy was not a real issue. Lately, much has been done to preserve the privacy of information of the individual, especially when this resulted in giving the individual more control over his/her personal information. The problem that we are faced with now, is the following: From a privacy viewpoint, in the case of an emergency or other unforeseen situation, what has to be done when private and sensitive information has to be acquired immediately, or in some situations has to be disclosed without the consent of the individual(s) concerned? This paper will identify such situations and propose emergency measures that will apply in such circumstances, while still attempting to achieve maximum privacy on behalf of the individual, where applicable.
Specification of Fair Data Practice Principles Using Privacy Policy Languages	During the last decades, multiple initiatives have formulated various fair data practice principles. Today, privacy policies are used to define how personal data can be created, disclosed, stored, used, shared, and destroyed by entities other than the data subject. However, there was a lack of comprehensive framework to reason about the fundamentals of privacy policy-based private data protection schemes. This paper presents a comprehensive yet generic set of fair data practice requirements. Next, the requirements are used as a consistent framework to reason about the capabilities, limitations and challenges of privacy policy-based private data protection in general and privacy policy languages in particular. More specifically, the paper discusses which fair data practice principles can be expressed by P3P.
Adapting Privacy-Preserving Computation to the Service Provider Model	There are many applications for secure multi-party computation (SMC), but practical adoption is still an issue. One reason is that the business model of the application does not match the system architecture of regular secure computation. An important business model is that of a single service provider dealing with many customers. Applications with this business model are e.g. auctions or benchmarking. This paper provides SMC in a system architecture for service providers. Furthermore we achieve an interesting performance improvement. Our SMC protocol has a significantly improved complexity if all parties behave semi-honest, but can still deal with a minority of malicious parties at the usual complexity.The solution also relates to distributed algorithmic mechanism design which proposes to build distributed algorithms that implement mechanisms that compute the result given rational players.
A Privacy Framework for Personal Self-Improving Smart Spaces	There are various critical privacy issues that need to be addressed in the majority of smart space environments. This paper elaborates on the design of a privacy protection framework for personal self-improving smart spaces (PSSs), a concept introduced by the persist project consortium. Compared to other smart spaces, such as smart homes and vehicles, this new paradigm provides a truly ubiquitous and fully personalizable user centric environment. However, the information that needs to be collected, processed and distributed in such an environment is by nature highly privacy sensitive, as it includes user profile data and preferences, as well as data regarding the past, current and even future user activities and context in general. In this respect, the designed privacy framework aims to address all privacy issues that arise by providing facilities which support multiple digital identities of PSS owners and privacy preferences for deriving privacy policies based on the context and the trustworthiness of the third parties that interact with PSSs.
Privacy Requirements in Vehicular Communication Systems	A primary goal of vehicular communication systems is the enhancement of traffic safety by equipping vehicles with wireless communication units to facilitate cooperative awareness. Privacy issues arise from the frequent broadcasting of real-time positioning information. Thus privacy protection becomes a key factor for enabling widespread deployment. At the same time, stakeholders demand accountability due to the safety-critical nature of many applications. Earlier works on privacy requirements for vehicular networks often discussed them as a part of security. Therefore many aspects of privacy requirements have been overlooked. In this paper, we identify a structured and comprehensive set of privacy-related requirements for vehicular communication systems, and analyze the complex inter-relations among them. Our results enable system designers to better understand privacy issues in vehicular networks and properly address privacy requirements during the system design process. We further show that our requirements set facilitates the comparison and evaluation of different privacy approaches for vehicular communication systems.
A Framework to Balance Privacy and Data Usability Using Data Degradation	Personal data is a valuable asset for service providers. To collect such data, free services are offered to users, for whom the risk of loosing privacy by subscribing to a service is often not clear. Although the services are free in terms of money, the user does not know how much he or she actually pays for a given service when allowing his or her data to be collected, unaware of taking a significant privacy risk by doing so. In practice, this risk is even not taken into account when deciding how long the data will be retained; the service provider simply wants to optimize the total worth of the stored data by retaining the data as long as possible. In this paper, we express the privacy risk for the user in terms of such a retention period; the user wants to optimize its privacy by allowing the data to be retained as short as possible. Now, in stead of only considering the interests of the service provider, we argue that we should optimize the common interest of both parties, and present a framework to reason about worth and privacy to find such optimum. Going one step further, we refine and generalize limited retention to data degradation, which prescribes to store data in progressively less accurate forms. Data degradation gives users and service providers a fine grained control over the price to be paid, in terms of privacy risks, and to optimize their common interest: balancing privacy and data usability.
Usable Privacy Controls for Blogs	Web 2.0 applications such as blogs, wikis and social networking sites have challenging privacy issues. Many users are unaware that search engines index personal information from these sites and offer public access to collected data. As a consequence, privacy invasions are rampant. In this paper, we demonstrate that tag-based privacy policies are a usable and flexible privacy control method for Web 2.0 applications. Content owners express their privacy policy in terms of tags on content objects; the system then applies the policy to objects based on the tags assigned to them. We implemented tag-based privacy controls as a plugin to the WordPress blogging system, and conducted a user study to measure whether users could efficiently address real-world privacy concerns using tag-based policies. Despite limited time and training, a third of the participants chose the tag-based policy tools. These users were able to perform privacy-related tasks with the same accuracy and increased speed using our tag-based privacy controls versus per-object privacy controls.
Routing Policy Conflict Detection without Violating ISP's Privacy	The inter-domain routing system consists of many interconnected autonomous systems (ASes) that configure their routing policy independently. The uncoordinated routing policy decision causes various problems such as routing oscillations, network disruption and traffic engineering failure. Although the contrast analysis on multi-AS policy configuration can detect the policy conflict, it is unacceptable for ISP because it discloses ISP's routing policy and reveals commercial secret and security vulnerability. To make the cross-AS routing policy analysis operationally practical, this paper proposes a cross-AS routing policy analysis method based on BGP route inferring and studies of security multi-party computation (SMC). By using this method, ISP can automate the multi-AS routing policy analysis without violating ISP's confidentiality requirements. This method does not modify the BGP routing protocol, it is easy to deploy and cheap to implement. It can be used in many cooperative applications such as routing policy conflict detection, traffic engineering and intrusion detection.
An Empirical Study on Privacy and Secure Multi-party Computation Using Exponentiation	Protocols for secure multi-party computation allow participants to share a computation while each party learns only what can be inferred from their own inputs and the output of the computation. However, the execution time of a secure protocol may be too high therefore it is not practical unless some tradeoffs are made between data access and confidentiality. This paper aims to provide some empirical basis for making such tradeoffs in computing exponentiation. We have designed exponentiation protocols for secure two-party computation using scalar products as the basic building blocks. A detailed performance evaluation was carried out by taking advantage of the compositional nature of our protocols. We have come up with a time function which provides good prediction of the execution time of the proposed exponentiation protocols based on the execution time of scalar products. Using the time function, we have obtained several interesting tradeoffs between execution time and privacy. In particular, compromising some private information enables a reduction in the execution time from years, if not centuries, to days or even minutes. Based on our results, we argue that there are indeed reasonable tradeoffs between privacy and execution time. Furthermore, our study indicates that a system intelligently offering users possible tradeoff options will make secure multi-party computation a more attractive approach to enhancing privacy in practice.
A Protocol of Secure Multi-party Multi-data Ranking and Its Application in Privacy Preserving Sequential Pattern Mining	A secure multi-party multi-data ranking protocol was proposed, which was not related to any specific encryption algorithm. And it was shown that the protocol was correct and secure in the semi-honest model. A privacy-preserving sequential pattern mining solution was also designed based on secure multi-party sum protocol and secure multi-party multi-data raking protocol and a simple analysis of this solution was given. This solution can be used in many aspects: privacy-preserving consumptive action analysis of multi-marketplace, privacy-preserving disease diagnose of multi-hospital and so on.
Privacy-preserving data acquisition protocol	Current investigative data acquisition techniques often breach human and natural rights of the data subject and can jeopardize an investigation. Often the investigators need to reveal to the data controller precise details of their suspect's identity or suspect's profile. In this research a novel approach to investigative data acquisition is presented and privacy preserving Investigative Data Acquisition Protocol (IDAP) is defined. This protocol is the first that allows for performing private information retrieval of records matching multiple selection criteria.
Advance Program 1987 IEEE Symposium on Security and Privacy	Provides a listing of upcoming conference events of interest to practitioners and researchers.
Privacy-Preserving Data Mining Systems	Although successful in many applications, data mining poses special concerns for private data. An integrated architecture takes a systemic view of the problem, implementing established protocols for data collection, inference control, and information sharing. Our goal in investigating privacy preservation issues was to take a systemic view of architectural requirements and design principles and explore possible solutions that would lead to guidelines for building practical privacy-preserving data mining systems
Social Networking Privacy: Understanding the Disconnect from Policy to Controls	A proposed method for mapping privacy policy statements to privacy controls can help providers improve data management transparency, thereby increasing user trust.
Public Concerned About Privacy	Two out of three Americans are concerned about the threat to their personal privacy posed by computer-operated data banks in the hands of business and government. They want something done to give individuals practical rights of privacy, confidentiality, and access to records of themeselves. These are the key findings of a Louis Harris survey, as reported by Prof. Alan F. Westin of Columbia University, during the plenary session on computers and society. The survey was sponsored as a public service by Sentry Insurance.
Privacy and Protection in Operating Systems	The IEEE Committee on Operating Systems sponsored a workshop on privacy and protection in operating systems in Princeton, New Jersey, from June 12-14, 1972. Thirty-two people interested in operating system protection met at the Nassau Inn to discuss various problems and their possible solutions. The workshop was organized by Dr. R. Stockton Gaines of the Institute for Defense Analysis, Princeton. He and Professor Peter Denning, Princeton University, acted as session chairmen.
Ubiquitous Data Collection: Rethinking Privacy Debates	A discussion about the ubiquitous collection, dissemination, and processing of data requires a comprehensive perspective of the risks involved.
1986 Symposium on Security and Privacy	Provides a listing of upcoming conference events of interest to practitioners and researchers.
1987 IEEE Symposium on Security and Privacy	Provides notice of upcoming conference events of interest to practitioners and researchers.
Privacy and Data Security	The third in a series of articles providing basic information on legal issues facing people and businesses that operate in computing-related markets focuses on the responsibility to ensure privacy and data security. The featured Web extra is an audio podcast by Brian M. Gaff and Thomas J. Smedinghoff, two of the article's coauthors.
Electronic Personal Health Records and the Question of Privacy	Personal health records (PHRs), centralized places for consumers to electronically store, manage, and share their personal health information, offer new opportunities to help consumers manage their own health and health care. However, ensuring the privacy and confidentiality of health information contained within PHRs is challenging. This paper analyzes the major properties of existing PHR systems and identifies specific privacy and security issues with each type of PHR. It proposes a consumer-controlled privacy protection approach that includes high-minded privacy principles such as independent consent management, independent privacy and security audits, and regulatory compliance requirements. It further presents a consumer-controlled system architecture that embodies these principles in the web-based PHR system.
1987 IEEE Symposium on Security and Privacy	Provides notice of upcoming conference events of interest to practitioners and researchers.
1987 IEEE Symposium on Security and Privacy	Provides notice of upcoming conference events of interest to practitioners and researchers.
Security and privacy in sensor networks	Sensor networks offer economically viable solutions for a variety of applications. For example, current implementations monitor factory instrumentation, pollution levels, freeway traffic, and the structural integrity of buildings. Other applications include climate sensing and control in office buildings and home environmental sensing systems for temperature, light, moisture, and motion. Sensor networks are key to the creation of smart spaces, which embed information technology in everyday home and work environments. The miniature wireless sensor nodes, or motes, developed from low-cost off-the-shelf components at the University of California, Berkeley, as part of its smart dust projects, establish a self-organizing sensor network when dispersed into an environment. The privacy and security issues posed by sensor networks represent a rich field of research problems. Improving network hardware and software may address many of the issues, but others will require new supporting technologies.
Biometric Authentication: System Security and User Privacy	While biometric systems aren't foolproof, the research community has made significant strides to identify vulnerabilities and develop measures to counter them.
On piracy and privacy	While a rich set of technologies can be used to combat content piracy, the protection of consumer privacy is dominated by legislative policies and legal agreements.
Ensuring Trust, Privacy, and Etiquette in Web 2.0 Applications	An analysis of three user studies of Web 2.0 applications reveals the most important requirements related to ethical issues. The development of features that support these requirements should be tailored to the type of application and specific community needs.
Security and privacy challenges in open and dynamic environments	Information system security and privacy, once narrow topics primarily of interest to IS designers, have become critically important to society at large. The scope of associated challenges and applications is broadening accordingly, leading to new requirements and approaches. Information networks are evolving into more open and dynamic systems. Security and privacy enforcement is problematic in these systems due to the lack of a common understanding of requirements and information as well as user unpredictability. Shared ontologies, declarative policies, and trust models offer the most promising approaches to meet these challenges
1988 IEEE Symposium on Security and Privacy	Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.
Dynamic Privacy in Public Surveillance	In implementing privacy protection in surveillance systems, designers must maximize privacy while retaining the system's purpose. One way to achieve this is to combine data-hiding techniques with context-aware policies governing access to securely collected and stored data.
IEEE Security & Privacy Ad	
Protecting privacy in remote-patient monitoring	With ubiquitous Internet accessibility, audio-video-based remote-patient monitoring is becoming a viable option for people who are responsible for providing in-home healthcare management. In Japan's rapidly aging society, many elderly patients who have lost mobility, speech, or memory live with their families. Although they do not necessarily need intense medical care, these patients require constant attention to ensure their safety. Broadband audio and video introduce a novel possibility for applying remote-monitoring technology to home healthcare. For example, various MPEG compression technologies can transmit high-quality audio-video via the Internet so that a family member can use an office PC or wireless mobile terminal to monitor a bedridden patient's image and vital signs while a caregiver runs errands. Using live audio and video streaming in this manner, however, raises privacy concerns. Transmitting unprotected audio-visual signals, compressed in a standard format, over the Internet carries the risk that someone can monitor these transmissions, whether accidentally or intentionally
Toward adequate online privacy safeguards	The author is concerned with the disclosure of information that might make a student vulnerable to everything from simple spam to criminal harassment or worse. Computing professionals working in a university environment have an opportunity to ensure that universities respect the personal privacy of students.
The Final Frontier: Confidentiality and Privacy in the Cloud	The boundary between the trusted inside and the untrusted outside blurs when a company adopts cloud computing. The organization's applications-and data-are no longer onsite, fundamentally changing the definition of a malicious insider.
Security and Privacy in an Online World	Due to the amazing advances in information and communications technologies, we're heading for an online world in which convenience goods have unprecedented computing power and are permanently connected to the Internet or stored in the cloud. The Internet is everywhere, and now people are talk ing about the Internet of Things (IoT). Look at your own belongings; it's likely that you carry around at least one or possibly several handheld devices such as smartphones that are permanently connected to the Internet. Each device has computing power that was sufficient for navigating a rocket to the moon 40 years ago. Now we use that power to download and play songs and movies, access social media such as Facebook or Twitter, run e-mail or messenger software, or access any of the other myriad apps people have created recently.
Is technology meeting the privacy challenge?	Privacy is one of consumers' most important concerns about using the Internet for e-commerce and other purposes. With this in mind, a number of privacy-related technologies are emerging, including improved software that anonymizes user identities, tools that audit a company's privacy policy adherence, and standards. Technology's effect on privacy has caused concern since commercial computing emerged in the 1960s. However, the Internet has caused people to look at this issue again in a new way, and we have seen a lot more technologies that are invasive, as well as technologies that enhance privacy
Will Carnivore devour online privacy?	In February 2001, the Federal Bureau of Investigation (FBI) renamed its controversial Internet surveillance tool, Carnivore, as the innocuous-sounding ΓÇ£DCS1000ΓÇ¥. Although the move is sensible from a public relations perspective, more than the system's name must change to protect innocent Internet users' rights. According to the FBI, Carnivore (as everyone outside the Bureau still calls it) allows law enforcement agents to intercept and collect e-mail and other electronic communications only when authorized by a court order. What is so controversial about Carnivore, and why has it provoked strong negative reactions from privacy advocates, editorial boards and members of the US Congress? The answers lie in how the system works and who controls it
Sticky Policies: An Approach for Managing Privacy across Multiple Parties	Machine-readable policies can stick to data to define allowed usage and obligations as it travels across multiple parties, enabling users to improve control over their personal information. The EnCoRe project has developed such a technical solution for privacy management that is suitable for use in a broad range of domains.
Letters - Privacy and freedom of speech	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01023774.png" border="0">
IEEE Security & Privacy Silver Bullet Podcast ad	
Technological solutions for protecting privacy	The Web is commonly viewed as an information access tool for end users. But as much as it simplifies access to stock quotes, medical libraries, or reference manuals, the Web also makes it easier for individuals and organizations to obtain and infer. Emerging technologies can protect privacy without restricting the information flow crucial to efficient organizations. Solutions to privacy concern must combine laws, societal norms, market and technology.
Cloud Computing and EU Data Privacy Regulations	To leverage the cloud's power, EU authorities must revisit policies related to various types of personal data and their associated privacy risks.
Wireless location privacy protection	After more than two decades of hype, computing and communication technologies are finally converging. Java-enabled cell phones run a host of powerful applications including mobile Internet access, while many notebook computers offer high-speed wireless connectivity as a standard feature. The big decision when purchasing a PDA is whether to get integrated cellular service or Wi-Fi capability. Location-based services are emerging as the next killer app in personal wireless devices, but there are few safeguards on location privacy. In fact, the demand for improved public safety is pushing regulation in the opposite direction. Today, when a person reports an emergency from a landline phone by dialing 911 in the United States or 112 in Europe, the system displays the caller's phone number and address to the dispatcher. The US Federal Communications Commission has mandated that, by December 2005, all cellular carriers be able to identify the location of emergency callers using mobile phones to within 50 to 100 meters. However, how cellular carriers and other businesses will use this capability remains open to question. The article looks at some of the areas this capability affects, including: privacy risks; economic damages; location-based spam; intermittent connectivity; user interfaces; network privacy; and privacy protection.
Association rule mining algorithm based on privacy preserving	The goal of privacy preserving association rule is to find an approach of the original data set, making the relevant sensitive rules not to be found in a process of data mining. In order to efficiently achieve privacy preserving, this paper proposes an effective method for privacy preserving association rule. Trough the way of combining the basic strategies of PPARM algorithm and IMBA which are improved, making less-sensitive operations, a greater degree of hiding can be made while a less degree impact for the non-sensitive rules can be made too. Theoretical and experimental results show that the algorithm is highly efficient, and can ensure the privacy preserving better.
Analysis of the privacy issues of human flesh search engine	ΓÇ£Human flesh searchΓÇ¥ engine is rapidly developing, and leading to strong social effects. The article conducts a systematic analysis on the ΓÇ£human flesh searchΓÇ¥, describes the working principle and characteristics of ΓÇ£human flesh searchΓÇ¥, analyzes privacy issues raised by ΓÇ£human flesh searchΓÇ¥, and criticizes legally ΓÇ£human flesh searchΓÇ¥ from the perspective of privacy, finally puts forward a number of insights and ideas combining of these problems.
Protecting location privacy in Augmented Reality using k-anonymization and pseudo-id	Location based services (LBS) are one of the most commonly used services in Augmented Reality(AR). In LBS, the safety and security of data is one of the most important things to be taken care. A privacy-aware management of location information, which provides location privacy for clients against vulnerabilities or abuse, is very much needed. This paper discusses how to protect the location privacy from various privacy threats, which occurred because of the unlimited usage of LBS, by a scalable architecture. We have developed an efficient LBS privacy protection algorithm. In our model, k-anonymization and pseudo-anonymization methods have been used hand in hand. The proposed location privacy frame work is implemented by an efficient TTP server. We have studied the efficiency of our algorithm under different conditions using realistic workloads. Our experiment shows that the k-anonymization and the pseudo-anonymization methods used together in our algorithm provide an efficient location privacy.
An approach for data privacy in hybrid cloud environment	The cloud computing immerges as a new computing technology where all required services are available as a service. In a cloud environment, location of data is generally maintained by a third party (service provider/vendor) and hence an individual has no control over its own data. In this context, data privacy is an important issue for cloud computing both in terms of legal compliance and user trust. In this paper, an approach for data privacy in hybrid cloud environment is focused. Initially, a data privacy model for cloud computing is provided in which sensitive and non-sensitive data are maintained separately. In order to maintain data privacy, an authentication monitor is introduced in this privacy model. Finally, the authentication algorithm is implemented in a very small setup cloud environment and experimental results are provided at the end of the paper.
Privacy Preserving Data Mining Techniques: Current Scenario and Future Prospects	Privacy preserving has originated as an important concern with reference to the success of the data mining. Privacy preserving data mining (PPDM) deals with protecting the privacy of individual data or sensitive knowledge without sacrificing the utility of the data. People have become well aware of the privacy intrusions on their personal data and are very reluctant to share their sensitive information. This may lead to the inadvertent results of the data mining. Within the constraints of privacy, several methods have been proposed but still this branch of research is in its infancy. The success of privacy preserving data mining algorithms is measured in terms of its performance, data utility, level of uncertainty or resistance to data mining algorithms etc. However no privacy preserving algorithm exists that outperforms all others on all possible criteria. Rather, an algorithm may perform better than another on one specific criterion. So, the aim of this paper is to present current scenario of privacy preserving data mining tools and techniques and propose some future research directions.
Privacy preservation in context aware systems: Overview and applications	Summary form only given, as follows. Advent of 4 G networks, IPv6 and increasing number of subscribers indicate that each mobile device will have its own IP address and virtually become a hotspot. In the coming years, systems that track and record our movements will indispensably be integrated in our everyday life. Location-based systems: dashboard navigation systems, Internet enabled smartphones with GPS features, and electronic tags that help us at various locations are extensively in use. In near future, location-aware/ context aware tools will become more common and sophisticated. Increasing number of services (apps)/devices that will track not only the location, but also the context / environment of the user will enter the market. The perils of exposure on Internet and subsequent exploitation have been widely recorded in literature. Some of the services provided do necessitate the knowledge of exact location, context and some personal details, like in case of assistance during accidents, but generally, applications like finding the restaurants or movies playing in an area do not require the exact location and context of the user. When a user??s movement in public spaces is tracked and systematically recorded along with the context of his actions, his contextual privacy is under threat. This presentation will discuss the current state of research in this area and analyses the effect of threat on the privacy of context aware system users. Based on the insight, this talk will provide an integrated framework to tackle the privacy preservation issue comprehensively: from user perspective as well as service provider perspective. In addition, this talk will also include a discussion on context aware distributed storage system.
A Privacy Policy of P3P Based on Relational Database	P3P is an industry standard method that enables users to gain powerful control over their processing of personal information on Web sites being visited. Traditional methods of database access control places great dependence on the use application of statically defined views. In this paper, we propose the procedure by which current RDBMS can be transformed into their privacy-preserving equivalents. In addition, architectural for implementing P3P based on RDBMS is dissected and a server-centric implementation that reuses database querying technology is suggested
A Privacy-Preserving Mining Algorithm of Association Rules in Distributed Databases	Association rules mining is one of the most important and fundamental problems in data mining. Recently, in need of security, more and more people are studying privacy- preserving association rules mining in distributed database. This paper addresses a secure mining algorithm of association rules, which builds a globe hash table to prune item-sets and incorporate cryptographic techniques to minimize the information shared
A Flexible Method of Privacy Preserving Clustering	Privacy protection is an important issue in data processing. In this paper, we present a novel clustering method for privacy preserving in homogenous data sets. By developing matrix transformation method, our method can not only protect privacy in face of collusion, but also achieves a higher level of accuracy as compared to the existing method. The importance of independent perturbation is addressed in the random matrix generation. The performance of the method including the levels of accuracy and privacy are also analyzed in detail. Experimental results further demonstrate that our method is also adaptive to large data dimensions.
Privacy and Security on Anonymous Routing Protocols in MANET	Routing in wireless ad hoc networks are vulnerable to traffic analysis, spoofing and denial of service attacks due to open wireless medium communications. Anonymity mechanisms in ad hoc networks are critical security measures used to mitigate these problems by concealing identification information, such as those of nodes, links, traffic flows, paths and network topology information from harmful attackers. Providing security and anonymity to users are critical in wireless ad hoc networks. This report presents a state-of-the-art review and a comparison for typical representatives of Anonymous routing protocols designed for mobile ad hoc networks. The report aims at providing criteria according to which those protocols can be compared and classified.
PRBAC: an extended role based access control for privacy preserving data mining	Issues about privacy-preserving data mining have emerged globally, but still the main problem is that non-sensitive information or unclassified data, one is able to infer sensitive information that is not supposed to be disclosed. This paper proposes an approach to PPDM based on an extended role based access control called privacy preserving data mining using an extended role based access control(PRBAC); Sensitive objects (SOBS) component is added to the model in order to privacy protecting during data mining. Users are allowed to access and thereby mine different sets of data according to their roles. Our proposed model can be used over the existing technologies. The paper goal is to preserve individual's privacy.
Privacy-Preserving Data Publishing Based on De-clustering	In recent years, privacy preservation has become a serious concern in publication of personal data because of the wide availability of personal data. In the literature, we know that the degree of privacy protection is really determined by the number of distinct sensitive values in each group which is classified according to quasi-identifiers. In this paper, we present a novel method to protect data privacy by partitioning the microdata into some groups based on de-clustering. In this method, we make the records contained in each group possess distinct sensitive values and ensure that the size of the minimal groups not to be less than a threshold zeta. According to a novel privacy measure proposed in this paper, our method can provide strong privacy protection. Extensive experiments confirm that our method can provide stronger privacy protection than the methods based on l-diversity.
Efficient secure storage of privacy enhanced video surveillance data in intelligent video surveillance systems	The trade-off between privacy and security was a subject of intensive discussion. Giving up privacy does not necessarily result in greater security, and greater security does not necessarily require a loss of privacy. In this work, three different novel approaches are presented to store personal data obtained from intelligent video surveillance systems in an efficient and secure way. The storage process of this data poses a number of challenges e.g. storage optimization, query performance, security management, access control and performance management. Each of the proposed technique is evaluated and analyzed with respect to the above-mentioned challenges. Field test results showed that each of the technique can be successfully applied to hide/conceal privacy related data with a maximum storage as well as retrieval performance.
A Privacy Enhanced Data Aggregation Model	This paper proposes an enhanced privacy-preserving data aggregation scheme, which balances the onerous task of extracting reasonable data value and preserving data privacy even with incomplete or malicious data presentence. We propose an innovative encryption algorithm to preserve data privacy while it can provide secure data comparison between the encrypted data. Furthermore, we define a robust and efficient aggregation operator to fuse the encrypted data without decryption by secure data comparison and density based data mining. The proposed aggregation scheme can remove both potentially malicious and redundant data before aggregation so that it can provide a robust aggregation result without scarifying data privacy. We also discuss the scheme performance in terms of aggregation accuracy, distribution recovery ability and aggregation efficiency. The experiment results show that this scheme can give reasonable aggregation values, recover the data distribution well even under 50% malicious readings, much more robust than the commonly used aggregation while it has good aggregation efficiency with above 80% redundant data removal.
Mix-zones Deployment for Location Privacy Preservation in Vehicular Communications	Location privacy is a main concern in vehicular communications where vehicles have to broadcast traffic routine information frequently. A promising approach to prevent a vehicle from been tracked suggests vehicle to change pseudonyms in regions called mix-zones, where the adversary cannot eavesdrop the vehicular communication. However, the deployment problem of mix-zones has not been well addressed in previously reported works. In this paper, we propose a statistics-based metric for evaluating and locating a mix-zone. Furthermore, a cost-efficient mix-zones deployment scheme is presented to guarantee that vehicles at any place can pass through an effective mix-zone in certain driving time (DT), and the extra overhead time (ET) of adjusting routes to across the mix-zone is small. Finally, several deployment examples are given for a real-world map.
Privacy-preserving Data Aggregation Based on the P-function Set in Wireless Sensor Networks	In-network data aggregation presents a critical challenge for data privacy in resource constraint wireless sensor networks. Existing schemes based on local collaboration have unfavourable communication cost, and some other schemes based on secret sharing with the sink are low resistant to data loss. To address these issues, we propose a PAPF scheme, in which a novel p-function set taking advantage of the algebraic properties of modular operation is constructed. Thanks to the p-functions, nodes can perturb their privacy data without extra data exchange, and the aggregation result can be recovered from the perturbed data in the cluster head. Extensive analysis and simulations show that PAPF scheme is able to preserve privacy more efficiently while consuming less communication overhead, and has a good resistance to data loss.
A Privacy-Preserving Trust Model for VANETs	Vehicular ad hoc network (VANET) is a promising technology for providing safer roads and a more efficient driving experience. However, the deployment of VANETs is dependent on several issues in security and privacy. In this paper, a trust-based privacy-preserving model for VANETs is presented. The model is unique in its ability to protect privacy while maintaining accurate reputation-based trust. We use the notion of groups in order to make the VANET users anonymous within their groups and yet identifiable and accountable to their group managers. The use of groups simplifies the task of building reputation and calculating trust in the received messages in order to provide better and more confident decisions. We present simulations of the proposed model that verify its correctness and reliability.
Designing Cloud Services Adhering to Government Privacy Laws	Cloud computing delivers on-demand services with flexibility and scalability on a simple pay-per-use basis. However, major concerns regarding to security and privacy hinder a broad adoption by users, especially small- and medium-sized enterprises (SMEs). This is because existing guidelines, IT standards and laws on security and privacy do not take virtual environments into account. Thus, they present a significant challenge for cloud providers to comply with. As a result, the cloud providers are unable to provide SMEs with an assurance. In order to address these privacy and security issues, this paper presents the Cloud Data Security (CloudDataSec) project that aims to design cloud services adhering to government privacy laws. In particular, this paper introduces a six-layer security model for cloud computing and three level of security assurance for SMEs to take advantage of. Finally, Security Management as a Service (SMaaS) modules, as proposed in this paper, enable users to apply necessary security and privacy operations, based on the sensitivity of their data.
A Distributed Query Protocol for Continuous Privacy Preserving in Wireless Sensor Networks	With the rapid proliferation of wireless sensor networks, data are becoming easily obtainable. While the information is very useful in many aspects, privacy concern is also becoming more challenging, especially when we face more and more serious security and privacy threats. In these privacy concerns, location privacy is a very interesting yet difficult issue. To date, existing research commonly focus on protecting the current location of objects only, yet, we found another privacy threat caused by the capability of inferring location by knowing previous location sequence, we call it the continuous privacy threat. In this paper, we design P-preserving, a new distributed protocol for continuous data collection with privacy preserving in sensor networks. In P-preserving, it integrates continuous privacy awareness algorithms into existing data collection framework, i.e., raw data collection and in-network processing. Extensive simulation results demonstrate the effectiveness of our P-preserving protocol.
Enabling Privacy-preserving Credential-based Access Control with XACML and SAML	In this paper we describe extensions to the access control industry standards XACML and SAML to enable privacy-preserving and credential-based access control. Rather than assuming that an enforcement point knows all the requester's attributes, our extensions allow the requester to learn which attributes have to be revealed and which conditions must be satisfied, thereby enabling to leverage the advantages of privacy-preserving technologies such as anonymous credentials. Moreover, our extensions follow a credential-based approach, i.e., attributes are regarded as being bundled together in credentials, and the policy can refer to attributes within specific credentials. In addition to defining language extensions, we also show how the XACML architecture and model of evaluating policies can be adapted to the credential-based setting, and we discuss the problems that such extensions entail.
A Practical Approach to Improve the Data Privacy of Virtual Machines	Cloud computing can provide users dynamically scalable, shared resources over the internet, but users usually fear about security threats and loss of control of data and systems. This paper presents a practical architecture to protect the data confidentiality for guest virtual machines. With this solution, even the cloud computing service providers cannot access the private data of their clients. This is very important and attractive for the cloud clients. In our work, we utilize virtualization technology and trusted computing technology to construct a secure and robust virtualization platform. On this platform, we customize the guest virtual machine operating system, strengthen the isolation between virtual machines, and therefore, greatly improve the data privacy of cloud services. With our solution, the cloud service provider can compromise the availability, but not the confidentiality of the guest virtual machines.
Privacy-Aware Access Control and Authorization in Passive Network Monitoring Infrastructures	Despite the usefulness of passive network monitoring for the operation, maintenance, control and protection of communication networks, as well as law enforcement, network monitoring activities are surrounded by serious privacy implications. In this paper, an innovative approach for privacy-preserving authorization and access control to data originating from passive network monitoring is described. The proposed framework relies on an ontological model for the specification of the access control policies, which are evaluated and enforced on a two-phase and two-stage basis by a system that intercedes between the network link and the monitoring applications. The two stages refer to controlled access regarding both the data that are disclosed to the monitoring application from the mediating system and the raw data that the mediator retrieves from the network link. On the other hand, the two phases concern respectively the execution of ΓÇ£staticΓÇ¥ and ΓÇ£dynamicΓÇ¥ control; the former enforces the rules that are a priori applicable, grounded on the data, role and purpose semantics, while the latter evaluates the real-time contextual parameters for the adaptation of the access control procedures to the particular conditions underlying a request.
A Culture of Trust Threatens Security and Privacy in Qatar	This paper describes experiments in the State of Qatar to test Qataris' vulnerability to e-mail phishing in reality through two penetration tests. Factors which make Qatari citizens vulnerable to e-mail phishing attacks are identified, such as culture, country-specific factors, interests, beliefs, religion and personal characteristics. It has been found that Qataris put too much trust in technology and their own abilities to detect email phishing, making them an easy target for phishing. The paper identifies the need for an awareness programme to enhance Qataris' level of awareness of the phishing threat.
Achieving Scalable Privacy Preserving Data Aggregation for Wireless Sensor Networks	A sink node must be aware of the identifications (node IDs) of those all sensor nodes which contribute in aggregated value of sensors data in order to derive exact result of them in privacy preserving data aggregation scheme for wireless sensor networks (WSNs). This is possible only when if there exists such a scheme which can transmit IDs of all the participating sensor nodes to the sink node. But, currently existing TinyOS based privacy preserving data aggregation protocols for WSNs can not transmit the IDs of those all sensor nodes which contribute to aggregated value of sensor data to the sink node due to following two reasons. The first is that TinyOS offers limited payload size of 29 bytes. The second is that each sensor node ID is transmitted as a plaintext (2 bytes) to the sink node. As a result, it restricts sending IDs of all contributed sensor nodes. To resolve the problem, we, in this paper, propose a novel mechanism in which a special set of real numbers are assigned as the IDs of sensor nodes so that a single bit is sufficient to hold ID of a sensor node during transmission of aggregated data to the sink node. For this, we, first, generate fixed size signatures for the IDs of all sensor nodes and then superimpose the signatures during data aggregation phase. By analytical evaluations, we show that our scheme is more scalable and energy efficient than the existing work to transmit IDs of sensor nodes to the sink node.
A New K-NN Query Processing Algorithm Enhancing Privacy Protection in Location-Based Services	Location-Based Services (LBSs) are becoming popular due to the advances in mobile networks and positioning capabilities. When a user sends a query with his exact location to the LBS server, the server processes the query and returns Points of Interest (POIs) to the user. Providing user's exact location to the LBS server may lead revealing his private information to unauthorized parties (e.g., adversaries). There exist two main fields of research to overcome this problem. They are cloaking region based query processing method which blurs a user's location into a cloaking region and Private Information Retrieval (PIR) based query processing methods which encrypt location data by using PIR protocol. However, they suffer from high computation and communication overheads. To resolve these problems, we, in this paper, propose a hybrid scheme to process an approximate k-Nearest Neighbor (k-NN) query by combining above two methods. Through performance analysis, we have shown that our hybrid scheme outperforms the existing work in terms of both query processing time and accuracy of the result set.
A Privacy Preserving System for Cloud Computing	Cloud computing is changing the way that organizations manage their data, due to its robustness, low cost and ubiquitous nature. Privacy concerns arise whenever sensitive data is outsourced to the cloud. This paper introduces a cloud database storage architecture that prevents the local administrator as well as the cloud administrator to learn about the outsourced database content. Moreover, machine readable rights expressions are used in order to limit users of the database to a need-to-know basis. These limitations are not changeable by administrators after the database related application is launched, since a new role of rights editors is defined once an application is launched. Furthermore, trusted computing is applied to bind cryptographic key information to trusted states. By limiting the necessary trust in both corporate as well as external administrators and service providers, we counteract the often criticized privacy and confidentiality risks of corporate cloud computing.
Spatial Cloaking Method Based on Reciprocity Property for Users' Privacy in Road Networks	The proliferation of position identifying devices becomes increasing privacy threat in location-based services (LBSs). It is necessary to tackle the privacy threat of a user in processing his/her request because the user has to submit his/her exact location with a query to the LBS. In road networks, X-Star provides a star-graph based cloaking method that can protect a user's privacy from attack resilience as well as optimize a query processing cost. However, it incurs a low anonymization success rate and a high computation overhead. We propose the Hilbert-order based cloaking algorithm to resolve the problems. Our algorithm guarantees K-anonymity under the strict reciprocity condition and increases anonymization success rate by reducing computation overhead. Experimental evaluations show the effectiveness of our method in the field of spatial cloaking.
A study of privacy policy enforcement in access control models	Internet has gained huge popularity over the last decade. It offers its users reliable, efficient and exciting online services. However, the users reveal a lot of their personal information by using these services. Websites that collect information state their practices with data in their privacy policies. However, it is difficult to ensure if the policies are enforced properly in their practices. This can lead to unintentional leakage of private information to unauthorized parties and thus increase the chance of private data to be misused. Taking the help of legal systems is expensive, time consuming and cannot compensate the loss completely. Therefore, an effective way to protect privacy is to use privacy policy to control data access. In this paper, we review some distinguished research works that address this problem. We also discuss the completeness of the privacy definition used in these works.
A User-Centric Privacy Authorization Model Based on Role and Session in the Context-Aware Home	The seamless combining with context-aware sensors and numerous devices and e-home server will soon become a part of our home environment in the near future. We name it as a context-aware home based on ubiquitous computing concept. This context-aware home reduces participations of users in order to realize a ubiquitous computing and automates various services. Therefore, the risk of privacy violation is higher than that of the general computing environment given user participations. This paper presents a user-centric access control model based on role and session in the context-aware home. Our model provides privacy protection for the users using a range of services of the context-aware home and provides anonymity by joining ID and roles.
Articulated Modeling of Distributed Privacy: Transitive Closure of Composition of Narrowcasting and Multipresence	Our group is exploring models and interfaces for advanced conferencing, especially considering "narrowcasting," a filtering of sent or received media streams, and "multipresence," designation by each human user of possibly multiple avatars, iconic delegates in a virtual conference space. Shared virtual environments, like chatspaces, require generalized control of user-dependent media streams. Privacy operations can be specified as various narrowcasting commands, which are compounded by multipresent designations, arbitrary mappings between users and avatars. These distributed multiuser narrowcasting and multipresence configurations can be compiled into connectivity state suitable for configuring media servers. The transitive closure of the composition of the narrowcasting and multipresence models the communication ├é┬┐indirectionability├é┬┐ of the system, setting limits on media stream privacy.
Towards Balancing Data Usefulness and Privacy Protection in K-Anonymisation	K-anonymisation, as an approach to protecting data privacy, has received much recent attention from the database research community. Given a single table, there can be many ways to anonymise it. So criteria for determining a preferred solution is important. Various techniques have been proposed, all attempting to achieve some form of optimality in k-anonymisation, but few have considered the balance between the usefulness of the anonymised data and the protection of the original. In this paper, we address this issue and propose a two-step approach which allows data usefulness and privacy protection requirements to be considered and balanced in k-anonymisation.
Data privacy and integrity appropriate for disk protection	To protect data privacy and integrity, it encrypts each protected disk sector and creates hash tree upon all the protected sectors to resist against any possible attacks. To make it an appropriate way for disk protection, it designs the required solutions of disk layout, performance optimizing and consistency maintaining. Disk layout uses a fixed disk region to preserve hash tree nodes; performance optimizing utilizes system memory to buffer those frequently used hash tree nodes to offload the big working cost; and consistency maintaining logs disk modifications to recovery the valid result after unexpected failures. The implementation cost is low and running performance is satisfiable. Analysis and experimental simulations show that it is a practical and available way to build secure disk.
(p<sup>+</sup>, ╬▒)-sensitive k-anonymity: A new enhanced privacy protection model	Publishing data for analysis from a microdata table containing sensitive attributes, while maintaining individual privacy, is a problem of increasing significance today. The k-anonymity model was proposed for privacy preserving data publication. While focusing on identity disclosure, k-anonymity model fails to protect attribute disclosure to some extent. Many efforts are made to enhance the k-anonymity model recently. In this paper, we propose a new privacy protection model called (p<sup>+</sup>, alpha)-sensitive k-anonymity, where sensitive attributes are first partitioned into categories by their sensitivity, and then the categories that sensitive attributes belong to are published. Different from previous enhanced k-anonymity models, this model allows us to release a lot more information without compromising privacy. We also provide testing and heuristic generating algorithms. Experimental results show that our introduced model could significantly reduce the privacy breach.
Trusted Email protocol: Dealing with privacy concerns from malicious email intermediaries	It is well-known that intermediate mediums that route emails between senders and recipients can be a real threat to privacy as these intermediaries can easily intercept and tamper with email messages. Many software-based solutions have been proposed to solve such privacy concerns by means of end-to-end data encryption such as PGP, OpenPGP, and S/MIME. These solutions pose yet another challenging issue for the secure and trusted management of cryptographic keys they utilize. To address this issue, we propose a new protocol for a Trusted Email System using hardware-based cryptographic functionality of Trusted Platform Module (TPM) and the Ephemerizer concept. By leveraging the advantages of these two technologies, our protocol provides a safeguard to cryptographic keys so that only designated email senders and recipients can read email messages. Furthermore, our protocol guarantees that nobody can read email messages that have expired or have been securely deleted. In this paper, we first describe the protocol of our Trusted Email System and then verify the security aspects of the protocol using a popular cryptographic verification tool, ProVerif.
A Method for Privacy Protection in Location Based Services	Privacy protection is a very important issue and solutions must be developed for wide acceptance of location based services (LBSs) in wireless applications. Current approaches rely mostly on the use of privacy policies to describe and solve this problem in an ad hoc way. In this paper, we propose a method based on the three-dimensional access control model to support privacy requirements. We show that our method can better describe and support user location privacy requirements in LBSs. By introducing the notions of privacy-concerning subjects and enhancing the traditional access control mechanism, we demonstrate how our method can provide all the privacy-concerning users with the necessary means of controlling access to private location information.
A Privacy Preserving Algorithm for Mining Distributed Association Rules	For resolving the problem that the existing protocol of secure two-party vector dot product computation has the low efficiency and may disclose the privacy data, a method which is effective to find frequent item sets on vertically distributed data is put forward. The method uses semi-honest third party to participate in the calculation, put the converted data of the parties to a third party to calculate. The results show that compared to the original Vector dot product algorithm, the method can obviously improve the algorithm efficiency and accuracy of the results at the precondition that assured the data privacy of all parties.
Application of secure multi-party computation on judging privacy-preserving path	Judging private path is a kind of special privacy-preserving geometric calculation. In this paper, a private-preserving curvet-ellipse position relation determination protocol is proposed based on the Private-Preserving Dot Product Protocol and Millionaires' Protocol in semi-honest model along with analysis of protocol' capability. It can be used to solve the problem about judging private path.
Privacy protection in location-sharing services	With the fast development in mobile computing devices, location-sensing technology and wireless communication, new applications for share users' real-time location information are developing at an amazing pace. Location privacy is of utmost concern for location-sharing services. There is already a full agreement that users would like to have the complete control over their location information. Existing privacy protection methods often let users specify their privacy peferences to the service provider and thus not only fail to consider the dynamic nature of privacy preferences but also fail to protect user privacy from service provider. In this paper, we propose an user-centric privacy access control method. By separating sensitive privacy polices apart from standard privacy policies, which are now stored at user side and therefore fully under user's control, we demonstrate that our system can provide users with a flexible way of complete controlling over information about their location without adding too much user burden.
An improved trusted cloud computing platform model based on DAA and privacy CA scheme	Security and privacy are two prime barriers to adoption of the cloud computing. To address this problem on Infrastructure-as-a-Service model, a trusted cloud computing platform model has been proposed to provide a closed box execution environment that guarantees confidential execution of guest virtual machines. However this model has significant drawbacks that it relies on the trusted third party outside of the cloud circumstance too much. In this paper we show how to address this issue based on the neutral feature of the Trusted Platform Module. By moving the responsibility of managing trusted platforms from the trusted third party to the trusted platforms of Infrastructure-as-a-Service model, our improved TCCP model achieves higher availability, reliability and safety.
Privacy And Security In An Oncology Information System	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00679957.png" border="0">
Privacy-Enhanced Trusted Location Based Services (PE-TLBS) framework based on Direct Anonymous Attestation (DAA) protocol	The proliferation of heterogeneous mobile applications has overridden privacy and security issues. Since privacy threat in Location Based Services (LBS) is very hard to define, new approach of addressing the anonymity issues in Privacy Enhancing Technologies (PETs) using Trusted Computing technologies will result the privacy enhancement of user personal data and location information in mobile network services. In this paper we present a framework called Privacy Enhanced Trusted LBS (PE-TLBS) providing trusted services while protecting the client privacy. This paper mainly focuses on implementing a simplified protocol based on anonymous attestation that allows users to attest and authenticate an attribute while keeping their identity hidden under anonymity. The key idea behind the new approach is to hierarchically encrypt location information using RSA key pairs known as Endorsement Key (EK) and Attestation Identity Key (AIK), and distribute the appropriate keys only to Trusted Group of clients with the necessary permission. The trust-ability is measured based on Direct Anonymous Attestation (DAA) scheme supported by Trusted Platform Module (TPM) functionalities in terms of preserving anonymity, detecting rogue users/TPM and possible linkability complying with privacy requirements. We form Virtualized Secure Framework technique using TPM Emulator and TCG Software Stack (TSS) to simulate and make the accession to TPM much simpler while maintaining the functionality as well as provide Application Programming Interfaces (APIs).
Patient privacy: a consumer protection approach	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00764729.png" border="0">
Border crossing security and privacy in biometric passport using cryptographic authentication protocol	Biometric passport (e-passport) is to prevent the illegitimate entry of traveller into a particular country and border the use of counterfeit documents by more accurate identification of an individual. The electronic passport, as it is sometimes called, represents a bold proposal in the procedure of two new technologies: cryptography authentication protocols and biometrics (face, fingerprints, palm prints and iris). A passport contains the important personal information of holder such as photo, name, date of birth and place, nationality, date of issue, date of expiry, authority and so on. The goal of the adoption of the electronic passport is not only to accelerate processing at border crossings, but also to increase safety measures. The paper explores the border crossing privacy and security implications of this impending worldwide experiment in biometrics passport technology.
Security and Privacy Objectives for Sensing Applications in Wireless Community Networks	Wireless Community Networks (WCN) are formed by the integration of user-operated wireless sensor networks that are internetworked by wireless mesh networks available within urban communities. WCNs enable novel applications for the members of the community. These include different sensing applications, where individuals contribute sensor data for further use within their community at large or with well-defined restrictions to certain users. Sensing application scenarios for WCNs differ from traditional sensor network applications with respect to their security and privacy requirements. In this paper, we define three representative scenarios-personal sensing, designated sensing, and community sensing. These scenarios are then studied with respect to their privacy and security implications. In particular, we identify main research questions and highlight the challenges of using various security and privacy approaches from networking and cryptography to make sensing applications in WCNs security and privacy aware.
Fast Privacy-Preserving Top-k Queries Using Secret Sharing	Over the past several years a lot of research has focused on distributed top-k computation. In this work we are interested in the following privacy-preserving distributed top-k problem. A set of parties hold private lists of key-value pairs and want to find and disclose the fe key-value pairs with largest aggregate values without revealing any other information. We use secure multiparty computation (MPC) techniques to solve this problem and design two MPC protocols, PPTK and PPTKS, putting emphasis on their efficiency. PPTK uses a hash table to condense a possibly large and sparse space of keys and to probabilistically estimate the aggregate values of the top-k keys. PPTKS uses multiple hash tables, i.e., sketches, to improve the estimation accuracy of PPTK. We evaluate our protocols using real traffic traces and show that they accurately and efficiently aggregate distributions of IP addresses and port numbers to find the globally most frequent IP addresses and port numbers.
Challenges to Privacy in Social Networking Mashups: Social TV as a Case Study	Social networking provides opportunities to expand the nature of existing applications and user activities in cyberspace. Consider the idea of "social TV". Along with these opportunities to combine activities such as social networking and TV or entertainment, comes an interesting set of challenges to the privacy of identity information. In this paper we will examine a key set of these challenges. These include issues of merged identities, inference across identities, merged privacy policies, and flow of information among the composition identity management systems involved in a new composite application service. We conclude with a set of observations to keep in mind when designing such a composition or mashup of existing services, especially with respect to identity and privacy.
STEP: Source Traceability Elimination for Privacy against Global Attackers in Sensor Networks	Preserving privacy is one of the most challenging yet essential issues in many mission critical WSN applications. As most of the existing privacy solutions additionally inject fake traffic assuming limited local adversary models, they can be easily defeated by highly motivated global attackers that monitor the entire network communications. We propose a scheme against a global adversary model, named Source Traceability Elimination for Privacy (STEP) using heterogeneous links. The STEP uses wormhole pairs (WHPs) to hide the communication of an original source location and scatter it to a remote location. Unlike the existing privacy mechanisms, the STEP provides privacy without incurring any additional communication overhead. We quantify a source location privacy level, evaluate the STEP with various parameters, and discuss its effect when used with other privacy techniques simultaneously.
A Context-Aware Approach for Enhanced Security and Privacy in RFID Electronic Toll Collection Systems	RFID Electronic Toll Collection (ETC) systems have been deployed worldwide to improve toll collection efficiency, reduce road congestion, increase road safety and traveler satisfiability. However, the use of such systems raises a number of security and privacy issues due to unauthorized reading and relay attacks. Unfortunately, currently deployed or proposed solutions targeting these attacks often fail to satisfy the constraints and requirements of the underlying RFID toll road application in terms of (one or more of) efficiency, security, and usability. In this paper, we report our initial work toward a new approach, one that utilizes sensing technologies, to tackle the problems of unauthorized reading and relay attacks in RFID ETC systems by considering efficiency, security, and usability simultaneously. In our approach, on-board tag sensors are used to collect contextual information (location, speed) about the tag. Such contextual information is then used to design context-aware selective unlocking mechanisms for toll cards such that they can selectively respond to reader interrogations and thus minimize the likelihood of unauthorized reading and relay attacks. The premise of our work is a current technological advancement that enables many RFID tags with sensing capabilities.
Smart Grid Privacy: Issues and Solutions	Migration to an electronically controlled electrical grid to transmit, distribute, and deliver power to consumers has helped enhance the reliability and efficiency of conventional electricity systems. At the same time, this digitally enabled technology called the Smart Grid has brought new challenges to businesses and consumers alike. A key component of such a grid is the smart-metering technology, which is used to collect energy consumption data from homes and transmitting it back to power distributors. A crucial concern is the privacy related to the collection and use of energy consumption data. We present an analysis of Smart Grid privacy issues and discuss recently proposed solutions that can protect the privacy of Smart Grid users.
Security and Privacy Analysis of RFID Authentication Protocol for Ubiquitous Computing	Radio frequency identification (RFID) is an emerging technology which brings enormous productivity benefits in applications where objects have to be identified automatically in mobile and ubiquitous computing. In this paper we describe problems of previous works on RFID security protocols and specify several known attacks and introduce a modified RFID security protocol which serves as a proof of concept for authentication an RFID tag to a reader device using the vernam and standard encryption as a cryptographic primitive. To verify our protocol, we use model checking methodology and then verify security properties such as secrecy and authentication using FDR(Failure Divergence Refinement) tool.
A Study on Context-aware Privacy Protection for Personal Information	By using personal information in a pervasive computing environment, context-aware applications can provide appropriate services for people. This personal information is often involved in personal privacy. In order to protect personal privacy concerns about personal information, privacy role is proposed to control access personal information. We also construct an information system about the privacy decision of personal information disclosure based on people's interaction history. In the initial period of personal information disclosure, the privacy decision is made by people and the information system is constructed based on the decision data. Then privacy disclosure policies are extracted from this information system using rough set theory. According to deducing from the privacy disclosure policies and people's context information, the context-aware application is assigned to an adequate privacy role. It reduces the distraction of privacy decision for people. A case study further shows the proposed method is effective. Finally, it provides about the overload performance of privacy role analysis engine.
Addressing Heterogeneity, Scalability, and Privacy in Layered Multicast Congestion Control	Multicast is attracting a resurgence of interest because it has a potential to address the explosively growing need for efficient streaming of large-volume Internet content. However, to realize the potential, large-scale multicast distribution requires effective congestion control. In this paper, we design SIM, a protocol that combines three distinct mechanisms (Selective participation, Intra-group transmission adjustment, and Menu adaptation) to provide a general solution for efficient fair scalable privacy-preserving multicast congestion control with heterogeneous receivers. Whereas the individual mechanisms have appeared in earlier multicast protocols, our main contribution lies in the cohesive integration of the techniques. SIM achieves such integration by operating the three mechanisms at different timescales and distributing the responsibility for control to different entities in the network. Besides, to instantiate and integrate the three control mechanisms, SIM employs several novel techniques of independent interest. Our extensive evaluation confirms the salient properties of SIM in diverse settings where receiving capabilities are highly heterogeneous, bottleneck capacities fluctuate, bottlenecks migrate, and session membership is dynamic.
A Preliminary Look at the Privacy of SSH Tunnels	Secure Shell (SSH) tunnels are commonly used to provide two types of privacy protection to clear-text application protocols. First and foremost, they aim at protecting the privacy of the data being exchanged between two peers, such as passwords, details of monetary transactions and so on. Second, they are supposed to protect the privacy of the behavior of end-users, by preventing an unauthorized observer from detecting which application protocol is being transported by an SSH tunnel. In this paper we introduce a GMM-based (Gaussian Mixture Model) technique that, under a set of reasonable assumptions, can be used to identify which application is being tunneled inside an SSH session by simply observing the stream of encrypted packets. This technique can therefore break the presumption of privacy in its second incarnation as described above. Although still preliminary, experimental results show that the technique can be quite effective, and that the standard bodies might need to take this approach under consideration when designing new obfuscation techniques for SSH.
Privacy-Preserving Querying in Sensor Networks	Wireless sensor networks (WSNs) provide sensing and monitoring services by means of many tiny autonomous devices equipped with wireless radio transceivers. With large-scale WSNs being deployed on a long-term basis, not only security but also privacy issues must be taken into account. Furthermore, when network operators offer on-demand access to sensor measurements to their clients, query mechanisms should ideally leak neither client interests nor query patterns. In this paper, we present a privacy-preserving WSN query mechanism that uses standard cryptographic techniques. Besides preventing unauthorized entities from accessing sensor readings, it minimizes leakage of (potentially sensitive) information about users' query targets and patterns.
Mixing Ring-Based Source-Location Privacy in Wireless Sensor Networks	Wireless sensor networks consist of low-cost and low- power radio devices and are deployed in open and unprotected areas. Privacy is becoming one of the major issues that jeopardize the successful deployment of wireless sensor networks. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address the source-location privacy. For wireless sensor networks, computationally intensive cryptographic algorithms (such as public-key cryptosystems) and large scale broadcasting-based protocols are not suitable. In this paper, we propose a scheme to provide source-location privacy through a three-phase routing: routing to a randomly selected intermediate node, routing in a network mix ring, and message forwarding to the SINK node. While being able to provide source-location privacy for WSN, our simulation results also demonstrate that the proposed scheme is very efficient and can be used for practical applications.
Lightweight privacy-preserving routing and incentive protocol for hybrid ad hoc wireless network	We propose a privacy-preserving routing and incentive protocol, called PRIPO, for hybrid ad hoc wireless network. PRIPO uses micropayment to stimulate node cooperation without submitting payment receipts. The lightweight hashing and symmetric-key-cryptography operations are implemented to preserve the users' privacy. The nodes' pseudonyms are efficiently computed using hashing operations. Only a trusted party can link these pseudonyms to the real identities for charging and rewarding operations. Moreover, PRIPO protects the location privacy of the anonymous source and destination nodes. Extensive analysis and simulations demonstrate that PRIPO can secure the payment and preserve the users' privacy with acceptable overhead.
K-anonymity privacy protection using ontology	Blinded data mining is a branch of data mining technique which is focused on protecting user privacy. To mine sensitive data such as medical information, it is desirable to protect privacy and there is not worry about revealing personalized data. In this paper a new approach for blinded data mining is suggested. It is based on ontology and k-anonymity generalization method. Our method generalizes a private table by considering table fields' ontology, so that each tuple will become k-anonymous and less specific to not reveal sensitive information. This method is implemented using prote├é┬┐ge├é┬┐ and java for evaluation.
Privacy protecting digital payment system using ID-based blind signatures with anonymity revocation trustees	In this paper, a new digital payment system based on an ID-based blind signature scheme is presented. Blind signatures represent one cryptographic primitive tailored for applications where anonymity of the participants is an important requirement for instance in electronic commerce, in particular for payment systems. Since anonymity could be in conflict with law enforcement, for instance in cases of black mailing or money laundering, it has been proposed in literature to design systems in which a trustee or a set of trustees can selectively revoke the anonymity of the participants involved in a suspicious transaction. The trustee in the proposed payment system is only invoked in case of disputes and does not get involved in neither opening accounts nor issuing digital coins.
Privacy-preserving identity federation middleware for web services (PIFM-WS)	The emergence of XML-based web services as a new software development paradigm increases the expectations of getting better software that address the various collaboration demands over Internet between organizations, or what's termed virtual Organization (VO). The development of appropriate identity management systems between these heterogeneous security domains will be the key enabler for such collaboration. One major drawback resulted from VO is the real concerns and threats to human privacy. In this paper, we introduce a middleware (PIFM-WS) design to provide anonymous yet authenticated and accountable interaction between users and services in identity federation systems. The pivotal issue is the user privacy protection in cross-domains computing. A prototype is developed using state-of-the-art WS-* stack tools (.Net). The prototype implements the main core functionalities of access control where the privacy-protection measures get implemented. An analysis of the middleware features and performance evaluation results using the software prototype are presented. Slight overhead is exhibited and could be ignored in the prototype compared to features gained.
Context protecting privacy preservation in ubiquitous computing	In ubiquitous computing domain context awareness is an important issue. So, in ubiquitous computing, mere protection of message confidentiality is not sufficient for most of the applications where context-awareness can lead to near deterministic ideas. An adversary might deduce sensitive information by observing the contextual data, which when correlated with prior information about the people and the physical locations that are being monitored by a set of sensors can reveal most of the sensitive information. So, it is obvious that for security and privacy preservation in ubiquitous computing context protection is of equal importance. In this paper, we propose a scheme which provides two layer privacy protection of user's or application's context data. Our proposed context protecting privacy preservation scheme focuses on protecting spatial and temporal contextual information. We consider the communication part of ubiquitous computing consists of tiny sensor nodes forming Wireless Sensor Networks (WSNs). Through simulation we show the efficacy of our scheme. We also demonstrate the capability of our scheme to overcome the constraints of WSNs.
Location Privacy: User-Centric Threat Analysis	Information that describes the geographic locations of a person over time is a fairly new class of potentially privacy-harming data. In pace with certain technological advances of the recent years, more and more location data is generated and processed by various systems. Its usage for different location-based services (including the integration into social network services) encounters a steep and still ongoing rise in popularity. Besides communication infrastructure based localization methods that map IP-addresses, GSM-cell identifiers or wireless router MAC-addresses to geographic locations, the main contribution to this development comes from the proliferation of GPS-enabled mobile user devices. The critical point is that plain location data has the potential to both identify a single user and disclose sensitive information about that user's activity at the same time. This makes the robust anonymization of position information a non-trivial task and has created a lively branch in privacy research over the last years.
Privacy issues in social networking platforms: comparative study of facebook developers platform and opensocial	Most of the privacy research in online social networks has focused on protecting profile information of users from other users of online social networks. Another equally important research area is protection of users profile information from social applications. With the introduction of the Google's OpenSocial and Facebook's Developer Platform millions of third party developers are building thousands of social applications for existing massive user base. This fact poses serious privacy risk because current social networking platforms don't provide any mechanism to control disclosure of user's personal information to social applications and their developers. In this paper, we investigate two very popular social networking platform s, i.e. Facebook Developers Platform and OpenSocial. We demonstrate inherit flaws in these social networking platforms. We also point out limitations in existing solutions to the problem suggested by researcher community in the area. We recognise the need for extension of current APIs available for these social networking platforms so that extended version of APIs provide fine grain access control to the user of online social networks.
A distortion based technique for preserving privacy in OLAP data cube	This paper is about privacy preservation of the data in OLAP data cube. Data cube is a multidimensional view of a database, which helps in analysis of data from different perspectives. Preserving privacy of individual's data while providing all data available for the analysis is one of the main challenges for OLAP systems. Because legitimate queries on aggregated values lead to the inference of individual's data or sensitive data. We propose a data perturbation technique called uniformly adjusted distortion, which initially distorts one cell and then uniformly distributes this distortion in the whole data cube. This uniform distribution not only preserves the aggregates but also provides maximum accuracy with range sum queries and high availability.
A Guideline to Enforce Data Protection and Privacy Digital Laws in Malaysia	In the Malaysian cyber law, no law has been enacted to protect the personal data of the people when a theft of personal data occurs. This paper will suggest a guideline for applying and enforcing the data protection and privacy digital laws in Malaysia. By enforcing the suggested guideline we achieve a means to process data strictly by commercial sectors for commercial activities in sectors of tourism, finance, insurance, telecommunications, and such other commercial transaction sectors.
Preserving location privacy for location-based services with continuous queries on road network	Recently, several techniques have been proposed to protect the user location privacy for location-based services in road network environments. A typical approach for user location privacy protection is to blur a user location into a cloaked set of road segments S such that S satisfies the user specified privacy requirements. However, these location cloaking algorithms work with snapshot locations only and do not consider the effect of continuous location updates. Applying these algorithms directly to continuous queries would lead to privacy leakage if attackers have knowledge about maximum user velocity, namely velocity-based Attack. In this paper, we present the privacy safety condition to defend against velocity-based attack, and propose an anonymity algorithm based on greedy strategy to preserve user privacy. The experiment results based on dataset of real network show the algorithm is effective and feasible.
A Privacy-Preserving Access Control Protocol for Database as a Service	Database as a Service (DaaS) is a common service mode in Cloud Computing. Based on Feldman (t,n) VSS protocol and ElGamal homomorphism property, we proposed a privacy-preserving access control protocol for DaaS. Using Secret Sharing, we can protect the security of data owner's dataset, based on ElGamal homomorphism property, the data requester's query combining with the proxy servers' access control strategy, the data requesters can obtain the query results when they have enough permission. Theoretical analysis shows that without the Trust Third Party, the protocol can hide the proxy servers' access control information, while protecting both the data owner's and the data requesters' privacy.
A Data Privacy Service for Structured P2P Systems	Online peer-to-peer (P2P) communities such as professional ones (e.g., medical or research) are becoming popular due to increasing needs on data sharing. P2P environments offer valuable characteristics but limited guarantees when sharing sensitive or confidential data. They can be considered as hostile because data can be accessed by everyone (by potentially untrustworthy peers) and used for everything (e.g., for marketing or for activities against the owner's preferences or ethics). In this paper we propose PriServ, a privacy service located on top of distributed hash table (DHT) based P2P systems which prevents data privacy violations. Based on data owner privacy preferences, PriServ uses Hippocratic database principles, takes into account which operations will be realized on shared data (e.g., read, write, disclosure) and uses reputation techniques to increase trust on peers. Several simulation results encourage our ideas and a prototype of PriServ is under development.
Privacy preserving research for re-publication multiple sensitive attributes in data	Previous works about privacy preserving data publication have most focused on static dataset, which have no update and need ΓÇ£one-timeΓÇ¥ releases. Only a little of literature has considered the serial data publication on dynamic dataset, but none of them consider perfectly. They can not against various kind of background, or the utility for serial data publishing is low. Based on theoretical analysis, we develop a new generalization principle that effectively limits the risk of Multiple Sensitive Attributes privacy disclosure in re-publication. The results show that our algorithm has higher degree of privacy protection and lower hiding rate.
A privacy-preserving access control in outsourced storage services	In Storage-as-a-Services application,data owner delegates access control enforcement to external storage service privider while storing his data at it so as to free him from much involvement in users' query process. But the delegation of access control enforcement may cause privacy problem since the storage service privider may learn ΓÇ£who is granted access to the dataΓÇ¥ from access control policies and the indentities of the users who request the data. A privacy-preserving access control mechanism is proposed to solve this problem and its security is analyzed. The security analysis shows that the proposed mechanism guarantees secure access to outsourced data while preserving privacy of access control policies and users' IDs.
Privacy preservation in transaction databases based on anatomy technique	This paper considers the problem of privacy preserving transaction data publishing. Transaction data are usually useful for data mining. While it is high-dimensional data, traditional anonymization techniques such as generalization and suppression are not suitable. In this paper, we present a novel technique based on anatomy technique and propose a simple linear-time anonymous algorithm that meets the l-diversity requirement. The simulation experiments on real datasets and the results of association rules mining on the anonymous transaction data showed that our algorithm can safely and efficiently preserve the privacy in transaction data publication, while ensuring high utility of the released data.
Data Security and Privacy Protection Issues in Cloud Computing	It is well-known that cloud computing has many potential advantages and many enterprise applications and data are migrating to public or hybrid cloud. But regarding some business-critical applications, the organizations, especially large enterprises, still wouldn't move them to cloud. The market size the cloud computing shared is still far behind the one expected. From the consumers' perspective, cloud computing security concerns, especially data security and privacy protection issues, remain the primary inhibitor for adoption of cloud computing services. This paper provides a concise but all-round analysis on data security and privacy protection issues associated with cloud computing across all stages of data life cycle. Then this paper discusses some current solutions. Finally, this paper describes future research work about data security and privacy protection issues in cloud.
Location Privacy Protect Model Based on Positioning Middleware among the Internet of Things	Internet of Things is not only a platform for communication between people, but also it provides the real-time information exchange between things and things, people and things, things and people. With the popularity of the internet of things, the application services are increasing. However, those services are usually based on the user's location information, which contains user's privacy information directly or indirectly. This paper discussed on how to protect user's location privacy while providing personalized services. Proposed a strategy of pseudonym policy and user's location information acquisition, and built a model for protecting user policy of pervasive computing based on that policy.
A Privacy-Preserving Book Recommendation Model Based on Multi-agent	Recommendation systems are widely used to cope with the problem of information overload in digital libraries, consequently, many recommendation methods have been successfully applied in the present book recommendation systems, such as collaborative filtering, content-based, association rule mining-based and so on. But they are always lack of user's privacy concerns. Aiming at this disadvantage, in this work, a privacy-preserving book recommendation system (PPBRS) is introduced. This paper discusses the system structure of PPBRS at first. In addition, it discusses the functions of every agents and the operating process in the system. This recommendation system allows multiple recommendation methods to cooperate with one another to present their best recommendations to the user, can meet the needs of multiple recommendation, and also can protect users' privacy while providing high-quality recommendations efficiently. Finally, we give a simple review of the work accomplished and conclude further research directions of the system by analyzing the existing work.
Privacy Preserving k-Anonymity for Re-publication of Incremental Datasets	Most of the previous works on k-anonymization focused on one-time release of data. However, data is often released continuously to serve various information purposes in reality. The purpose of this study is to develop an effective solution for the re-publication of incremental datasets. First, we analyze several possible generalizations in the anonymization for incremental updates and propose an important monotonic generalization principle that effectively prevents privacy breach in re-publication. Based on the monotonic generalization principle, we then propose a partitioning based algorithm for re-publication, which can securely anonymize a continuously growing dataset in an efficient manner while assuring high data quality. The effectiveness of our approach is confirmed by extensive experiments with real data.
Privacy Preserving Association Rules by Using Greedy Approach	Data mining techniques have been developed in many applications. However, they also cause a threat to privacy. In this paper, we proposed a greedy method for hiding the number of sensitive rules. The experimental results showed that the undesired side effects can be avoided in the rule hiding process by use of our approach. The results also revealed that in most cases, all the sensitive rules are hidden without generating spurious rules. First, the good scalability of our approach in terms of database sizes is achieved by using an efficient data structure FCET to store solely maximal frequent itemsets rather than the entire frequent itemsets. Furthermore, we proposed a new framework for enforcing the privacy in mining association rules, that combine the techniques for efficiently hiding sensitive rules and the transaction retrieval engine based on the FCET index tree. In particular, four strategies are implemented in the sanitized procedure, for hiding a group of association rules characterized as sensitive or artificial rules.
The privacy protection study against incremental updates	Static privacy protection technologies available are not well protected already published data, and dynamic protection technology is becoming a research hotspot. In this paper we propose an effective method of privacy protection based on dynamic protection technology, analyzing how inferences from multiple releases may temper the category of privacy and resolving the problems of privace loss of inference tables be made of multiple releases tables. Using space-filling curve to multi-dimensional quasi-identifiers into a one-dimensional quasi-identifiers, solving the situation of a high degree of information loss. Experiments not only show that the running time of this method is linear time but also show that the method can guarantee k-anonymity and l-diversity of many published tables.
Privacy preserving stereoscopic vision with One-Bit transform	This paper proposes a stereoscopic vision algorithm to calculate the disparity map using One-Bit transform (1BT). There are two advantages of the proposed algorithm over the conventional stereoscopic vision algorithms. First, the use of the 1BT reduces the computational complexity of the disparity map calculation. Second, for implementation in private spaces such as homes and communities, the use of the 1BT preserves the privacy of the occupants. Simulations results are presented to show that the use of the 1BT does not significantly affect the performance of the stereo matching algorithm.
Identity-based broadcast encryption with recipient privacy	In many broadcast systems, it is important to protect both distributed content and the identities of authorized recipients. But many systems fail to protect the privacy of their users. In this paper, we propose the first identity-based broadcast encryption scheme with recipient privacy, enables the efficient encryption of messages to multiple recipients without revealing the identities of authorized recipients. In our scheme, the size of private keys is constant, the public key and ciphertexts are of size linear in the maximal size m of the set of authorized recipients, which is smaller than the number of possible users in the system. Finally we prove the security of our scheme by using the GDDHE framework.
Trust management in privacy ΓÇö Preserving information system	In many information management applications, sensitive information must be stored as a record and be retrieved when necessary. When the record is stored in a distributed way in multiple databases and shared by multiple users with different trust levels and accessing privileges, the trust management model is called M-to-M model. In this model, on one hand the record is stored in a distributed way; one the other hand every user obtains a different version of the record in their retrieving operations according to their different trust levels and access privileges. A scheme is proposed in this paper to specify M-to-M trust management. The new scheme not only realizes privacy-preserving information storage and sharing in a multi-level-trust environment, but also achieves robustness through information redundancy. The new technique is quite simple and does not need any cryptographic operation like encryption, digital signature or hash function, so its security is unconditional and does not depend on any computational assumption.
Research on privacy preserving keyword search in cloud storage	The development of cloud storage services makes companies who outsourced their data to cloud storage server can't control their data by themselves as before. Then comes the security issues, especially the privacy preserving has become an more important security problem. The users always search their documents through keyword in plaintext, which may leak privacy of users in cloud storage environment. In this paper we propose an efficient privacy preserving keyword search scheme in cloud storage, the scheme satisfies the multi-user requirement with low computational overhead and flexible key management., and it is proved to be secure and feasible.
A semantic framework for privacy-aware access control	The issue of privacy is constantly brought to the spotlight since an ever increasing number of services collects and processes personal information from users. In fact, recent advances in mobile communications, location and sensing technologies and data processing are boosting the deployment of context-aware personalized services and the creation of smart environments but, at the same time, they pose a serious risk on individualspsila privacy rights. Being situated in the realms of legal and social studies, the notion of privacy is mainly left, concerning its protection, to legislation and service providerspsila self-regulation by means of privacy policies. However, all laws and codes of conduct are useless without enforcement. Based on this concept, this paper presents a framework conceived on the basis of privacy legislation. It uses a semantic model for the specification of privacy-aware data access rules and a middleware system which mediates between the service providers and the data sources and caters for the enforcement of the regulatory provisions.
Towards a Privacy Diagnosis Centre: Measuring k-Anonymity	Most of the recent efforts addressing the issue of privacy have focused on devising algorithms for the anonymization and diversification of data. Our objective is upstream of these works: we are concerned with privacy diagnosis. In this paper, we start by investigating the issue of k-anonymity. We propose algorithms to explore various questions about k-anonymity of data. Such questions are, for instance, "is my data sufficiently anonymous?", "which information, if available from an outside source, threatens the anonymity of my data?" In this paper we focus on anonymity and, in particular, k-anonymity. The algorithms that we propose leverage two properties of k-anonymity that we express in the form of two lemmas. The first lemma is a monotonicity property that enables us to adapt the a-priori algorithm for k-anonymity. The second lemma is a determinism property that enables us to devise an efficient algorithm for delta-suppression. We illustrate and empirically analyze the performance of the proposed algorithms.
RWSIS: (R)FID-Enabled (W)arranty (S)ervice (I)nformation (S)ystem on Resolving Security and Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404228.png" border="0">
A Privacy-Secure Content Trading System for Small Content Providers Using Semi-Blind Digital Watermarking	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404205.png" border="0">
The Surveillance System Based on RFID System for Privacy Protection	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404176.png" border="0">
Approximation Algorithms for Optimizing Privacy and Utility	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404306.png" border="0">
On the Observability of RFID Data Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404178.png" border="0">
Energy Efficient Privacy Preserved Data Gathering in Wireless Sensor Networks Having Multiple Sinks	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05404315.png" border="0">
An empirical study of user's attitudes and behavior of privacy concerns	As the Internet grows in importance, concerns about online privacy have arisen. College students routinely provide personal information on profiles that can be viewed by huge numbers of unknown people and potentially used in harmful ways. SNS like Renren allow users to control the privacy level of their profile, thus limiting access to this information. The purpose of this paper is to investigate the current situations of online privacy among college students. In this article, we take the preference for privacy itself as our unit of analysis, and analyze the factors that are predictive of a student having a private versus public profile and the protection for it. Finally, we argue that privacy behavior is an upshot of both social influences and personal incentives. Through an in-depth interview, the author also find the perceived benefits from Renren outweigh the potential risks of privacy.
Implement Privacy Protection Act in Human Payroll System	Passed by the legislature on Apr. 27, 2010, Taiwan's new Privacy Protection Act will take effect in 2012. In order to avoid penalties and loss of reputation for violation of the act, all enterprises must pay additional attention to information security. Among the current corporate information systems, human payroll systems contain most personal information of a company. Therefore, this paper investigates domestic laws governing information security and internal information security controls commonly used by enterprises. With assistance of experts and scholars, this paper explores the necessary adjustments of human payroll systems for compliance with the Privacy Protection Act. The human payroll systems of a case company is used as an example to validate whether these adjustments can make it compliant with the Privacy Protection Act and reduce the relative impacts on the company. Holding a positive view of the benefits of the Privacy Protection Act, this paper attempts to find a cost-effective response plan, which can ultimately minimize the crime rate of information leakage.
Blocking Based Approach for Classification Rule Hiding to Preserve the Privacy in Database	Now-a-days it is common to share data between two organizations in many application areas. When data are to be shared between parties, there could be some sensitive patterns which should not be disclosed to the other parties. We address such the problem of sensitive classification rule hiding. We propose a blocking based approach for sensitive classification rule hiding. First we find the supporting transactions of sensitive rules. Then we replace known values with unknown values ("?") in those transactions to hide a given sensitive classification rule. Finally the sanitized dataset is generated from which sensitive classification rules are no longer mined. We also discuss experimental results of our algorithm.
Online Social Network with flexible and dynamic privacy policies	Online Social Networks (OSN) have become widely popular in recent years. OSN enable people to connect with their friends based on sharing information about their personal life. There are some serious privacy problems that need to be resolved in existing OSN: Firstly, there has to be a method to protect user-generated data from OSN providers. Secondly, a fully flexible and dynamic access control mechanism should exist to protect private data against attackers and unauthorized friends. Thirdly, the aforementioned access control system should be efficient in managing the privacy policies of OSN users. To meet these requirements, this paper presents a privacy protection solution for OSN with a customizable privacy control. In the proposed approach, the users keep control of their data without any help from the OSN provider or a trusted third party. The introduced scheme employs identity based broadcast encryption (IBBE) system to communicate the private data to intended OSN users. The privacy and efficiency analysis show the proposed architecture is a great improvement over existing approaches in preserving the privacy of OSN users.
Privacy Preserving Decision Tree Learning over Vertically Partitioned Data	Data mining over multiple data sources has become an important practical problem with applications in different areas. Although the data sources are willing to mine the union of their data, they donpsilat want to reveal any sensitive and private information to other sources due to competition or legal concerns. In this paper, we consider a scenario where data are vertically partitioned over more than two parties. We focus on the classification problem, and present a novel privacy preserving decision tree learning method. Theoretical analysis and experiment results show that this method can provide good capability of privacy preserving, accuracy and efficiency.
A Novel Strategy Enhancing Location Cloaker for Privacy in Location Based Services	Prosperity of mobile devices makes location-based services more and more popular in recent years. However, with existing service infrastructure, users have to reveal their location information in order to access location based services. It is possible that adversaries can collect the location information, which in turn invades userpsilas privacy. In this paper, we proposed an novel architecture to enhance location cloaker, which provides stronger privacy protection by adopting a buffer and periodical (B&P) query processing strategy. This B&P strategy enables the location cloaker to blur the userpsilas locations in terms of both spatial and temporal attributes. Through intensive simulation, we verified the correctness and effectiveness of this new strategy.
Consumer online-privacy and anonymity protection using infomediary schemes	The rapid evolution of the Internet may largely depend on gaining and maintaining the trust of users. This possibility may especially rule enterprises whose financial viability depends on electronic commerce. Customers will neither have the time, the ability or the endurance to work out the best deals with vendors, nor will vendors have time to bargain with every customer. In order for customers to strike the best bargain with vendors, they need a privacy supporter, an information intermediary or "infomediary". Infomediaries will become the custodians, agents and brokers of customer personal information exchanged via the Internet, while at the same time protecting their privacy. There is a scale between security and privacy that currently leans towards security; security adopts strong user authentication mechanisms. In order to control access to personal data, while privacy requires loose authentication in order to provide user anonymity. In this paper, we introduce a new infomediary-based privacy-enhancing business model, which is capable of providing anonymity, privacy and security to customers and vendors of e-commerce. Using this model, customers can buy goods or services without revealing their real identity or preferences to vendors, and vendors can sell or advertise goods or services without violating the privacy of their customers
Supporting quality of privacy (QoP) in pervasive computing	Privacy might be the greatest barrier to the long-term success of pervasive or ubiquitous computing (ubicomp). The invisibility of embedded computing devices has made it easier to collect and use information about individuals without their knowledge. Sensitive and private information might be stored for long periods of time and appear anywhere at anytime. Thus, a cost, in the form of privacy, might need to be paid to benefit from ubicomp. In this paper, we introduce the concept of quality of privacy (QoP) which allows balancing the trade-off between the amount of privacy a user is willing to concede and the value of the services that can be provided by a ubicomp application, in a similar way as that of quality of service (QoS). We propose an agent-based architecture that adapts the behavior of the ubicomp application to the users' context, in order to satisfy the level of QoP, that both, the application and the user have agreed upon. To illustrate this architecture, we extend a handheld-based mobile hospital information system in order to preserve privacy in ubicomp hospitals environment.
EDPPS: An Energy-efficient Data Privacy Protection Scheme for wireless sensor networks	In wireless sensor networks (WSNs) sensors may be deployed in unpredictable environment, a limited energy of the sensor nodes has led to the development of the Energy-efficient Data Privacy Protection Scheme (EDPPS). It is a process of ensuring privacy and security to the sensed data as well as maximizing the network lifetime. Many schemes have been proposed using symmetric key cryptography algorithm for securing data. However, a current limitation of protecting data privacy in WSNs is that the symmetric key cryptography algorithms are vulnerable to node compromise attacks. To overcome this limitation, we investigate the facts of ensuring secure sensed data in a balanced energy network backbone based on distance from the source node to base station. Specifically, a checking data integrity mechanism has been proposed in this paper. Our analysis and simulation results show that EDPPS has a better performance through four abstract parameters: anonymity of the sensor nodes, confidentiality, authenticity and integrity of the actual sensed data. It also provides a good level for energy consumption as well as maximizing the network lifetime.
Search engines: The invader to our privacy ΓÇö A survey	The popularity of search engines has grown exponentially, as Internet users are relying more on search engines in order to filter relevant piece of search results out of Information Sea within a single-click time. However, due to the publicly accessible nature of web space these search engines threatens our privacy by revealing our personal data to others that may otherwise be hidden. This paper identifies that how serious the threat of search engine hacking is and how its advanced search queries facilitates potential attackers that further causes application and identity fraud to collect financial and personal data. It further explains the ways to counteract it and discusses the challenges and problem of this crime that may have direct and indirect impacts on the internet security.
Privacy preserved entrust mechanism in cloud computing environment	Cloud computing technology enables service to add special characteristics such as remote execution, service mobility and virtual workspace in a handheld device. However, it has a limitation on application areas for the reason that mobile applications distinctly need a help of the host computer. To eliminate those threats, hash chain based approaches are proposed [1][2]. However, it also has some restriction that a mobile device sends request messages to each server when the device needs a multi-entity co-operative work. Therefore, this paper introduces a concept of secure entrustment, which provides most near and trusted servers whenever your mobile devices want to use a trusted computing.
Personal Information Classification for Privacy Negotiation	Privacy has been recognized as a critical topic in the Internet for a long time, and technical developments in this area are ongoing. With the proliferation of various network sites and the unification of them, it has become more evident that the problem of privacy is not bounded by the perimeters of a specific system. Nowadays, many network services rapidly drive toward unification. In this paper, we mainly consider unified personal information. We propose an evaluation method of privacy sensitivity-level. The information sensitivity level (S<sub>L</sub>) is evaluated with four main factors; the degree of conjunction (D<sub>C</sub>), the principle of identity (J<sub>A</sub>), the principle of privacy (P<sub>A</sub>), and the value of analogism (A<sub>A</sub>), S<sub>L</sub>:= ├é┬┐(D<sub>C</sub>, J<sub>A</sub>, P<sub>A</sub> , A<sub>A</sub>). If we classify the information based on the information sensitivity level (S<sub>L</sub>), it can show the objective validity. Finally, we outline new research directions for currently existing methods for privacy-preserving data analysis in the combined social network environment.
A Data Privacy-Oriented Multi-parities Location Collect Scheme in Location Based Services	Two important challenges in the wide deployment of location-based services (LBSs) are privacy and confidentiality. Existing privacy-enhancing techniques rely on encryption to safeguard communication channels, and on pseudonyms to protect user identities, or rely on a well-established k-anonymity area without characters to compute exact answers for range and nearest neighbor search without revealing the query source. From the view of data privacy obtained for distributed k-anonymity in LBSs, we propose a novel multi-parties' location collect scheme which is data privacy preserving. The formal proof shows the correctness of the new scheme.
Use of privacy-enhanced mail for software distribution	There is currently only limited assurance that software electronically downloaded from a central source is a faithful copy of the original software. Current Internet standards for privacy enhancement of electronic mail can also be employed to protect electronic distribution of software. The standards offer disclosure protection, source (sender) authentication, and message integrity services. However, electronic mail is a relatively inefficient means for distributing software. Proposed modifications to the mail privacy-enhancement standards will permit files to be afforded integrity and source authentication protection in a manner compatible with current file transfer conventions
Achieving user privacy in mobile networks	Third generation mobile networks aim to offer `any service, anywhere, at any time'. Users require privacy within these systems in order to feel confident of their use. Privacy requirements (in mobile networks) are: content, location and identification privacy, and authentication. Differing from previous approaches to privacy, the network itself is considered to be an untrusted party. The paper proposes a scheme that allows the user to register with the network and remain anonymous (both location and identification). Digital mixes are used to create anonymity and authentication is achieved through a token based scheme. Finally the aspect of information leaking to authorised third parties is discussed and billing requirements are detailed which involve the use of `coin' like tokens traded for services
Privacy-preserving cooperative statistical analysis	The growth of the Internet opens up tremendous opportunities for cooperative computation, where the answer depends on the private inputs of separate entities. Sometimes these computations may occur between mutually untrusting entities. The problem is trivial if the context allows the conduct of these computations by a trusted entity that would know the inputs from all the participants; however if the context disallows this then the techniques of secure multiparty computation become very relevant and can provide useful solutions. Statistical analysis is a widely used computation in real life, but the known methods usually require one to know the whole data set; little work has been conducted to investigate how statistical analysis could be performed in a cooperative environment, where the participants want to conduct statistical analysis on the joint data set, but each participant is concerned about the confidentiality of its own data. We have developed protocols for conducting the statistical analysis in such a cooperative environment based on a data perturbation technique and cryptography primitives.
Protecting Privacy in Key-Value Search Systems	This paper investigates the general problem of efficiently performing key-value search at untrusted servers without loss of user privacy. Given key-value pairs from multiple owners that are stored across untrusted servers, how can a client efficiently search these pairs such that no server, on its own, can reconstruct the key-value pairs? We propose a system, called Peekaboo, that is applicable and practical to any type of key-value search while protecting both data owner privacy and client privacy. The main idea is to separate the key-value pairs across different servers. Supported by access control and user authentication, Peekaboo allows search to be performed by only authorized clients without reducing the level of user privacy.
Privacy and Security in Public Health: Maintaining the Delicate Balance between Personal Privacy and Population Safety	Amidst threats of pandemic avian influenza and bioterrorist attack, public health surveillance and preparedness have never been more important. Early detection of biological events, electronic reporting of laboratory test results, efficient exchange of case reports across jurisdictions, and timely alerting of health threats are critical components of effective health protection. Essential to public health surveillance and preparedness is the timely availability of information relating to individuals├é┬┐ healthcare behaviors and clinical conditions -- posing a threat to personal privacy. Public health is challenged to maintain an optimal balance between protecting the nation├é┬┐s health and respecting the personal privacy of its citizens.
An Internet Voting System Supporting User Privacy	This work introduces the Adder system , an Internet-based, free and open source electronic voting system which employs strong cryptography. Our system is a fully functional e-voting platform and enjoys a number of security properties, such as robustness, trust distribution, ballot privacy, auditability and verifiability. It can readily implement and carry out various voting procedures in parallel and can be used for small scale boardroom/department-wide voting as well as large-scale elections. In addition, Adder employs a flexible voting scheme which allows the system to carry out procedures such as surveys or other data collection activities. Adder offers a unique opportunity to study cryptographic voting protocols from a systems perspective and to explore the security and usability of electronic voting systems
Personal Privacy without Computational Obscurity: Rethinking Privacy Protection Strategies for Open Information Networks	Summary form only given. Throughout the history of computer and network security research, privacy has been treated as synonymous with confidentiality, with the presumed high water mark of privacy being mathematically provable anonymity. Despite the fact that technical innovation in cryptography and network security has enabled all manner of confidentiality control over the exposure of identity in information systems, the vast majority of Internet user remain deeply worried about their privacy rights and correctly believe that they are far more exposed today than they might have been a generation earlier. Have we just failed to deploy the proper security technology to protect privacy, are our laws inadequate to meet present day privacy threats, or have business practices and social conventions simply rendered privacy dead? While there is some truth to each possibility, the central failure to achieve robust privacy in the information age can be traced to an a long-standing misassocation of privacy with confidentiality and access control. In order to revitalize privacy protection, we should shift our legal attention away from rules limiting disclosure of personal information toward policies governing how personal information can be used. And technical efforts currently focused on access control and anonymization should be redirected toward technical measures that make information usage more transparent and accountable to clearly stated policies that address proper and improper users of personal information.
Privacy-Aware Biometrics: Design and Implementation of a Multimodal Verification System	A serious concern in the design and use of biometric authentication systems is the privacy protection of the information derived from human biometric traits, especially since such traits cannot be replaced. Combining cryptography and biometrics, several recent works proposed to build the protection in the biometric templates themselves. While these solutions can increase the confidence in biometric systems when biometric information is stored for verification, they have been shown difficult to apply to real biometrics. In this work we present a biometric authentication technique that exploits multiple biometric traits. It is privacy-aware as it ensures privacy protection and allows the extraction of secure identifiers by means of cryptographic primitives. We also discuss the implementation of our approach by considering, as a significant example, the combination of iris and fingerprint biometrics and present experimental results obtained from real data. The implementation shows the feasibility of the scheme in practical applications.
Privacy through Noise: A Design Space for Private Identification	To protect privacy in large systems, users should be able to authenticate against a central server without disclosing their identity to others. Private identification protocols based on public key cryptography are computationally expensive and cannot be implemented on small devices like RFID tags. Symmetric key protocols, on the other hand, provide only modest levels of privacy, but can be efficiently executed on servers and cheaply implemented on devices. The privacy of symmetric-key privacy protocols derives from the fact that an attacker only ever knows a small fraction of the keys in a system while the legitimate reader knows all keys. We propose to amplify this gap in the ability to distinguish users by adding noise to user responses. We focus on scenarios where an attacker is not able to acquire multiple different reads known to be from the same device, and justify this threat model by proposing a simple modification to RFID tag designs. In such scenarios, we can use noise to blur the borders between groups of users that the attacker would otherwise be able to distinguish. We evaluate the effectiveness and cost of this randomization and find that the information leakage from the tree protocol can be decreased to two thousandths of its original value with 150 times the number of server-side cryptographic operations and minimal cost to the tag. Degrees of privacy up to those achieved by public key protocols can be reached while staying well below the cost of public key cryptography.
Privacy requirements implemented with a JavaCard	Privacy is extremely important in healthcare systems. Unfortunately, most of the solutions already deployed are developed empirically. After discussing some of such existing solutions, this paper describes an analytic and generic approach to protect personal data by anonymization. This approach is then applied to some representative scenarios. The architecture and its implementation with a JavaCard are finally presented. Our analysis, solution and implementation are generic enough to be adapted to various collaborative systems that process sensitive data such as e-commerce, e-government, social applications, etc
Privacy-preserving alert correlation: a concept hierarchy based approach	With the increasing security threats from infrastructure attacks such as worms and distributed denial of service attacks, it is clear that the cooperation among different organizations is necessary to defend against these attacks. However, organizations' privacy concerns for the incident and security alert data require that sensitive data be sanitized before they are shared with other organizations. Such sanitization process usually has negative impacts on intrusion analysis (such as alert correlation). To balance the privacy requirements and the need for intrusion analysis, we propose a privacy-preserving alert correlation approach based on concept hierarchies. Our approach consists of two phases. The first phase is entropy guided alert sanitization, where sensitive alert attributes are generalized to high-level concepts to introduce uncertainty into the dataset with partial semantics. To balance the privacy and the usability of alert data, we propose to guide the alert sanitization process with the entropy or differential entropy of sanitized attributes. The second phase is sanitized alert correlation. We focus on defining similarity functions between sanitized attributes and building attack scenarios from sanitized alerts. Our preliminary experimental results demonstrate the effectiveness of the proposed techniques
Formal Verification of Privacy for RFID Systems	RFID tags are being widely employed in a variety of applications, ranging from barcode replacement to electronic passports. Their extensive use, however, in combination with their wireless nature, introduces privacy concerns as a tag could leak information about the owner's behaviour. In this paper we define two privacy notions, unlinkability and forward privacy, using a formal model based on the applied pi calculus, and we show the relationship between them. Then we focus on a generic class of simple privacy protocols, giving sufficient and necessary conditions for unlinkability and forward privacy for this class. These conditions are based on the concept of frame independence that we develop in this paper. Finally, we apply our techniques to two identification protocols, formally proving their privacy guarantees.
Regret Minimizing Audits: A Learning-Theoretic Basis for Privacy Protection	Audit mechanisms are essential for privacy protection in permissive access control regimes, such as in hospitals where denying legitimate access requests can adversely affect patient care. Recognizing this need, we develop the first principled learning-theoretic foundation for audits. Our first contribution is a game-theoretic model that captures the interaction between the defender (e.g., hospital auditors) and the adversary (e.g., hospital employees). The model takes pragmatic considerations into account, in particular, the periodic nature of audits, a budget that constrains the number of actions that the defender can inspect, and a loss function that captures the economic impact of detected and missed violations on the organization. We assume that the adversary is worst-case as is standard in other areas of computer security. We also formulate a desirable property of the audit mechanism in this model based on the concept of regret in learning theory. Our second contribution is an efficient audit mechanism that provably minimizes regret for the defender. This mechanism learns from experience to guide the defender's auditing efforts. The regret bound is significantly better than prior results in the learning literature. The stronger bound is important from a practical standpoint because it implies that the recommendations from the mechanism will converge faster to the best fixed auditing strategy for the defender.
Verifying Privacy-Type Properties in a Modular Way	Formal methods have proved their usefulness for analysing the security of protocols. In this setting, privacy-type security properties (e.g. vote-privacy, anonymity, unlink ability) that play an important role in many modern applications are formalised using a notion of equivalence. In this paper, we study the notion of trace equivalence and we show how to establish such an equivalence relation in a modular way. It is well-known that composition works well when the processes do not share secrets. However, there is no result allowing us to compose processes that rely on some shared secrets such as long term keys. We show that composition works even when the processes share secrets provided that they satisfy some reasonable conditions. Our composition result allows us to prove various equivalence-based properties in a modular way, and works in a quite general setting. In particular, we consider arbitrary cryptographic primitives and processes that use non-trivial else branches. As an example, we consider the ICAO e-passport standard, and we show how the privacy guarantees of the whole application can be derived from the privacy guarantees of its sub-protocols.
A flow-sensitive analysis of privacy properties	In this paper we consider service oriented architectures where many components interact with one another using a wireless network. We are interested in questions like: ldr Can I be sure that I do not get unsolicited information from some service? - unless I give my permission? ldr Can I be sure that information I send to some service never is leaked to another service? - unless I give my permission? We shall develop a static program analysis for the pi- calculus and show how it can be used to give privacy guarantees like the ones requested above. The analysis records the explicit information flow of the system and keeps track of, not only the potential configurations of the system, but also the order in which they may be encountered.
Privacy and Utility in Business Processes	We propose an abstract model of business processes for the purpose of (i) evaluating privacy policy in light of the goals of the process and (ii) developing automated support for privacy policy compliance and audit. In our model, agents that send and receive tagged personal information are assigned organizational roles and responsibilities. We present approaches and algorithms for determining whether a business process design simultaneously achieves privacy and the goals of the organization (utility). The model also allows us to develop a notion of minimal exposure of personal information, for a given process. We investigate the problem of auditing with inexact information and develop methods to identify a set of potentially culpable individuals when privacy is breached. The audit methods draw on traditional causality concepts to reduce the effort needed to search audit logs for irresponsible actions.
Collaborative Planning With Privacy	Collaboration among organizations or individuals is common. While these participants are often unwilling to share all their information with each other, some information sharing is unavoidable when achieving a common goal. The need to share information and the desire to keep it private/ secret are two competing notions which affect the outcome of a collaboration. This paper proposes a formal model of collaboration which addresses privacy/secrecy concerns. We draw on the notion of a plan which originates in the AI literature. We consider transition systems in which actions have pre- and post-conditions of the same size. We show it is PSPACE-complete to decide whether a given such system protects the privacy/secrecy of its participants and whether it contains a plan leading from a given initial state to a desired goal state.
Privacy-preserving cooperative scientific computations	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00930152.png" border="0">
A privacy policy model for enterprises	Privacy is an increasing concern in the marketplace. Although enterprises promise sound privacy practices to their customers, there is no technical mechanism to enforce them internally In this paper we describe a privacy policy model that protects personal data from privacy violations by means of enforcing enterprise-wide privacy, policies. By extending Jajodia et al.'s flexible authorization framework (FAF) with grantors and obligations, we create a privacy control language that includes user consent, obligations, and distributed administration. Conditions impose restrictions on the use of the collected data, such as modeling guardian consent and options. Access decisions are extended with obligations, which list a set of activities that must be executed together with the access request. Grantors allow to define a separation of duty between the security officer and the privacy officer.
Privacy APIs: access control techniques to analyze and verify legal privacy policies	There is a growing interest in establishing rules to regulate the privacy of citizens in the treatment of sensitive personal data such as medical and financial records. Such rules must be respected by software used in these sectors. The regulatory statements are somewhat informal and must be interpreted carefully in the software interface to private data. This paper describes techniques to formalize regulatory privacy rules and how to exploit this formalization to analyze the rules automatically. Our formalism, which we call privacy APIs, is an extension of access control matrix operations to include (1) operations for notification and logging and (2) constructs that ease the mapping between legal and formal language. We validate the expressive power of privacy APIs by encoding the 2000 and 2003 HIPAA consent rules in our system. This formalization is then encoded into Promela and we validate the usefulness of the formalism by using the SPIN model checker to verify properties that distinguish the two versions of HIPAA
An Approach for Ensuring Robust Safeguard against Location Privacy Violation	The challenge of preserving user's location privacy is more important now than ever before with the proliferation of handheld devices and the pervasive use of location based services. To protect location privacy, we must ensure k-anonymity so that the user remains indistinguishable among k-1 other users. There is no better way but to use a location anonymizer (LA) to achieve k-anonymity. However, its knowledge of each user's current location makes it susceptible to be a single-point-of-failure. In this paper, we propose a formal location privacy framework, termed SafeGrid that can work with or without an LA. In SafeGrid, LA is designed in such a way that it is no longer a single point of failure. In addition, it is resistant to known attacks and most significantly, the cloaking algorithm it employs meets reciprocity condition. Simulation results exhibit its better performance in query processing and cloaking region calculation compared with existing solutions. As an added feature, in SafeGrid a user has the option of not using LA, yet achieving as much obfuscation (deliberate degradation of location data) as needed without ever sacrificing performance gain.
Privacy in the Cloud	
P3D - Privacy-Preserving Path Discovery in Decentralized Online Social Networks	One of the key service of social networks is path discovery, in that release of a resource or delivering of a service is usually constrained by the existence of a path with given characteristics in the social network graph. One fundamental issue is that path discovery should preserve relationship privacy. In this paper, we address this issue by proposing a Privacy-Preserving Path Discovery protocol, called P<sup>3</sup>D. Relevant features of P<sup>3</sup>D are that: (1) it computes only aggregate information on the discovered paths, whereas details on single relationships are not revealed to anyone, (2) it is designed for a decentralized social network. Moreover, P<sup>3</sup>D is designed such to reduce the drawbacks that offline nodes may create to path discovery. In the paper, besides giving the details of the protocol, we provide an extensive performance study. We also present the security analysis of P<sup>3</sup>D, showing its robustness against the main security threats.
Privacy-Preserving Data Publishing for Free Text Chinese Electronic Medical Records	The practice of using electronic medical records (EMR) to store healthcare data instead of traditional paper is becoming popular, as it's widely believed that the efficiency of medical institution could be improved and the cost could be reduced by using EMR. Nevertheless, EMR makes the sensitive healthcare data much easier to collect, process, store and publish. The change has increased the privacy risk of patients significantly. There are still many problems about patients' privacy protection in practical application, although many methods have been proposed to handle privacy risk when using EMR. Many hospitals are trying to make use of accumulated free text EMR for medical research and training. However, the hospitals may lose control with the EMR as the EMR may be transferred to different organizations in such application. And properly dealing with patients' privacy in EMR is an important requirement to avoid privacy leakage in such applications. In this paper, we study the privacy protection challenge those Hospitals are facing when they try to share EMR with other institutions. Then, we identify the major problems that make the traditional privacy preserving methods not suitable to process free text EMR, especially for free text Chinese EMR. Furthermore, we propose a new method to solve the problems and design a privacy-preserving data publishing system for electronic medical records based on it. Experiments with real-life data is showed to evaluate the new method.
A Solution for Privacy Protection in MapReduce	Recently, the development of storage and networking technology have made processing tremendous data become real. As a result, the demand of discovering knowledge from the bigdata by using tools such as statistical analysis and data mining become higher. Using MapReduce a software framework introduced by Google in 2004 to implement computations on clusters of commodity computers is an economical solution. However, malicious MapReduce framework or source codes can leak the sensitive data through computation process. Giving user the least privilege on MapReduce-based system can solve the problem. Therefore, in our research, we propose a MapReduce-based computational system limiting the access to system resource by using RBAC and TE. Moreover, noise were added to the output of the Reduce to ensure the computational result can not signal the presence of a sensitive data. Our prototype implementation demonstrates the efficiency of preserving privacy on several cases.
A Privacy-Preserving Cloud Computing System for Creating Participatory Noise Maps	Participatory sensing is a crowd-sourcing technique which relies both on active contribution of citizens and on their location and mobility patterns. As such, it is particularly vulnerable to privacy concerns, which may seriously hamper the large-scale adoption of participatory sensing applications. In this paper, we present a privacy-preserving system architecture for participatory sensing contexts which relies on cryptographic techniques and distributed computations in the cloud. Each individual is represented by a personal software agent, which is deployed on one of the popular commercial cloud computing services. The system enables individuals to aggregate and analyse sensor data by performing a collaborative distributed computation among multiple agents. No personal data is disclosed to anyone, including the cloud service providers. The distributed computation proceeds by having agents execute a cryptographic protocol based on a homomorphic encryption scheme in order to aggregate data. We show formally that our architecture is secure in the Honest-But-Curious model both for the users and the cloud providers. Our approach was implemented and validated on top of the NoiseTube system [1], [2], which enables participatory sensing of noise. In particular, we repeated several mapping experiments carried out with NoiseTube, and show that our system is able to produce identical outcomes in a privacy-preserving way. We experimented with real and simulated data, and present a live demo running on a heterogeneous set of commercial cloud providers. The results show that our approach goes beyond a proof-of-concept and can actually be deployed in a real-world setting. To the best of our knowledge this system is the first operational privacy-preserving approach for participatory sensing. While validated in terms of NoiseTube, our approach is useful in any setting where data aggregation can be performed with efficient homomorphic cryptosystems.
Privacy Preserving Distributed Learning Clustering of HealthCare Data Using Cryptography Protocols	Data mining is the process of knowledge discovery in databases (centralized or distributed); it consists of different tasks associated with them different algorithms. Nowadays the scenario of one centralized database that maintains all the data is difficult to achieve due to different reasons including physical, geographical restrictions and size of the data itself. One approach to solve this problem is distributed databases where different parities have horizontal or vertical partitions of the data. The data is normally maintained by more than one organization, each of which aims at keeping its information stored in the databases private, thus, privacy-preserving techniques and protocols are designed to perform data mining on distributed data when privacy is highly concerned. Cluster analysis is a frequently used data mining task which aims at decomposing or partitioning a usually multivariate data set into groups such that the data objects in one group are the most similar to each other. It has an important role in different fields such as bio-informatics, marketing, machine learning, climate and healthcare. In this paper we introduce a novel clustering algorithm that was designed with the goal of enabling a privacy preserving version of it, along with sub-protocols for secure computations, to handle the clustering of vertically partitioned data among different healthcare data providers.
Privacy Preserving Outlier Detection Using Hierarchical Clustering Methods	Data objects which do not comply with the general behavior or model of the data are called Outliers. Outlier Detection in databases has numerous applications such as fraud detection, customized marketing, and the search for terrorism. However, the use of Outlier Detection for various purposes has raised concerns about the violation of individual privacy. Therefore, Privacy Preserving Outlier Detection must ensure that privacy concerns are addressed and balanced, so that the data analyst can get the benefits of outlier detection without being thwarted by legal counter-measures by privacy advocates. In this paper, we propose a technique for detecting outliers while preserving privacy, using hierarchical clustering methods. We analyze our technique to quantify the privacy preserved by this method and also prove that reverse engineering the perturbed data is extremely difficult.
STPSA 2010 - The Fifth IEEE International Workshop on Security, Trust, and Privacy for Software Applications	
STPSA 2011 - The Sixth IEEE International Workshop on Security, Trust, and Privacy for Software Applications	
Medical Technology in Smart Homes: Exploring the User's Perspective on Privacy, Intimacy and Trust	This paper reports on a study exploring the attitudes of users towards video-based monitoring systems for long-term care of elderly or disabled people in smart home environments. The focus of the study was on investigating the willingness of users to accept medical technology in their homes and the specific conditions under which continuous monitoring would be acceptable. Using the questionnaire method, a total of 165 users (17-95 years) were examined regarding privacy, intimacy and trust issues for medical technology in homes. The results highlight trust and privacy as central requirements, especially when implemented within private spaces. The reported concerns were mostly insensitive to gender and age. Overall, it was revealed that acceptance issues and users' needs and wants should be seriously considered in order to successfully design new medical technologies.
A Privacy Preserving Reputation Protocol for Web Service Provider Selection	Reputation systems offer web service consumers an effective solution for selecting web service providers who meet their Quality of Service (QoS) expectations. A reputation system computes the reputation of a provider as an aggregate of the feedback submitted by consumers. Truthful feedback is clearly a pre-requisite for accurate reputation scores. However, it has been observed that users of a reputation system often hesitate in providing truthful feedback, mainly due to the fear of reprisal from target entities. We present a privacy preserving reputation protocol that enables web service consumers to provide feedback about web service providers in a private and thus uninhibited manner.
Lightweight Software Product Line Based Privacy Protection Scheme for Pervasive Applications	Protecting user's privacy is one of the main concerns for the deployment of pervasive computing systems in the real world. In pervasive environments, the user context information is naturally distributed among different spatial or logical domains. Many efforts have been done to match the service privacy policy with the user's privacy preferences. However, since the pervasive environments are characterized by a large number of available services as well as a large amount of context information, the privacy protection mechanism poses two main requirements. Firstly, policies are created on a per task basis. We argue here that specifying the privacy on a per domain basis facilitates specifying the privacy preferences for the user. Secondly, to ease specifying the user' privacy preferences, an intuitive mechanisms to specifying the context information that can be consumed by services are thus needed. In this paper, and in order to bridge the gap of the context information perception by the developers and by the users, we propose to represent the available context information in each domain as a feature model. In this way, the developers are able to configure this feature model to get the context information they need, the users can easily specify the context features they are willing to share. The result is a domain-oriented user-centric privacy protection scheme.
STPSA 2012: The Seventh IEEE International Workshop on Security, Trust, and Privacy for Software Applications	
Privacy Preserving Data Publishing for Recommender System	Driven by mutual benefits, exchange and publication of data among various parties is an inevitable trend. However, released data often contains sensitive user information thus direct publication violates individual privacy. Among many privacy models, k-anonymity framework is popular and well-studied, it protects information by constructing groups of anonymous records such that each record in the table released is covered by no fewer than k-1 other records. In this paper, we first investigate different privacy preserving technologies and then focus on achieving k-anonymity for large scale and sparse databases, especially recommender systems. We present a general process for anonymization of large scale database. A preprocessing phase strategically extracts preference matrix from original data by Singular Value Decomposition (SVD) and eliminates the high dimensionality and sparsity problem. We developed a new clustering based k-anonymity heuristic named Bisecting K-Gather (BKG) and it is proven to be efficient and accurate. To support customized user privacy assignments, we also proposed a new concept called customized k-anonymity along with a corresponding algorithm (BOKG). We use MovieLens database to assess our algorithms. The results show that we can efficiently release anonymized data without compromising the utility of data.
Proposal and Evaluation of the Digital Certificate System with Sumi-coating Module for Privacy Protection	PKI (Public Key Infrastructure) is a system to secure procedures on the Internet with a digital signature using the public key cryptosystem. In this system, a trusted certification authority enables the authentication of communicators and/or signers using digital certificate published from the certificate authority. The digital certificate contains information such as names or addresses, etc., which can be used to identify the individual, although a common opinion is it is a privacy problem to disclose such information. In this paper, therefore, we propose a digital certificate system using the revised sumi-coated signature to solve the privacy as well as the security problems. We also report the evaluated results on the function and the performance using a partially implemented system.
A Semantics-Based Privacy-Aware Approach for Fragmenting Business Processes	There is a growing need for the ability to fragment ones business processes effectively, in order to get useful fragments for future reutilization in building business processes. This can prove to increase the productivity and shorten the development time. The decomposition task aims at clustering workflow activities into fragments according to business constraints. Existing approaches lack semantic and privacy concerns. In this paper, we propose a semantic fragment identification approach to assemble activities that are semantically close according a semantic attraction threshold. Moreover, Fragments must be aware of sensitive information preserving. Our fragmentation approach is based on the so-called formal concept analysis approach, while integrating a semantic clustering technique for avoiding the association of sensitive information.
Security and Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00810378.png" border="0">
Technical aspects of privacy protection	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00810391.png" border="0">
A workbench for privacy policies	This paper describes a tool that may be used to create and analyse privacy policies based on the InfoPriv model (proposed by us elsewhere). It is called the Privacy Workbench and consists of four modules: the Privacy Policy, Graph Module, Inference Engine and Rule Base. The Workbench maps privacy policies to graphs called information can-flow graphs. The vertices of an information can-flow graph represent entities while the arcs depict the potential information flow: It is the purpose of the Inference Engine to analyse the graph for all possible information flow between entities including conflicting information flow. It does this by using graph-traversal algorithms. The Inference Engine further resolves conflicting information flows. It uses a rule-based approach to choose the ΓÇ£bestΓÇ¥ arcs to remove in order to resolve conflicts. These rules are contained in the Rule-base and make use of the information can-flow graph's structure and specifics of the privacy policy
A Chinese Wall approach to privacy policies for the Web	The security, of private information is of paramount importance to the continuing use of the Internet for business dealings, as the risk of fraud or unintentional disclosure of private information could be a serious deterrent to individuals. Privacy, policies are being used more and more to promise the security of an individual's private information, but the checking of privacy policies was a daunting task until P3P made it possible to automate such checking. We propose a conceptual method to extend P3P in order to add more flexibility to the decision on whether or not a given item of private information will be supplied to a target organisation by using the Chinese Wall security policy. This will enable a user to not only define rules as to which items of private information she would disclose, but also to define what collection of private information any given organisation would be able to build about her.
Automated negotiation of privacy contracts	Privacy in the Internet is currently not addressed or just stated to tacit acceptance. The user is left to either accept or deny the contractual conditions. A negotiation and thus dynamic contract placement would allow for fairer chances concerning privacy. This article introduces a data-model to describe negotiation preferences and the resulting contracts. It is described, how proposals of contracts are to be compared with the preferences for acceptance and what steps of negotiation can be taken. This model is examined for privacy contracts between enterprises and their customers.
Rule languages for security and privacy in cooperative systems	The open nature of modern network applications is potentially an excellent support to cooperative work of all sorts, and at the same time a major source of security and privacy concerns. It is now commonly recognized that traditional authentication techniques do not scale to the new open scenarios, and are not suitable for the dynamic nature of virtual organizations. Research is focussing on more flexible trust management models that let two or more peers interact securely even if they have never interacted with each other before and have no previous knowledge about each other's properties and protection requirements. This situation occurs whenever a new virtual organization is created or extended. Trust management is based on electronic credentials, that constitute a flexible way of representing properties of individuals, groups and organizations. In principle, any entity can issue its own credentials, thereby signing some statements about some entities. Other peers may decide whether that entity can be trusted on those statements, in the framework of a specific task. Credentials are verifiable and un-forgeable, so it can be robustly checked whether a given statement has been actually signed (hence issued) by a specific peer.
Security and privacy in collaborative distributed systems	With the rapid development of various types of open infrastructures, including Internet, grid, and wireless networks, much attention has been focused on the development of distributed systems for collaborative applications in many areas, including collaborative research and development, healthcare, e-commerce, disaster management and homeland security. Besides reliability and timeliness, the great advantages of collaborative distributed systems for improved group awareness and collaboration opportunities are, however, often overshadowed by accompanying security and privacy concerns. In practice, it is desirable that security and privacy for collaborative distributed systems are flexible, scalable and adaptable to the changing and heterogeneous environments. Ensuring efficient collaboration with such security and privacy requirements is a great challenge due to the difficulties of: 1) Ensuring flexible and verifiable security in collaboration. 2) Negotiating and reconciling policies of multiple organizations when the collaboration occurs across organizational boundaries. 3) Collaboratively drawing a conclusion based on data collected from various members while maintaining the privacy of each member. This panel will address various challenging issues of security and privacy in developing collaborative distributed systems and discuss recent advances as well as future trends in dealing with them.
SSRD+: A Privacy-aware Trust and Security Model for Resource Discovery in Pervasive Computing Environment	SSRD is a secure resource discovery model for devices running in a pervasive computing environment. SSRD is based on a lightweight trust model. SSRD+ is an extension of the existing SSRD model. In SSRD+, we enhance the trust model by adding dynamic trust relationship and also specifying behavioral characteristics that determine the level of trust among devices. We also add a risk model to address challenges posed by the pervasive and ad hoc nature of the network. These models work together to make the entire discovery process lightweight and secure. In this paper we present details of the trust and risk models. We illustrate the design and implementation of SSRD+ as a whole that optimally explores resources without degrading the performance of the devices while ensuring user security and privacy
Information Privacy Management in Smart Home Environments: Modeling, Verification, and Implementation	In this paper, we describe our efforts at modeling and verifying information privacy management in smart home environments. By proposing a three-step research plan, this work will help us and others better understand and define the behavior of smart home technology, information privacy, and the relationship between them
Avoiding Privacy Violation for Resource Sharing in Ad hoc Networks of Pervasive Computing Environment	Users of handheld devices may want to share services resources with each other in pervasive computing environment. Availability of information regarding users may lead to privacy violations while communicating with others for services and resources. Providing a model to resolve this issue in centralized or distributed environment is not desirable or not feasible if we really want to achieve ubiquity. In this paper, we present a privacy aware model for resource sharing in pervasive computing environment with an illustrative example. Our model exploits the concepts of policies and ordered binary decision diagrams.
Towards the Modeling of Personal Privacy in Ubiquitous Computing Environments	Privacy is a known barrier to the acceptance of ubiquitous computing technologies because they require individuals to trade control of their personal information and personal spaces for improved quality of life and assistance with daily activities. Previous work has been done to analyze and protect privacy in ubiquitous computing environments, but such efforts do not include a formal underlying model. We seek to approach the privacy problem from a different perspective. Namely, we seek to propose, verify, and analyze a formal model of privacy for these environments. In this paper, we discuss the beginning stages of our model, namely the resources that need to be protected, the guidelines for constructing the model, and the high-level components of our personal privacy model.
A Soft Constraint Privacy Model based on Identifiability	Disclosing any information contained within an information system that stores personal data can be associated with risk. Nevertheless, the risk of privacy violation is often considered acceptable, since otherwise the most routine business operations can become impossible. Traditional privacy protection methods limit this risk indirectly by using access control policies for the protection of private information, authorizing the release of information only when the purpose of access justifies doing so. While simple and robust, these policies are binary, and therefore they can be too rigid in practice. A data access operation that is only slightly more risky than usual will be denied, and treated no differently than disclosing all possible data contained in the system. If the risk was justified, the access control policy will be modified later to allow it, but the original declined operation will not be performed in time. In this paper we build upon existing research in disclosure risk assessment, and propose a new flexible privacy protection approach based on soft constraints, as opposed to the hard constraints of traditional systems. The proposed model uses identifiability risk computation to estimate the risk of data access, and allows those requesting data access to decide whether the risk is justified. To prevent abuse of the system, each granted access will be recorded, and those taking high risks will need to justify their decisions later. However, the system will not decline access at the time when the request is made, unless, of course, the risk is unjustifiably high. We believe that this novel approach will help achieve the perfect balance between privacy protection and business efficiency. We illustrate our approach using data published by the U. S. Census Bureau.
A Fine-Grained Privacy Structure for Service-Oriented Architecture	In this paper we propose the creation and use of a privacy policy vocabulary. The elements of this policy will have criteria for comparison, creating hierarchical relationships between those elements that could not otherwise be directly compared. This policy vocabulary can be used in conjunction with the eXtensible Access Control Markup Language (XACML) to provide storage and enforcement.
A Privacy Enhancing Approach for Identity Inference Protection in Location-Based Services	Recent advances in mobile handheld devices have facilitated the ubiquitous availability of location based services. Systems which provide location based services have always been vulnerable to numerous privacy threats. The more we aim at safe usage of location based services, the more we feel the necessity of a secure location privacy system. Most of the existing systems adopt the mechanism of satisfying k-anonymity which means that the exact user remains indistinguishable among k-1 other users. These systems usually propose the usage of a location anonymizer (LA) to achieve k-anonymity. In this paper we show that satisfying k-anonymity is not enough in preserving location privacy violation. Especially in an environment where a group of colluded service providers collaborate with each other, a userpsilas privacy can be compromised. We present a detailed analysis of such attack on privacy and propose a novel and powerful privacy definition called s-proximity. In addition to building a formal definition for s-proximity, we show that it is practical and it can be incorporated efficiently into existing systems to make them secure.
A Model for Privacy Policy Visualization	Privacy is a leading concern for anyone that utilizes computing resources whether shopping on the Internet or visiting their doctor. Legislative acts require enterprises and data collectors to protect the privacy of their customers and data owners. Although privacy policy frameworks such as P3P assist data collectors in demonstrating their privacy policies to customers (i.e. publishing privacy policy on Web sites), insufficient research has been reported to help users visualize privacy policies. This paper presents a privacy policy visualization model based on the predicates of a privacy policy model. The key contribution is to provide a visualization model that facilitates understanding the policies for the data owners and provides the opportunity for the policy officers to better understand the designed policies. Finally, we demonstrate the model with a use case drawn from the policies of an online social network.
ELALPS: A Framework to Eliminate Location Anonymizer from Location Privacy Systems	Countless challenges to preserving a userpsilas location privacy exist and have become more important than ever before with the proliferation of handheld devices and the pervasive use of Location-based Services. It is not possible to access Location-based services and, at the same time, to preserve privacy when the user provides his exact location information. To achieve privacy, most third party based systems use a location anonymizer to achieve k-anonymity so that the user remains indistinguishable among k-1 other requesters. In this paper, we present a novel approach called ELALPS to preserve location privacy without any intermediate location anonymizer. Our framework uses a new concept, namely, Landmark Influence Space (LIS) that proves to be efficient in location anonymization and query processing. The framework is complemented by a collaboration-based light-weight k-anonymity protocol that does not require standard cryptographic operations and trust formation among users. Evaluation shows that our system has been able to bridge the gap between privacy and performance.
FPCS: A Formal Approach for Privacy-Aware Context-Based Services	The emergence of new technologies and the proliferation of mobile and handheld devices have facilitated development of context-based services. Common examples include the location based services. However, the revelation of the context and static information gives rise to new and very complex privacy concerns in such services. In this paper, we propose a formal model to regulate the privacy level of information passed to the service provider without disrupting the quality of information required for service access. The framework takes on two forms based on the receiver of the request generalization task to a trusted party or local device. A formal attack model assumes different levels of knowledge by the attacker and demonstrates the relative concerns of static information over contexts.
Preserving Privacy in E-health Systems Using Hippocratic Databases	Safeguarding patientspsila private information is one of the most challenging issues in the design and implementation of modern e-Health systems. Recent advances in Hippocratic Databases (HDB) show a promising direction towards the enforcement of privacy policies in e-Health systems. This paper tackles issues in applying the HDB design to e-Health systems. More specifically, we design an architecture for integrating APPEL preferences with HDB; we extend the original HDB design to support fine-grained privacy authorizations demanded by patients; we adapt the design to a multi-dimensional model; we also propose a design for hierarchical authorizations. Finally, we discuss implementation issues and justify our designs with experimental results.
A System to Prevent Multi-users and Multi-sessions Attack to Breach Privacy Policies in a Trust-End Filter	Among the different technological solutions realized in order to preserve data privacy, the front end trust filter could be effectively applied in environments characterized by high dynamism and untrustworthiness. Unfortunately, a preliminary assessment of this approach suggested a possible weakness: by using different user's profiles the privacy policy can be eluded and sensitive information could be obtained by inference over legal data set. This paper proposes a solution that could be helpful for two purposes: it could be used in the design phase for identifying which use scenarios (i.e., sequences of legal queries) could threaten data privacy; additionally, it could be used for identifying users which could potentially exploit inference for disclosing confidential information.
A framework for privacy policy management in service aggregation	With a rapid growth of the Internet, exploring cost-effective and time-efficient methods for creating Internet services has become critical. As an emerging technology, service aggregation has been regarded as a promising candidate. However, it also raises serious issues on privacy management, as a service is usually provided by multiple providers that are usually transparent to its users. We observe that these issues have not been formally studied in the literature. In this paper, we propose a formal model for the privacy management in service aggregation and present a negotiation strategy on different privacy policies between two organizations.
The complexity of a data privacy protection algorithm	To share data with other parties in computer collaboration is an important issue of data security. k-anonymity and Γäô-diversity are used to protect privacy and secure data sharing. It was proved that optimal k-anonymity are NP hard for k ΓëÑ 3 and that there is a polynomial algorithm for optimal 2-anonymity. This paper proves that an optimal 2-diversity is NP hard. Since Γäô-diversity must be Γäô-anonymity, it follows that the Γäô-diversity is NP hard for Γäô ΓëÑ 2. The result shows that finding polynomial algorithm for efficient (but not optimal) Γäô-diversity is important.
Path planning for privacy preserving in location based service	With the development of mobile networks and positioning technologies, location based service is becoming more and more popular, such as location-aware emergency response, advertisement, and car navigation system etc. However, while people enjoy more convenient life provided by location based services, their location privacy may leak. To tackle this problem, many researchers propose different ways to make users' privacy preserving and most of them focus on how to confuse users' true identities, or hide users' exact position while a user is in a cloaking square. The representative method is K-anonymity method which requires not less than k users in the same square when a location based service request occurs. In case there are not enough users in this cloaking square, the condition of the k-anonymity is not satisfied and location privacy would be leak. In this paper, we would tackle the problem of location privacy in a different way by predicating a safe path to users. Our objective is to provide more guarantee of privacy preserving for users under the K-anonymity criteria. We propose a path predicting algorithm from a user's current position to his/her destination. Every point on such path satisfies a location privacy policy under K-anonymity criteria. We also consider an upper threshold so as to balance privacy requirement and performance. Furthermore, the path would be dynamic adjusted according to users' movement and environment changes. Experiments are performed to verify our method and the experiment results show that this method is correct and efficient.
Security and privacy considerations for Wireless Sensor Networks in smart home environments	Wireless Sensor Network (WSN) has emerged as a dependable technology to improve the quality of life in smart homes through offering various automated, interactive and comfortable services. Sensors integrated at different places in homes, offices, and even in clothes, equipment, and utilities are used to sense and monitor occupants' positions, movements, vital signs, utility usage, temperature and humidity levels of rooms, etc. Along with sensing and monitoring capabilities, sensors cooperate and communicate with themselves to deliver, share and process sensed information and assist real-time decision-making procedures through triggering appropriate alerts and actions. However, ensuring privacy and providing adequate security in these crucial services provided by WSNs is a major issue in smart home environments. In this paper, we examine the privacy and security challenges of WSNs and survey its practicality for smart home environments. We discuss the unique characteristics that distinguish a smart environment from the rest, elaborate on security and privacy issues and their respective solution measures. A number of challenges and interesting research issues emerging from this study have been reported for further investigation.
Awareness and Privacy in Groupware Systems	Awareness has recently been a central research issue in CSCW. The more aware the collaborators of others' activities and situations they might be in, the more effective teamwork would be. However, awareness support actually means sacrifice of privacy. When it comes to systems design, therefore, it is of great importance to decide the extent to which awareness is supported, without damaging privacy seriously. Emphasizing on the trade-offs between awareness and privacy, this paper presents some guidelines in groupware design concerning how to handle both notions, based on two interview studies we carried out and description of scenarios largely hinted by the interviews. We discuss them in relation to the five types of awareness: task awareness, member awareness, presence awareness, schedule awareness and activity awareness
A Model to Incorporate Privacy in Organizational Memory Systems	People are usually concerned with the privacy of their personal information. However, the problem of privacy is also present when the information is directly linked to people, for example in personal opinions, discussions and decisions. Typically, if this information is indefinitely stored in an organizational memory system, then it may cause privacy problems inside the organization. Privacy is needed for users to feel free enough to express themselves honestly, and consequently, for the collaborative software to succeed. This paper presents a model to incorporate automatic privacy measures in an Organizational Memory System
A Strategy to Automatically Feed OMS and Implement Information Privacy	The use of past information is becoming critical for organizations. Coordination, decision making and negotiation are some of the collaborative activities that depend on it. However, the need to provide privacy and information retrieval capabilities to all users of an organizational memory system (OMS), requires a good strategy for acquiring and structuring the information. This paper presents a strategy intended to (a) facilitate the feeding of an OMS based on information stored in legacy information systems, (b) ease the information retrieval process, and (c) provide an automatic privacy mechanism for the information stored in the OMS.
Digital Identity Design and Privacy Preservation for e-Learning	This paper tries to address the security issue which e-learning systems are facing. Through well designed meta-formats of digital identities, the privacy of e-learning users can be well preserved.
Portable devices of security and privacy preservation for e-learning	This paper systematically addresses the security and privacy concerns for e-learning systems. An effective architecture of e-learning system is proposed for a thorough overview on security and privacy issues related to current e-learning systems. This paper further examines the relationship among security & privacy policy, available security & privacy technolongy, and the degree of e-learning privacy & security. This paper significantly contributes to the knowledge of e-learning security & privacy research communities and will generate more research interests in this regard.
Efficient K-anonymization for privacy preservation	Privacy preservation during cooperation has become an interesting issue in the last few years. This problem attracted much research work. k-anonymization is an efficient approach to protect data privacy. However, k-anonymization problem was proven NP-hard though the idea of k-anonymizafion is not complex. In this paper, we propose two simple but very efficient algorithms, which work for numeric and categorical data respectively, can minimize information loss as low as possible. We show that these algorithms can produce better performance comparing to other known algorithms.
Implement privacy for an OMS	Currently, the use of transfer information is becoming critical for organizations. Collaborative activities such as coordination, decision making and negotiation depend on it. Organizational memory systems (OMS) have been proposed to accumulate, organize, preserve and share diverse information coming from various sources. However, the need to provide privacy capability to all the users of an OMS requires a good strategy for acquiring and structuring the information. This paper presents a new privacy mechanism strategy for the information stored in the OMS.
Privacy preserving on Radio Frequency Identification systems	This paper focuses on the challenges on the privacy of Radio Frequency Identification (RFID) systems. RFID systems have already widely applied in industry and have been bringing lots of benefits to our daily life, it also creates new security and privacy problems to individuals and organizations. The security and privacy challenges are analysed after a brief introduction of various RFID systems and their associated operations. A proposal to protecting security and privacy of customers, as a solution of the challenge for low-cost RFID systems is designed. Finally, comparisons to related works of the proposal are described.
Towards distributed privacy for CSCW	Tools for computer supported collaborative work offer many advantages for their users. Some developments in this field have included agent-based approaches for CSCW. Many challenges face the development and application of distributed, agent-based solutions for CSCW. A concern often overlooked is the acceptability and social impact of these technologies. In particular, the management of the privacy of collaborators is a paramount issue that must be accommodated. Included and related to the privacy of user information and interactions are assurances of integrity, certification, validation, ownership, non-repudiation, and authentication of individuals and software systems operating on disparate computers and operating systems, communicating over heterogeneous networks. We outline our early work on an approach for accountable privacy that may be applied to distributed computer supported cooperative work (CSCW) environments. Particular challenges for the issue of privacy associated with the CSCW application scenario are discussed
A secure and privacy protection digital goods trading scheme in cloud computing	In a cloud computing environment, a seller can store her/his digital goods in a cloud server, and then sell them when a buyer needs. In order to protect the digital content's privacy, the seller should store her/his digital goods in an encrypted form before being stored in a cloud. However, the method of directly encrypting digital goods maybe not work well if buyers and sellers trade with the digital goods in this environment. The reason is that the cloud server could not decide which digital goods contain certain keywords requested by a buyer if the meta data of the encrypted digital goods is not searchable. In this paper, we propose a secure digital goods trading scheme in the cloud computing. Our scheme can efficiently protect keywords privacy for buyers, and make the cloud server to search the keywords on the encrypted digital content to protect the privacy of sellers' digital content. We also provide an efficient trading method to let buyers and sellers trade with the matched digital goods in a cloud.
An efficient and privacy protection multi-server authentication scheme for low-cost RFID tags	Due to the wide use of the Internet and information technology, there are many attractive services provided in the network environment. Since the Internet is a public environment, a user must pass the authentication before using these services. Also, due to the reduced cost of the RFID tags, RFID technologies are widely used in various information applications. In this paper, we propose a mutual authentication RFID scheme for multiserver environment. Since in our proposed scheme, the tag only needs random number generation and one-way hash function operations, the computation cost for the tags is low. Our scheme does not need to store any verification table in the server and the registration center. Our proposed scheme can withstand all well-known security attacks, and can achieve anonymity for the tag.
A novel metropolitan area network service model with free use and privacy protection	Nowadays, wireless network technology is booming and becoming more popular. It is convenience for people to access information from Internet. In this paper, we propose a novel model on free WLAN service. It has a high enough value to advertisers, because users are forced to view advertisements before being given access. Moreover, user's privacy is also considered. The concern of user's privacy is particularly signified in roaming network, user should keep anonymous to service provider. The free WLAN service provider can make money enough to keep and maintain free wireless service. The goal of profit-making comes from the advertisement impression will be workable in our scheme. This scheme, profit-making comes from advertisement impression by forcing user to browse advertisements before using network service, and still guarantee that user identity is anonymous, non-traceable and non-forgeable.
Privacy in E-learning: How to implement anonymity	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01387141.png" border="0">
A Privacy Preferences Architecture for Context Aware Applications	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01618491.png" border="0">
Privacy preserving ID3 using Gini Index over horizontally partitioned data	The ID3 algorithm is a standard, popular, and simple method for data classification and decision tree creation. Since privacy-preserving data mining should be taken into consideration, several secure multi-party computation protocols have been presented based on this technique. Entropy and Gini Index are two protocols which compute information-gain at each step when producing a decision tree. The Gini index, however, has been less studied in privacy-preserving data mining protocols. In this paper, we show how Gini can be used in privacy-preserving ID3 algorithms to create decision tree classifications in such a way that involved parties can jointly compute the gain value of each normal attribute without revealing their own private information to each other, while the database is horizontally partitioned over two or more parties. Three secure multiparty sub-protocols are presented to evaluate the intermediate computations. The communication overhead has been kept reasonably low to make the whole protocol efficient and practical.
Privacy and the market for private data: A negotiation model to capitalize on private data	The market for consumer information is already a lively market, where consumer information and consumer profile data are often among the most valuable assets owned by online retailers. The value of such commodity derives from the ability of firms to identify consumers and charge them personalized prices flj. We argue that if consumers' identity and personal information is such a valuable asset, should not consumers benefit from their asset as well? In this paper, we propose a negotiation process between an online consumer agent and an online seller. The online consumer agent acts on behalf of consumers to maximize their social welfare. In our model, the agent derives a quantified privacy risk for each private data and uses it to determine a cost premium value to make the bargaining process manageable. We also provide a computational example to evaluate the model.
Privacy protection issues in social networking sites	Social networking sites (SNS) have become very popular during the past few years, as they allow users to both express their individuality and meet people with similar interests. Nonetheless, there are also many potential threats to privacy associated with these SNS such as identity theft and disclosure of sensitive information. However, many users still are not aware of these threats and the privacy settings provided by SNS are not flexible enough to protect user data. In addition, users do not have any control over what others reveal about them. As such, we conduct a preliminary study which examines the privacy protection issues on social networking sites (SNS) such as MySpace, Facebook and LinkedIn. Based on this study, we identify three privacy problems in SNS and propose a privacy framework as a foundation to cope with these problems.
Portable web browser forensics: A forensic examination of the privacy benefits of portable web browsers	Portable web browsers are installed on removable storage devices which can be taken by a user from computer to computer. One of the claimed benefits of portable web browsers is enhanced privacy, through minimization of the traces of browsing activity left on the host's hard disk. On the basis of this claim, it would appear that portable web browsers pose a challenge to forensic examiners trying to reconstruct past web browsing activity in the context of a digital investigation. The research examines one popular portable web browser, Google Chrome in both normal and private browsing mode, and compares the forensic traces of its use to forensic traces of the installed version of the same browser. The results show that Google Chrome Portable leaves traces of web browsing activity on the host computer's hard disk, and demonstrate a need for forensic testing of the privacy claims made for the use of portable web browsers.
A client privacy preserving discovery service scheme	The EPCglobal Network is a global information architecture for objects carrying RFID tags with Electronic Product Codes (EPC) in supply chains. Discovery Service (DS) is an important component storing large amounts of indices from EPCs to detailed information in EPCISes. However, to the client, DS is a third-party server which can easily get clients' privacy when they send queries. In this paper, using the policy of Private Information Retrieval (PIR), we propose a client privacy preserving DS scheme that can meet both basic functional requirement and client privacy requirement. Compared to existing privacy preserving DS schemes, our work is more concise in architecture and can completely guarantee the client privacy.
PA-SET: Privacy-aware SET protocol	E-payment is considered a cornerstone in daily e-transactions. There are many proposed e-payment protocols but the majority of such protocols were designed just to satisfy the traditional flow of payment data which increases the users' risk because of security vulnerabilities and privacy leakage. The Secure Electronic Transaction protocol (SET), a de facto standard, is limited in application due to computation overhead and privacy leakage. In this paper, a new privacy-aware SET enhancement is proposed. The SET protocol is enhanced by hiding the payer's identity and providing transaction privacy during the whole e-payment process. Privacy protection is achieved for the payer while incurring acceptable overhead as demonstrated by performance evaluation experiments.
Privacy & Security Issues Related to Match Scores	Security and privacy issues remains a major hurdle in wide deployment of biometric based authentication system. For example, unauthorized access or regeneration of face templates has serious implications on the privacy of the concerned users. For robust and practical implementation of such system it is necessary to identify and explore the possible ways by which reconstruction of template is feasible. In this paper, we show that even match scores carries sufficient information for reconstruction of the original face templates. We propose a novel non-iterative scheme to reconstruct face templates from match scores. We use an affine transformation of the images to approximate the behavior of a given face recognition system using an independent set of face templates termed as "break-in" set. Selected templates from the break-in set are matched only once with the enrolled template of the target account and match scores are recorded. These scores are then embedded in the approximating affine space along with break-in set templates to compute the co-ordinates of the target template. The inverse transformation is used to reconstruct the original target template. We present the reconstruction of templates for a commercial off the shelf (COTS) face recognition system. The COTS system is set to operate at 1% False Acceptance Rate and 99% True Acceptance Rate with 100 enrollments. We observed that with proposed scheme, at most 450 attempts are required to achieve a 0.93 probability of break into the COTS face recognition system by choosing a random gallery target.
Scrambling for Video Surveillance with Privacy	In this paper, we address the problem of scrambling regions of interest in a video sequence for the purpose of preserving privacy in video surveillance. We propose an efficient solution based on transform-domain scrambling. More specifically, the sign of selected transform coefficients is pseudo-randomly flipped during encoding. We address more specifically the two cases of MPEG-4 and Motion JPEG 2000. Simulation results show that the technique can be successfully applied to conceal information in regions of interest in the scene while providing with a good level of security. Furthermore, the scrambling is flexible and allows adjusting the amount of distortion introduced. Finally, this is achieved with a small impact on coding performance and negligible computational complexity increase.
Illumination invariant representation for privacy preserving face identification	Most effective face recognition methods store biometric information in the clear. Doing so exposes those systems to the risk of identity theft and violation of privacy. This problem significantly narrows the practical use of face recognition technology. Recent methods for privacy preserving face recognition address face verification task. Most of them are unable to generalize to unseen conditions and require a large number of images of every user for training. We address the problem of face identification, which is more useful in security applications, and propose a binary, illumination invariant representation that can be easily integrated with various efficient cryptographic tools for protection. We propose several privacy preserving applications for our representation and test it on a number of benchmark databases to show its robustness to severe illumination changes, occlusions, and some other appearance variations.
PrivacyCam: a Privacy Preserving Camera Using uCLinux on the Blackfin DSP	Considerable research work has been done in the area of surveillance and biometrics, where the goals have always been high performance, robustness in security and cost optimization. With the emergence of more intelligent and complex video surveillance mechanisms, the issue of "privacy invasion" has been looming large. Very little investment or effort has gone into looking after this issue in an efficient and cost-effective way. The process of PICO (privacy through invertible cryptographic obscuration) is a way of using cryptographic techniques and combining them with image processing and video surveillance to provide a practical solution to the critical issue of "privacy invasion". This paper presents the idea and example of a realtime embedded application of the PICO technique, using uCLinux on the tiny Blackfin DSP architecture, along with a small Omnivision camera. It demonstrates how the practical problem of "privacy invasion" can be successfully addressed through DSP hardware in terms of smallness in size and cost optimization. After review of previous applications of "privacy protection", and system components, we discuss the "embedded jpeg-space" detection of regions of interest and the real time application of encryption techniques to improve privacy while allowing general surveillance to continue. The resulting approach permits full access (violation of privacy) only by access to the private-key to recover the decryption key, thereby striking a fine trade-off among privacy, security, cost and space.
Privacy preserving crowd monitoring: Counting people without people models or tracking	We present a privacy-preserving system for estimating the size of inhomogeneous crowds, composed of pedestrians that travel in different directions, without using explicit object segmentation or tracking. First, the crowd is segmented into components of homogeneous motion, using the mixture of dynamic textures motion model. Second, a set of simple holistic features is extracted from each segmented region, and the correspondence between features and the number of people per segment is learned with Gaussian process regression. We validate both the crowd segmentation algorithm, and the crowd counting system, on a large pedestrian dataset (2000 frames of video, containing 49,885 total pedestrian instances). Finally, we present results of the system running on a full hour of video.
PICO: Privacy through Invertible Cryptographic Obscuration	Signifiicant research progress has been made in intelligent imaging systems, surveillance and biometrics improving robustness, increasing performance and decreasing cost. As a result, deployment of surveillance and intelligent video systems is booming and increasing the impact of these on privacy. For many, networked intelligent video systems, especially video surveillance and biometrics, epitomize the invasion of privacy by an Orwellian "big brother:. While tens of millions in government funding have been spent on research improving video surveillance, virtually none has been invested in technologies to enhance privacy or effectively balance privacy and security. This paper presents an example that demonstrates how using and adapting cryptographic ideas and combining them with intelligent video processing, technological pproaches can provide for solutions addressing these critical trade-offs, potentially improving both security and privacy. After reviewing previous research in privacy improving technology in video systems, the paper then presents cryptographically invertible obscuration. This is an application of encryption techniques to improve the privacy aspects while allowing general surveillance to continue and allowing full access (i.e. violation ofprivacy) only with use of a decryption key, maintained by a court or other thirdparty.
Efficient privacy preserving video surveillance	Widespread use of surveillance cameras in offices and other business establishments, pose a significant threat to the privacy of the employees and visitors. The challenge of introducing privacy and security in such a practical surveillance system has been stifled by the enormous computational and communication overhead required by the solutions. In this paper, we propose an efficient framework to carry out privacy preserving surveillance. We split each frame into a set of random images. Each image by itself does not convey any meaningful information about the original frame, while collectively, they retain all the information. Our solution is derived from a secret sharing scheme based on the Chinese Remainder Theorem, suitably adapted to image data. Our method enables distributed secure processing and storage, while retaining the ability to reconstruct the original data in case of a legal requirement. The system installed in an office like environment can effectively detect and track people, or solve similar surveillance tasks. Our proposed paradigm is highly efficient compared to Secure Multiparty Computation, making privacy preserving surveillance, practical.
Large-scale privacy protection in Google Street View	The last two years have witnessed the introduction and rapid expansion of products based upon large, systematically-gathered, street-level image collections, such as Google Street View, EveryScape, and Mapjack. In the process of gathering images of public spaces, these projects also capture license plates, faces, and other information considered sensitive from a privacy standpoint. In this work, we present a system that addresses the challenge of automatically detecting and blurring faces and license plates for the purpose of privacy protection in Google Street View. Though some in the field would claim face detection is ΓÇ£solvedΓÇ¥, we show that state-of-the-art face detectors alone are not sufficient to achieve the recall desired for large-scale privacy protection. In this paper we present a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding-window detector. Using a completely automatic system, we are able to sufficiently blur more than 89% of faces and 94 - 96% of license plates in evaluation sets sampled from Google Street View imagery.
Privacy-Openness Game in Virtual Life: The Game is a Premise for a Computer Supported Virtual Life	Computers are not merely data-processing devices. They are an unlimited vast world that enables virtual life. This paper maintains that humans are paradoxical beings who want private and secret life on one hand, and make their thoughts and actions public and open on the other hand. Coining the notion of the Privacy-Openness (PO) game that humans play, this paper reveals that such paradoxical desire is a crucial momentum for computer-supported virtual life, and that the PO game is an indispensible premise for virtual life. It also discusses the relationship between the PO game and freedom which is a major source from which virtual life begins.
Privacy violation in limited disclosure of database having functional dependency	Upholding the privacy of data has gathered increased interest in the current industrial scenario. The databases that hold personal information and the individuals' choices of privacy are often subjected to attacks from mischievous sources which try to access undisclosed data. The means used to achieve such ends may be in the form of complex queries that combine sensitive data with the non-sensitive ones. Access control mechanisms are already in place to prevent such malicious accesses. But the problem is highly compounded when there is a functional dependency among some of the attributes of the data. In such cases often the disclosed data of one person allows the user to infer the undisclosed data of another person. In this paper we propose a model to prevent the breach of privacy through such inference channels of functional dependency. Then we describe the architecture of our model and the corresponding implementation. Finally we carry out a performance analysis to evaluate the cost overheads of time and space and look out topics for future research.
Privacy and confidentiality in healthcare delivery information system	The issue of confidentiality and invasion of privacy has become increasingly prominent as the use of computing and communication technologies becomes widespread. The importance of individual privacy has long been recognized in a democratic society. Laws and regulations, such as privacy and freedom of information acts, have been introduced to assure and safeguard individual rights. However, the meaning and actual requirements of information and data security for protecting these rights has not been clearly understood. Information security concerns in health care delivery information systems are particularly sensitive. This plenary address is intended to stimulate discussions at the conference on identifying and representing information security requirements and semantics for the development of security policies and enforcement techniques for healthcare delivery information system
Privacy versus safety: who is safe?	The increasing storage of vast amounts of information on computers and the rapidly increasing size of databases stored online has the population (and even many politicians) worried about invasion of privacy. This paper examines some possible ways in which privacy maybe invaded by the use of medical databases, particularly during the analysis and publication of results.
The medical privacy rule: can hospitals comply using current health information systems?	This research provides an analysis of the implementation of the "standards for the privacy of individually identifiable health information " (medical privacy rule) published in August 14, 2002 by the Department of Health and Human Services (HHS) following the issuing of a privacy rule by the Clinton administration in December 2000 and later support by the Bush administration. The privacy rule went into effect April 14, 2001, with compliance required by April 2003 for most health providing entities. The resulting legislation is designed to ensure that the business activity of health providers is subject to privacy regulation. In this research we examine the ability of health organisations to respond to the requirements of this legislation and illustrate that this ability is affected by the quality of their patient data and the structure and security of their databases. This paper suggests that compliance with the legislative provisions creates implications for information systems development and design which large public hospitals have so far failed to consider or act upon.
Privacy of medical records: from law principles to practice	Regulating access to electronic health records has become a major social and technical challenge. Unfortunately, existing access control models fail in translating accurately basic law principles related to the safeguard of personal information (e.g., medical folder). This paper identifies the problem and proposes a solution in the EHR context.
Privacy compliance in european healthgrid domains: An ontology-based approach	The integration of different European medical systems by means of grid technologies will continue to be challenging if technology does not intervene to enhance interoperability between national regulatory frameworks on data protection. Achieving compliance in European healthgrid domains is crucial but challenging because of the diversity and complexity of Member State legislation across Europe. Lack of automation and inconsistency of processes across healthcare organizations increase the complexity of the compliance task. In the absence of automation, the compliance task entails human intervention. In this paper we present an approach to automate privacy requirements for the sharing of patient data between Member States across Europe in a healthgrid domain and ensure its enforcement internally and within external domains where the data might travel. This approach is based on the semantic modelling of privacy obligations that are of legal, ethical or cultural nature. Our model reflects both similarities and conflicts, if any, between the different Member States. This will allow us to reason on the safeguards a data controller should demand from an organization belonging to another Member State before disclosing medical data to them. The system will also generate the relevant set of policies to be enforced at the process level of the grid to ensure privacy compliance before allowing access to the data.
Generate Sub-Agent Mechanism to protect mobile agent privacy	In recent years, the mobile agent system has taken a wide area of researchers' attention. They conducted intensive researches in the security areas to reach an ideal mobile agent model. The security area still needs more efforts to protect the mobile agent system. The protection of the mobile agent is one of these issues. this paper a new mechanism called Generated Sub-Agent Mechanism (GSAM) to protect mobile agent against malicious Hosts has been proposed. The main idea behind GSAM is to generate a sub-mobile agent from the mobile agent in case the mobile agent will visit an untrusted host. The sub-mobile agent visits the untrusted host instead of the mobile agent. After the sub-mobile agent completes its work, it returns to the original mobile agent location and the mobile agent continues its journey. By this way, the untrusted host could not reach the content of the mobile agent. It couldn't attack the mobile agent behavior. The paper describes all GSMA components. GSMA cost analysis has been done. The analysis result mentions that the increasing of the untrusted host number reduces the time cost and GSMA has not.
Privacy-aware policy matching	Security policies exchanged between applications are typically huge, complex and private. A server must publish these policies to permit any client that wants to use the service to match it with its own preferences and assess whether it complies with its security policy. This matching process consists of first verifying whether the client can access the service and then checks if the security policy of the server is compliant with the client's privacy preferences. In this paper we propose a privacy-aware policy matching model, where security policies and user's preferences are represented as binary vectors using bloom filter vectors. These vectors can be published by the server without any risk of disclosing its security policy. When the client wants to match this vector to its preferences vector it just compares the two binary arrays, without disclosing its policy. The binary comparison is also much faster and cost effective than parsing two XML files.
Open issues on privacy and trust in collaborative environments	Exploiting the advantages of Web 2.0 technologies and collaborative applications and tools such as wikis, blogs, forums, real-time text editors and other groupware systems, modern services and Information Systems have evolved towards collaborative and social environments where user-generated content is a common task. In this paper we will identify the additional privacy and trust requirements posed by collaborative knowledge tools and suggest a number of guidelines for the development of privacy-aware Identity and Access Management systems that are capable to ensure trust in the context of collaborative workspaces.
Privacy-preserving scheme for mobile ad hoc networks	In this paper we propose a decentralized privacy-preserving scheme for mobile ad hoc networks (MANETs), where nodes establish security associations. In order to achieve privacy and security, we use homomorphic encryption and polynomial intersection so as to find the common friends of two nodes. Through our experimental results we verify the correctness of our scheme given the limitations of MANETs.
Improving source-location privacy through opportunistic routing in wireless sensor networks	Wireless sensor networks (WSN) can be an attractive solution for a plethora of communication applications, such as unattended event monitoring and tracking. One of the looming challenges that threaten the successful deployment of these sensor networks is source-location privacy, especially when a network is deployed to monitor sensitive objects. In order to enhance source location privacy in sensor networks, we propose the use of an opportunistic mesh networking scheme and examine four different approaches. Each approach has different selection criteria for the next relay node. In opportunistic mesh networks, each sensor transmits the packet over a dynamic path to the destination. Every packet from the source can therefore follow a different path toward the destination, making it difficult for an adversary to backtrack hop-by-hop to the origin of the sensor communication.
Analyzing application private information leaks with privacy Petri Net	Private information leak has been discovered in many applications and has become serious and challenging problem to cyber security. Previous works are based on two categories of road map, the one focuses on the outbound network traffic of application, the other one dives into the inside information flow of application. We incorporate application dynamic behavior analysis with network traffic analysis and present abstract model called Privacy Petri Net (PPN) which is more applicable to various applications and more meaningful to users. We apply our approach on both real world regular application and malware. The experiment result shows that our approach can effectively find categories, content, source and destination of the private information leaks for the target application.
Electronic mail and privacy in the corporate environment	The author addresses the issues related to electronic mail (E-mail) with respect to privacy in the workplace. The first topic reviews the sections of the Electronic Communications Privacy Act (ECPA) of 1986 that may be applicable to E-mail privacy in the corporate environment. The ECPA was enacted to protect against unwarranted search and seizure on the part of the government. However, there is some question as to how the ECPA applies to corporations. The second topic reviews recent litigation that has risen out of corporate inspections of employee E-mail. These employee suits involve the use of corporate assets that supported private E-mail for employees. The third topic presents some proactive corporate strategies to prevent or at least reduce the risk of corporate liability. It is important to establish a corporate privacy policy with respect to E-mail and publish it. A policy in a manual will be of little help in the event of a lawsuit
Achieving Privacy-preserving Computation on Data Grids	This paper proposes a generic Grid privacy-preserving computation(G2PC) model which supports privacy-preserving data analysis and computation on multiple distributed datasets without compromising both the raw data privacy of Grid nodes and data statistics (intermediate result) privacy. The center of the design is our novel Data Privacy-Preserving Broker (D2PB) that combines the GSI (Grid Security infrastructure) with a number of cryptographic primitives. G2PC model requires neither one-to-all interactions among participating entities, nor reassignment of security parameters when membership or data changes. Therefore, it is efficient, scalable, and suited to large-scale Data Grid systems that are expected to host thousands of dynamic nodes. The privacy-preserving variance computation and privacy-preserving k-means clustering algorithm have been used as examples to demonstrate the efficacy and efficiency of our proposed framework.
PPMLP: A Special Modeling Language Processor for Privacy Policies	In today's age of information technology, there is an increasing concern for the privacy of an individual's records stored on computers. The Internet and security vulnerabilities provide an opportunity for hackers to misuse information. The level of an individual's trust for an organization can be ensured or influenced by the organization's privacy policy. Privacy has become a concern only recently and hence, creating well documented and comprehensive organizational privacy policies still remains a challenge. The paper presents results on a special privacy policy modeling language processor (PPMLP) based on service oriented architecture (SOA) for an organization to model the structure and contents of private policy they want through a meta type of privacy policy specifications.
Caller identity privacy in SIP heterogeneous realms: A practical solution	The growing demand for voice services and multimedia delivery over the Internet has raised SIPpsilas popularity making it a subject of extensive research. SIP is an application layer control signaling protocol, whose main purpose is to create, modify and terminate multimedia sessions. Research has shown that SIP has a number of security issues that must be solved in order to increase its trustworthiness and supersede or coexist with PSTN. In this paper our purpose is to address such a weakness, namely the caller identity privacy issue. While some solutions to this problem do exist, we will show that they are inadequate in a number of situations. Furthermore, we will propose a novel scheme for the protection of callerpsilas identity which can also support roaming between different administrative domains. Finally, we provide some performance results, which demonstrate that the proposed solution is efficient even in low-end mobile devices.
LPBS - Location Privacy Based System	The use of geographical information about users is the main quality of Location Based Services (LBS). Services like finding routes between places or finding friends can offer benefits and facilities. However, the misuse of location information can raise some threats to the user's privacy. We present the Location Privacy Based System (LPBS), a system that guarantees LBS execution with privacy relying on a multi-level approach. By using different techniques we can offer distinct levels of privacy. Therefore, the system presented in this paper is able to attend different requirements and preferences of users. Besides, LPBS follows the recommendations of existing privacy guidelines.
Personal Information & Privacy - I	Welcome to the first of two sessions on personal information and privacy. My name is Lance Hoffman. I'm professor of Computer Science at the George Washington University in Washington, D.C., and I am the moderator for both sessions. In this first session, we have two individual presentations followed by a debate.
Personal Information & Privacy - II	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00664755.png" border="0">
Computers Freedom and Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00664735.png" border="0">
Security Capabilities, Privacy & Integrity	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00664761.png" border="0">
VSPN: VANET-based Secure and Privacy-preserving Navigation	In this paper, we propose a navigation scheme that utilizes the online road information collected by a vehicular ad hoc network (VANET) to guide the drivers to desired destinations in a real-time and distributed manner. The proposed scheme has the advantage of using real-time road conditions to compute a better route and at the same time, the information source can be properly authenticated. To protect the privacy of the drivers, the query (destination) and the driver who issues the query are guaranteed to be unlinkable to any party including the trusted authority. We make use of the idea of anonymous credential to achieve this goal. In addition to authentication and privacy-preserving, our scheme fulfills all other necessary security requirements. Using the real maps of New York and California, we conducted a simulation study on our scheme showing that it is effective in terms of processing delay and providing routes of much shorter travelling time.
Design and Analysis of a Highly User-Friendly, Secure, Privacy-Preserving, and Revocable Authentication Method	A large portion of system breaches are caused by authentication failure, either during the login process or in the post-authentication session; these failures are themselves related to the limitations associated with existing authentication methods. Current authentication methods, whether proxy based or biometrics based, are not user-centric and/or endanger users' (biometric) security and privacy. In this paper, we propose a biometrics based user-centric authentication approach. This method involves introducing a reference subject (RS), securely fusing the user's biometrics with the RS, generating a BioCapsule (BC) from the fused biometrics, and employing BCs for authentication. Such an approach is user friendly, identity bearing yet privacy-preserving, resilient, and revocable once a BC is compromised. It also supports "one-click sign-on" across systems by fusing the user's biometrics with a distinct RS on each system. Moreover, active and non-intrusive authentication can be automatically performed during post-authentication sessions. We formally prove that the secure fusion based approach is secure against various attacks. Extensive experiments and detailed comparison with existing approaches show that its performance (i.e., authentication accuracy) is comparable to existing typical biometric approaches and the new BC based approach also possesses many desirable features such as diversity and revocability.
Dynamic Bit Encoding for Privacy Protection against Correlation Attacks in RFID Backward Channel	Today Radio Frequency Identification (RFID) technologies are applied in many fields for a variety of applications. Though bringing great productivity gains, RFID systems may cause new security and privacy threats to individuals or organizations. Therefore, it is important to protect the security of RFID systems and the privacy of RFID tag owners. Unfortunately, none of the existing solutions provide a complete defense against eavesdroppers who could monitor the communication between RFID readers and tags and recover the contents of tags. Based on our research, we propose two novel RFID backward channel protection protocols, namely dynamic bit encoding and optimized dynamic bit encoding. Our schemes are able to achieve high anonymity with limited communication overhead. Our extensive simulations show that both proposed schemes provide much stronger backward channel protection than existing techniques. In addition, analytical models were created and validated through comparisons with simulation results.
Handauth: Efficient Handover Authentication with Conditional Privacy for Wireless Networks	Existing mechanisms for handover authentication mainly focus on designing a secure authentication module, little attention has been paid to protect users' privacy when they are authenticated by the access points for data access. Further, most existing approaches do not support user revocation. In this paper, we present a secure and efficient authentication protocol named Handauth. Similar to the mechanisms of this field, Handauth provides user authentication and session key establishment. However, compared to other well-known approaches, Handauth not only enjoys both computation and communication efficiency, but also achieves strong user anonymity and untraceablility, forward secure user revocation, conditional privacy-preservation, AAA server anonymity, access service expiration management, access point authentication, easily scheduled revocation, dynamic user revocation and attack resistance. Experimental results show that the proposed approach is feasible for real applications.
Privacy and Security Issues in Information Systems	A law now in effect in the United States requires protection of individual privacy in computerized personal information record-keeping systems maintained by the federal government. Similar laws apply in certain state and local governments. Legislation has also been introduced to extend the requirements for privacy protection to the private sphere. Central in privacy protection are the rights of an individual to know what data are maintained on him, challenge their veracity and relevance, limit their nonroutine use or dissemination, and be assured that their quality, integrity, and confidentiality are maintained. In all computer systems that maintain and process valuable information, or provide services to multiple users concurrently, it is necessary to provide security safeguards against unauthorized access, use, or modifications of any data file. This difficult problem has not yet been solved in the general case. Computer systems must also be protected against unauthorized use, disruption of operations, and physical damage. The growing number of computer applications involving valuable information or assets plus the growing number of criminal actions directed against computer applications and systems or perpetrated by using computers underscore the need for finding effective solutions to the computer security problem. In the future, concerns for privacy and security must become integral in the planning and design of computer systems and their applications.
Privacy-Preserving Public Auditing for Secure Cloud Storage	Using cloud storage, users can remotely store their data and enjoy the on-demand high-quality applications and services from a shared pool of configurable computing resources, without the burden of local data storage and maintenance. However, the fact that users no longer have physical possession of the outsourced data makes the data integrity protection in cloud computing a formidable task, especially for users with constrained computing resources. Moreover, users should be able to just use the cloud storage as if it is local, without worrying about the need to verify its integrity. Thus, enabling public auditability for cloud storage is of critical importance so that users can resort to a third-party auditor (TPA) to check the integrity of outsourced data and be worry free. To securely introduce an effective TPA, the auditing process should bring in no new vulnerabilities toward user data privacy, and introduce no additional online burden to user. In this paper, we propose a secure cloud storage system supporting privacy-preserving public auditing. We further extend our result to enable the TPA to perform audits for multiple users simultaneously and efficiently. Extensive security and performance analysis show the proposed schemes are provably secure and highly efficient. Our preliminary experiment conducted on Amazon EC2 instance further demonstrates the fast performance of the design.
The Method of Protecting Privacy Capable of Distributing and Storing of Data Efficiently for Cloud Computing Environment	Large amounts of information being generated in real time in a distributed environment due to recent development of cloud services such as SaaS, etc. is stored and managed in a database and is shared by users. But because the sensitive information of an individual is included in this information, the privacy damage by illegal utilization is worried. As the sensitive information is linked with specific individuals, this privacy damage is generated, so its anonymity, namely, unlinkability should be provided to solve this. Currently, the method of V. Ciriani, etc. for guaranteeing data privacy such as unlinkability, etc. is solving the unlinkability problem by using fragmentation and encryption. But this method includes a problem that the database capacity increases due to duplicate encryption data of attributes caused by fragmentation. This paper proposes a privacy enforcing method based on AONT to solve this problem. The proposed method is suitable for large data processing through variability of transformed pieces according to AONT properties and an XOR operation and can minimize the increase of database capacity.
Privacy Preserving EM-Based Clustering	The problem of privacy-preserving EM-based clustering was solved when the dataset is horizontally partitioned into more than two parts (i.g., more than two computation parties). The aim of this work is to develop a method for the more difficult problem when the dataset is horizontally partitioned into only two parts. The key question is how to compute and reveal only the covariance matrix at various steps of the EM iterative process to the participating parties. We propose a method consisting of several protocols that provide privacy preservation for the computation of covariance matrices and final results without revealing the private information and the means. We also extend the proposed method for a better solution to the problem of privacy preserving k-means clustering.
An Enhanced Scheme for Privacy-Preserving Association Rules Mining on Horizontally Distributed Databases	In this paper, we propose an Enhanced M.Hussein et al.'s Scheme (EMHS) for privacy-preserving association rules mining on horizontally distributed databases. EMHS is based on the M.Hussein et al.'s Scheme (MHS) proposed in 2008 and improves privacy and performance when increasing the number of sites. EMHS uses two servers, Initiator and Combiner, combined with MFI approach to generate candidate set and homomorphic Paillier cryptosystem to compute global supports. Experimental results show that the performance of EMHS is better than MHS in specific databases when increasing the number of sites. A second scheme is also proposed for the other databases.
Factors influencing privacy legislation and regulation in U.S. judicial systems	This paper investigated factors influencing legislation and privacy regulation of personal data in Internet transactions and medical data. The purpose of privacy law is to determine how to curtail abuses resulting in theft, selling and improprieties of consumer personal data collected as a result of Internet activities or medical treatments. Statistical analysis was performed on common factors found in legislation, judicial decisions and privacy regulations to establish their relevancy to legislation and privacy regulations. The results were interpreted with relevancy to the degree of the relationships between legislation, regulations and the crossed product of legislation and regulations observing how these factors influenced each respectively.
Randomization techniques in privacy studies	Randomization is one of the most popular techniques that implemented in data mining. Randomization technique prevents selection bias and insures against accidental bias. With produces comparable groups, the technique eliminates the source of bias in any assignments. Finally, in randomization technique, it permits the use of probability theory to express the likelihood of chance as a source for the difference between outcomes. In this paper four common randomization methods are highlighted that are niche with the privacy issues.
Common privacy patterns in video surveillance and smart energy	The issue of incorporating privacy into complex information systems has grown substantially over the past few years. At the same time, the design of converging IT-systems still lacks a structural approach respecting privacy. Similar to software and security engineering, a useful toolkit for system developers would be a set of privacy design patterns. This work evaluates established privacy approaches in video surveillance and smart energy. Common patterns in these two real world scenarios are identified. Based on that, a general structure for a privacy pattern language is proposed.
Unconditional security and privacy preserving oblivious transfer	Various cybercrimes are major threats to E-business. We propose an offline oblivious data distribution framework that preserves the sender's security and the receiver's privacy using tamper-proof smart cards. This framework provides persistent content protections from digital piracy and promises private content consumption. In contrast to all known oblivious transfer protocols that require public key operations, our approach does not require any public/private key operation and consequently it is computationally very efficient. It is particularly useful for data-intensive and data-rich environments. In addition, our framework is flexible to manage various business scenarios and diverse generalized oblivious transfer models.
Shearing based data transformation approach for privacy preserving clustering	Data mining is a technique used to extract un-known patterns from large volume of data. Privacy has be-come a major concern in data mining. The data which are stored in the organization's database may have some confi-dential information and hence it has to be protected from any unauthorized usage. In order to overcome the privacy problem in this paper we propose a new technique called shearing based composite transformation. Data owner trans-forms the original data into distorted data by shearing based composite data transformation. Only this distorted data is given to the clients. For clustering we have used k-means algorithm and from our experiments we found that the total number of elements in the clusters is same with the original and distorted data.
A new model for privacy preserving sensitive Data Mining	Data Mining and Knowledge Discovery is an indispensable technology for business and researches in many fields such as statistics, machine learning, pattern recognition, databases and high performance computing. In which Privacy Preserving Data Mining has the potential to increase the reach and benefits of data mining technology. This allows publishing a microdata without disclosing private information. Publishing data about individuals without revealing sensitive information about them is an important problem. k-anonymity and l-Diversity has been proposed as a mechanism for protecting privacy in microdata publishing. But both the mechanisms are insufficient to protect the privacy issues like Homogeneity attack, Skewness Attack, Similarity attack and Background Knowledge Attack. A new privacy measure called ΓÇ£(n, t)-proximityΓÇ¥ is proposed which is more flexible model. Here first introduction about data mining is presented, and then research challenges are given. Followed by privacy preservation measures and problems with k-anonymity and l-Diversity are discussed. The rest of the paper is organised as (n, t)-proximity model, experimental results and analysis followed by conclusion.
Privacy preserving association rules in unsecured distributed environment using cryptography	In this paper, we propose algorithm to mine association rule using elliptic curve cryptography technique over horizontally partitioned data. Here we consider unsecured distributed environment. Our proposed algorithm provides security against involving parties and intruder and also provides authentication between involving parties. Finally we analyze the privacy and security provided by our proposed algorithm.
Maintaining privacy and data quality in privacy preserving association rule mining	Privacy preserving data mining (PPDM) is a novel research direction to preserve privacy for sensitive knowledge from disclosure. Many of the researchers in this area have recently made effort to preserve privacy for sensitive association rules in statistical database. In this paper, we propose a heuristic algorithm named DSRRC (Decrease Support of R.H.S. item of Rule Clusters), which provides privacy for sensitive rules at certain level while ensuring data quality. Proposed algorithm clusters the sensitive association rules based on certain criteria and hides as many as possible rules at a time by modifying fewer transactions. Because of less modification in database it helps maintaining data quality.
Advertiser Index and IEEE Security & Privacy Podcast house advertisements	
Security and Privacy subscription information	
Privacy protection of user-created content on multicore-based handheld devices	Privacy protection is an important issue in user created content. Especially, satisfying both real-time constraint and energy efficiency with handheld devices is challenging since the battery-operated devices need to compress and protect the user-created content in real-time. In this paper, we propose a multicore-based solution to compress and protect user created content, and evaluate the effectiveness of the solution in terms of both real-time constraint and energy efficiency. Based on the experimental results with MPEG2/AES-CCM software, we confirm that the multicore-based solution can improve the energy efficiency of a singlecore-based solution by a factor of 1.8 under the real-time constraint.
A novel ID-based authentication framework with adaptive privacy preservation for VANETs	In Vehicular Ad hoc Networks (VANETs), authentication is a crucial security requirement to avoid attacks to both inter-vehicle and vehicle-roadside communication. Vehicles have to be prevented from the misuse of their private data and the attacks on their privacy. In this paper, we investigate the authentication and privacy issues in VANETs. We propose a novel ID-based authentication framework with adaptive privacy preservation for VANETs. In this framework, adaptive self-generated pseudonyms are used as identifiers instead of real-world IDs. The update of the pseudonyms depends on vehicular demands. The ID-Based Signature (IBS) scheme and the ID-Based Online/Offline Signature (IBOOS) scheme are used, for authentication between the Road Side Units (RSUs) and vehicles, as well as authentication among vehicles, respectively. System evaluation has been executed using efficient IBS and IBOOS schemes. It shows that, the proposed authentication framework with privacy preservation is suitable to the VANET environment.
Privacy Preserving Vehicle Purchase Marketplace	The car customer in the U.S. market has come to expect many incentives during her purchase process. Many of these incentives are based on the private profile information of the customer, which she would not want to disclose to the set of all possible dealers. On the other hand, the dealers want to keep the exact information on various incentives on offer private as well due to various business reasons. In this paper, we present design of a privacy preserving marketplace that executes control on information disclosure while enabling the purchasing process. Marketplace designs pertaining to both single dealer and multiple dealer participation are dealt with
Security and privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00846196.png" border="0">
Towards Unconditional Anonymity: Privacy Enforcement Model in Web Services	Privacy in Web services is of great importance and a critical requirement for any business and non-business environments. The growth of Web services has been accompanied by sharing more and more user personal information with Web service providers between diverse and heterogeneous computing systems, which has raised concern about possible malicious or accidental unauthorized abuse of user information. The security assertion markup language (SAML) architecture is an XML standard for exchanging authentication and authorization data. However privacy preserving in SAML is inadequate for user privacy protection. In this paper, the SAML architecture is extended to address this shortcoming. A privacy enforcement model-based on ring signature is presented, which provides unconditional anonymity for Web service users. This model enables verification of individuals who belong to a specific group with access right without actually being identified by their IDs or names. Therefore the risk of information leak is reduced. Furthermore, even if the third party is corrupted or the ID correspondence relationship is leaked, the individual remains unrecognizable. Meanwhile most SAML authorization between individual and web services can be done without the presence of the third party, which largely decreases communication overhead and enhances the privacy. Finally, a web services conversation establishment protocol is constructed based on this model, which has been implemented in Java/Tomcat.
AntiSybil: Standing against Sybil Attacks in Privacy-Preserved VANET	In this paper, we aim at two conflicting goals, privacy and Sybil attacks in Vehicular Ad Hoc NETworks (VANETs). Sybil attack refers to impersonation of one physical entity for many, namely Sybil nodes. Such attacks may cause dire consequences such as traffic jams or even deadly accidents. We leverage pseudonymless beaconing in order to preserve privacy. To cope with the Sybil attack, we put forth a two fold strategy. For scheduled beacons, we mploy TRM (Tamper Resistant Module) to perform a lightweight pre-assembly data analysis on beacons whereas for ERMs (Event Reporting Messages), RSUs distribute authorized tokens among benign vehicular nodes which in turn are consumed to report ERM. Our proposed scheme preserves privacy in both beacons and ERMs, and offers conditional anonymity.
Virtual ID: A Technique for Mobility, Multi-Homing, and Location Privacy in Next Generation Wireless Networks	Cellular networking standards organizations such as the 3<sup>rd</sup> Generation Partnership Project (3GPP) are currently developing System Architecture Evolution (SAE) as their core network architecture. SAE is all-IP based. However, IP-based networks face several known issues, such as mobility, multi-homing, location privacy, path preference, etc. Mobile IP (MIP) and its variants, such as Mobile IPv6 (MIPv6), Hierarchical MIP, and Proxy MIP, have been developed primarily to alleviate the mobility problem. These variation and extensions, however, still do not provide many of the features required in Next Generation Wireless Networks (NGWN). The limitations are especially due to the overloading of IP addresses as both node identity and locator. In this paper, we propose an extension to MIPv6 called Virtual ID. This concept applies the ID/Locator split idea into a Mobile IPv6 environment. Virtual ID and its extensions provide many features that would be desired in the NGWN. Since our proposed scheme is based on the standard MIPv6 and Proxy MIPv6, the scheme is fully compatible with the legacy MIPv6.
A Web-Based Privacy-Secure Content Trading System for Small Content Providers Using Semi-Blind Digital Watermarking	A privacy-secure content trading system based on semi-blind fingerprinting is presented. Semi-blind fingerprinting provides privacy-secure content trading as secure as blind fingerprinting at feasible processing cost with sufficient robustness. This system assures a fair trading for both a content provider and a purchaser which is effective for a market where a number of small or not so reliable content providers deal with purchasers. We have been aiming at providing a useful tool for the market by overcoming the following defects. In the basic models of conventional fingerprinting, the user's security could be guaranteed only under the premise that a content provider was perfectly trustworthy. Such premise makes a system unpractical. To overcome this defect, various scheme of blind fingerprinting have been proposed in which cryptography technique is used in order to protect user's privacy. However, these are not practical due to heavy computation cost and insufficient robustness of watermark against manipulations. The semi-blind fingerprinting fulfills the need for both feasibility and robustness by altering encryption with image decomposition that blinds up an image to be unrecognizable. Image decomposition and a customized embedding algorithm are implemented to a web-based system, whose perceptual condition of decomposed images and robustness of watermark is evaluated.
A privacy-preserving broadcast encryption scheme with revocability	In secure content distribution systems, it is important to protect what is transmitted. For privacy purposes, another issue is the protection of the list of recipients. However, in most practical and commercial systems, providing complete recipient's anonymity is not always desirable. There may be a need for the content owner to recover the identity of malicious users. This paper proposes a privacy-preserving broadcast encryption scheme offering a balanced trade-off between full traceability and user's privacy.
Enforcing privacy as access control in a pervasive context	Pervasive applications promote a seamless integration of computer artifacts with our daily an business lives. However, they threaten privacy in two ways. Firstly, adaptation to a user's context necessitates a large collection of data. Secondly, context should be addressed when granting users access to information. This paper handles privacy management as an access control problem and argues that privacy should be specified from a global point of view. Investigating privacy specification at a high level of abstraction and its implementation leads to the proposition of a generative approach relying on model-driven engineering. This approach distinguishes a design level for privacy from its execution level. The design level provides a specification language for privacy which emphasizes its contextual features. It is implemented at the execution level as a service composition generated through model transformations. This composition gathers heterogenous entities, such as pieces of software code or devices. The approach is validated on the example of a medical workflow.
Digital rights and privacy policies management as a service	Controlling, protecting and managing access to multimedia content could be a difficult task if a system was not prepared for it. To solve this situation minimizing the impact on the existing system, we propose the use of a modular architecture which provides digital rights and privacy policies management features. It can be integrated just invoking some web service calls, depending on which services are needed. To show its use, we present several scenarios where we have successfully integrated it, like distribution of content for digital terrestrial television broadcasting and access to personal health information.
Leveraging real-world data while protecting privacy Framework using personal agent system for distributed data	We propose a real-world data exchange framework based on the concept of data ownership. The most important issues with these data are the protection of user privacy and preserve the value of the information derived from the data to consumers. This framework enables the protection of privacy and enables maximum leverage of real-world data belonging to each person at the same time. In our framework, real-world data and its information value are managed and protected by the personal agent system that works on each person's authority. On that basis, the information value can be exchanged and leveraged using a market mechanism that distributes transactions of queries and answers concerning the data. We also present the basic design of the framework and its personal agent system that works on multiple user devices.
Towards enforcement of purpose for privacy policy in distributed healthcare	Purpose of access is one of the core concepts in privacy which considers the data user's intent as a factor in making access control decisions and enforcement of purpose is required to ensure that data is used as what it intends for. In general, the enforcement of purpose is a complicated task. The main difficulty is how to identify the purpose of an agent when it requests to perform an action. In this paper, we discuss the design issue of purpose enforcement based on our proposed (defined) enforcement structure: pre-enforcement, ongoing-enforcement, and post-enforcement. We also propose an enforcement solution for usage control designed for distributed healthcare information system, particularly, the pre-enforcement of purpose (the validation of claimed purpose at the initial state before data is granted access).
Towards practical privacy-preserving digital rights management for cloud computing	We propose a privacy-preserving digital rights management scheme for (future) cloud computing. Users buy software from software providers and execute it at computing centers. Our solution allows software providers to provide different license models, like execute at most n-times models. Users' anonymity and unlinkability of actions are preserved and thus, profile building is not even possible under (a) pseudonym. Privacy protection in the honest-but-curious model is achieved by combining ring signatures with an anonymous recipient scheme. We employ secret sharing in a unique manner that allows the software provider to expose the user's identity if the user commits fraud, e.g. by exceeding the execution limit n.
An operating system security method for integrity and privacy protection in consumer electronics	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01593096.png" border="0">
Privacy Protection Among Drivers in Vehicle-to-Vehicle Communication Networks	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04199150.png" border="0">
A DRM System Protecting Consumer Privacy	Digital rights management (DRM) is widely used to protect intellectual property for content owners but consumer privacy is sacrificed. A user's playing statistics can be collected by the client DRM module and the license server. In this paper, we propose a DRM system in which the license server can generate the content decryption key for a user to play an encrypted content object without gaining any information to link to the specific content object encrypted by the content encryption key. This is achieved by applying a (partially) blind signature primitive in the license acquisition protocol and by adopting a key scheme that a content encryption key depends on the information retrieved from the content object and a secret that only the license server knows. By requesting that the client DRM module does not send any information about a user's playing statistics and all the messages the client DRM module sends out are in plain text for easy checking by a user if the client DRM module abides by this rule, consumer privacy is fully protected in our DRM system.
Proxy Framework for Enhanced RFID Security and Privacy	Radio frequency IDentification (RFID) is a method of remotely storing and retrieving data using small and inexpensive devices called RFID tags. In this work we propose a proxy agent framework that uses a personal device for privacy enforcement and increased protection against eavesdropping, impersonation and cloning attacks. Using the proxy a user decides when and where information carried in a tag will be released. In particular, the user can put tags under her control, authenticate requests, release tags, transfer them to new owners, and so on. This is the first framework that unifies previous attempts and presents detailed protocols for all the operations required in such a proxy environment.
Privacy Preserving DRM Solution with Content Classification and Superdistribution	Digital rights management (DRM) is indispensable to prevent various kinds of illegal content usage. However, personal privacy is vulnerable for disclosure when the detailed consumption reports are collected by the service provider to charge consumers. Usually those kinds of data could apparently render the work and rest schedule and reveal the hobby of certain customers. Although it is claimed that all of the private data should be protected without the fear for disclosure, it had better to avoid generating those sensitive records. Therefore, a new DRM solution is proposed to provide an obscure consumption report to the service provider with content classification and superdistribution while maintain the normal charge system. In addition, a novel key management scheme is presented to support the above solution. In this scheme, multiple encryption keys and decryption keys in the same content level are designed through a specific algorithm. Distributing a unique decryption key set to each user facilitates the tracing in case of deliberate key leakage and then assists realistic deployment of the DRM system.
Privacy and Scalability Analysis of Vehicular Combinatorial Certificate Schemes	Vehicular networks require secure communication, especially for safety applications. A public key infrastructure using a Combinatorial Certificate Scheme was implemented in the US Vehicle Infrastructure Integration (VII) Proof-of- Concept (PoC) trial to secure V2V communication and preserve vehicle privacy. This paper analyzes the privacy and scalability of the Combinatorial Certificate approach for a nationwide network of 200 million vehicles. It examines the tradeoffs between privacy, the ability to efficiently detect and remove bad actors, and the need to minimize the impact on innocent vehicles due to revocation and replacement of compromised shared certificates. Key findings include the level of vehicle anonymity that exists in situations of low vehicular density and the impact that certificate revocations have on innocent vehicles. A refinement to the Combinatorial Certificate Scheme is described that improves the innocent vehicle re-key quota lifetime by an order of magnitude.
A Security Framework with Strong Non-Repudiation and Privacy in VANETs	This paper proposes a security framework with strong non-repudiation and privacy using new approach of ID-based cryptosystem in VANETs. To remove the overheads of certificate management in PKI, security frameworks using an ID-based cryptosystem are proposed. These systems, however, cannot guarantee strong non-repudiation and private communication since they suffer from the inherent weakness of an ID-based cryptosystem like the key escrow problem. The key idea of this paper is that the ID of the third-party is used as the verifier of vehicle's ID and self-generated RSA public key instead of using the ID of the peers. Our scheme provides strong non-repudiation and privacy preservation without the inherent weaknesses of an ID-based cryptosystem in VANETs. Also, the proposed scheme is efficient in terms of signature and verification time for safety-related applications.
Location Privacy Enforcement in a Location-Based Services Platform	Location privacy management is an important requirement for location based services. Here we describe the design and implementation of location privacy enforcement mechanisms based on the IETF Geopriv specifications as part a location-based services platform that we previously developed. Our design involves a new and more efficient session-based access validation mechanism. In addition, we evaluate the expressiveness of Geopriv rules for describing a variety of privacy rules. We find a number of limitations and propose some methods for extending the rule notation for addressing these limitations. We conclude with an overview of our prototype implementation.
Privacy Preserving Multiparty Multilevel DRM Architecture	Traditional digital rights management (DRM) systems are only two party systems, involving the owner and consumers. However, for scalability of business it is often necessary to involve additional levels of distributors and sub-distributors, who can promote and distribute the content in regions unknown to the owner. Thus, we propose an architecture for multiparty multilevel DRM system. The term 'multiparty' refers to involvement of many parties such as the owner, distributors, sub-distributors and consumers and the term 'multilevel' refers to multiple levels of distributors/sub-distributors. The architecture also supports the log files based violation detection, in case of violation of DRM system by any party. However, violation detection imposes a problem of preserving privacy of consumers. So, in the architecture, a provision is made to preserve their privacy.
A study of mobile proxy for privacy enhancement	Radio frequency identification (RFID) is a promising technology for identifying physical objects in an automated manner, but raises privacy infringement problems significantly in the real world. The low-cost RFID tags are much more vulnerable, meaning traceable, than active tags due to their restricted (poor) capabilities. In this paper, we present a practical method for enhancing the privacy of consumers, who may hold low-cost tags in everyday life, through a mobile phone. We set the mobile phone as a mobile proxy, which registers and renames RFID tags, monitors radio communications, and simulates the low-cost tags for privacy enhancement, along with providing a user setting mechanism for privacy levels.
A privacy-enabled solution for sharing social data in ad-hoc mobile networks	There is an enormous growth of the use of mobile devices and the social Web. Thus the users want to exchange their social data easily by using their phones and PDAs. We show that existing solutions put the users at security and privacy risks. Then, we describe our protocol for exchanging users' social data. We demonstrate that enables better security and privacy for exchanging social data. In addition we show that our solution causes lower data overhead for the participants.
A privacy enhanced contents sharing in mobile networks	In this paper, we propose an access control model for privacy protection when personal contents are shared in mobile networks via personal CE devices without any centralized server or service provider. We adopt an encryption based content protection with Access Control List (ACL) approach which provides the information about content encryption key only for permitted users. Our scheme is particularly suitable for recent smart phone platforms equipped with hierarchical content structure, which can also communicate with other devices ubiquitously.
Privacy protected content sharing in extended home environment over Content-Centric Networking	Today, consumers possess a huge amount of personal contents due to increasing mobile devices and home appliances. This leads to extension of content sharing domain and thus, privacy protection of consumers becomes more important. In this paper, we propose a privacy protection mechanism providing the fine-grained access control on contents in the extended home environment. Our access control scheme is based on content encryption and supports a notion of groups and flexible access policy definition in content hierarchy using Access Control List (ACL). Though our proposed scheme is built on the hierarchical named content following CCN naming, it is also applicable to general hierarchies of named content or file systems as well.
Conditional privacy preserving security protocol for NFC applications	Recently, various mobile terminals equipped with NFC are released. However, The NFC security standard currently applied uses the user's public key constantly in the process of key agreement. Since it does not provide with unlinkability between user messages, privacy infringement may happen. This paper proposes a method provide a conditional anonymity using dynamic public key to solve this problem. Also it defines PDU for the conditional anonymity, so that the user can use the dynamic public key selectively. Through this, the user can protect privacy and can verify identity through a trusted authority if necessary.
Privacy enhanced cloud services home aggregator	During the past years we have assisted to the huge diffusion of Cloud based Services, but security and privacy are still an issue in the Cloud due to a problem of trust endemic in the Cloud paradigm; users who have subscribed some kind of Cloud service must fully trust their providers. In this paper we propose a new, yet simple way to guarantee privacy for end user's data and operations. We propose to use an application inside an STB as single point of concentration for user's Cloud services accounts. Thus, a higher degree of privacy could be achieved by splitting user's data and operations over multiple identities and even over multiple providers' networks. In this article we depict, as example, the case of on-line storage and synchronization service.
Enabling secure and privacy-aware mobile sensing and e-health applications on everybodys smartphone	Mobile surveillance of patients vital data is of prominent use in today's e-health applications. Given the fact that smartphones provide Internet connectivity almost anywhere and at any time, these seem to be the perfect key device for such application. In contrast to available solutions, our approach described in this paper allows using almost any smartphone for such purpose. In addition, the system enables to dynamically reconfigure the e-health infrastructure without putting the privacy and data security of monitored patients at risk.
Ensuring privacy in a Distributed Video Coding surveillance scenario	In this paper, a permutation scheme is introduced for Distributed Video Coding. The main goal is to preserve privacy and security in video surveillance video communications and can be adapted for other scenarios. The proposed approach consists to apply permutation based encryption to the DVC scenario. The permutation is defined by a secret key which is required at the decoder for decompression providing security. Simulation results show that the reference architecture and the permutation-based proposed have similar rate distortion performance.
Private cloud and media privacy in social networks	Privacy rules imposed by social networks (SNs) impose several restrictions to user privacy. Though they usually offer the user some control to limit access to his own data, the social network may share uploaded data with other partners and marketing companies. Pictures and videos may have a second life, even after being deleted by the user, and consequently storage and access must take place in the user home domain or facilities managed by the user, following an end to end approach. We propose to combine the usage of private clouds, specialized in media contents, in cooperation with SNs, offering the user complete control over his data, while benefiting from the SNs visibility to announce and spread the data. To achieve transparency, we propose a plug-in system to embed links as annotations in reduced media replacement uploaded in the SN. These links point to the real resource stored in the private cloud, now under complete user control. We perform validation tests which show important improvements in uploading time and user experience.
IEEE Consumer Electronics Magazine call for articles - security, privacy, and consumer electronics	Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.
PKI-based security and privacy controls using synchronized 2-way double-type smartcard terminals for healthcare information access	This research paper presents a new 2-way double-type smartcard terminal and a new system design and development of a prescription order communication system (POCS) based on the Internet between the hospital and the pharmacy, on the public-key infrastructure (PKI), and on the concurrently parallel co-operation with both medical professional and patient smart cards in the 2-way double-type terminal under synchronized status, in order to control security and privacy of patients and to manage their drug histories.
Privacy and security control architecture for ubiquitous RFID healthcare system in wireless sensor networks	In this paper, we have designed and modeled the ubiquitous RFID healthcare system architecture and framework workflow, which are described by six classified core players or subsystems. They are consisting of the patient and wearable ECG sensor, network service, healthcare service, emergency service, and PKI service providers, whose individual private and public keys should be stored on their smart card and be used to enhance security level control for the patient's medical privacy. All of the patient and providers in the proposed security control architecture need suitable secure private and public keys in order to access to ECG medical raw data and diagnosis results with RFID/GPS tracking information for emergency service. By enforcing the requirements of necessary keys among the patient and providers, the patient's ECG data can be successfully protected and be effectively controlled over the open medical directory service. Consequently, the proposed architecture for ubiquitous RFID healthcare system is appropriate to build up medical privacy policies in ubiquitous sensor networking environments.
Privacy-Friendly Mobile RFID Reader Protocol Design based on trusted Agent and PKI	As the technology of automatic identification using radio frequency called RFID which is expected to be the alternative of the next generation barcode improves, concerns to the privacy infringement grow harder. Since personal information is combined with the tagged objects in the information integration system, it can be arbitrarily misused. To solve the drawbacks of radically emerging technology, it should be implemented in a privacy conscious manner. Without providing approvable countermeasures, it is hard to utilize the technological innovation. In this paper, we will provide privacy protection scheme in terms of RFID reader. So far, RFID tag and its owner related privacy have been mainly focused on in the RFID fields, but reader-side consideration cannot be negligible when envisioning the whole RFID service architecture
A Security and Privacy Enhanced Protection Scheme for Secure 900MHz UHF RFID Reader on Mobile Phone	This paper proposes light-weight security mechanism which is constructed by mobile RFID (radio frequency identification) security mechanism based on WIPI (wireless Internet platform for interoperability) mobile platform. WIPI-based light-weight mobile RFID security platform can be applied to various mobile RFID services that require secure business in mobile environment. By modifying the tag ID of objects periodically or manually using cellular phone built-in a RFID reader chip or with a external RFID reader module, we can prevent other people from selecting the information related with objects querying information server with a tag ID or deriving the information from tag ID's code structure or finding the location of the objects and the owner of the objects. Consequently we will propose the way to protect the personal privacy effectively using privacy preference on this paper
Usability Enhanced Privacy Protection System Based on Users' Responses	Recently, the concern and significance about the privacy protection for Internet users are increased as many incidents of privacy violation have been occurred. Regarding the privacy problem, there are a few traditional privacy protection schemes. One of them is setting privacy policies of users' private information. P3P, EPAL and XACML are famous examples of that kind of privacy protection methods which requires presetting of privacy policy. However, there are three problems. First, privacy policy setting is difficult to users who have no knowledge of privacy policy and how to use of the methods. Second, it is impossible to define the privacy policies considering all cases. Lastly, privacy policy setting without considering the privacy-related consequences may cause privacy violations. In this paper, we propose a usability enhanced privacy protection system based on users' responses. The proposed system uses the users' responses to measure and reflect their privacy preferences. Moreover, the system considers data sensitivities to notice the expected privacy- related consequences when users allow release of their sensitive personal information.
Presence Technology with Its Security and Privacy Implications	With its broadening scope, presence technology is gaining significant interest and becoming an indispensable component in nowadays telecommunications industry as well as in the vertical market. Presence-based services are driving new business opportunities and changing every aspect of our daily life. Meanwhile, with the sensitive nature of rich presence information, security and privacy issues are among the greatest concerns to the end-users of presence-based services. In the present paper, we briefly introduce the presence technology, the evolution of the presence notion and the fundamental model of presence service. We also give an overview of presence- based services together with example implementations of presence-enhanced directory services in enterprise environment. Understanding the presence technology and presence-based services together with their design issues is an important prerequisite to discuss security and privacy implications of presence-based services.
Privacy-Enhanced Adult Certification Method for Multimedia Contents on Mobile RFID Environments	Recently, RFID (radio frequency identification) technology is practically applied to a number of logistics processes as well as asset management, and RFID is also expected to be permeated in our daily life with the name of 'ubiquitous computing' or 'ubiquitous network' within the near future. The R&D groups in global now have paid attention to integrate RFID with mobile devices as well as to associate with the existing mobile telecommunication network. Such a converged technology and services would lead to make new markets and research challenges. However, the privacy violation on tagged products has become stumbling block. We propose a privacy-enhanced method of certifying adults in mobile RFID environments. This paper is for checking a user whether he/she is an adult or not, when a user would like to read some adult-related data using mobile devices playing a role of tag readers on mobile RFID environments. Instead of current adult-certification method using one's own mobile devices, an adult certification in this paper uses any mobile devices and provides user's anonymity.
A Reference Monitor Model for Improving User Comfort and Privacy of Home Gateway in OSGi Service Platform	In home network environments, user comfort, and privacy are very important issues that need to be addressed. The reference monitor is the collection of access controls for devices, files, memory, and other kinds of objects and it is also able to provide advanced facilities for access control. In order to meet the user's requirements for comfortability and privacy, a reference monitor model is proposed for improving the home gateway in the OSGi service platform. The proposed model is based on the RBAC model, and the policy is classified into two types: user-role assignment policy and permission-role assignment policy. The policies are in XML format. With the use of the proposed reference monitor model, more effective guidelines can be provided for user access control in home networks.
A Model for Privacy Preserving Metering Service	In this paper, we propose a DRM system to protect users' privacy. The proposed system utilizes special protocols designed to preserve privacy using pseudonyms and an obfuscation mechanism. Those provide different levels of controls on metered data and personal identifiers, by expressing their preference on privacy sensitive information.
Robust local privacy problem: RFID tag authentication protocol	This paper propose a RFID tag authentication protocol to solve privacy issues. Especially, the proposed protocol is robust local privacy problem in RFID system. To solve the local privacy problem, output value of tag must be changed regardless of secret value update. So, the proposed protocol is designed to satisfy this.
PPAS: A privacy preservation authentication scheme for vehicle-to-infrastructure communication networks	Security issues related to vehicular ad hoc networks (VANETs) have attracted great attention recently. In this paper, we propose a privacy preservation authentication scheme (PPAS) for vehicle-to-infrastructure (V2I) communication environments in VANETs. The authentication process of PPAS is performed locally without returning to the trust authority (TA) to reduce the authentication latency. Moreover, PPAS satisfies the following security requirements: anonymity, location untraceability, mutual authentication to prevent server spoofing attack, stolen-verified attack resistance, forgery attack resistance, no clock synchronization problem, modification attack resistance, replay attack resistance, and session key agreement. To the best of our knowledge, this is the first work to provide a lightweight authentication scheme (i.e., only uses the symmetric cryptography, an XOR operation, and a hash function) with high security property in V2I communication networks.
A modified scheme for privacy-preserving data aggregation in WSNs	Wireless Sensor Networks (WSNs) have been wildly used in our daily life. How to collect data efficiently and keep users' privacy are more and more important. The goal of this paper is to find a new effective scheme to solve this problem. In this paper, I propose a modified scheme for privacy preserving data aggregation which is inspired by CPDA. This scheme could aggregate data without revealing any private information and consume less resources than CPDA. In addition, I made a comparison with CPDA in computation overhead and communication overhead. At last, the simulation results are presented which show the efficacy and efficiency of this scheme.
The protection of the privacy right in electronic commerce	With the popularization and application of the electronic commerce, online shopping, internet supermarkets and a large number of online bookstore web retailers emerge and e-commerce advances quickly in China. The development of e-commerce brings not only convenience to consumers but also challenges to the protection of consumer rights. Problem about privacy is unavoidable in e-commerce. An important prerequisite for the development of e-commerce is the well control over privacy information that could be used as the competitors' advantage in e-commerce, so privacy protection is particularly important. By analyzing the domestic privacy protection in the present situation of e-commerce environment, this paper provides legislation advices to protect individual privacy in e-commerce. Our country is in the early stage of electronic commerce now, there will be a win-win outcome for individuals and businesses to establish and complete e-commerce environment and the protection system of personal privacy. If the internet privacy problem were resolved, e-commerce and online information industries will be more prosperous.
Fairness and privacy on pay-per view system for Web-based video service	Zhou-Lam (see Second International Workshop on Practice and Theory in Public Key Cryptography, PKC'99, Kamakura, Japan, p.315-26, 1999) proposed a fair pay-per view (PPV) protocol for Web-based video service. Their protocol allows viewers to freely choose the video programs to view at any time and pay for what they have viewed. However, we have found that their protocol has a security flaw. It can make an attacker free view video programs from the PPV server. Therefore, we design a remedy to withstand the security flaw. Moreover, we develop an efficient fair PPV protocol with additional privacy property. With our protocol, a viewer can assert his/her video-watching on net privacy. The security and performance of the proposed protocol are also examined
Enhancing privacy and dynamic federation in IdM for consumer cloud computing	Consumer cloud computing paradigm has emerged as the natural evolution and integration of advances in several areas including distributed computing, service oriented architecture and consumer electronics. In this complex ecosystem, security and identity management challenges have cropped up, given their dynamism and heterogeneity. As a direct consequence, dynamic federated identity management with privacy improvements has arisen as an indispensable mechanism to enable the global scalability and usability that are required for the successful implantation of Cloud technologies. With these requirements in mind, we present an IdM architecture based on privacy and reputation extensions compliance with the SAMLv2/ID-FF standards<sup>1</sup>.
Analysis of privacy and non-repudiation on pay-TV systems	Lee-Chang-Lin-Hwang (see IEEE Trans. On Consumer Electronics, vol.46, no.1, p.20-26, 2000) in 2000 proposed a set of protocols for pay-TV systems in order to secure subscriber's privacy and build a fair pay-TV system. However, we have found that an attacker can easily get other subscriber's privacy in watching TV-programs. We analyze the reason and discuss the possible amendments. Moreover, we expose a weakness on non-repudiation and suggest an improvement to support non-repudiation
Smart privacy-preserving screen based on multiple sensor fusion	Privacy problems arise with the popular usage of personal devices with display screen, e.g., laptop, smart phone or pad, in public areas, one of which is the screen peeping. This paper proposes a smart privacy-preserving screen system that can detect someone else see the consumer's screen and then protect the screen automatically and adaptively. It depends on multiple sensors, i.e., video camera module, ultrasonic distance module, light sensor module, to detect screen peeping, user distance and environmental lightness, and decide whether to adjust the screen's lightness. With limited lightness or contrast, the screen can only be seen by the consumer, while others cannot watch the screen clearly. Especially, the screen peeping detection scheme is composed of several algorithms, i.e., eye detection, eye pair decision and person counting. Based on the video frames captured by the video camera module, the scheme will detect eyes in the video frame, decide the number of persons peeping at the private screen, and inform the smart screen to protect the screen by adjusting the light or contrast. With the smart phone as an example, various experiments are done and comparative results show that the proposed scheme obtains better performance than existing works and is a good solution for automatic screen privacy protection.
A hash-based RFID security protocol for strong privacy protection	RFID (Radio Frequency Identification) tags are small, wireless electronic devices that help identify objects and people. Privacy protection and integrity assurance become rather crucial in the RFID systems, because these RFID tags may have a wide transmission range, making them subject to unauthorized scanning by malicious readers and various other attacks. Hence, Ha et al. proposed an RFID protocol and proved that their protocol can provide the forward privacy service. However, in this paper, it is shown that an attacker can track a target tag by observing unsuccessful previous session of the tag. That is, Ha et al.'s RFID protocol fails to provide the forward privacy protection as claimed. Therefore, to overcome the privacy weaknesses of Ha et al.'s RFID protocol, an RFID protocol based on the cryptographic hash functions is proposed. Moreover, the proposed RFID protocol is evaluated according to both the privacy attribute and the implementation performance.
Home gateway operating model using reference monitor for enhanced user comfort and privacy	In home network environments, user comfort and privacy are key prerequisites for customer satisfaction and data security. Although methods such as ACLs and others control the user-access for home network devices, most existing methods have yet to satisfactorily address the issues related to a user's comfort level and his or her protection of privacy. Therefore, this paper outlines the proposal for home gateway operating model using reference monitor in an OSGi service platform, whose goal is to enhance the operation required to efficiently meet a user's access, convenience, and privacy concerns. The reference monitor is a collection of access controls for objects, and is also capable of providing the facilities for access control. Furthermore, it adds the element of comfort to user access control, because it is intended as a core part of how subjects interact with objects. The proposed model is based on an RBAC model to effectively manage access control. Its policy is classified into two types (e.g., user-role assignment policy and permission-role assignment policy) in an attempt to not only better protect user privacy, but also to improve the performance of the policy operation. It is argued that the new home gateway model provides sufficient and effective guidelines to suggest future access control policies.
Conditional privacy preserving security protocol for NFC applications	In recent years, various mobile terminals equipped with NFC (Near Field Communication) have been released. The combination of NFC with smart devices has led to widening the utilization range of NFC. It is expected to replace credit cards in electronic payment, especially. In this regard, security issues need to be addressed to vitalize NFC electronic payment. The NFC security standards currently being applied require the use of user's public key at a fixed value in the process of key agreement. The relevance of the message occurs in the fixed elements such as the public key of NFC. An attacker can create a profile based on user's public key by collecting the associated messages. Through the created profile, users can be exposed and their privacy can be compromised. In this paper, we propose conditional privacy protection methods based on pseudonyms to solve these problems. In addition, PDU (Protocol Data Unit) for conditional privacy is defined. Users can inform the other party that they will communicate according to the protocol proposed in this paper by sending the conditional privacy preserved PDU through NFC terminals. The proposed method succeeds in minimizing the update cost and computation overhead by taking advantage of the physical characteristics of NFC<sup>1</sup>.
Privacy and non-repudiation on pay-TV systems	Privacy is becoming more and more precious in modern society. A viewer's TV-watching habits may reveal information about him/her that will make the viewer uncomfortable or cause him/her inconvenience. People should have the right to assert their privacy about the TV-programs they are in the habit of watching. This article develops a practical conditional access system (CAS) mechanism for pay-TV systems to secure such personal privacy in watching TV-programs. Disputes about transactions are usually unavoidable and can endanger the life of any business, including commercial TV systems. In order to prevent possible disputes or settle existing disputes, pay-TV systems need non-repudiation services to provide some evidence-digital signatures, for example-such that a fairer environment can be created. The conventional approaches for pay-TV systems have not provided any non-repudiation services to facilitate dispute resolution. This article also intends to demonstrate the use of digital signature techniques to make pay-TV systems fairer than before
Pay-TV system with strong privacy and non-repudiation protection	Current pay-TV systems enable service providers to acquire personal data easily, e.g. the customers' TV-watching habits, which can make customers uncomfortable or cause them inconvenience. Although many privacy protection schemes have been proposed, they only protect customer privacy from abuse by outsiders, not the service providers. This paper develops a new conditional access system (CAS) mechanism - "e-ticket" - for pay-TV systems to protect customer privacy from abuse by both outsiders and providers, while protecting both the customers and the providers against double-spending, loss, misuse, and/or stealing of the e-ticket. This article also demonstrates that the combination of the partial blind digital signature and anonymous digital signature makes pay-TV systems more robust and fairer than before.
DCT sign based robust privacy preserving image copy detection for cloud-based systems	In this paper we propose an architecture for message-privacy preserving copy detection and content identification for images based on the signs of the Discrete Cosine Transform (DCT) coefficients. The architecture allows for searching in encrypted data and places the computational burden on the server. Sign components of the low frequency DCT coefficients of an image are used to generate a dual set of keys that in turn are used to encrypt the source image and serve as a robust hash that can be queried for content identification. The statistical properties of these DCT sign vectors are modelled and we analyse their robustness against real world image distortions. Finally, the trade-off between the discriminative power of such vectors, the offered security and the resilience against errors is demonstrated.
Research on the transmission of the message privacy protection in RFID	Radio frequency identification (RFID) has been used in an increasing field, such as national defense, industry, Environmental protection, security, and logistics owing to its good performance. Specially, RFID gets much attention in the construction of IOT, developing faster and faster. This paper introduces the principle and realization mode of RFID and develops a new-type of RFID system aiming at privacy threats in traditional RFID system, which solves the privacy threats reliably and effectively. And this new-type of RFID system has got application in the protection of important things.
Perceived security, privacy, and trust concerns within Social Networking Sites: The role of Information sharing and relationships development in the Malaysian Higher Education Institutions' marketing	Nowadays, higher education is facing big challenges that made a lot of Higher Education Institutions (HEIs) become increasingly interested in attracting more students. Social Networking Sites (SNSs) such as Facebook have experienced exponential growth in recent years. These SNSs offer attractive means of online social interactions and communications, but also raise privacy security, and trust concerns. This study identified the effect of security, privacy, and trust in SNSs in order to share information and develop new relationships, which will affect students' enrollment and employees' application in HEIs. From the survey of 66 participants, the findings suggested that perceived privacy and perceived trust in other members in SNSs is significantly related with the Information sharing. Also, members' trust in SNSs and its members positively associated with development of new relationships, which is positively associated with students' enrollment and employees' application in HEIs. However, there is no significant impact from information sharing to develop new relationships in SNSs.
Privacy-preserving self-localization techniques in next generation manufacturing An interdisciplinary view on the vision and implementation of smart factories	Future manufacturing processes have to be highly adaptive and transformable in order to support short product life cycles and highly customized products. For an implementation of such a flexible, so-called smart factory, which is driven by a massive proliferation and usage of tiny embedded, context-aware information and communication technologies, many challenges - technical and social ones - have to be addressed. We identify major problems and focus on the location of objects and persons within manufacturing environments as an enabling key technology. Existing methods and possible solutions are evaluated and discussed. Thereby, we focus on the crucial aspect of privacy for workers when location systems are utilized. We also present a semi-automatic positioning approach that solves the discrepancy of guaranteeing the privacy of persons and highly accurate location tracking.
An Approach to Privacy Enhancement for Access Control Model in Web 3.0	The recent Web technology has been developed by three mainsprings which include integration, virtualization, and socialization. The Web technology provides the increment of the social networking ability. However it deepens the exposure of privacy about personal information as more complicating and difficult problems. Representatively, it is impossible to define and manage the specific relation, so the personal information and interest can be inferred from collecting and summarizing the contents. Also, there are some problems that it is hard to construct the information owner's own social network. Thus this paper proposes the new access control model which enhances the user privacy of the existing access control methods in web 2.0. This method prevents privacy such as personal inclination from being exposed and enables to define and manage the specific relation. By doing this the information owners can construct their social network. This social network can be applied and extended to Web contents.
An Improvement on RFID Authentication Protocol with Privacy Protection	Due to the well-developed technology, the radio frequency identification (RFID) is widely used in all areas. For some applications, the RFID system simply worked as a memory card without security mechanism. However, in many applications, the RFID systems need security mechanism for authentication. In scenario such as e-passport, the RFID systems even need mechanism to protect userpsilas privacy. In 2004, Gao et al. proposed a RFID system for supply chain, and their system has security drawbacks. In 2007, Chen et al. proposed an improved mechanism to enhance the security. However, in this paper, we will show that Chen et al.'s protocol is not so secure as they claimed. Any adversary can masquerade as a legal user if he/she eavesdrops the transmitted message. We propose an improvement protocol to fix the flaws. The improvement protocol is secure with merits of privacy protection, resisting counterfeit attack and obtain mutual authentication.
A Novel Authentication Protocol for Sensitive Information Privacy Protection Using Dynamic Key Based Group Key Management	This paper presents a secure authentication and authorization protocol for protecting privacy in sensitive information systems. It allows involved individuals and group participants to achieve high security levels and tight authorization control. The need of long term shared secrets to authenticate individuals and group users is eradicated in the proposed protocol by dynamic keys. It overcomes the secrets compromising during authentication via open networks. Furthermore, it also offers an ability allowing information owners to have fine-gained control of their critical data. Finally, the paper gives a formal analysis to demonstrate how secure the proposed protocol together with discussions of security issues. It is argued that the proposed protocol achieves strong authentication and authorization, and solves the involved participants' plausible deniability issues.
Probability Distribution Reconstruction for Nominal Attributes in Privacy Preserving Classification	Concerns about privacy of data used in data mining have emerged recently. Users are afraid of misuse of this data and discovered knowledge. Thus several methods of preserving privacy classification have been proposed in literature. One of these methods enables miners to use continuous and nominal attributes simultaneously in classification. Reconstruction of probability distribution is an important task in privacy preserving classification for both nominal and continuous attributes which were distorted with the randomization-based technique and are stored in centralized database. We present the new algorithm - EQ - for reconstruction of probability distribution of nominal attributes, which outperforms former algorithm especially for high privacy levels. Effectiveness of the new solution (information loss in reconstruction of probability distribution of nominal attributes and accuracy of classification) has been tested and presented in this paper.
Privacy Aware Adaptable Web Services Using Petri Nets	Many researchers have developed frameworks capable of handling context information and able to be adapted and used by any Web service. However, no research has been conducted on the systematic analysis of existing frameworks. This paper analyses the context framework, an example of existing frameworks, using a Petri net, and analyzing the advantages and disadvantages of it. Then, a Petri net model is introduced, with disadvantages removed. Based on the model, a new framework is presented. The proposed PAWS (privacy aware Web services) framework provides extension to context management and communicates flexible context information for every session. The proposed framework can solve overhead problems of context in SOAP messages. It also protects user privacy according to user preferences.
Anonymous PKI Framework for Privacy-Guaranteed e-Services	This paper is on the study of anonymous PKI (public key infrastructure) framework using pseudonym - is generated by using IKE (Internet key exchange) protocol based on the DH (Diffie-Hellman) key exchange algorithm between user and PCA (Privacy CA) - and this is designed to cooperate with existing PKI. We use IKE protocol for creating pseudonym against replay attack and use RSA-based PKI certificate for guaranteeing reliability of user's anonymous public key against MITM (man-in-the- middle) attack. This anonymous PKI framework can be used in privacy-guaranteed premium e-services (like e-payment, no full-fledged PKI for anonymous adult verification, anonymous SSO (single sign-on), and etc.). The computational complexity of the proposed method is similar to existing PKI solution.
Data Privacy: Fiction or Reality? How Much Privacy are Individuals Entitled to Under the Law	Data protection law stands in the way of a surveillance society where government and commercial bodies know everything about everybody. It helps prevent the growing problems of identity theft and the buying and selling of personal information. Data protection act applies when there is processing of personal data by a data controller established in the UK in the context of that establishment or using equipment in the UK.
An improvement of privacy-preserving ECC-based grouping proof for RFID	In 2010, Batina et al. proposed a privacy-preserving grouping proof protocol for RFID (Radio-Frequency Identification) based on ECC (Elliptic Curve Cryptography). Recently, Lv et al. have shown that Batina et al.'s protocol is not secure against the tracking attack. Lv et al. also proposed an enhancement protocol based on Batina et al.'s work to against the tracking attack. In this paper we proved Lv et al.'s protocol can not work. We also present an improvement version of privacy-preserving ECC-based grouping-proof protocol to against the tracking attack.
Social networking by the youth in the UAE: A privacy paradox	This paper has been written to take a deeper look into the influences which affect the way people decide to use the social networking websites. The main focus of the paper is to find why identities are being hidden by the youth in the UAE while using the social networking websites. It is believed that UAE social networking users do not reveal their identities mainly because of the culture and privacy. A survey has been conducted to collect data about the most visited online social networking websites in the UAE, the gender who uses them to the most. Also, the survey questions were prepared to explore the reasons for hiding personal information by some users, analyze the results and define the advantages and disadvantages of this hiding personal information.
Natural Privacy Preservation Protocol for electronic mail	Espionage plays a major role in military and paramilitary cyber warfare activities. While cyber espionage is mainly considered as the act of obtaining (confidential) information using illegal, technical methods, we have explored the possibilities of obtaining confidential material with technical methods using legal exploits. Due to routing conventions, messages containing confidential information may be sent through different states and herewith through conflicting communities. The servers that are used in this routing process are subject to the corresponding states legal system. In the case of electronic mail (e-mail), back-ups or copies being made are accessible to the corresponding authorities and/or private institutions. These copies of e-mails may be requested without knowledge of the sender or the sender's state and can be kept for an uncontrollable period of time. This may also heighten the risk of disclosure for encrypted messages. We have developed a concept based on IPv6 to allow static and dynamic adjustment of the selected routes to maintain the specified or expected level of confidentiality. This concept may be developed further to be used as a privacy enhancing technology. The concept increases the level of control of transmitted data, technically enforces the expected or negotiated level of privacy and confidentiality, allows data tracking and heightens the user's awareness regarding the differences between postal and electronic mail.
Preserving organizational privacy in intrusion detection log sharing	This paper presents a privacy-preserving framework for organizations that need to share their logs of intrusion detection systems with a centralized intrusion log management center. This centralized center may be an outsourced company that provides an intrusion detection management service to organizations or a system of the National Computer Emergency Response Team that probes the attacks targeting organizations that have critical information systems. For reasons of ensuring privacy, we adopt the notion of l-Diversity in the course of collecting intrusion logs from organizations. Within our framework, an organization ensures the people in the center cannot discern the exact origin of any intrusion log among the other l-1 organizations. Also, it is not possible to precisely identify the classification type of an intrusion log from among other l-1 types. Within this framework, the intrusion log management center can analyze the anonymous data, since the proposed privacy preserving solution creates little information loss. If required, it sends an alarm to the appropriate organization within a reasonable time. The center has the option of publishing useful information security statistics about specific organizations or about the whole ecosystem by using the privacy preserved intrusion logs.
Privacy Versus Society?	This chapter contains sections titled: Forgeries and Pseudonyms, Privacy and Cryptography, The Politics of Anonymity, The Case for Anonymity, Tales of the Cryptographers, A Word on Human Nature, A 2002 Update: The New Cryptographic Landscape
The role of Identity Management Systems in enhancing protection of user privacy	Identity Management Systems (IDMS) aim to support development, productivity and security while lowering costs related to managing users and their identities, credentials and attributes. Users may desire many of the benefits that well-designed IDMS could potentially offer, such as increased privacy and security. However, users have demonstrated that they are unwilling to spend money or time on security enhancements. Privacy is a major concern to consumers in the online world. The current paper outlines the concept of privacy, the concern over the protection of privacy in the cyber realm, and discusses the role of IDMS in enhancing protection of user privacy. The conclusion of this paper outlines the implications and suggests further directions for future research in this area.
3D body scanning technology: Privacy and ethical issues	Recently, 3D body scanning technology has been deployed in many airports around the world for security purposes and in many other places for research, health care and apparel industry purposes. However, the accuracy of the images of the human body that these scanners produce has raised privacy and ethical issues among researchers and the general public. Many questions about whether and how these scanners violate privacy have been raised. In this paper, privacy and ethical issues surrounding 3D body scanning technology are discussed and reviewed, as well as the question of how can we utilize this scanning technology without compromising our privacy. In addition, this paper higlights the usfullness of 3D body scanning in the clothing industry, as this is an emerging market for efficient data collection for better-fitting clothing, and reviews the issues of violating privacy when conducting anthropometric surveys.
Controllable Privacy Preserving Search Based on Symmetric Predicate Encryption in Cloud Storage	Predicate encryption is a novel cryptographic primitive that provides fine-grained control over the accesses to encrypted data. It is often used in secure cloud storage and biometric matching. In this manuscript, we first propose a variant of symmetric predicate encryption, which provides controllable privacy preserving search functionalities, including revocable delegated search and un-decryptable delegated search. Due to these functionalities, the owner of a cloud storage can easily control the lifetimes and search privileges of cloud data.
Conceptual Framework and a Critical Review for Privacy Preservation in Context Aware Systems	Advent of 4 G networks, IPv6 and increasing number of subscribers to these indicate that each mobile device will have its own IP address and virtually become a hotspot. In the coming years, systems that track and record our movements will indispensably be integrated in our everyday life. Location-based systems: dashboard navigation systems, Internet enabled smart phones with GPS features, and electronic tags that help us at various locations are extensively in use. In near future, location-aware/ context aware tools will become more common and sophisticated. Increasing number of services (apps)/devices that will track not only the location, but also the context / environment of the user will enter the market. The perils of exposure on Internet and subsequent exploitation have been widely recorded in literature. Some of the services provided do necessitate the knowledge of exact location, context and some personal details, like in case of assistance during accidents, but generally, applications like finding the restaurants or movies playing in an area do not require the exact location and context of the user. When a user's movement in public spaces is tracked and systematically recorded along with the context of his actions, his contextual privacy is under threat. This paper surveys current state of research in this area and analyses the effect of threat on the privacy of context aware system users. Based on the insight, we propose a novel framework to tackle the privacy preservation issue comprehensively: from user perspective as well as service provider perspective.
Legislation concerning the protection of the right to online privacy in China: A comparative study with EU	Triggered by a spat between China's two top Internet firms, this paper explores the legal system concerning the protection of the right to online privacy in mainland China by an international and comparative study, with special reference to that of EU. The authors point out that all the problems of existing laws and regulations concerning the protection of the right to online privacy should be regarded as the combined results of both the legal system building and the current stage characteristic of rapid development. The authors offers suggestions for China to better the legislation concerning the protection of the right to online privacy systematically, such as the constitutional protection of the right to privacy should be strengthened; the protection of the right to privacy in civil law system should be unified and be more detailed; the protection of the right to privacy in criminal law should be promulgated and be more updated; the protection of the right to privacy in administrative law should be strengthened and the special law protecting the right to online privacy should be enacted.
Protecting privacy in a decentralized environment	This paper describes the decentralized label model, a new model for controlling information flow in systems with mutual distrust and decentralized authority. The model allows users to share information with distrusted code (e.g., downloaded applets), yet still control how that code disseminates the shared information to others. The model improves on existing multilevel security models by allowing users to declassify information in a decentralized way, and by improving support for fine-grained data sharing. It supports static program analysis of information flow so that programs can be certified to permit only acceptable information flows and to avoid most run-time information flow checks. In addition to presenting the model, the paper also discusses how the model can be supported in a distributed environment, including an introduction to Jif, an extension to Java that incorporates the model and permits static checking of information flow
A view-based Monitoring for Privacy-aware Web services	The demonstration addresses the problem of monitoring the compliance of privacy agreement that spells out a consumer's privacy rights and how their private information must be handled by the service provider. We present a Privacy Agreement Monitoring system, an easy-to-use, and an efficient tool for tightly controlling the private data usage flow dynamically in the area of web services. Some reasoning can be made upon the observations to enhance the compliance of the privacy agreement and enrich the knowledge on misuses.
A privacy-preserving approach to policy-based content dissemination	We propose a novel scheme for selective distribution of content, encoded as documents, that preserves the privacy of the users to whom the documents are delivered and is based on an efficient and novel group key management scheme. Our document broadcasting approach is based on access control policies specifying which users can access which documents, or subdocuments. Based on such policies, a broadcast document is segmented into multiple subdocuments, each encrypted with a different key. In line with modern attribute-based access control, policies are specified against identity attributes of users. However our broadcasting approach is privacy-preserving in that users are granted access to a specific document, or subdocument, according to the policies without the need of providing in clear information about their identity attributes to the document publisher. Under our approach, not only does the document publisher not learn the values of the identity attributes of users, but it also does not learn which policy conditions are verified by which users, thus inferences about the values of identity attributes are prevented. Moreover, our key management scheme on which the proposed broadcasting approach is based is efficient in that it does not require to send the decryption keys to the users along with the encrypted document. Users are able to reconstruct the keys to decrypt the authorized portions of a document based on subscription information they have received from the document publisher. The scheme also efficiently handles new subscription of users and revocation of subscriptions.
Privacy in data publishing	This tutorial gives an overview of techniques for releasing data about individuals while preserving privacy.
Differential privacy via wavelet transforms	Privacy preserving data publishing has attracted considerable research interest in recent years. Among the existing solutions, ├é┬┐-differential privacy provides one of the strongest privacy guarantees. Existing data publishing methods that achieve ├é┬┐-differential privacy, however, offer little data utility. In particular, if the output dataset is used to answer count queries, the noise in the query answers can be proportional to the number of tuples in the data, which renders the results useless. In this paper, we develop a data publishing technique that ensures ├é┬┐-differential privacy while providing accurate answers for range-count queries, i.e., count queries where the predicate on each attribute is a range. The core of our solution is a framework that applies wavelet transforms on the data before adding noise to it. We present instantiations of the proposed framework for both ordinal and nominal data, and we provide a theoretical analysis on their privacy and utility guarantees. In an extensive experimental study on both real and synthetic data, we show the effectiveness and efficiency of our solution.
XColor: Protecting general proximity privacy	As a severe threat in anonymized data publication, proximity breach is gaining increasing attention. Such breach occurs when an attacker learns with high confidence that the sensitive information of a victim associates with a set of semantically proximate values, even though not sure about the exact one. Recently (├é┬┐, ├é┬┐)-dissimilarity [14] has been proposed as an effective countermeasure against general proximity attack. In this paper, we present a detailed analytical study on the fulfillment of this principle, derive criteria to efficiently test its satisfiability for given microdata, and point to a novel anonymization model, XCOLOR, with theoretical guarantees on both operation efficiency and utility preservation.
Global privacy guarantee in serial data publishing	While previous works on privacy-preserving serial data publishing consider the scenario where sensitive values may persist over multiple data releases, we find that no previous work has sufficient protection provided for sensitive values that can change over time, which should be the more common case. In this work, we propose to study the privacy guarantee for such transient sensitive values, which we call the global guarantee. We formally define the problem for achieving this guarantee. We show that the data satisfying the global guarantee also satisfies a privacy guarantee commonly adopted in the privacy literature called the local guarantee.
MobiMix: Protecting location privacy with mix-zones over road networks	This paper presents MobiMix, a road network based mix-zone framework to protect location privacy of mobile users traveling on road networks. In contrast to spatial cloaking based location privacy protection, the approach in MobiMix is to break the continuity of location exposure by using mix-zones, where no applications can trace user movement. This paper makes two original contributions. First, we provide the formal analysis on the vulnerabilities of directly applying theoretical rectangle mix-zones to road networks in terms of anonymization effectiveness and attack resilience. We argue that effective mix-zones should be constructed and placed by carefully taking into consideration of multiple factors, such as the geometry of the zones, the statistical behavior of the user population, the spatial constraints on movement patterns of the users, and the temporal and spatial resolution of the location exposure. Second, we develop a suite of road network mix-zone construction methods that provide higher level of attack resilience and yield a specified lower-bound on the level of anonymity. We evaluate the MobiMix approach through extensive experiments conducted on traces produced by GTMobiSim on different scales of geographic maps. Our experiments show that MobiMix offers high level of anonymity and high level of resilience to attacks compared to existing mix-zone approaches.
Processing private queries over untrusted data cloud through privacy homomorphism	Query processing that preserves both the data privacy of the owner and the query privacy of the client is a new research problem. It shows increasing importance as cloud computing drives more businesses to outsource their data and querying services. However, most existing studies, including those on data outsourcing, address the data privacy and query privacy separately and cannot be applied to this problem. In this paper, we propose a holistic and efficient solution that comprises a secure traversal framework and an encryption scheme based on privacy homomorphism. The framework is scalable to large datasets by leveraging an index-based approach. Based on this framework, we devise secure protocols for processing typical queries such as k-nearest-neighbor queries (kNN) on R-tree index. Moreover, several optimization techniques are presented to improve the efficiency of the query processing protocols. Our solution is verified by both theoretical analysis and performance study.
DObjects+: Enabling Privacy-Preserving Data Federation Services	The emergence of cloud computing implies and facilitates managing large collections of highly distributed, autonomous, and possibly private databases. While there is an increasing need for services that allow integration and sharing of various data repositories, it remains a challenge to ensure the privacy, interoperability, and scalability for such services. In this paper we demonstrate a scalable and extensible framework that is aimed to enable privacy preserving data federations. The framework is built on top of a distributed mediator-wrapper architecture where nodes can form collaborative groups for secure anonymization and secure query processing when private data need to be accessed. New anonymization models and protocols will be demonstrated that counter potential attacks in the distributed setting.
Privacy in Social Networks: How Risky is Your Social Graph?	Several efforts have been made for more privacy aware Online Social Networks (OSNs) to protect personal data against various privacy threats. However, despite the relevance of these proposals, we believe there is still the lack of a conceptual model on top of which privacy tools have to be designed. Central to this model should be the concept of risk. Therefore, in this paper, we propose a risk measure for OSNs. The aim is to associate a risk level with social network users in order to provide other users with a measure of how much it might be risky, in terms of disclosure of private information, to have interactions with them. We compute risk levels based on similarity and benefit measures, by also taking into account the user risk attitudes. In particular, we adopt an active learning approach for risk estimation, where user risk attitude is learned from few required user interactions. The risk estimation process discussed in this paper has been developed into a Facebook application and tested on real data. The experiments show the effectiveness of our proposal.
Privacy-Preserving and Content-Protecting Location Based Queries	In this paper we present a solution to one of the location-based query problems. This problem is defined as follows: (i) a user wants to query a database of location data, known as Points Of Interest (POI), and does not want to reveal his/her location to the server due to privacy concerns, (ii) the owner of the location data, that is, the location server, does not want to simply distribute its data to all users. The location server desires to have some control over its data, since the data is its asset. Previous solutions have used a trusted anonymiser to address privacy, but introduced the impracticality of trusting a third party. More recent solutions have used homomorphic encryption to remove this weakness. Briefly, the user submits his/her encrypted coordinates to the server and the server would determine the user's location homomorphically, and then the user would acquire the corresponding record using Private Information Retrieval techniques. We propose a major enhancement upon this result by introducing a similar two stage approach, where the homomorphic comparison step is replaced with Oblivious Transfer to achieve a more secure solution for both parties. The solution we present is efficient and practical in many scenarios. We also include the results of a working prototype to illustrate the efficiency of our protocol.
Destination prediction by sub-trajectory synthesis and privacy protection against such prediction	Destination prediction is an essential task for many emerging location based applications such as recommending sightseeing places and targeted advertising based on destination. A common approach to destination prediction is to derive the probability of a location being the destination based on historical trajectories. However, existing techniques using this approach suffer from the ΓÇ£data sparsity problemΓÇ¥, i.e., the available historical trajectories is far from being able to cover all possible trajectories. This problem considerably limits the number of query trajectories that can obtain predicted destinations. We propose a novel method named Sub-Trajectory Synthesis (SubSyn) algorithm to address the data sparsity problem. SubSyn algorithm first decomposes historical trajectories into sub-trajectories comprising two neighbouring locations, and then connects the sub-trajectories into ΓÇ£synthesisedΓÇ¥ trajectories. The number of query trajectories that can have predicted destinations is exponentially increased by this means. Experiments based on real datasets show that SubSyn algorithm can predict destinations for up to ten times more query trajectories than a baseline algorithm while the SubSyn prediction algorithm runs over two orders of magnitude faster than the baseline algorithm. In this paper, we also consider the privacy protection issue in case an adversary uses SubSyn algorithm to derive sensitive location information of users. We propose an efficient algorithm to select a minimum number of locations a user has to hide on her trajectory in order to avoid privacy leak. Experiments also validate the high efficiency of the privacy protection algorithm.
Secure and privacy-preserving database services in the cloud	Cloud computing becomes a very successful paradigm for data computing and storage. Increasing concerns about data security and privacy in the cloud, however, have arisen. Ensuring security and privacy for data management and query processing in the cloud is critical for better and broader uses of the cloud. This tutorial covers recent research on cloud security and privacy, while focusing on the works that protect data confidentiality and query access privacy for sensitive data being stored and queried in the cloud. We provide a comprehensive study of state-of-the-art schemes and techniques for protecting data confidentiality and access privacy, and explain their tradeoffs in security, privacy, functionality and performance.
VERDICT: Privacy-preserving authentication of range queries in location-based services	We demonstrate VERDICT, a location-based range query service featuring the privacy-preserving authentication capability. VERDICT adopts the common data-as-a-service (DaaS) model, which consists of the data owner (a location registry or a mobile operator) who provides the querying data, the service provider who executes the query, and the querying users. The system features a privacy-preserving query authentication module that enables the user to verify the correctness of results while still protecting the data privacy. This feature is crucial in many location-based services where the querying data are user locations. To achieve this, VERDICT employs an MR-tree based privacy-preserving authentication scheme proposed in our earlier work [3]. The use case study shows that VERDICT provides efficient and smooth user experience for authenticating location-based range queries.
A Genetic Approach to Multivariate Microaggregation for Database Privacy	Microaggregation is a technique used to protect privacy in databases and location-based services. We propose a new hybrid technique for multivariate microaggregation. Our technique combines a heuristic yielding fixed-size groups and a genetic algorithm yielding variable-sized groups. Fixed-size heuristics are fast and able to deal with large data sets, but they sometimes are far from optimal in terms of the information loss inflicted. On the other hand, the genetic algorithm obtains very good results (i.e. optimal or near optimal), but it can only cope with very small data sets. Our technique leverages the advantages of both types of heuristics and avoids their shortcomings. First, it partitions the data set into a number of groups by using a fixed-size heuristic. Then. it optimizes the partitions by means of the genetic algorithm. As an outcome of this mixture of heuristics, we obtain a technique that improves the results of the fixed-size heuristic in large data sets.
Ranking Privacy Policy	Almost all company Web sites collect some information about the user in some form. The information may be a simple IP address of the host to extensive personal information about the user. It is now a well established procedure for a company to state its privacy policy on their website, due to the prevalent laws of the land or just to establish their credibility. But the stated privacy policy may not be fully understood by Web site visitors. In this paper, we suggest a mathematical model which will assign a privacy score/rank to a privacy policy, after analyzing the different components of that company's privacy statement. This score can be one criterion to decide whether to continue using a certain Web site.
Privacy Preserving Pattern Discovery in Distributed Time Series	The search for unknown frequent pattern is one of the core activities in many time series data mining processes. In this paper we present an extension of the pattern discovery problem in two directions. First, we assume data to be distributed among various participating peers, and require overhead communication to be minimized. Second, we allow the participating peer to be malicious, which means that we have to address privacy issues. We present three problems along with algorithms to solve them. They are presented in increasing order of complexity according to the extensions we are pursuing, i.e. distribution and privacy constraints. As the main result we present our secure multiparty protocol for the privacy preserving pattern discovery problem.
The Third International Workshop on Privacy Data Management	
Privacy Support and Evaluation on an Ontological Basis	This work is concerned with user perceived privacy and how clients (which we call data subjects here) can be empowered to control their own data consistently with their own interests. To support building and evaluation of privacy-aware applications, we describe a privacy ontology, how the privacy principles relate to that and how they are influenced by the core concepts as well as by each other. We use this influence of the privacy principles to evaluate the level of privacy for a particular transaction, when applying and extending the core concepts for an application domain.
Privacy Access Control Model with Location Constraints for XML Services	Information privacy is usually concerned with the confidentiality of personal identifiable information (PII), such as electronic medical records. Nowadays XML services are used to support different applications which may contain of PII, such as healthcare applications. Thus, the information access control mechanism for XML services must be embedded with privacy-enhancing technologies. Role-based access control (RBAC) model has been widely investigated and applied into various applications for a period of time. This paper focuses on research issues of location constraints in privacy access control. This paper presents an extended framework of RBAC with privacy-based extensions with location constraints to tackle such a need. This paper also investigates XML technologies, such as extensible access control markup language (XACML) and WS-policy constraints for implementing the proposed model.
Detecting Aggregate Bursts from Scaled Bins within the Context of Privacy	In this paper, we consider burst detection within the context of privacy. In our scenario, multiple parties want to detect a burst in aggregated time series data, but none of the parties want to disclose their individual data. We introduce two data perturbation approaches that alter the local data so that raw time series data values are not shared and bursts can be identified using a Shewhart threshold. The first involves lossy data compression via windowing. Unfortunately, windowing alone does not guarantee enough privacy because the envelope of the time series can still be determined. Therefore, we introduce a second data perturbation approach that employs scaled binning. This method transmits values for each data point based on the distance of the data point to a local mean of the time series. The strength of this approach is its increased privacy. We empirically demonstrate the burst detection results using both real and synthetic distributed data sets. When attempting to optimize both privacy guarantees and burst detection accuracy, we find that a combined approach using both windowing and scaled binning balances burst accuracy and privacy better than either approach individually.
Privacy Protected Query Processing on Spatial Networks	With the proliferation of mobile devices (e.g., PDAs, cell phones, etc.), location-based services have become more and more popular in recent years. However, users have to reveal their location information to access location-based services with existing service infrastructures. It is possible that adversaries could collect the location information, which in turn invades user's privacy. There are existing solutions for query processing on spatial networks and mobile user privacy protection in Euclidean space. However there is no solution for solving queries on spatial networks with privacy protection. Therefore, we aim to provide network distance spatial query solutions which can preserve user privacy by utilizing K-anonymity mechanisms. In this paper, we present two novel query algorithms, PSNN and PSRQ, for answering nearest neighbor queries and range queries on spatial networks without revealing private information of the query initiator. The effectiveness of our privacy protected algorithms has been validated using real world road networks. In addition, we demonstrate the appeal of our technique using extensive simulation results.
Realizing Privacy-Preserving Features in Hippocratic Databases	Presenting privacy has become a crucial requirement for operating a business that manages personal data. Hippocratic databases have been proposed to answer this requirement through a database design that includes responsibility for the privacy of data as a founding tenet. We identify, study, and implement several privacy-preserving features that extend the previous work on Limiting Disclosure in Hippocratic databases. These features include the support of multiple policy versions, retention time, generalization hierarchies, and multiple SQL operations. The proposed features facilitate in making Hippocratic databases one step closer to fitting real-world scenarios. We present the design and implementation guidelines of each of the proposed features. The evaluation of the effect in performance shows that the cost of these extensions is small and scales well to large databases.
Inferring privacy information via social relations	Currently, millions of individuals are sharing personal information and building social relations with others, through online social network sites. Recent research has shown that those personal information could compromise owners' privacy. In this work, we are interested in the privacy of online social network users with missing personal information. We study the problem of inferring those users' personal information via their social relations. We present an iterative algorithm, by combining a Bayesian label classification method and discriminative social relation choosing, for inferring personal information. Our experimental results reveal that personal information of most users in an online social network could be inferred through mere social relations with high accuracy.
PLUS: Synthesizing privacy, lineage, uncertainty and security	Privacy, lineage, uncertainty, and security are important to many information integration efforts, and these "PLUS" properties interact in a number of complex ways. This paper presents requirements and use cases for PLUS systems that gracefully handle those interactions. We describe related work, and present the goals of a new research project which is developing a theory and implementation of PLUS systems.
On breaching enterprise data privacy through adversarial information fusion	Data privacy is one of the key challenges faced by enterprises today. Anonymization techniques address this problem by sanitizing sensitive data such that individual privacy is preserved while allowing enterprises to maintain and share sensitive data. However, existing work on this problem make inherent assumptions about the data that are impractical in day-to-day enterprise data management scenarios. Further, application of existing anonymization schemes on enterprise data could lead to adversarial attacks in which an intruder could use information fusion techniques to inflict a privacy breach. In this paper, we shed light on the shortcomings of current anonymization schemes in the context of enterprise data. We define and experimentally demonstrate Web-based Information-Fusion Attack on anonymized enterprise data. We formulate the problem of finding a fusion resilient enterprise data anonymization and propose a prototype solution to address this problem.
Privacy-preserving data publishing	Data publishing has generated much concern on individual privacy. Recent work has focused on different background knowledge and their various threats to the privacy of published data. However, there still exist a few types of adversary knowledge waiting to be investigated. In this paper, I explain my research on privacy-preserving data publishing (PPDP) by using full functional dependencies (FFDs) as part of adversary knowledge. I also briefly explain my research plan.
Privometer: Privacy protection in social networks	The increasing popularity of social networks, such as Facebook and Orkut, has raised several privacy concerns. Traditional ways of safeguarding privacy of personal information by hiding sensitive attributes are no longer adequate. Research shows that probabilistic classification techniques can effectively infer such private information. The disclosed sensitive information of friends, group affiliations and even participation in activities, such as tagging and commenting, are considered background knowledge in this process. In this paper, we present a privacy protection tool, called Privometer, that measures the amount of sensitive information leakage in a user profile and suggests self-sanitization actions to regulate the amount of leakage. In contrast to previous research, where inference techniques use publicly available profile information, we consider an augmented model where a potentially malicious application installed in the user's friend profiles can access substantially more information. In our model, merely hiding the sensitive information is not sufficient to protect the user privacy. We present an implementation of Privometer in Facebook.
Improved Mobile Device Security through Privacy Risk Assessment and Visualization	We offer a vision for improving mobile device security through the assessment and subsequent visualization of information privacy risk. We note that many security measures from the traditional notebook, desktop, and server domains do not translate well to mobile devices. Moreover, users of mobile devices may often lack security expertise and awareness. Thus, other options must be considered with respect to securing smart phones, tablets, and the like. In particular, we propose a means to assess the information privacy risk for a given mobile device and alert the user when there appears to be significant risk. At its heart, our approach attempts to visualize the privacy disposition of a mobile device, thereby guiding the user to work in a more secure fashion.
Empirical privacy and empirical utility of anonymized data	Procedures to anonymize data sets are vital for companies, government agencies and other bodies to meet their obligations to share data without compromising the privacy of the individuals contributing to it. Despite much work on this topic, the area has not yet reached stability. Early models (k-anonymity and Γäô-diversity) are now thought to offer insufficient privacy. Noise-based methods like differential privacy are seen as providing stronger privacy, but less utility. However, across all methods sensitive information of some individuals can often be inferred with relatively high accuracy. In this paper, we reverse the idea of a ΓÇÿprivacy attack,ΓÇÖ by incorporating it into a measure of privacy. Hence, we advocate the notion of empirical privacy, based on the posterior beliefs of an adversary, and their ability to draw inferences about sensitive values in the data. This is not a new model, but rather a unifying view: it allows us to study several well-known privacy models which are not directly comparable otherwise. We also consider an empirical approach to measuring utility, based on a workload of queries. Consequently, we are able to place different privacy models including differential privacy and early syntactic models on the same scale, and compare their privacy/utility tradeoff. We learn that, in practice, the difference between differential privacy and various syntactic models is less dramatic than previously thought, but there are still clear domination relations between them.
Privacy-protecting index for outsourced databases	In this paper, we present dithered B-tree, a B-tree index structure that can serve as a building block for realizing efficient system implementations in the area of secure and private database outsourcing. A dithered B-tree prevents a third party that searches this index structure from learning whether or not the search term (i.e., key) is present in the database. This privacy-related property is crucial in application domains where the party responsible for answering a query is not allowed to learn whether a specific value exists in the database.
On syntactic anonymity and differential privacy	Recently, there has been a growing debate over approaches for handling and analyzing private data. Research has identified issues with syntactic anonymity models. Differential privacy has been promoted as the answer to privacy-preserving data mining. We discuss here issues involved and criticisms of both approaches, and conclude that both have their place. We identify research directions that will enable greater access to data while improving privacy guarantees.
Privacy against aggregate knowledge attacks	This paper focuses on protecting the privacy of individuals in publication scenarios where the attacker is expected to have only abstract or aggregate knowledge about each record. Whereas, data privacy research usually focuses on defining stricter privacy guarantees that assume increasingly more sophisticated attack scenarios, it is also important to have anonymization methods and guarantees that will address any attack scenario. Enforcing a stricter guarantee than required increases unnecessarily the information loss. Consider for example the publication of tax records, where attackers might only know the total income, and not its constituent parts. Traditional anonymization methods would protect user privacy by creating equivalence classes of identical records. Alternatively, in this work we propose an anonymization technique that generalizes attributes, only as much as needed to guarantee that aggregate values over the complete record, will create equivalence classes of at size k. The experimental evaluation on real data shows that the proposed method produces anonymized data that lie closer to the original ones, with respect to traditional anonymization algorithms.
1st International Workshop on Privacy-Preserving Data Publication and Analysis (PrivDB 2013) [front matter]	Conference proceedings front matter may contain various advertisements, welcome messages, committee or program information, and other miscellaneous conference information. This may in some cases also include the cover art, table of contents, copyright statements, title-page or half title-pages, blank pages, venue maps or other general information relating to the conference that was part of the original conference proceedings.
Strong location privacy: A case study on shortest path queries	The last few years have witnessed an increasing availability of location-based services (LBSs). Although particularly useful, such services raise serious privacy concerns. For example, exposing to a (potentially untrusted) LBS the client's position may reveal personal information, such as social habits, health condition, shopping preferences, lifestyle choices, etc. There is a large body of work on protecting the location privacy of the clients. In this paper, we focus on shortest path queries, describe a framework based on private information retrieval (PIR), and conclude with open questions about the practicality of PIR and other location privacy approaches.
Advanced Metadata for Privacy-Aware Representation of Credentials	SemanticWeb languages like OWL and RDFS promise to be viable means for representing metadata describing users and resources available over the Internet. Recently, interest has been raised on the use of such languages to represent individual data items contained in Personally Identifiable Information (PII), supporting fine-grained release. To achieve this goal, the informative content of a credential must be dissected into atomic components so that users can selectively single out those to be released. In this paper, we outline methodologies for taking advantage of a distributed ontology-based framework for controlled release at both policy writing and evaluation time.
SemCrypt - Ensuring Privacy of Electronic Documents Through Semantic-Based Encrypted Query Processing	The trend towards outsourcing increases the number of documents stored at external service providers. This storage model, however, raises privacy and security concerns because the service providers cannot be trusted with respect to maintaining the privacy of the documents. The research project SemCrypt^1 explores techniques for processing queries and updates over encrypted XML documents stored at untrusted servers. By performing encryption and decryption only on the client and not on the server, SemCrypt guarantees that neither the document structure nor the document content are disclosed on the server. Filtering query results and processing as much as possible of the query/update statement on the server does not depend on special encryption techniques. Instead, the chosen approach exploits the structural semantics of XML documents and uses standard, well-proven encryption techniques. SemCrypt thus enables to query and update encrypted XML documents on untrusted servers while ensuring data privacy.
Protection of Location Privacy using Dummies for Location-based Services	Recently, highly accurate positioning devices enable us to provide various types of location-based services. On the other hand, because position data obtained by such devices include deeply personal information, protection of location privacy is one of the most significant issues of location-based services. Therefore, we propose a technique to anonymize position data. In our proposed technique, the psrsonal user of a location-based service generates several false position data (dummies) sent to the service provider with the true position data of the user. Because the service provider cannot distinguish the true position data, the user┬Æs location privacy is protected. We conducted performance study experiments on our proposed technique using practical trajectory data. As a result of the experiments, we observed that our proposed technique protects the location privacy of users.
Privacy mechanisms supporting the building of trust in e-commerce	Consumer trust is crucial for the survival of Webbased businesses, since the lack of faith on Web merchants or stores can prevent the accomplishment of transactions. Techniques guaranteeing privacy in the management of customers┬Æ data in Web stores can help building trust by giving users a feeling of control on the vendor┬Æs handling of their personal information. This article analyzes the privacy concerns of Internet users and evaluates and proposes methods to handle privacy issues in Web stores that can help the development of trust in e-commerce.
Privacy Contracts as an Extension of Privacy Policies	Individuals are becoming increasingly concerned regarding the protection of their personal information. In an attempt to ease the privacy concerns of individuals, organisations publish privacy policies, promising how they will handle personal information. However, privacy policies as such do not guarantee the protection of personal information and do not offer much customisation on an individual level. Individual privacy contracts are proposed as a solution to this problem. A privacy contract constitutes a legal base on which to contest privacy breaches, should any occur. Every data subject has to enter into a privacy contract (consisting of privacy agreements) with the data controller, otherwise no transactions can be performed between the two parties. A data subject must consent to a privacy agreement before the data controller can use the data of the transaction associated with the agreement. This paper presents the principles and a conceptual view of the management of privacy contracts.
Improved Privacy-Preserving Bayesian Network Parameter Learning on Vertically Partitioned Data	Privacy concerns often prevent different parties from sharing their data in order to carry out data mining applications on their joint data. Privacy-preserving data mining seeks to address this by enabling parties to jointly compute a data mining algorithm on distributed data without sharing their data. In this paper, we address a particular data mining problem, that of learning the parameters of Bayesian network on a vertically partitioned database. We provide a simple privacy-preserving protocol for learning the parameters of Bayesian network on vertically partitioned databases. In comparison to the previously known solution for this problem (Meng, Sivakumar, and Kargupta, 2004), our solution provides better performance, full privacy, and complete accuracy. In combination with our previous work on privacy-preserving learning of Bayesian network structure on vertically partitioned databases, this work provides a complete privacy-preserving protocol for learning Bayesian networks (both structure and parameters) on vertically partitioned data, with very little overhead beyond computing the structure alone.
Trusted Privacy Manager: A System for Privacy Enforcement	In this paper, we show how a third-party architecture can be used for a secure management of personal data over the web. Main benefits of the proposed system are its scalability, the compliance with emerging web standards, and the enforcement of privacy requirements of both data owners and consumers. This is obtained by making use of non-standard encryption strategies and by relying on a Trusted Privacy Manager in charge of data encryption and key delivering. In the paper, besides providing an overview of the proposed architecture we focus on the Trusted Privacy Manager and on the strategies it adopts for key generation and management.
Privacy-Preserving Basic Operations on Outsourced Search Trees	Security issues in outsourcing database services have recently attracted special attention in the research community. However, to the best of our knowledge, none of the previous work has radically addressed the problem of preserving privacy for basic operations on outsourced search trees. Basic operations of search trees include search and updates. Search trees have played a fundamental and vital role in both traditional and modern database application domains due to their efficiency in managing the storage and retrieval of data. The outsourced search trees and data are all encrypted and stored at some untrusted server. In this paper, we will discuss security issues in outsourced databases that come together with search trees, and present techniques to ensure privacy in the execution of these trees┬Æ basic operations on the untrusted server. By privacy, we mean the outsourced tree structure and data as well as user┬Æs queries are all hidden from unauthorized people.
Defining and Protecting Meta Privacy: A New Conceptual Framework Within Information Privacy	When considering information security and privacy issues most of the attention has previously focused on data protection and the privacy of personally identifiable information (PII). What is often overlooked is consideration for the operational and transactional data. Specifically, the security and privacy protection of metadata and metastructure information of computing environments has not been factored in to most methods. Metadata, or data about data, can contain many personal details about an entity. It is subject to the same risks and malicious actions personal data is exposed to. This paper presents a new perspective for information security and privacy. It is termed Meta Privacy and is concerned with the protection and privacy of information system metadata and metastructure details. We first present a formal definition for Meta Privacy, and then analyze the factors that encompass and influence Meta Privacy. In addition, we recommend some techniques for the protection of Meta Privacy within the information systems. Further, the paper highlights the importance of ensuring all informational elements of information systems are adequately protected from a privacy perspective.
PRINDA: Architecture and Design of Non-Disclosure Agreements in Privacy Policy Framework	Non Disclosure Agreements(NDAs) in real life are typically used whenever there is transfer of private or confidential information from one organization to another. The provider organization can not have any control over privacy mechanisms of the receiving organization. The privacy policy work so far has addressed itself for preventing privacy violation within an organization. We aim to give an architecture of PRINDA(PRIvacy NDA) system which incorporates NDA┬Æs in privacy policy framework. Advantages of PRINDA system will be the following: i) As there can be traces of malicious activity(invasion of privacy) either at provider-end or at recipient-end, if detected/reported, NDA can help to relegate the responsibility to the organization violating the agreement, and will strengthen control in the privacy arena. ii) detailed information of usage of data can be provided to the owner of data e.g. information of all accesses at every level, and hence strengthening the principle of providing the individual data usage information.
PRIVATE-IYE: A Framework for Privacy Preserving Data Integration	Data integration has been a long standing challenge to the database and data mining communities. This need has become critical in numerous contexts, including building e-commerce market places, sharing data from scientific research, and improving homeland security. However, these important activities are hampered by legitimate and widespread concerns of data privacy. It is necessary to develop solutions that enable integration of data, especially in the domains of national priorities, while effective privacy control of the data. In this paper, we present an architecture and key research issues for building such a privacy preserving data integration system called PRIVATE-IYE.
Privacy Preserving Clustering on Horizontally Partitioned Data	Data mining has been a popular research area for more than a decade due to its vast spectrum of applications. The power of data mining tools to extract hidden information that cannot be otherwise seen by simple querying proved to be useful. However, the popularity and wide availability of data mining tools also raised concerns about the privacy of individuals. The aim of privacy preserving data mining researchers is to develop data mining techniques that could be applied on databases without violating the privacy of individuals. Privacy preserving techniques for various data mining models have been proposed, initially for classification on centralized data then for association rules in distributed environments. In this work, we propose methods for constructing the dissimilarity matrix of objects from different sites in a privacy preserving manner which can be used for privacy preserving clustering as well as database joins, record linkage and other operations that require pair-wise comparison of individual private data objects horizontally distributed to multiple sites.
Finding the Leak: A Privacy Audit System for Sensitive XML Databases	Whenever private information that is legally used by multiple employees of a company has been illegally exposed to a third party, it is of significant importance to the concerned company to find the information leak in its staff for a variety of reasons, e.g., to keep confidence of its customers. In this paper, we present a privacy audit system for XML databases and the XPath query language which uses the concept of an audit query to describe the secret information. For a given audit query, our system returns a set of suspicious user queries that may have used the secret information. Suspicious user queries are identified in a sequence of four steps: first, a static analysis based on the time constraints; second, a comparison of the nodename tests of the audit query and the user queries; third, an analysis of the associations of the node-name tests found in the audit query and in the user queries; and finally, a test on ┬Æhistoric data┬Æ. Furthermore, we discuss privacy violation detection in case of an attacker who submits multiple queries and externally compares the results.
Privacy Protection: p-Sensitive k-Anonymity Property	In this paper, we introduce a new privacy protection property called p-sensitive k-anonymity. The existing kanonymity property protects against identity disclosure, but it fails to protect against attribute disclosure. The new introduced privacy model avoids this shortcoming. Two necessary conditions to achieve p-sensitive kanonymity property are presented, and used in developing algorithms to create masked microdata with p-sensitive k-anonymity property using generalization and suppression.
Mining Popular Paths in a Transportation Database System with Privacy Protection	This paper proposes an algorithm to identify popular paths in a transportation system, while the privacy of drivers is preserved. A popular path is one of the most frequently used routes between any two points in a road map. In order to identify popular paths with privacy protection, the algorithm figures out what information is useless for identifying popular paths, and this information is not revealed to the data mining system so that privacy is preserved. In addition, the system does not record the identifications of the vehicles. Moreover, in the mining process, the database does not contain complete path information. The experimental results verify the correctness of the proposed algorithm and show that the proposed algorithm is scalable.
Towards Privacy-Aware Location-Based Database Servers	The wide spread of location-based services results in a strong market for location-detection devices (e.g., GPS-like devices, RFIDs, handheld devices, and cellular phones). Examples of location-based services include location-aware emergency service, location-based advertisement, live traffic reports, and location-based store finder. However, location-detection devices pose a major privacy threat on its users where it transmits private information (i.e., the location) to the server who may be untrustworthy. The existing model of location-based applications trades service with privacy where if a user wants to keep her private location information, she has to turn off her location-detection device, i.e., unsubscribe from the service. This paper tackles this model in a way that protects the user privacy while keeping the functionality of location-based services. The main idea is to employ a trusted third party, the Location Anonymizer, that expands the user location into a spatial region such that: (1) The exact user location can lie anywhere in the spatial region, and (2) There are k other users within the expanded spatial region so that each user is k-anonymous. The location-based database server is equipped with additional functionalities that support spatio-temporal queries based on the spatial region received from the location anonymizer rather than the exact point location received from the user.
The personal model of data towards a privacy oriented information system	A general report is presented on an approach problem of privacy-oriented information systems. The report is based on extensive research experiences in specifying the structure of such a system, including the underlying data model and the privacy policy, as well as on the insight gained from a prototype implementation of selected parts of the specification. The system is called DORIS (datenschutz-orientiertes informations system). While the model is basically object-oriented, it is possible conveniently to describe an application by non-first-normal-form tuples and relations, and the data-manipulation language is high-level and relational. An expression is evaluated in three stages: navigation in the set of surrogates of persons, asking for knowledge, and finally normalization, prime value processing and output preparation. A prototype implementation of selected parts of the model is based on a kernel concept
"My personal web": a seminar on personalization and privacy for web and converged services	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01320098.png" border="0">
Privacy preservation for data cubes	Data privacy refers to the issue of how to preserve the confidential information in individual data cells while still being able to provide an accurate estimation of the original summation values for range queries. There are three major goals in data privacy:l)Security - the data must be protected from being revealed; 2)Accuracy - results of analysis are valuable in a business's decision making and 3)Accessibility - data should be as easy to be accessed as possible. However, the open nature of data warehouses creates a security conflict. Another conflict is between security and accuracy of the query results. With the increase in the number of data warehouses and OLAP users, the misuse of data warehouse is steadily growing, which has led to the needs for proper techniques to support all three goals of data privacy. We propose a novel and simple but effective solution to fulfill all three goals.
Extending relational database systems to automatically enforce privacy policies	Databases are at the core of successful businesses. Due to the voluminous stores of personal data being held by companies today, preserving privacy has become a crucial requirement for operating a business. This paper proposes how current relational database management systems can be transformed into their privacy-preserving equivalents. Specifically, we present language constructs and implementation design for fine-grained access control to achieve this goal.
Data privacy through optimal k-anonymization	Data de-identification reconciles the demand for release of data for research purposes and the demand for privacy from individuals. This paper proposes and evaluates an optimization algorithm for the powerful de-identification procedure known as k-anonymization. A k-anonymized dataset has the property that each record is indistinguishable from at least k - 1 others. Even simple restrictions of optimized k-anonymity are NP-hard, leading to significant computational challenges. We present a new approach to exploring the space of possible anonymizations that tames the combinatorics of the problem, and develop data-management strategies to reduce reliance on expensive operations such as sorting. Through experiments on real census data, we show the resulting algorithm can find optimal k-anonymizations under two representative cost measures and a wide range of k. We also show that the algorithm can produce good anonymizations in circumstances where the input data or input parameters preclude finding an optimal solution in reasonable time. Finally, we use the algorithm to explore the effects of different coding approaches and problem variations on anonymization quality and performance. To our knowledge, this is the first result demonstrating optimal k-anonymization of a non-trivial dataset under a general model of the problem.
A framework for high-accuracy privacy-preserving mining	To preserve client privacy in the data mining process, a variety of techniques based on random perturbation of individual data records have been proposed recently. In this paper, we present FRAPP, a generalized matrix-theoretic framework of random perturbation, which facilitates a systematic approach to the design of perturbation mechanisms for privacy-preserving mining. Specifically, FRAPP is used to demonstrate that (a) the prior techniques differ only in their choices for the perturbation matrix elements, and (b) a symmetric perturbation matrix with minimal condition number can be identified, maximizing the accuracy even under strict privacy guarantees. We also propose a novel perturbation mechanism wherein the matrix elements are themselves characterized as random variables, and demonstrate that this feature provides significant improvements in privacy at only a marginal cost in accuracy. The quantitative utility of FRAPP, which applies to random-perturbation-based privacy-preserving mining in general, is evaluated specifically with regard to frequent-itemset mining on a variety of real datasets. Our experimental results indicate that, for a given privacy requirement, substantially lower errors are incurred, with respect to both itemset identity and itemset support, as compared to the prior techniques.
Top-down specialization for information and privacy preservation	Releasing person-specific data in its most specific state poses a threat to individual privacy. This paper presents a practical and efficient algorithm for determining a generalized version of data that masks sensitive information and remains useful for modelling classification. The generalization of data is implemented by specializing or detailing the level of information in a top-down manner until a minimum privacy requirement is violated. This top-down specialization is natural and efficient for handling both categorical and continuous attributes. Our approach exploits the fact that data usually contains redundant structures for classification. While generalization may eliminate some structures, other structures emerge to help. Our results show that quality of classification can be preserved even for highly restrictive privacy requirements. This work has great applicability to both public and private sectors that share information for mutual benefits and productivity.
Privacy and ownership preserving of outsourced medical data	The demand for the secondary use of medical data is increasing steadily to allow for the provision of better quality health care. Two important issues pertaining to this sharing of data have to be addressed: one is the privacy protection for individuals referred to in the data; the other is copyright protection over the data. In this paper, we present a unified framework that seamlessly combines techniques of binning and digital watermarking to attain the dual goals of privacy and copyright protection. Our binning method is built upon an earlier approach of generalization and suppression by allowing a broader concept of generalization. To ensure data usefulness, we propose constraining binning by usage metrics that define maximal allowable information loss, and the metrics can be enforced off-line. Our watermarking algorithm watermarks the binned data in a hierarchical manner by leveraging on the very nature of the data. The method is resilient to the generalization attack that is specific to the binned data, as well as other attacks intended to destroy the inserted mark. We prove that watermarking could not adversely interfere with binning, and implemented the framework. Experiments were conducted, and the results show the robustness of the proposed framework.
Privacy - preserving top-k queries	The primary contribution of this paper is a secure method for doing top-k selection from vertically partitioned data. This has particular relevance to privacy-sensitive searches, and meshes well with privacy policies such as k-anonymity. We have demonstrated how secure primitives from the literature can be composed with efficient query processing algorithms, with the result having provable security properties. The paper also shows a trade-off between efficiency and disclosure. It is worth exploring whether one could have a suite of algorithms to optimize these tradeoffs, e.g., algorithms that guarantee k-anonymity with efficiency based on the choice of k rather than the guarantees of secure multiparty computation.
Models and Methods for Privacy-Preserving Data Analysis and Publishing	The digitization of our daily lives has led to an explosion in the collection of data by governments, corporations, and individuals. Protection of confidentiality of this data is of utmost importance. However, knowledge of statistical properties of this private data can have significant societal benefit, for example, in decisions about the allocation of public funds based on Census data, or in the analysis of medical data from different hospitals to understand the interaction of drugs. This tutorial will survey recent research that builds bridges between the two seemingly conflicting goals of sharing data while preserving data privacy and confidentiality. The tutorial will cover definitions of privacy and disclosure, and associated methods how to enforce them.
L-diversity: privacy beyond k-anonymity	Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called kappa-anonymity has gained popularity. In a kappa-anonymized dataset, each record is indistinguishable from at least kΓÇö1 other records with respect to certain "identifying" attributes. In this paper we show with two simple attacks that a kappa-anonymized dataset has some subtle, but severe privacy problems. First, we show that an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. Second, attackers often have background knowledge, and we show that kappa-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks and we propose a novel and powerful privacy definition called ell-diversity. In addition to building a formal foundation for ell-diversity, we show in an experimental evaluation that ell-diversity is practical and can be implemented efficiently.
Privacy Preserving Query Processing Using Third Parties	Data integration from multiple autonomous data sources has emerged as an important practical problem. The key requirement for such data integration is that owners of such data need to cooperate in a competitive landscape in most of the cases. The research challenge in developing a query processing solution is that the answers to the queries need to be provided while preserving the privacy of the data sources. In general, allowing unrestricted read access to the whole data may give rise to potential vulnerabilities as well as may have legal implications. Therefore, there is a need for privacy preserving database operations for querying data residing at different parties. In this paper, we propose a new query processing technique using third parties in a peer-to-peer system. We propose and evaluate two different protocols for various database operations. Our scheme is able to answer queries without revealing any useful information to the data sources or to the third parties. Analytical comparison of the proposed approach with other recent proposals for privacy-preserving data integration establishes the superiority of the proposed approach in terms of query response time
Hiding in the Crowd: Privacy Preservation on Evolving Streams through Correlation Tracking	We address the problem of preserving privacy in streams, which has received surprisingly limited attention. For static data, a well-studied and widely used approach is based on random perturbation of the data values. However, streams pose additional challenges. First, analysis of the data has to be performed incrementally, using limited processing time and buffer space, making batch approaches unsuitable. Second, the characteristics of streams evolve over time. Consequently, approaches based on global analysis of the data are not adequate. We show that it is possible to efficiently and effectively track the correlation and autocorrelation structure of multivariate streams and leverage it to add noise which maximally preserves privacy, in the sense that it is very hard to remove. Our techniques achieve much better results than previous static, global approaches, while requiring limited processing time and memory. We provide both a mathematical analysis and experimental evaluation on real data to validate the correctness, efficiency, and effectiveness of our algorithms.
The New Casper: A Privacy-Aware Location-Based Database Server	This demo presents Casper; a framework in which users entertain anonymous location-based services. Casper consists of two main components; the location anonymizer that blurs the users' exact location into cloaked spatial regions and the privacy-aware query processor that is responsible on providing location-based services based on the cloaked spatial regions. While the location anonymizer is implemented as a stand alone application, the privacy-aware query processor is embedded into PLACE; a research prototype for location-based database servers.
Worst-Case Background Knowledge for Privacy-Preserving Data Publishing	Recent work has shown the necessity of considering an attacker's background knowledge when reasoning about privacy in data publishing. However, in practice, the data publisher does not know what background knowledge the attacker possesses. Thus, it is important to consider the worst-case. In this paper, we initiate a formal study of worst-case background knowledge. We propose a language that can express any background knowledge about the data. We provide a polynomial time algorithm to measure the amount of disclosure of sensitive information in the worst case, given that the attacker has at most k pieces of information in this language. We also provide a method to efficiently sanitize the data so that the amount of disclosure in the worst case is less than a specified threshold.
t-Closeness: Privacy Beyond k-Anonymity and l-Diversity	The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain "identifying" attributes) contains at least k records. Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure. The notion of l-diversity has been proposed to address this; l-diversity requires that each equivalence class has at least l well-represented values for each sensitive attribute. In this paper we show that l-diversity has a number of limitations. In particular, it is neither necessary nor sufficient to prevent attribute disclosure. We propose a novel privacy notion called t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t). We choose to use the earth mover distance measure for our t-closeness requirement. We discuss the rationale for t-closeness and illustrate its advantages through examples and experiments.
Preservation Of Patterns and Input-Output Privacy	Privacy preserving data mining so far has mainly focused on the data collector scenario where individuals supply their personal data to an untrusted collector in exchange for value. In this scenario, random perturbation has proved to be very successful. An equally compelling, but overlooked scenario, is that of a data custodian, which either owns the data or is explicitly entrusted with ensuring privacy of individual data. In this scenario, we show that it is possible to minimize disclosure while guaranteeing no outcome change. We conduct our investigation in the context of building a decision tree and propose transformations that preserve the exact decision tree. We show with a detailed set of experiments that they provide substantial protection to both input data privacy and mining output privacy.
Link Privacy in Social Networks	We consider a privacy threat to a social network in which the goal of an attacker is to obtain knowledge of a significant fraction of the links in the network. We formalize the typical social network interface and the information about links that it provides to its users in terms of lookahead. We consider a particular threat in which an attacker subverts user accounts to gain information about local neighborhoods in the network and pieces them together in order to build a global picture. We analyze, both experimentally and theoretically, the number of user accounts an attacker would need to subvert for a successful attack, as a function of his strategy for choosing users whose accounts to subvert and a function of the lookahead provided by the network. We conclude that such an attack is feasible in practice, and thus any social network that wishes to protect the link privacy of its users should take great care in choosing the lookahead of its interface, limiting it to 1 or 2, whenever possible.
Preserving Privacy in Social Networks Against Neighborhood Attacks	Recently, as more and more social network data has been published in one way or another, preserving privacy in publishing social network data becomes an important concern. With some local knowledge about individuals in a social network, an adversary may attack the privacy of some victims easily. Unfortunately, most of the previous studies on privacy preservation can deal with relational data only, and cannot be applied to social network data. In this paper, we take an initiative towards preserving privacy in social network data. We identify an essential type of privacy attacks: neighborhood attacks. If an adversary has some knowledge about the neighbors of a target victim and the relationship among the neighbors, the victim may be re-identified from a social network even if the victim's identity is preserved using the conventional anonymization techniques. We show that the problem is challenging, and present a practical solution to battle neighborhood attacks. The empirical study indicates that anonymized social networks generated by our method can still be used to answer aggregate network queries with high accuracy.
OptRR: Optimizing Randomized Response Schemes for Privacy-Preserving Data Mining	The randomized response (RR) technique is a promising technique to disguise private categorical data in privacy-preserving data mining (PPDM). Although a number of RR-based methods have been proposed for various data mining computations, no study has systematically compared them to find optimal RR schemes. The difficulty of comparison lies in the fact that to compare two PPDM schemes, one needs to consider two conflicting metrics: privacy and utility. An optimal scheme based on one metric is usually the worst based on the other metric. In this paper, we first describe a method to quantify privacy and utility. We formulate the quantification as estimate problems, and use estimate theories to derive quantification. We then use an evolutionary multi-objective optimization method to find optimal disguise matrices for the randomized response technique. The experimental results have shown that our scheme has a much better performance than the existing RR schemes.
Privacy: Theory meets Practice on the Map	In this paper, we propose the first formal privacy analysis of a data anonymization process known as the synthetic data generation, a technique becoming popular in the statistics community. The target application for this work is a mapping program that shows the commuting patterns of the population of the United States. The source data for this application were collected by the U.S. Census Bureau, but due to privacy constraints, they cannot be used directly by the mapping program. Instead, we generate synthetic data that statistically mimic the original data while providing privacy guarantees. We use these synthetic data as a surrogate for the original data. We find that while some existing definitions of privacy are inapplicable to our target application, others are too conservative and render the synthetic data useless since they guard against privacy breaches that are very unlikely. Moreover, the data in our target application is sparse, and none of the existing solutions are tailored to anonymize sparse data. In this paper, we propose solutions to address the above issues.
Anonymizing Streaming Data for Privacy Protection	In many applications, transaction data arrive in the form of high speed data streams. These data contain a lot of information about customers, not just transactions, and thus have to be carefully managed to protect customers' privacy. This paper presents a novel method called SKY (stream K-anon Ymtiy) to continuously facilitate k-anonymity on data streams. Experimental results show that SKY is efficient and effective.
SpaceTwist: Managing the Trade-Offs Among Location Privacy, Query Performance, and Query Accuracy in Mobile Services	In a mobile service scenario, users query a server for nearby points of interest but they may not want to disclose their locations to the service. Intuitively, location privacy may be obtained at the cost of query performance and query accuracy. The challenge addressed is how to obtain the best possible performance, subjected to given requirements for location privacy and query accuracy. Existing privacy solutions that use spatial cloaking employ complex server query processing techniques and entail the transmission of large quantities of intermediate result. Solutions that use transformation-based matching generally fall short in offering practical query accuracy guarantees. Our proposed framework, called SpaceTwist, rectifies these shortcomings for k nearest neighbor (kNN) queries. Starting with a location different from the user's actual location, nearest neighbors are retrieved incrementally until the query is answered correctly by the mobile terminal. This approach is flexible, needs no trusted middleware, and requires only well-known incremental NN query processing on the server. The framework also includes a server-side granular search technique that exploits relaxed query accuracy guarantees for obtaining better performance. The paper reports on empirical studies that elicit key properties of SpaceTwist and suggest that the framework offers very good performance and high privacy, at low communication cost.
Butterfly: Protecting Output Privacy in Stream Mining	Privacy preservation in data mining demands protecting both input and output privacy. The former refers to sanitizing the raw data itself before performing mining. The latter refers to preventing the mining output (model/pattern) from malicious pattern-based inference attacks. The preservation of input privacy does not necessarily lead to that of output privacy. This work studies the problem of protecting output privacy in the context of frequent pattern mining over data streams. After exposing the privacy breaches existing in current stream mining systems, we propose Butterfly, a light-weighted countermeasure that can effectively eliminate these breaches without explicitly detecting them, meanwhile minimizing the loss of the output accuracy. We further optimize the basic scheme by taking account of two types of semantic constraints, aiming at maximally preserving utility-related semantics while maintaining the hard privacy and accuracy guarantee. We conduct extensive experiments over real- life datasets to show the effectiveness and efficiency of our approach.
Privacy Preserving Joins	In this paper, we design a system for mutually distrustful entities to perform privacy preserving joins, leveraging the power of a memory-limited secure coprocessor. Under this setting, we critique a questionable assumption in a previous privacy definition [1] that leads to unnecessary information leakage. We then remove the assumption and propose a new definition. Based on this definition, we propose three correct and provable secure algorithms to compute general joins of arbitrary predicates, by utilizing available cryptographic tools in a nontrivial way. We discuss different memory requirements of our proposed algorithms, and explore how to trade little privacy with significant performance improvement. In [2], we evaluate the performance of our algorithms by numerical examples. We also show the performance superiority of our approach over secure multi-party computation in [2].
On Anti-Corruption Privacy Preserving Publication	This paper deals with a new type of privacy threat, called "corruption" in anonymized data publication. Specifically, an adversary is said to have corrupted some individuals, if s/he has already obtained their sensitive values before consulting the released information. Conventional generalization may lead to severe privacy disclosure in the presence of corruption. Motivated by this, we advocate an alternative anonymization technique that integrates generalization with perturbation and stratified sampling. The integration provides strong privacy guarantees, even if an adversary has corrupted any number of individuals. We verify the effectiveness of the proposed technique through experiments with real data.
On Unifying Privacy and Uncertain Data Models	The problem of privacy-preserving data mining has been studied extensively in recent years because of the increased amount of personal information which is available to corporations and individuals. Most privacy transformations use some form of data perturbation or representational ambiguity in order to reduce the risk of identification. The final results from privacy transformation methods often require the underlying applications to be modified in order to work with the new representation of the data. Since the end results of privacy-transformation methods have not been standardized, the required modifications may vary with the method used for the privacy transformation. In some cases, it can be an enormous effort to re-design applications to work with the anonymized data. While the results of privacy-transformation methods are a natural form of uncertain data, the two problems have generally been studied independently. In this paper, we make a first attempt to unify the two fields, and propose a privacy transformation for which existing uncertain data management tools can be directly used. This is a great advantage, since it means that the wide spectrum of research available for uncertain data management can also be used for privacy-preserving data mining. We propose an uncertain version of the k-anonymity model which is related to the well known deterministic model of k- anonymity. The uncertain version of the k-anonymity model has the additional feature of introducing greater uncertainty for the adversary over an equivalent deterministic model. As specific instantiations of this approach, we test the effectiveness of the privacy transformation on the problems of query estimation and classification, and show that the technique retains greater accuracy than other k-anonymity models.
A General Proximity Privacy Principle	This work presents a systematic study of the problem of protecting general proximity privacy, with findings applicable to most existing data models. Our contributions are multi-folded: we highlighted and formulated proximity privacy breaches in a data-model-neutral manner; we proposed a new privacy principle (epsiv,delta)<sup>k</sup>-dissimilarity, with theoretically guaranteed protection against linking attacks in terms of both exact and proximate QI-SA associations; we provided a theoretical analysis regarding the satisfiability of (epsiv,delta)<sup>k</sup> -dissimilarity, and pointed to promising solutions to fulfilling this principle.
OPAQUE: Protecting Path Privacy in Directions Search	Directions search returns the shortest path from a source to a destination on a road network. However, the search interests of users may be exposed to the service providers, thus raising privacy concerns. For instance, a path query that finds a path from a resident address to a clinic may lead to a deduction about "who is related to what disease". To protect user privacy from accessing directions search services, we introduce the OPAQUE system, which consists of two major components: (1) an obfuscator that formulates obfuscated path queries by mixing true and fake sources/destinations; and (2) an obfuscated path query processor installed in the server for obfuscated path query processing. OPAQUE reduces the likelihood of path queries being revealed and allows retrieval of requested paths. We propose two types of obfuscated path queries, namely, independently obfuscated path query and shared obfuscated path query to strike a balance between privacy protection strength and query processing overhead, and to enhance privacy protection against collusion attacks.
Privacy Preserving Publishing on Multiple Quasi-identifiers	In some applications of privacy preserving data publishing, a practical demand is to publish a data set on multiple quasi-identifiers for multiple users simultaneously, which poses several challenges. Can we generate one anonymized version of the data so that the privacy preservation requirement like k-anonymity is satisfied for all users and the information loss is reduced as much as possible? In this paper, we identify and tackle the novel problem by an elegant solution.The full paper is available at http://www.cs.sfu.ca/~jpei/publications/butterfly-tr.pdf.
Privacy-Preserving Singular Value Decomposition	In this paper, we propose secure protocols to perform singular value decomposition (SVD) for two parties over horizontally and vertically partitioned data. We propose various secure building blocks for the computations of QR algorithm so that it is privacy-preserving. Some of the proposed secure building blocks include secure matrix multiplication, (x+y)<sup>-1</sup>, and radic(x+y). Together, they allow us to derive privacy-preserving SVD (PPSVD) based on a privacy-preserving QR algorithm. Finally we conduct experiments to evaluate the proposed secure building blocks and protocols. The results show that the proposed protocols for SVD achieve high accuracy for matrices of small and medium size.
Privacy Risk in Graph Stream Publishing for Social Network Data	To understand how social networks evolve over time, graphs representing the networks need to be published periodically or on-demand. The identity of the participants (nodes) must be anonymized to protect the privacy of the individuals and their relationships (edges) to the other members in the social network. We identify a new form of privacy attack, which we name the degree-trail attack. This attack re-identifies the nodes belonging to a target participant from a sequence of published graphs by comparing the degree of the nodes in the published graphs with the degree evolution of a target. The power of this attack is that the adversary can actively influence the degree of the target individual by interacting with the social network. We show that the adversary can succeed with a high probability even if published graphs are anonymized by strongest known privacy preserving techniques in the literature. Moreover, this success does not depend on the distinctiveness of the target nodes nor require the adversary to behave differently from a normal participant. One of our contributions is a formal method to assess the privacy risk of this type of attacks and empirically study the severity on real social network data.
A General Framework for Publishing Privacy Protected and Utility Preserved Graph	The privacy protection of graph data has become more and more important in recent years. Many works have been proposed to publish a privacy preserving graph. All these works prefer publishing a graph, which guarantees the protection of certain privacy with the smallest change to the original graph. However, there is no guarantee on how the utilities are preserved in the published graph. In this paper, we propose a general fine-grained adjusting framework to publish a privacy protected and utility preserved graph. With this framework, the data publisher can get a trade-off between the privacy and utility according to his customized preferences. We used the protection of a weighted graph as an example to demonstrate the implementation of this framework.
Privacy-Preserving SimRank over Distributed Information Network	Information network analysis has drawn a lot attention in recent years. Among all the aspects of network analysis, similarity measure of nodes has been shown useful in many applications, such as clustering, link prediction and community identification, to name a few. As linkage data in a large network is inherently sparse, it is noted that collecting more data can improve the quality of similarity measure. This gives different parties a motivation to cooperate. In this paper, we address the problem of link-based similarity measure of nodes in an information network distributed over different parties. Concerning the data privacy, we propose a privacy-preserving Sim Rank protocol based on fully-homomorphic encryption to provide cryptographic protection for the links.
Frequent Closed Itemset Mining with Privacy Preserving for Distributed Databases	In the present paper we introduce closed item sets into frequent item set mining from horizontally-partitioned transaction databases with preserving privacy. Closed item sets were originally from the research area of Formal Concept Analysis, and it is shown that even if results of frequent item set mining are restricted to closed item sets, all frequent item sets can be recovered from the results. This property suggests that using closed item sets would contribute to decreasing the cost of communication among distributed sites where a piece of horizontally-partitioned database is stored. We present a mining procedure revising and amalgamating two previous works: one is for mining closed item sets from horizontally-partitioned databases, and the other is for privacy preserving mining of item sets from such databases. We analyze the procedure on both of the viewpoint of communication cost and that of security. We also show results of some experimental practice of applying the procedure to a well-known dataset.
On Attribute Disclosure in Randomization Based Privacy Preserving Data Publishing	Privacy preserving micro data publication has received wide attentions. In this paper, we investigate the randomization approach and focus on attribute disclosure under linking attacks. We give efficient solutions to determine optimal distortion parameters such that we can maximize utility preservation while still satisfying privacy requirements. We compare our randomization approach with l-diversity and anatomy in terms of utility preservation (under the same privacy requirements) from three aspects (reconstructed distributions, accuracy of answering queries, and preservation of correlations). Our empirical results show that randomization incurs significantly smaller utility loss.
A Privacy Preserving Framework for Gaussian Mixture Models	This paper presents a framework for privacy-preserving Gaussian Mixture Model computations. Specifically, we consider a scenario where a central service wants to learn the parameters of a Guassian Mixture Model from private data distributed among multiple parties with privacy constraints. In addition, the service also has security constraints where none of the data owners are allowed to learn the values of the trained parameters. We use Secure Multiparty Computations to propose a framework that allows such computations. In addition, we also show how such a central service can classify new test data from privacy constrained third parties without exposing the learned models. The classification occurs with the added constraint that the service learns no information about either the test data or the result of the classification.
Introduction to the Second IEEE International Workshop on Privacy Aspects of Data Mining	No abstract.
Privacy Violations Using Microtargeted Ads: A Case Study	In this paper we propose a new class of attacks that exploit advertising systems offering micro targeting capabilities in order to breach user privacy. We study the advertising system offered by the world's largest online social network, Face book, and the risks that the design of the system poses to the privacy of its users. We propose, describe and provide experimental evidence of several novel approaches to exploiting the advertising system in order to obtain private user information. We communicated our findings to Face book on July 13, 2010, and received a prompt response. On July 20, 2010, Face book launched a change to their advertising system that made the kind of attacks we describe more difficult but not impossible to implement.
Privacy Preserving GWAS Data Sharing	Traditional statistical methods for the confidentiality protection for statistical databases do not scale well to deal with GWAS (genome-wide association studies) databases and external information on them. The more recent concept of differential privacy, introduced by the cryptographic community, is an approach which provides a rigorous definition of privacy with meaningful privacy guarantees in the presence of arbitrary external information. Building on such notions, we propose new methods to release aggregate GWAS data without compromising an individual's privacy. We present methods for releasing differentially private minor allele frequencies, chi-square statistics and p-values. We compare these approaches on simulated data and on a GWAS study of canine hair length involving 685 dogs. We also propose a privacy-preserving method for finding genome-wide associations based on a differentially private approach to penalized logistic regression.
Data Mining and Privacy of Personal Behaviour Types in Smart Grid	Privacy protection is one of the key requirements of smart grids. To understand the importance of privacy threats it is necessary to study nature of power signals. In this paper, we propose a well-known statistical method which relies on the empirical probability distribution. The method is used to reveal trends in the power signal data and how these trends are changed if a) different data sampling rates are assumed, and b) a privacy algorithm is applied to protect the power data of different home appliances. Our results suggest that the privacy of personal behaviour types is exposed even if relatively infrequent measurements are obtained. On the other hand, battery-assisted home energy management solutions are more likely to protect the customers.
Rating: Privacy Preservation for Multiple Attributes with Different Sensitivity Requirements	Motivated by the insufficiency of the existing framework that could not process multiple attributes with different sensitivity requirements on modeling real world privacy requirements for data publishing, we present a novel method, rating, for publishing sensitive data. Rating releases AT (Attribute Table) and IDT (ID Table) based on different sensitivity coefficients for different attributes. This approach not only protects privacy for multiple sensitive attributes, but also keeps a large amount of correlations of the micro data. We develop algorithms for computing AT and IDT that obey the privacy requirements for multiple sensitive attributes, and maximize the utility of published data as well. We prove both theoretically and experimentally that our method has better performance than the conventional privacy preserving methods on protecting privacy and maximizing the utility of published data. To quantify the utility of published data, we propose a new measurement named classification measurement.
Preface to the Third International Workshop on Privacy Aspects of Data Mining	
Privacy Preserving Outlier Detection Using Locality Sensitive Hashing	In this paper, we give approximate algorithms for privacy preserving distance based outlier detection for both horizontal and vertical distributions, which scale well to large datasets of high dimensionality in comparison with the existing techniques. In order to achieve efficient private algorithms, we introduce an approximate outlier detection scheme for the centralized setting which is based on the idea of Locality Sensitive Hashing. We also give theoretical and empirical bounds on the level of approximation of the proposed algorithms.
enList: Automatically Simplifying Privacy Policies	Online social networking sites have become extremely popular. Due to the pervasiveness of these sites, it is important to provide tools that allow users to specify detailed policies controlling access to their data. However, the policies specified using existing tools are often complex, verbose, and difficult to understand. In this paper, we study the policy simplification problem. Given a complex or verbose policy, our goal is to automatically produce an equivalent policy that is easier to understand. We propose a novel framework called enList, which automatically extracts friend "lists" (semantically meaningful subgroups of a user's friends) and then simplifies an existing policy using the lists. A laboratory-based user study confirms that the resulting policies are easier for users to comprehend, remember, and maintain than the policies produced by an existing recommendation tool.
Preface to the International Workshop on Discrimination and Privacy-Aware Data Mining -- DPADM 2012	
Exploiting Dynamic Privacy in Socially Regularized Recommenders	In this paper we introduce a privacy-aware collaborative filtering recommender framework which aims to address the privacy concern of profile owners in the context of social trust sparsity. While sparsity in social trust is mitigated by similarity driven trust using a probabilistic matrix factorization technique, the privacy issue is addressed by employing a dynamic privacy inference model. The privacy inference model exploits the underlying inter-entity trust information to obtain a personalized privacy view for each individual in the social network. We evaluate the proposed framework by employing an off-the-shelf collaborative filtering recommender method to make predictions using this personalized view. Experimental results show that our method offers better performance than similar non-privacy aware approaches, while at the same time meeting user privacy concerns.
Preface to the First Workshop on Privacy in Social Data -- PinSoDa 2012	
A Practical System for Privacy-Preserving Collaborative Filtering	Collaborative filtering is a widely-used technique in online services to enhance the accuracy of a recommender system. This technique, however, comes at the cost of users having to reveal their preferences, which has undesirable privacy implications. We propose a collaborative filtering system where the system does not observe the users' data and is still able to provide useful recommendations. Compared to prior systems, our emphasis is on building a practical system that can be reasonably used by a large number of users. Our approach involves creating a primitive to cluster similar users privately by modifying existing methods such as Locality Sensitive Hashing. Another technique we use is artificial ratings, as part of the process of privately predicting the rating for an item within a particular cluster. We evaluate our scheme on the Netflix Prize dataset, reporting the accuracy of our recommendations as a function of the privacy provided.
Injecting Discrimination and Privacy Awareness Into Pattern Discovery	Data mining is gaining societal momentum due to the ever increasing availability of large amounts of human data, easily collected by a variety of sensing technologies. Data mining comes with unprecedented opportunities and risks: a deeper understanding of human behavior and how our society works is darkened by a greater chance of privacy intrusion and unfair discrimination based on the extracted patterns and profiles. Although methods independently addressing privacy or discrimination in data mining have been proposed in the literature, in this context we argue that privacy and discrimination risks should be tackled together, and we present a methodology for doing so while publishing frequent pattern mining results. We describe a combined pattern sanitization framework that yields both privacy and discrimination-protected patterns, while introducing reasonable (controlled) pattern distortion.
A Sorted Neighborhood Approach to Multidimensional Privacy Preserving Blocking	Privacy Preserving Record Linkage is an emerging field of research which aims to integrate data from heterogeneous data sources while respecting privacy. It is evident that this task exhibits high computational complexity, therefore Privacy Preserving Blocking has been introduced in order to improve performance by eliminating unrelated candidate pairs. In this paper we present a solution to this problem by introducing the Sorted Neighborhood for Encrypted Fields algorithm and combining it with a secure multidimensional privacy preserving blocking method. Our approach is applicable to all types of data fields and manages to significantly boost the Privacy Preserving Record Linkage process without sacrificing matching accuracy. We analytically prove that our method is secure and we also provide empirical evidence where the high performance of our method is established by comparing it to other established methods.
Privacy-Preserving Data Imputation	In this paper, we investigate privacy-preserving data imputation on distributed databases. We present a privacy-preserving protocol for filling in missing values using a lazy decision tree imputation algorithm for data that is horizontally partitioned between two parties. The participants of the protocol learn only the imputed values; the computed decision tree is not learned by either party
NNMF-Based Factorization Techniques for High-Accuracy Privacy Protection on Non-negative-valued Datasets	The challenge in preserving data privacy is how to protect attribute values without jeopardizing the similarity between data objects under analysis. In this paper, we further our previous work on applying matrix techniques to protect privacy and present a novel algebraic technique based on iterative methods for non-negative-valued data distortion. As an unsupervised learning method for uncovering latent features in high-dimensional data, a low rank nonnegative matrix factorization (NNMF) is used to preserve natural data non-negativity and avoid subtractive basis vector and encoding interactions present in techniques such as principal component analysis. It is the first in privacy preserving data mining in our paper that combining non-negative matrix decomposition with distortion processing. Two iterative methods to solve bound-constrained optimization problem in NMF are compared by experiments on Wisconsin Breast Cancer Dataset. The overall performance of NMF on distortion level and data utility is compared to our previously-proposed SVD-based distortion strategies and other existing popular data perturbation methods. Data utility is examined by cross validation of a binary classification using the support vector machine. Our experimental results on data mining benchmark datasets indicate that, in comparison with standard data distortion techniques, the proposed NMF-based method are very efficient in balancing data privacy and data utility, and it affords a feasible solution with a good promise on high-accuracy privacy preserving data mining
An Approach to Outsourcing Data Mining Tasks while Protecting Business Intelligence and Customer Privacy	Data mining is playing an important role in decision making. It is beneficial to outsource data mining tasks if an organization does not have required expertise in-house. However, the organization may lose business intelligence and customer privacy during this outsourcing process. In this paper, we present a Bloom filter based solution to enable organizations to outsource their tasks of mining association rules while protecting their business intelligence and customer privacy. Our approach can achieve high precision in data mining by trading-off storage requirements
Privacy-Preserving Data Linkage and Geocoding: Current Approaches and Research Directions	Data linkage is the task of matching and aggregating records that relate to the same entity from one or more data sets. A related technique is geocoding, the matching of addresses to their geographic locations. As data linkage is often based on personal information (like names and addresses), privacy and confidentiality are of paramount importance. In this paper we present an overview of current approaches to privacy-pre serving data linkage, and discuss their limitations. Using real-world scenarios we illustrate the significance of developing improved techniques for automated, large scale and distributed privacy-pre serving linking and geocoding. We then discuss four core research areas that need to be addressed in order to make linking and geocoding of large confidential data collections feasible
A Crypto-Based Approach to Privacy-Preserving Collaborative Data Mining	To conduct data mining, we often need to collect data from various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties collaboratively conduct data mining without breaching data privacy presents a challenge. In this paper, we propose a formal definition of privacy, develop a solution for privacy-preserving k-nearest neighbor classification which is one of data mining tasks, and show that our solution preserves data privacy according to our definition
Privacy Preserving Nearest Neighbor Search	Data mining is frequently obstructed by privacy concerns. In many cases data is distributed, and bringing the data together in one place for analysis is not possible due to privacy laws (e.g. HIPAA) or policies. Privacy preserving data mining techniques have been developed to address this issue by providing mechanisms to mine the data while giving certain privacy guarantees. In this work we address the issue of privacy preserving nearest neighbor search, which forms the kernel of many data mining applications. To this end, we present a novel algorithm based on secure multiparty computation primitives to compute the nearest neighbors of records in horizontally distributed data. We show how this algorithm can be used in three important data mining algorithms, namely LOF outlier detection, SNN clustering, and kNN classification
The Applicability of the Perturbation Model-based Privacy Preserving Data Mining for Real-world Data	Perturbation method is a very important technique in privacy preserving data mining. In this technique, loss of information versus preservation of privacy is always a trade off. The question is, how much are the users willing to compromise their privacy? This is a choice that changes from individual to individual. In this paper, we propose an individually adaptable perturbation model, which enables the individuals to choose their own privacy level. Hence our model provides different privacy guarantees for different privacy preferences. We test our new perturbation model by applying different reconstruction methods to the perturbed data sets. Furthermore, we build decision tree and Naive Bayes classifier models on the reconstructed data sets both for synthetic and real world data sets. For the synthetic data set, our experimental results indicate that our model enables the users to choose their own privacy level without reducing the accuracy of the data mining results. For the real world data sets, we got very interesting results, hence we pose the question of whether the perturbation reconstruction model-based privacy preserving data mining is applicable for real-world data?
Privacy-Preserving Data Mining Applications in the Malicious Model	Although the semi-honest model is reasonable in some cases, it is unrealistic to assume that adversaries will al- ways follow the protocols exactly. In particular, malicious adversaries could deviate arbitrarily from their prescribed protocols. Clearly, protocols that can withstand malicious adversaries provide more security. However, there is an ob- vious trade-off: protocols that are secure against malicious adversaries are generally more expensive than those secure against semi-honest adversaries only. In this paper, our goal is to make an analysis of trade-offs between perfor- mance and security in privacy-preserving distributed data mining algorithms in the two models. In order to make a realistic comparison, we enhance commonly used subpro- tocols that are secure in the semi-honest model with zero knowledge proofs to be secure in the malicious model. We compare the performance of these protocols in both models.
Privacy-Preserving k-NN for Small and Large Data Sets	It is not surprising that there is strong interest in k- NN queries to enable clustering, classification and outlier- detection tasks. However, previous approaches to privacy-preserving k-NN are costly and can only be realistically applied to small data sets. We provide efficient solutions for k-NN queries queries for vertically partitioned data. We provide the first solution for the L<sub>infin</sub> (or Chessboard) metric as well as detailed privacy-preserving computation of all other Minkowski metrics. We enable privacy-preserving L<sub>infin</sub> by providing a solution to the Yao's Millionaire Problem with more than two parties. This is based on a new and practical solution to Yao's Millionaire with shares. We also provide privacy-preserving algorithms for combinations of local metrics into a global that handles the large dimensionality and diversity of attributes common in vertically partitioned data.
Wavelet-Based Data Perturbation for Simultaneous Privacy-Preserving and Statistics-Preserving	With the rapid development of data mining technologies, preserving privacy in certain data becomes a challenge to data mining applications in many fields, especially in medical, financial and homeland security fields. We present a privacy-preserving strategy based on wavelet perturbation to keep the data privacy and data statistical properties and data mining utilities at the same time. Our mathematical analyses and experimental results show that this method can keep the distance before and after perturbation and it can preserve the basic statistical properties of the original data while maximizing the data utilities. Through experiments on real-life datasets, we conclude that this method is a promising privacy-preserving and statistics-preserving technique.
Differential Privacy for Clinical Trial Data: Preliminary Evaluations	The concept of differential privacy as a rigorous definition of privacy has emerged from the cryptographic community. However, further careful evaluation is needed before we can apply these theoretical results to privacy preservation in everyday data mining and statistical analysis. In this paper we demonstrate how to integrate a differential privacy framework with the classical statistical hypothesis testing in the domain of clinical trials where personal information is sensitive. We develop concrete methodology that researchers can use. We derive rules for the sample size adjustment whereby both statistical efficiency and differential privacy can be achieved for the specific tests for binomial random variables and in contingency tables.
An Attack on the Privacy of Sanitized Data that Fuses the Outputs of Multiple Data Miners	Data sanitization has been used to restrict re-identification of individuals and disclosure of sensitive information from published data. We propose an attack on the privacy of the published sanitized data that simply fuses outputs of multiple data miners that are applied to the sanitized data. That attack is practical and does not require any background or additional information. We use a number of experiments to show scenarios where an adversary can combine outputs of multiple miners using a simple fusion strategy to increase their success chance of breaching privacy of individuals whose data is stored in the database. The fusion attack provides a powerful method of breaching privacy in the form of partial disclosure, for both anonymized and perturbed data. It also provides an effective way of approximating predictions of the best miner (a miner that provides the best results among all considered miners) when this miner cannot be determined.
Privacy Preserving Classification with Emerging Patterns	In privacy preserving classification, when data is stored in a centralized database and distorted using a randomization-based technique, we have information loss and reduced accuracy of classification. This paper presents a new approach to privacy preserving classification for centralized data based on Emerging Patterns. The presented solution gives higher accuracy of classification than a decision tree proposed in the literature, especially for high privacy. Effectiveness of this solution has been tested on real data sets and presented in this paper.
On the privacy preserving properties of random data perturbation techniques	Privacy is becoming an increasingly important issue in many data mining applications. This has triggered the development of many privacy-preserving data mining techniques. A large fraction of them use randomized data distortion techniques to mask the data for preserving the privacy of sensitive data. This methodology attempts to hide the sensitive data by randomly modifying the data values often using additive noise. We question the utility of the random value distortion technique in privacy preservation. We note that random objects (particularly random matrices) have "predictable" structures in the spectral domain and it develops a random matrix-based spectral filtering technique to retrieve original data from the dataset distorted by adding random values. We present the theoretical foundation of this filtering method and extensive experimental results to demonstrate that in many cases random data distortion preserve very little data privacy. We also point out possible avenues for the development of new privacy-preserving data mining techniques like exploiting multiplicative and colored noise for preserving privacy in data mining applications.
Privacy-preserving distributed clustering using generative models	We present a framework for clustering distributed data in unsupervised and semisupervised scenarios, taking into account privacy requirements and communication costs. Rather than sharing parts of the original or perturbed data, we instead transmit the parameters of suitable generative models built at each local data site to a central location. We mathematically show that the best representative of all the data is a certain "mean" model, and empirically show that this model can be approximated quite well by generating artificial samples from the underlying distributions using Markov Chain Monte Carlo techniques, and then fitting a combined global model with a chosen parametric form to these samples. We also propose a new measure that quantifies privacy based on information theoretic concepts, and show that decreasing privacy leads to a higher quality of the combined model and vice versa. We provide empirical results on different data types to highlight the generality of our framework. The results show that high quality distributed clustering can be achieved with little privacy loss and low communication cost.
Privacy-preserving collaborative filtering using randomized perturbation techniques	Collaborative filtering (CF) techniques are becoming increasingly popular with the evolution of the Internet. To conduct collaborative filtering, data from customers are needed. However, collecting high quality data from customers is not an easy task because many customers are so concerned about their privacy that they might decide to give false information. We propose a randomized perturbation (RP) technique to protect users' privacy while still producing accurate recommendations.
Bottom-up generalization: a data mining solution to privacy protection	The well-known privacy-preserved data mining modifies existing data mining techniques to randomized data. In this paper, we investigate data mining as a technique for masking data, therefore, termed data mining based privacy protection. This approach incorporates partially the requirement of a targeted data mining task into the process of masking data so that essential structure is preserved in the masked data. The idea is simple but novel: we explore the data generalization concept from data mining as a way to hide detailed information, rather than discover trends and patterns. Once the data is masked, standard data mining techniques can be applied without modification. Our work demonstrated another positive use of data mining technology: not only can it discover useful patterns, but also mask private information. We consider the following privacy problem: a data holder wants to release a version of data for building classification models, but wants to protect against linking the released data to an external source for inferring sensitive information. We adapt an iterative bottom-up generalization from data mining to generalize the data. The generalized data remains useful to classification but becomes difficult to link to other sources. The generalization space is specified by a hierarchical structure of generalizations. A key is identifying the best generalization to climb up the hierarchy at each iteration. Enumerating all candidate generalizations is impractical. We present a scalable solution that examines at most one generalization in each iteration for each attribute involved in the linking.
Privacy-sensitive Bayesian network parameter learning	This paper considers the problem of learning the parameters of a Bayesian network, assuming the structure of the network is given, from a privacy-sensitive dataset that is distributed between multiple parties. For a binary-valued dataset, we show that the count information required to estimate the conditional probabilities in a Bayesian network can be obtained as a solution to a set of linear equations involving some inner product between the relevant different feature vectors. We consider a random projection-based method that was proposed elsewhere to securely compute the inner product (with a modified implementation of that method).
Privacy-preserving outlier detection	Outlier detection can lead to the discovery of truly unexpected knowledge in many areas such as electronic commerce, credit card fraud and especially national security. We look at the problem of finding outliers in large distributed databases where privacy/security concerns restrict the sharing of data. Both homogeneous and heterogeneous distribution of data is considered. We propose techniques to detect outliers in such scenarios while giving formal guarantees on the amount of information disclosed.
Preserving Privacy through Data Generation	Many databases will not or can not be disclosed without strong guarantees that no sensitive information can be extracted. To address this concern several data perturbation techniques have been proposed. However, it has been shown that either sensitive information can still be extracted from the perturbed data with little prior knowledge, or that many patterns are lost. In this paper we show that generating new data is an inherently safer alternative. We present a data generator based on the models obtained by the MDL-based KRIMP (Siebes et al., 2006) algorithm. These are accurate representations of the data distributions and can thus be used to generate data with the same characteristics as the original data. Experimental results show a very large pattern-similarity between the generated and the original data, ensuring that viable conclusions can be drawn from the anonymised data. Furthermore, anonymity is guaranteed for suited databases and the quality-privacy trade-off can be balanced explicitly.
Inference Analysis in Privacy-Preserving Data Re-publishing	Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.
Releasing the SVM Classifier with Privacy-Preservation	Support vector machine (SVM) is a widely used tool in classification problem. SVM solves a quadratic optimization problem to decide which instances of training dataset are support vectors, i.e., the necessarily informative instances to form the classifier. The support vectors are intact tuples taken from the training dataset. Releasing the SVM classifier to public use or shipping the SVM classifier to clients will disclose the private content of support vectors, violating the privacy-preservation requirement in some legal or commercial reasons. To the best of our knowledge, there has not been work extending the notion of privacy-preservation to releasing the SVM classifier. In this paper, we propose an approximation approach which post-processes the SVM classifier to protect the private content of support vectors. This approach is designed for the commonly used Gaussian radial basis function kernel. By applying this post-processor on the SVM classifier, the resulted privacy-preserving SVM classifier can be publicly released without exposing the private content of support vectors and is able to provide comparable classification accuracy to the original SVM classifier.
Fine-Grain Perturbation for Privacy Preserving Data Publishing	Recent work shows that conventional privacy preserving publishing techniques based on anonymity-groups are susceptible to corruption attacks. In a corruption attack, if the sensitive information of any anonymity-group member is uncovered, then the remaining group members are at risk. In this study, we abandon anonymity-groups and hide sensitive information through perturbation on the sensitive attribute. With each record being perturbed independently, corruption attacks cannot be effectively carried out. Previous anti-corruption work did not minimize information loss. This paper proposes to address this issue by allowing fine-grain privacy specification. We demonstrate the power of our approach through experiments on real medical and synthetic datasets.
A Framework for Computing the Privacy Scores of Users in Online Social Networks	A large body of work has been devoted to address corporate-scale privacy concerns related to social networks. The main focus was on how to share social networks owned by organizations without revealing the identities or sensitive relationships of the users involved. Not much attention has been given to the privacy risk of users posed by their information sharing activities. In this paper, we approach the privacy concerns arising in online social networks from the individual users' viewpoint: we propose a framework to compute a privacy score of a user, which indicates the potential privacy risk caused by his participation in the network. Our definition of privacy score satisfies the following intuitive properties: the more sensitive the information revealed by a user, the higher his privacy risk. Also, the more visible the disclosed information becomes in the network, the higher the privacy risk. We develop mathematical models to estimate both sensitivity and visibility of the information. We apply our methods to synthetic and real-world data and demonstrate their efficacy and practical utility.
Approximate inverse frequent itemset mining: privacy, complexity, and approximation	In order to generate synthetic basket datasets for better benchmark testing, it is important to integrate characteristics from real-life databases into the synthetic basket datasets. The characteristics that could be used for this purpose include the frequent itemsets and association rules. The problem of generating synthetic basket datasets from frequent itemsets is generally referred to as inverse frequent itemset mining. In this paper, we show that the problem of approximate inverse frequent itemset mining is NP-complete. Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining, and discuss privacy issues related to the synthetic basket dataset. In particular, we propose an approximate algorithm to determine the privacy leakage in a synthetic basket dataset.
Privacy-preserving frequent pattern mining across private databases	Privacy consideration has much significance in the application of data mining. It is very important that the privacy of individual parties is not exposed when data mining techniques are applied to a large collection of data about the parties. In many scenarios such as data warehousing or data integration, data from the different parties form a many-to-many schema. This paper addresses the problem of privacy-preserving frequent pattern mining in such a schema across two dimension sites. We assume that sites are not trusted and they are semi-honest. Our method is based on the concept of semi-join and does not involve data encryption which is used in most previous work. Experiments are conducted to study the efficiency of the proposed models.
Template-based privacy preservation in classification problems	In this paper, we present a template-based privacy preservation to protect against the threats caused by data mining abilities. The problem has dual goals: preserve the information for a wanted classification analysis and limit the usefulness of unwanted sensitive inferences that may be derived from the data. Sensitive inferences are specified by a set of "privacy templates". Each template specifies the sensitive information to be protected, a set of identifying attributes, and the maximum association between the two. We show that suppressing the domain values is an effective way to eliminate sensitive inferences. For a large data set, finding an optimal suppression is hard, since it requires optimization over all suppressions. We present an approximate but scalable solution. We demonstrate the effectiveness of this approach on real life data sets.
Privacy preserving data classification with rotation perturbation	Data perturbation techniques are one of the most popular models for privacy preserving data mining (Agrawal and Srikant, 2000; Aggarwal and Yu, 2004). It is especially convenient for applications where the data owners need to export/publish the privacy-sensitive data. A data perturbation procedure can be simply described as follows. Before the data owner publishes the data, they randomly change the data in certain way to disguise the sensitive information while preserving the particular data property that is critical for building the data models. Several perturbation techniques have been proposed recently, among which the most typical ones are randomization approach (Agrawal and Srikant, 2000) and condensation approach (Aggarwal and Yu, 2004).
PccP: A model for Preserving cloud computing Privacy	The widespread focus on the Cloud Computing has necessitated the corresponding mechanisms to ensure privacy and security. Various attempts have been made in the past to safeguard the privacy of the individual or agency trying to utilize the services being provided by the cloud. The most challenging task is to provide services to the users while also preserving the privacy of the user's information. In this paper a model that incorporates a three-level architecture, Preserving cloud computing Privacy (PccP) model is proposed which aims to preserve privacy of information pertaining to cloud users. The Consumer Layer deals with all the aspects which relate to enabling the user of the cloud to access the cloud services being provided by the cloud service provider. The Network Interface Layer creates an appropriate mapping between the original IP addresses of the users with a modified IP address, and thereby ensuring the privacy of the IP address of the users. The Privacy Preserved Layer utilizes the functionality of the Unique User Cloud Identity Generator for which an algorithm is proposed in this paper to generate an unique User Service Dependent Identity(USID) with privacy check by establishing mapping among the existing user identity(ID), if any to ID's available in a pool of User ID's to enhance the privacy of sensitive user information. A Privacy check method based on information privacy is being proposed which contributes significantly in maintaining user control over the generated user identities (USID's).
Purpose Based Access Control for Privacy Protection in Object Relational Database Systems	Privacy preservation of individuals is a challenging problem in the environment. While current information technology enables people to carry out their business virtually at any time in any place, it also provides the capability to store various types of information the users reveal during their activities. A key feature of our model is that it allows multiple purposes to be associated with each data element and also supports explicit prohibitions, thus allowing privacy offers to specify that some data should not be used for certain purposes. To maintain consistency between the privacy policy and the practices, privacy protection requirements in privacy policy should be formally specified.
Preserving Location Privacy in Peer-to-Peer Environments	In modern age portable handheld devices are changing the norms of traditional communication structure by introducing mobility and dynamism. In general when a mobile client wants services from a database server, the client has to continuously report its location to the server. With untrustworthy servers, location-based services (LBS) may pose a major privacy threat on its users. In this paper, we propose an efficient architecture to tackle this privacy threat. In the proposed architecture a client's location and messages are hidden from the database server as well as other clients in the network. In this paper, we define the location privacy preservation protocol and analysis the protocol in different threat situations.
Verification of Privacy Requirements in Web Services Composition	Web services collaborations environment are highly automatic, dynamic, and heterogeneous. These characteristics impose high levels of risk on the interacting parties. Hence, to guarantee that the private data of consumer in cross organizational services composition are not illegally collected, used and disclosed, it is necessary in designing to verify the privacy requirements of the services composition. Initially, this paper uses privacy policies to specify the privacy privileges of a services composition. Next, it models the interface behaviors of services by extending the interface automata to support privacy semantics. Furthermore, it formally verifies whether the behaviors of a services composition satisfy the privacy policy constraints.
The First International Symposium on Data, Privacy, and E-Commerce - Cover	Presents the front cover or splash screen of the proceedings.
An Efficient Ring Signature Scheme for Privacy and Anonymous Communication	signature scheme based on the conic curve over Zn (RSBCZ). In the random oracle model, the scheme was proved secure provided that computing discrete logarithm in conic and factoring large integer are hard. We argue that our scheme is a great tool for privacy and anonymous communication. Moreover, since the whole signature was operated in conic curve over Zn, the scheme is easier to accomplish for embedding plaintext, computing element order and points in curves, and speeding up the inverse operation. Keywords-ring signatures; conic curve over Zn; random oracle model; privacy; anonymous communication
The First International Symposium on Data, Privacy, and E-Commerce - Copyright	
Application of Oblivious Transfer Protocol in Distributed Data Mining with Privacy-preserving	Privacy-preserving data mining(PPDM) is a rising direction. Specifically, with distributed data sources and consideration of privacy protection for all participants, sensitive information is not allowed to be disclosed between them in a cooperative work. In this research, we suggested and implemented an oblivious transfer method (OT-PPDM). Moreover, we compared it with other two representative resolutions for cooperative data mining. Theoretical analysis and synthetic experiment results show that OT-PPDM is secured and efficient.
The First International Symposium on Data, Privacy, and E-Commerce - Table of contents	Presents the table of contents of the proceedings.
The First International Symposium on Data, Privacy, and E-Commerce - Title page	The following topics are dealt with: data analysis; data privacy; e-commerce.
Privacy-Preserving Authentication Based on Short Group Signature in Vehicular Networks	Security and privacy are two integrated issues in deploying vehicular networks. Privacy-preserving authentication is a key technique in addressing these two issues. We propose to use group signature to authenticate vehicles in vehicular networks. To meet the requirements of speediness of authentication, we improve NF05 (Nakanishi and Funabiki) group signature scheme without compromising security and obtain a new scheme with shorter signature and less computations. According to the proposed group signature scheme, we give two privacy-preserving authentication mechanisms suitable for vehicular networks. The outstanding properties of group signature guarantee that our authentication schemes have the desirable properties of a practical privacy- preserving authentication protocol.
Privacy Against the Business Partner: Issues for Realizing End-to-End Confidentiality in Web Service Compositions	For service-oriented business processes, an important security requirement is confidentiality of transmitted data. Here, existing Web Services security standards provide suitable solutions for single invocations, but fail to cover service composition scenarios properly, especially for securing business process data against partners. In this paper, we investigate the issues regarding the realization of process level confidentiality in WS-BPEL-based Web Service compositions.
Security and Privacy in Smart Grid Infrastructures	Adding digital intelligence and two-way functionalities to the power grid is one of the most flourishing topics in both academic and public institution communities. Efficiency, improved reliability and safety are the benefits promised by the new smart grid at the price of privacy and security challenges which are only in part similar to the security issues of IT networks. We survey the current grid architecture and the relation among the smart grid operators to analyze the security and privacy threats which needs to be addressed to secure the smart grid digital infrastructure.
Dynamic aspects of the InfoPriv model for information privacy	This paper describes the dynamic aspects of the InfoPriv model for privacy. The dynamic aspects are concerned with the actual information flow as well as the change of the privacy policy over time. An information can-flow graph represents the potential information flow between entities, thereby describing only the static aspects of InfoPriv. The dynamic aspects are divided into two categories: dynamic information flow and the evolution of the static aspects. ΓÇ£Dynamic information flowΓÇ¥ refers to the simulation of the actual information flow as it occurs over time. Information flow is, therefore, permitted or denied based on the past information flow of a system. The ΓÇ£evolution of the static aspectsΓÇ¥ refers to the change of the privacy policy over time. For instance, it is necessary to give entities access to more information during their lifetime. An algorithm is presented that extends the can-flow graph without introducing unauthorised information flow
Data privacy, US common practices	The advancement in Internet technologies has led to high expectations about the growth of e-commerce and e-business. Predictions, however, have not materialized; E-commerce represents less that 1% of the total trade and signs of a sharp growth are not in sight. Slow growth of e-commerce has often been attributed to the lack of trust in either the medium (Internet) or the agents involved in the transaction (organizations). Our research is aimed at providing some insights as what privacy policies are and how they are practiced in the US. To this effect we have surveyed firms in multiple sectors that have been listed as most active in trading online. Our findings indicate that most interactive companies have published privacy policies (PPP). However, the percentage of companies with PPP varies based on their type of business, size, and whether the company is 100% interactive or it also has brick and mortar presence.
Privacy-enabled services for enterprises	The IBM Enterprise Privacy Architecture (EPA) is a methodology for enterprises to provide an enhanced and well-defined level of privacy to their customers. EPA is structured in four building blocks. The privacy regulation analysis identifies and structures the applicable regulations. The management reference model enables an enterprise to define and enforce an enterprise privacy strategy and the resulting privacy practices. The privacy agreement framework is a methodology for privacy-enabling business process re-engineering. It outputs a detailed model of the privacy-relevant players and activities as well as the privacy policies that govern these activities. The technical reference architecture defines the technology needed for implementing the identified practices.
Privacy in a mobile environment	Future mobile network operators will provide users with all the information and services they want. Using a mobile phone for services is strongly dependent on personalization to provide the user with a comfortable experience. Hence many of these services (e.g. location, electronic wallet) will handle sensitive user data. This article presents a technique with which the network operator supports user needs for personal information privacy against third parties like Internet service providers. We propose a new and user-friendly method for handling privacy. The method is based on a privacy receipt mechanism for all personal data that the user agrees to be transferred to third parties. The role of the network operator in our scenario is that of consumer privacy protector, since the operators already store and process many sensitive user data and must comply with data protection legislation.
Privacy of trust in similarity estimation through secure computations	Current e-commerce applications provide a binary definition of trust depending on whether requirements are satisfied or not. However, trust can be seen as a more general and subjective concept tightly linked to reputation. The subjectivity of the evaluations of certain behaviours justifies this kind of trust. We intend agents to manage subjective trust as humans do, in a vague and abstract way, as a fuzzy concept. In this paper we extend our previous work about the introduction of newcomers into an already running agent system. Because of the economical and strategic value of the trust-related information exchanged in such e-commercial scenarios, access to this information should be restricted to a certain group of close agents. Agents were grouped in cooperative clusters according to similarity of opinions about others. Specifically this paper evaluates the privacy of these opinions while similarity can be easily estimated. The results of this evaluation will justify the use of secure computations in the introduction of newcomers.
Privacy and trusted computing	This paper examines a model of trusted computing wherein a computing platform is able to make assertions about its current software configuration that may be trusted by the user and remote third parties. The privacy implications of this approach are investigated in the context of the Trusted Computing Platform Alliance (TCPA) specification. The trust relationships of the TCPA architecture are examined in detail. An analysis of the revocation requirements inherent in the TCPA design is presented, which highlights the challenges that revocation presents in the context of a large scale deployment of TCPA platforms. Finally, a modification to the specification is suggested that reduces the level of trust that need to be placed on the Privacy CA.
Towards a logic of privacy-preserving selective disclosure credential protocols	This paper presents a first approach towards a logic suited for protocols aiming to achieve selective disclosure of credentials while preserving privacy. The analysis draws from the BAN and related logics by M. Burrows et al (1990) and P. Syverson and I. Cervesanto (2001) that are targeted to aid reasoning about authentication protocols, as well as from formal methods on PKIs by C. Liu et al (2000, 2001) . The families of protocols directly covered are built using selective disclosure certificates, blind signatures and one-way has functions as cryptographic primitives. The logic is able to prove that if the protocol's credentials are properly constructed and signed by trusted issuers, they should convince a verifier; furthermore, it provides a framework on which mechanized attacks against privacy may be attempted by an automatic theorem prover. The runner example is a protocol by J.E. Holt and K.E. Seamons (2002).
Privacy in an identity-based DRM system	The present paper addresses privacy issues in electronic audio/video content distribution. It introduces an identity-based rights distribution and management system that enables users to access content anytime, anywhere, and on any device by means of authorization certificates issued by a content provider. These certificates openly link the identity of the users to the content that they are entitled to access. This fact, together with the availability of the certificates everywhere in the network, raises user privacy issues. A solution is proposed which deals with these issues and still allows the device to securely check the user's entitlement to the content.
A flexible role-based secure messaging service: exploiting IBE technology for privacy in health care	The management of private and confidential information is a major problem for dynamic organizations. Secure solutions are needed to exchange confidential documents, protect them against unauthorized accesses and cope with changes of people's roles and permissions. Traditional cryptographic systems and PKI show their limitations, in terms of flexibility and manageability. This paper describes an innovative technical solution in the area of secure messaging that exploits identifier-based encryption (IBE) technology. It illustrates the advantages against a similar approach based on traditional cryptography and PKI. It discusses a few open issues. Our main contribution is a practical solutions based on IBE technology. A secure messaging system based on IBE has been fully implemented and it is currently used in a trial with a UK health service organization.
Amending P3P for clearer privacy promises	The Platform for Privacy Preferences (P3P) can be a viable tool for organizations to clarify their privacy promises. In this paper, we summarize our experiences and describe some of the problems we have encountered when using P3P. Our main criticisms on P3P are its complicated structure, ambiguities in the specification, and missing guidelines for user agents. We suggest several improvements such as an extended but simplified syntax and a revised consent model that groups opt-in/opt-out choices into one "consent block", which can be associated with multiple statements.
Towards accountable management of identity and privacy: sticky policies and enforceable tracing services	Digital identities and profiles are precious assets. On one hand they enable users to engage in transactions and interactions on the Internet. On the other hand, abuses and leakages of this information could violate the privacy of their owners, sometimes with serious consequences. Nowadays most of the people have limited understanding of security and privacy policies when applied to their confidential information and little control over the destiny of this information since it has been disclosed to third parties. In most cases this is a matter of trust. This document describes an innovative approach and related mechanisms to enforce users' privacy by putting users in control and making organizations more accountable. As part of our ongoing research activity, we introduce a technical solution based on sticky policies and tracing services that leverages identity-based encryption (IBE) and TCPA technologies. Work is in progress to build a full working prototype and deploy it in a real-life environment.
A Random ID Update Scheme to Protect Location Privacy in RFID-Based Student Administration Systems	Recently the RFID has been received great attentions and gotten wide applications in many different areas including some administration systems for automatically managing students in a campus. However, a RFID tag may infringe on its owner's location privacy because of its traceability. Therefore, location privacy problems in RFID-based student administration systems become a critical issue in applying such systems to the practical. Three representative schemes to solve these problems are explained and analyzed. Moreover, a safe, fast and low cost scheme which offers better privacy protections is proposed. In this scheme, a hash value is generated from a secret ID and a random number in a RFID tag by using a cheap hash circuit, and it is used for an identifier of a user. The secret ID is updated by using the hash circuit when a reader for updating is used. Finally, some comparisons between the proposed scheme and the other three typical schemes are presented in terms of safety, speed and cost
Innovative Ideas in Privacy Research (Keynote Talk)	Privacy is fundamental to trusted collaboration and interactions to protect against malicious users and fraudulent activities. It is difficult to even impossible to preserve privacy in peer to peer large distributed system. In such networks, privacy is needed to protect the source of information, the destination (end user) of information, the route of information transmission and dissemination, and information content itself
Privacy, Security and Trust in P2P environments: A Perspective	The peer-to-peer (P2P) paradigm of computing has been growing dramatically in popularity over the last decade. Consequently, large amounts of data are being shared among P2P users on a global-scale. Given the inherently untrustworthy nature of P2P networks, this paper provides a perspective concerning trust, privacy and security issues in P2P networks. Additionally, we discuss the applicability of the P2P paradigm to new application domains, the aim being to ensure that the power of the P2P paradigm goes well beyond P2Pfile-sharing interactions
A method of security improvement for privacy preserving association rule mining over vertically partitioned data	There have been growing interests in privacy preserving data mining. Secure multiparty computation (SMC) is often used to give a solution. When data is vertically partitioned scalar product is a feasible tool to securely discover frequent itemsets of association rule mining. However, there may be disparity among the securities of different parties. To obtain equal privacy, the security of some parties may be lowered. This paper discusses the disharmony between the securities of two parties. The scalar product of two parties from the point of view of matrix computation is described. We present one algorithm for completely two-party computation of scalar product. Then we give a method of security improvement for both parties.
Privacy aware data generation for testing database applications	Testing of database applications is of great importance. A significant issue in database application testing consists in the availability of representative data. In this paper, we investigate the problem of generating a synthetic database based on a-priori knowledge about a production database. Our approach is to fit general location model using various characteristics (e.g., constraints, statistics, rules) extracted from the production database and then generate the synthetic data using model learnt. The generated data is valid and similar to real data in terms of statistical distribution, hence it can be used for functional and performance testing. As characteristics extracted may contain information which may be used by attacker to derive some confidential information about individuals, we present our disclosure analysis method which applies cell suppression technique for identity disclosure analysis and perturbation for value disclosure.
Algorithms for balancing privacy and knowledge discovery in association rule mining	The discovery of association rules from large databases has proven beneficial for companies since such rules can be very effective in revealing actionable knowledge that leads to strategic decisions. In tandem with this benefit, association rule mining can also pose a threat to privacy protection. The main problem is that from non-sensitive information or unclassified data, one is able to infer sensitive information, including personal information, facts, or even patterns that are not supposed to be disclosed. This scenario reveals a pressing need for techniques that ensure privacy protection, while facilitating proper information accuracy and mining. In this paper, we introduce new algorithms for balancing privacy and knowledge discovery in association rule mining. We show that our algorithms require only two scans, regardless of the database size and the number of restrictive association rules that must be protected. Our performance study compares the effectiveness and scalability of the proposed algorithms and analyzes the fraction of association rules, which are preserved after sanitizing a database. We also report the main results of our performance evaluation and discuss some open research issues.
Malafide Intension and its mapping to Privacy Policy Purposes for Masquerading	In presence of a robust privacy infrastructure, an attacker can fulfil his purpose (malafide intension) only by masquerading it with bonafide purposes besides other authentication parameters. We address the issue of masquerading of purpose for a malafide intension by defining the mapping from a malafide intension to bonafide purposes in this paper. An understanding of such a mapping can facilitate both a hacker (assist him in masquerading) and a forensic expert to investigate malafide accesses. Determination of these bonafide purposes may help speed up the violation detection if the user accesses log has listed bonafide purpose with each user access. The bonafide purposes can be determined in data-independent (without accessing the database) or data-dependent (database access is required) mode. In this paper we define a mapping of a malafide intension to bonafide purposes in data-independent mode
Privacy preserving Data Mining Algorithms without the use of Secure Computation or Perturbation	In our era knowledge is not "just" information any more, it is an asset. Data mining can be used to extract important knowledge from large databases. These days, it is often the case that such databases are distributed among several organizations who would like to cooperate in order to extract global knowledge, but at the same time, privacy concerns may prevent the parties from directly sharing the data among them. The two current main methods to perform data mining tasks without compromising privacy are: the perturbation method and the secure computation method. Many papers and published algorithms are based on those two methods. Yet, both have some disadvantages, like reduced accuracy for the first and increased overhead for the second. In this article we offer a new paradigm to perform privacy-preserving distributed data mining without using those methods, we present three algorithms for association rule mining which use this paradigm, and discuss their privacy and performance characteristics
Towards a Lightweight Framework for Privacy Preserving P2P XML Databases	The problem of securing XML databases is rapidly gaining interest for both academic and industrial research. It becomes even more challenging when XML data are managed and delivered according to the P2P paradigm, as malicious attacks could take advantage from the totally-decentralized and untrusted nature of P2P networks. Starting from these considerations, in this paper we propose the guidelines of a distributed framework for supporting (i) secure fragmentation of XML documents into P2P XML databases by means of lightweight XPath-based identifiers, and (it) the creation of trusted groups of peers by means of "self-certifying" XPath links that exploit the benefits of well-known fingerprinting techniques
Probabilistic Internal Privacy Intrusion Detection	Many organizations need to maintain a lot of private data to run their businesses. Private data could be violated by both the inside and the outside intruders. In this paper, we propose a probabilistic method to detect insider privacy intrusion in database systems
Preserving Mobile-Sink-Location Privacy in Wireless Sensor Networks	As wide applications of wireless sensor networks, privacy concerns have emerged as the main obstacle to success. When wireless sensor networks are used to battlefield, the privacy about sink-locations become a crux issue. If sink location will be exposed to adversary, the consequence is inconceivable. In this paper, a scheme based on local flooding of source and greedy random-walk of sink is proposed to protect the location privacy of mobile sinks in sensor networks. In this scheme, sensor do not know any information about sink-location, data are forwarded by local flooding and stored at pass nodes in the network, the sink move in greedy random-walk to collect data from the local nodes occasionally, which prevents the attackers from predicting their locations and movements. The analysis shows that the scheme can provide location privacy of mobile sinks effectively, while providing satisfactory data collection services.
A Survey on Privacy Preserving Data Mining	Privacy preserving becomes an important issue in the development progress of data mining techniques. Privacy preserving data mining has become increasingly popular because it allows sharing of privacy-sensitive data for analysis purposes. So people have become increasingly unwilling to share their data, frequently resulting in individuals either refusing to share their data or providing incorrect data. In turn, such problems in data collection can affect the success of data mining, which relies on sufficient amounts of accurate data in order to produce meaningful results. In recent years, the wide availability of personal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been proposed for privacy preserving data mining of multidimensional data records. This paper intends to reiterate several privacy preserving data mining technologies clearly and then proceeds to analyze the merits and shortcomings of these technologies.
A Survey on Privacy Preserving Approaches in Data Publishing	Privacy preserving in data publishing has become one of the most important research topics in data security field and it has become a serious concern in publication of personal data in recent years. How to efficiently protect individual privacy in data publishing is especially critical. Thus, various proposals have been designed for privacy preserving in data publishing. In this paper, we summarize privacy preserving approaches in data publishing and survey current existing techniques, and analyze the advantage and disadvantage of these approaches. We divide these proposals into two categories, one is to achieve the purpose of privacy preserving based on k-anonymity model, and the other is to utilize the methods of probability or statistics to protect data privacy in the case of the statistical properties of the final data and classification properties are unchanged. For example, clustering, randomization approaches. Finally, we discuss the future directions of privacy preserving in data publishing.
Individual Privacy And The New Technology	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00697071.png" border="0">
Distributed privacy for visual sensor networks via Markov shares	Visual sensor networks (VSNs) can be used to acquire visual data (i.e. images) for applications such as military reconnaissance, surveillance, and monitoring. In these applications, it is of utmost importance that visual data be protected against eavesdropping to uphold confidentiality and privacy rights. Furthermore, protection mechanisms for these sensor nodes must be efficient and robust to node capture and tampering. This paper considers a distributed approach to privacy in which highly correlated images within a dense sensor cluster are obfuscated. The particular approach, in which nodes within a cluster work together to create and transmit shares (called Markov shares) makes it necessary for an attacker to capture several correlated visual nodes and/or shares in order to gain improved semantic information of the observation area. The proposed technique does not require that the individual sensor node readings be exactly registered, nor the correlation model be known a priori. Simulation results based on a cluster of 18 nodes show: (1) most Markov shares use fewer bits per pixel than the original image hence providing compression capability; (2) a denial of service attack on a single node (e.g., corrupting a region of interest) has minimal impact on the reconstructed data at the sink; (3) five or more Markov shares need to be intercepted by an attacker before the semantic content of the desired image can be understood; and (4) authorized reconstruction of unregistered individual images with random rotation transformations up to 10 degrees is possible
Current and Emerging Security, Trust, Dependability and Privacy Challenges in Mobile Telecommunications	We discuss the near-term and far-term security, trust and dependability challenges in wireless and mobile telecommunications, in an always-connected environment. We identify some relevant technological and threat trends and propose research priorities in order to solve and respond to the future security-related challenges. Threat trends include increase of complexity and connectivity and challenges in wirelessness, user devices and network management. To overcome future challenges, new proactive solutions should be developed. Furthermore, metrics, methods and tools for security assurance, forensics and vulnerability management are needed. In particular, widely-accepted security, trust, dependability and privacy solutions for the Future Internet architecture are needed.
Large Margin Gaussian Mixture Models with Differential Privacy	As increasing amounts of sensitive personal information is aggregated into data repositories, it has become important to develop mechanisms for processing the data without revealing information about individual data instances. The differential privacy model provides a framework for the development and theoretical analysis of such mechanisms. In this paper, we propose an algorithm for learning a discriminatively trained multiclass Gaussian mixture model-based classifier that preserves differential privacy using a large margin loss function with a perturbed regularization term. We present a theoretical upper bound on the excess risk of the classifier introduced by the perturbation.
Access Control with Privacy Enhancements a Unified Approach	We describe an approach that aims to unify certain aspects of access control and privacy. Our unified approach is based on the idea of axiomatizing access control in general terms. We show how multiple access control and privacy models and policies can be uniformly represented as particular logical theories in our axiom system. We show that our approach translates into different practical languages for implementation and we give some performance measures for some candidate implementations of our approach.
Guest Editors' Introduction: Special Section on Data and Applications Security and Privacy	The four papers in this special section focus on the latest advancements in data and application systems in the information security and privacy industry.
An Obfuscation-Based Approach for Protecting Location Privacy	The pervasive diffusion of mobile communication devices and the technical improvements of location techniques are fostering the development of new applications that use the physical position of users to offer location-based services for business, social, or informational purposes. In such a context, privacy concerns are increasing and call for sophisticated solutions able to guarantee different levels of location privacy to the users. In this paper, we address this problem and present a solution based on different obfuscation operators that, when used individually or in combination, protect the privacy of the location information of users. We also introduce an adversary model and provide an analysis of the proposed obfuscation operators to evaluate their robustness against adversaries aiming to reverse the obfuscation effects to retrieve a location that better approximates the location of the users. Finally, we present some experimental results that validate our solution.
Guest Editor's Introduction: 2005 IEEE Symposium on Security and Privacy	
On Privacy of Encrypted Speech Communications	Silence suppression, an essential feature of speech communications over the Internet, saves bandwidth by disabling voice packet transmissions when silence is detected. However, silence suppression enables an adversary to recover talk patterns from packet timing. In this paper, we investigate privacy leakage through the silence suppression feature. More specifically, we propose a new class of traffic analysis attacks to encrypted speech communications with the goal of detecting speakers of encrypted speech communications. These attacks are based on packet timing information only and the attacks can detect speakers of speech communications made with different codecs. We evaluate the proposed attacks with extensive experiments over different type of networks including commercial anonymity networks and campus networks. The experiments show that the proposed traffic analysis attacks can detect speakers of encrypted speech communications with high accuracy based on traces of 15 minutes long on average.
Achieving privacy in trust negotiations with an ontology-based approach	The increasing use of Internet in a variety of distributed multiparty interactions and transactions with strong real-time requirements has pushed the search for solutions to the problem of attribute-based digital interactions. A promising solution today is represented by automated trust negotiation systems. Trust negotiation systems allow subjects in different security domains to securely exchange protected resources and services. These trust negotiation systems, however, by their nature, may represent a threat to privacy in that credentials, exchanged during negotiations, often contain sensitive personal information that may need to be selectively released. In this paper, we address the problem of preserving privacy in trust negotiations. We introduce the notion of privacy preserving disclosure, that is, a set that does not include attributes or credentials, or combinations of these, that may compromise privacy. To obtain privacy preserving disclosure sets, we propose two techniques based on the notions of substitution and generalization. We argue that formulating the trust negotiation requirements in terms of disclosure policies is often restrictive. To solve this problem, we show how trust negotiation requirements can be expressed as property-based policies that list the properties needed to obtain a given resource. To better address this issue, we introduce the notion of reference ontology, and formalize the notion of trust requirement. Additionally, we develop an approach to derive disclosure policies from trust requirements and formally state some semantics relationships (i.e., equivalence, stronger than) that may hold between policies. These relationships can be used by a credential requestor to reason about which disclosure policies he/she should use in a trust negotiation.
PriPAYD: Privacy-Friendly Pay-As-You-Drive Insurance	Pay-As-You-Drive insurance schemes are establishing themselves as the future of car insurance. However, their current implementations, in which fine-grained location data are sent to insurers, entail a serious privacy risk. We present PriPAYD, a system where the premium calculations are performed locally in the vehicle, and only aggregated data are sent to the insurance company, without leaking location information. Our design is based on well-understood security techniques that ensure its correct functioning. We discuss the viability of PriPAYD in terms of cost, security, and ease of certification. We demonstrate that PriPAYD is possible through a proof-of-concept implementation that shows how privacy can be obtained at a very reasonable extra cost.
Security and Privacy-Enhancing Multicloud Architectures	Security challenges are still among the biggest obstacles when considering the adoption of cloud services. This triggered a lot of research activities, resulting in a quantity of proposals targeting the various cloud security threats. Alongside with these security issues, the cloud paradigm comes with a new set of unique features, which open the path toward novel security approaches, techniques, and architectures. This paper provides a survey on the achievable security merits by making use of multiple distinct clouds simultaneously. Various distinct architectures are introduced and discussed according to their security and privacy capabilities and prospects.
Incentive Compatible Privacy-Preserving Distributed Classification	In this paper, we propose game-theoretic mechanisms to encourage truthful data sharing for distributed data mining. One proposed mechanism uses the classic Vickrey-Clarke-Groves (VCG) mechanism, and the other relies on the Shapley value. Neither relies on the ability to verify the data of the parties participating in the distributed data mining protocol. Instead, we incentivize truth telling based solely on the data mining result. This is especially useful for situations where privacy concerns prevent verification of the data. Under reasonable assumptions, we prove that these mechanisms are incentive compatible for distributed data mining. In addition, through extensive experimentation, we show that they are applicable in practice.
On the Privacy Risks of Virtual Keyboards: Automatic Reconstruction of Typed Input from Compromising Reflections	We investigate the implications of the ubiquity of personal mobile devices and reveal new techniques for compromising the privacy of users typing on virtual keyboards. Specifically, we show that so-called compromising reflections (in, for example, a victim's sunglasses) of a device's screen are sufficient to enable automated reconstruction, from video, of text typed on a virtual keyboard. Through the use of advanced computer vision and machine learning techniques, we are able to operate under extremely realistic threat models, in real-world operating conditions, which are far beyond the range of more traditional OCR-based attacks. In particular, our system does not require expensive and bulky telescopic lenses: rather, we make use of off-the-shelf, handheld video cameras. In addition, we make no limiting assumptions about the motion of the phone or of the camera, nor the typing style of the user, and are able to reconstruct accurate transcripts of recorded input, even when using footage captured in challenging environments (e.g., on a moving bus). To further underscore the extent of this threat, our system is able to achieve accurate results even at very large distances-up to 61 m for direct surveillance, and 12 m for sunglass reflections. We believe these results highlight the importance of adjusting privacy expectations in response to emerging technologies.
Enhanced Privacy ID: A Direct Anonymous Attestation Scheme with Enhanced Revocation Capabilities	Direct Anonymous Attestation (DAA) is a scheme that enables the remote authentication of a Trusted Platform Module (TPM) while preserving the user's privacy. A TPM can prove to a remote party that it is a valid TPM without revealing its identity and without linkability. In the DAA scheme, a TPM can be revoked only if the DAA private key in the hardware has been extracted and published widely so that verifiers obtain the corrupted private key. If the unlinkability requirement is relaxed, a TPM suspected of being compromised can be revoked even if the private key is not known. However, with the full unlinkability requirement intact, if a TPM has been compromised but its private key has not been distributed to verifiers, the TPM cannot be revoked. Furthermore, a TPM cannot be revoked from the issuer, if the TPM is found to be compromised after the DAA issuing has occurred. In this paper, we present a new DAA scheme called Enhanced Privacy ID (EPID) scheme that addresses the above limitations. While still providing unlinkability, our scheme provides a method to revoke a TPM even if the TPM private key is unknown. This expanded revocation property makes the scheme useful for other applications such as for driver's license. Our EPID scheme is efficient and provably secure in the same security model as DAA, i.e., in the random oracle model under the strong RSA assumption and the decisional Diffie-Hellman assumption.
Non-Cooperative Location Privacy	In mobile networks, authentication is a required primitive for most security protocols. Unfortunately, an adversary can monitor pseudonyms used for authentication to track the location of mobile nodes. A frequently proposed solution to protect location privacy suggests that mobile nodes collectively change their pseudonyms in regions called mix zones. This approach is costly. Self-interested mobile nodes might, thus, decide not to cooperate and jeopardize the achievable location privacy. In this paper, we analyze non-cooperative behavior of mobile nodes by using a game-theoretic model, where each player aims at maximizing its location privacy at a minimum cost. We obtain Nash equilibria in static n-player complete information games. As in practice mobile nodes do not know their opponents' payoffs, we then consider static incomplete information games. We establish that symmetric Bayesian-Nash equilibria exist with simple threshold strategies. By means of numerical results, we predict behavior of selfish mobile nodes. We then investigate dynamic games where players decide to change their pseudonym one after the other and show how this affects strategies at equilibrium. Finally, we design protocols-PseudoGame protocols-based on the results of our analysis and simulate their performance in vehicular network scenarios.
Privacy-Preserving Enforcement of Spatially Aware RBAC	Several models for incorporating spatial constraints into role-based access control (RBAC) have been proposed, and researchers are now focusing on the challenge of ensuring such policies are enforced correctly. However, existing approaches have a major shortcoming, as they assume the server is trustworthy and require complete disclosure of sensitive location information by the user. In this work, we propose a novel framework and a set of protocols to solve this problem. Specifically, in our scheme, a user provides a service provider with role and location tokens along with a request. The service provider consults with a role authority and a location authority to verify the tokens and evaluate the policy. However, none of the servers learn the requesting user's identity, role, or location. In this paper, we define the protocols and the policy enforcement scheme, and present a formal proof of a number of security properties.
The F_f-Family of Protocols for RFID-Privacy and Authentication	In this paper, we present the design of the lightweight F<sub>f</sub> family of privacy-preserving authentication protocols for RFID-systems. F<sub>f</sub> results from a systematic design based on a new algebraic framework focusing on the security and privacy of RFID authentication protocols. F<sub>f</sub> offers user-adjustable, strong authentication, and privacy against known algebraic attacks and recently popular SAT-solving attacks. In contrast to related work, F<sub>f</sub> achieves these security properties without requiring an expensive cryptographic hash function. F<sub>f</sub> is designed for a challenge-response protocol, where the tag sends random nonces and the results of HMAC-like computations of one of the nonces together with its secret key back to the reader. In this paper, the authentication and privacy of F<sub>f</sub> is evaluated using analytical and experimental methods.
Location-Aware and Safer Cards: Enhancing RFID Security and Privacy via Location Sensing	In this paper, we report on a new approach for enhancing security and privacy in certain RFID applications whereby location or location-related information (such as speed) can serve as a legitimate access context. Examples of these applications include access cards, toll cards, credit cards, and other payment tokens. We show that location awareness can be used by both tags and back-end servers for defending against unauthorized reading and relay attacks on RFID systems. On the tag side, we design a location-aware selective unlocking mechanism using which tags can selectively respond to reader interrogations rather than doing so promiscuously. On the server side, we design a location-aware secure transaction verification scheme that allows a bank server to decide whether to approve or deny a payment transaction and detect a specific type of relay attack involving malicious readers. The premise of our work is a current technological advancement that can enable RFID tags with low-cost location (GPS) sensing capabilities. Unlike prior research on this subject, our defenses do not rely on auxiliary devices or require any explicit user involvement.
Privacy-Preserving Updates to Anonymous and Confidential Databases	Suppose Alice owns a k-anonymous database and needs to determine whether her database, when inserted with a tuple owned by Bob, is still k-anonymous. Also, suppose that access to the database is strictly controlled, because for example data are used for certain experiments that need to be maintained confidential. Clearly, allowing Alice to directly read the contents of the tuple breaks the privacy of Bob (e.g., a patient's medical record); on the other hand, the confidentiality of the database managed by Alice is violated once Bob has access to the contents of the database. Thus, the problem is to check whether the database inserted with the tuple is still k-anonymous, without letting Alice and Bob know the contents of the tuple and the database, respectively. In this paper, we propose two protocols solving this problem on suppression-based and generalization-based k-anonymous and confidential databases. The protocols rely on well-known cryptographic assumptions, and we provide theoretical analyses to proof their soundness and experimental results to illustrate their efficiency.
MultiPathPrivacy: Enhanced Privacy in Fault Replication	Most computer applications are published with bugs, whose reproducibility is strictly dependent on the availability of detailed information about the real usage of the application. Unfortunately, this data collection process raises severe privacy issues, as error reports are very likely to include personal information. This represents a strong disincentive for users to submit error reports, hampering the software maintenance process. In this work we address the issue of how to design data obfuscation mechanisms aimed at anonymizing the error reports generated by faulty applications, without compromising the bug reproducibility. The solution presented in this paper, MultiPathPrivacy, is based on an idea which is, to the best our knowledge, still unexplored in literature: maximizing the achievable degree of obfuscation by exploiting the presence of multiple execution paths leading to the manifestation of the same bug. MultiPathPrivacy relies on an off-line reach ability analysis phase, based on symbolic execution techniques, which is aimed at identifying not only the set of alternative execution paths leading to the execution of the code block where the bug manifested, but also to determine the symbolic constraints on the user inputs that are necessary to generate such execution paths. By exploiting the presence of disjoint sets of alternative user inputs/execution paths leading to the manifestation of the same bug, MultiPathPrivacy allows achieving striking improvements of the anonymization quality when compared to state of the art solutions. Via an experimental study, based both on a real, privacy-sensitive application and on publicly available software repositories, we show that MultiPathPrivacy can achieve up to 87% reduction of the amount of user input information leaked by the error report, evaluated in terms of bits of information revealed, and percentage of residual non-anonymized input.
Privacy-preserving Bayesian network structure learning on distributed heterogeneous data	Privacy concerns often prevent different parties from sharing their data in order to carry out data mining applications on their joint data. Privacy-preserving data mining provides a solution by creating distributed data mining algorithm in which the underlying data is not revealed. In this paper, we address a particular data mining problem, learning the structure of Bayesian network on distributed heterogeneous data. In this setting, three or more parties owning confidential databases wish to learn the structure on the combination of their databases without revealing anything about their data to each other. We provide a private generalized scalar product share protocol for learning the empirical entropy. Then we give an effective and privacy-preserving version of the B&BMDL algorithm to construct the structure of a Bayesian network for the parties' joint data. In comparison to the previously known solution for this problem (Wright and Yang, 2004), which is based on K2 algorithm, our solution provides complete accuracy, full privacy, ideal universality, and better performance. In particular, our solution provides fully private, in that the only thing the parties learn about each other's inputs is the desired output and the number of stochastic variables' value, and more universal, in that the databases partitioned vertically are among three or more parties, and completely accurate, in that the structure computed are exactly what they would be if the data was centralized. In addition, our solution works for both binary and non-binary discrete data.
An empirical study of the performance, security and privacy implications of domain name prefetching	An increasingly popular technique for decreasing user-perceived latency while browsing the Web is to optimistically pre-resolve (or prefetch) domain name resolutions. In this paper, we present a large-scale evaluation of this practice using data collected over the span of several months, and show that it leads to noticeable increases in load on name servers-with questionable caching benefits. Furthermore, to assess the impact that prefetching can have on the deployment of security extensions to DNS (DNSSEC), we use a custom-built cache simulator to perform trace-based simulations using millions of DNS requests and responses collected campus-wide. We also show that the adoption of domain name prefetching raises privacy issues. Specifically, we examine how prefetching amplifies information disclosure attacks to the point where it is possible to infer the context of searches issued by clients.
Improving privacy and lifetime of PCM-based main memory	Phase change memory (PCM) is a promising technology for computer memory systems. However, the non-volatile nature of PCM poses serious threats to computer privacy. The low programming endurance of PCM devices also limits the lifetime of PCM-based main memory (PRAM). In this paper, we first adopt counter-mode encryption for privacy protection and show that encryption significantly reduces the effectiveness of some previously proposed wear-leveling techniques for PRAM. To mitigate such adverse impact, we propose simple, yet effective extensions to the encryption scheme. In addition, we propose to reuse the encryption counters as age counters and to dynamically adjust the strength of error correction code (ECC) to extend the lifetime of PRAM. Our experiments show that our mechanisms effectively achieve privacy protection and lifetime extension for PRAM with very low performance overhead.
Scalable RFID systems: a privacy-preserving protocol with constant-time identification	In RFID literature, most ΓÇ£privacy-preservingΓÇ¥ protocols require the reader to search all tags in the system in order to identify a single tag. In another class of protocols, the search complexity is reduced to be logarithmic in the number of tags, but it comes with two major drawbacks: it requires a large communication overhead over the fragile wireless channel, and the compromise of a tag in the system reveals secret information about other, uncompromised, tags in the same system. In this work, we take a different approach to address time-complexity of private identification in large-scale RFID systems. We utilize the special architecture of RFID systems to propose the first symmetric-key privacy-preserving authentication protocol for RFID systems with constant-time identification. Instead of increasing communication overhead, the existence of a large storage device in RFID systems, the database, is utilized for improving the time efficiency of tag identification.
Privacy leakage in two-party group nearest neighbor queries	Location-based social network (LBSN) requires answering a variety of queries related to user locations. In this paper, we investigate issues in performing secure multi-party computation in LBNS and discuss some of the challenges and problems associated with it. In particular, we look at the group nearest neighbor queries and discuss the privacy leakage problem in two party group nearest neighbor computation. We elucidate the attack model and propose a privacy leakage index to measure the impact. We perform experiments to show the privacy leakage problem and suggest a solution to deal with this problem.
An Upper-Bound Control Approach for Cost-Effective Privacy Protection of Intermediate Dataset Storage in Cloud	Along with more and more data intensive applications have been migrated into cloud environments, storing some valuable intermediate datasets has been accommodated in order to avoid the high cost of re-computing them. However, this poses a risk on data privacy protection because malicious parties may deduce the private information of the parent dataset or original dataset by analyzing some of those stored intermediate datasets. The traditional way for addressing this issue is to encrypt all of those stored datasets so that they can be hidden. We argue that this is neither efficient nor cost-effective because it is not necessary to encrypt ALL of those datasets and encryption of all large amounts of datasets can be very costly. In this paper, we propose a new approach to identify which stored datasets need to be encrypted and which not. Through intensive analysis of information theory, our approach designs an upper bound on privacy measure. As long as the overall mixed information amount of some stored datasets is no more than that upper bound, those datasets do not need to be encrypted while privacy can still be protected. A tree model is leveraged to analyze privacy disclosure of datasets, and privacy requirements are decomposed and satisfied layer by layer. With a heuristic implementation of this approach, evaluation results demonstrate that the cost for encrypting intermediate datasets decreases significantly compared with the traditional approach while the privacy protection of parent or original dataset is guaranteed.
Privacy as a Service: Privacy-Aware Data Storage and Processing in Cloud Computing Architectures	In this paper we present PasS (privacy as a service); a set of security protocols for ensuring the privacy and legal compliance of customer data in cloud computing architectures. PasS allows for the secure storage and processing of users' confidential data by leveraging the tamper-proof capabilities of cryptographic coprocessors. Using tamper-proof facilities provides a secure execution domain in the computing cloud that is physically and logically protected from unauthorized access. PasS central design goal is to maximize users' control in managing the various aspects related to the privacy of sensitive data. This is achieved by implementing user-configurable software protection and data privacy mechanisms. Moreover, PasS provides a privacy feedback process which informs users of the different privacy operations applied on their data and makes them aware of any potential risks that may jeopardize the confidentiality of their sensitive information. To the best of our knowledge, PasS is the first practical cloud computing privacy solution that utilizes previous research on cryptographic coprocessors to solve the problem of securely processing sensitive data in cloud computing infrastructures.
An Algorithm for Privacy-Preserving Quantitative Association Rules Mining	When data mining occurs on distributed data, privacy of parties becomes great concerns. This paper considers the problem of mining quantitative association rules without revealing the private information of parties who compute jointly and share distributed data. The issue is an area of privacy preserving data mining (PPDM) research. Some researchers have considered the case of mining Boolean association rules; however, this method cannot be easily applied to quantitative rules mining. A new secure set union algorithm is proposed in this paper, which unifies the input sets of parties without revealing any element's owner and has lower time cost than existing algorithms. The new algorithm takes the advantages of both in privacy-preserving Boolean association rules mining and in privacy-preserving quantitative association mining. This paper also presents an algorithm for privacy-preserving quantitative association rules mining over horizontally portioned data, based on CF tree and secure sum algorithm. Besides, the analysis of the correctness, the security and the complexity of our algorithms are provided
IEEE Security & Privacy Magazine	
IEEE Security & Privacy Subscription Offer	
Secure and privacy aware RFIDs	Radio Frequency Identification (RFID) systems usage has seen a dramatic surge in recent years. The technology is pervasive and already pervades our daily lives from goods in retail stores, car tyres, through to car keys and medicine packaging. Increasingly RFID technology is being asked to do much more, for example in ePassports / identity Cards and in healthcare, which raises the stakes in terms of security and presents more acute privacy concerns. There are a number of deployed systems which raise both serious privacy and security concerns and potentially fail to meet their objectives.
An embedded platform for privacy-friendly road charging applications	Systems based on satellite localization are enabling new scenarios for road charging schemes by offering the possibility to charge drivers as a function of their road usage. An in-vehicle installation of a black box with the capabilities of a Location Based Service terminal suffices to deploy such a scheme. In the most straightforward architecture a back-end server collects vehicle's location data in order to extract the correct fees. However, with industry, governments and users being more and more aware of privacy issues the deployment of such system seems to be contradictory. Our contribution is the demonstration of a practical and functional road charging system based on PriPAYD [1]. Our black box is built guaranteeing most of the processing of location data in real-time, thus minimizing overheads required to ensure security and privacy. The performance of our software-based prototype is tested and proves that the deployment of a privacy-friendly solution can be achieved within a minimum cost increment compared to existing road charging schemes.
Preventing the Privacy Problem via Integration of Users Preferences and Semantic Structure	Web recommendation systems are affected by privacy concerns and legislations. In this paper, we suggested integration between abstract users' preferences and the website semantic structure, which enable us to identify users' power of thinking on specific items. Web personalization systems aim to provide users with what they are looking for on a specific web site. Therefore we collected abstract users' preferences, which are used to create users' integrated routes. These integrated routes were injected into the websites semantics. Users' browsing targets are used to identify them, and also they are used to generate personal recommendations. Our experimental results showed that users are highly satisfied with the use of their power of thinking to provide recommendations, instead of using their demographic information.
Privacy of general aviation aircraft in the NextGen	ADS-B presents location privacy threat to GA aircraft operators. Encryption based privacy solutions are impractical for GA. We proposed simple solutions to enhance ADS-B privacy. enable privacy preserving beneficial access to ATC services in GA. Specified metrics for assessing achievable operator privacy gains. Open problems include assessing impact on ADS-B applications, identifying opportune scenarios for flight privacy enhancement, and specifying privacy levels desired by GA operators.
Privacy of general aviation aircraft in the NextGen	Future general aviation aircraft are mandated to openly broadcast aircraft identities and real-time position reports for air traffic management. Significant safety, performance, and flexibility gains are expected for airspace users and air traffic control. However, easy access to air traffic communications and increasing data mining abilities on the Internet, potentially enable anyone to remotely identify and track an aircraft belonging to a targeted real-world user. This tracking capability and the personal, political, medical, or proprietary nature of air travel, together raise operator privacy concerns in general aviation. An example concern is ability to infer travel intent and profile places of interest of an aircraft operator. This paper presents a framework to classify the current state of the art in privacy protection for general aviation, and identify the major challenges and tradeoffs for privacy solution design. We propose a new solution space that can minimize the risk of general aviation operator privacy invasions.
Privacy of future air traffic management broadcasts	Future civil aircraft are envisioned to depend on air-to-air and air-to-ground data communications for air traffic management. However, ease of access to wireless communications as well as the personal, political or proprietary nature of air travel raises privacy concerns for some aircraft users. A major concern is exploitation of aircraft's communications for deriving identity and position trajectories of that aircraft, resulting in potential privacy violations such as by helping to infer travel intent and profile places of interest. Privacy enhancement is however challenging to achieve due to a delicate balance with airspace security. This paper identifies location privacy threats and proposes anonymity solutions that can enhance privacy level of aircraft operators and passengers without compromising airspace security.
Actor based domain specific privacy model for U-Healthcare system	The objective of the paper is to propose a privacy model for ubiquitous healthcare system involving unconventional information sources like laboratory scanning equipments, networked computing systems and distributed wireless sensors using an actor based domain specific approach. In the existing privacy models for ubiquitous healthcare systems the trust on the middleware and the deployed security mechanisms through which the privacy threshold levels reached are not discussed. The main focus of the paper is to design architecture for enhancing the privacy over different communication networks. The dynamic trust evaluation and the threat monitoring has been carried out to take a decision based on the role and relationship of the actor. A formal model of privacy in U-Healthcare is arrived involving the attributes of the actor classes and invoking methods in that scenario. The performance of the ubiquitous healthcare system is validated through the proposed privacy metrics based on trust and security over different media.
Special session 3 - security, privacy and trust	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05610676.png" border="0">
Conceptual Modelling: A Privacy Perspective	Current privacy enhancing database systems (e.g., Hippocratic) concentrate on facilitating known privacy regulations and guidelines without major change to the database design according to the properties of personal information. This paper introduces personal information database model based on personal information ontology below the levels of policy and privacy preferences. It includes such aspects as how to represent and store personal information, how to operate on (e.g., update, retrieve) personal information, and how to protect personal information utilizing access control designed according to the properties of personal information.
An Environmentally Adaptive Conceptual Framework for Addressing Information Privacy Issues in Digital Ecosystems	The evolution of collaborative environments towards digital ecosystems comes with increased risks to personal data and entity privacy. To address privacy protection concerns we propose a conceptual framework that integrates technical, legal and contextual components to provide comprehensive system wide privacy. Part of the framework is a privacy evaluator module (PEM). The PEM's function is to assimilate individual information system privacy protection strategies into a consistent ecosystem wide approach.
Towards Client Privacy Policy Enforcement for Small-Medium Enterprises	As information and communication technologies move towards service orientation, many small-medium enterprises (SMEs) are unlikely to consider possible security implications (such as privacy) due to their limited expertise with technology. Policies are commonly used in existing service oriented environments to secure sensitive data. However, failures such as human error, software malfunction, policy contradiction, etc. can result in privacy breaches. In this paper, we propose a privacy device based on the Fail-Safe concept to show how privacy breaches can be avoided. This device uses client-defined policies to protect data released by the service provider.
Papers in track 13 - Security and privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04635130.png" border="0">
Coupled multi-agent simulations for mobile security & privacy research	The complexity of mobile device digital ecosystems is rapidly increasing. Not only the absolute number of mobile devices, but also their diversity is on an ongoing rise. Devices are equipped with multiple short-range communication technologies that are used by different applications, which can become entry points for security or privacy threats. These threats need to be addressed in an early stage, while the mobile ecosystem is still relatively small and flexible. In prior work we presented the advantages of simulation approaches in the field of security and privacy research within the mobile domain. In this paper, we extend the Mobile Security & Privacy Simulator, which allows us to model the ecosystem of mobile devices and its surrounding environment with more details to achieve more realistic results. For this purpose we build up additional sub-simulations for discrete real world sub-scenarios like indoor places and connect them with the main map-based simulation. By this coupling we are able to better fit a simulation to the real world using tailored models for agents as well as for their environment depending on each sub-scenario's characteristics.
Big data privacy issues in public social media	Big Data is a new label given to a diverse field of data intensive informatics in which the datasets are so large that they become hard to work with effectively. The term has been mainly used in two contexts, firstly as a technological challenge when dealing with dataintensive domains such as high energy physics, astronomy or internet search, and secondly as a sociological problem when data about us is collected and mined by companies such as Facebook, Google, mobile phone companies, retail chains and governments. In this paper we look at this second issue from a new perspective, namely how can the user gain awareness of the personally relevant part Big Data that is publicly available in the social web. The amount of user-generated media uploaded to the web is expanding rapidly and it is beyond the capabilities of any human to sift through it all to see which media impacts our privacy. Based on an analysis of social media in Flickr, Locr, Facebook and Google+, we discuss privacy implications and potential of the emerging trend of geo-tagged social media. We then present a concept with which users can stay informed about which parts of the social Big Data deluge is relevant to them.
Towards a framework to handle privacy since the early phases of the development: Strategies and open challenges	Although almost any software application processes personal data, effective development frameworks that properly handle privacy are still missing. This work makes a step to fill this void. This paper investigates requirements and development strategies of a privacy-preserving development framework that deals with privacy since the early phases of the development.
Using contract and ontology for privacy protection in Service-Oriented Architecture	Privacy protection in Service-Oriented Architecture (SOA) is an open problem. As privacy protection can be considered as a contractual issue, the solution for the problem of privacy protection in SOA requires the use of electronic contracts. This is important, as the service consumer's confidence of the protection of their privacy is a factor for the success of electronic services (e-services). This confidence may increase if the service consumer and provider can establish a contract, which states how the provider deals with information collected from the consumer. The service consumer can sign the contract if the privacy protection practices described in it meet what the consumer defines as appropriate practices. The goal of this paper is to use contract and ontology for privacy protection in SOA. Privacy contracts follow an approach based on feature modeling. In addition, they use a base ontology that provides a common privacy vocabulary.
Government Electronic Service Delivery (ESD) and privacy in Ontario	Over the past ten years, web enabled technology has been the catalyst to enhanced Electronic Service Delivery (ESD) delivery. ESD has conveniently reduced the cost to governments and at the same time benefited Ontarians by providing convenient access to services. There remains a concern that the use of web technology increases one's risk to breach of privacy. A privacy breach, where information may be improperly released, can be catastrophic to an individual's identify and to the government's image of trust. The purpose of this report is to review critical web based defences designed by the government to fend off web attacks that may threaten the privacy of Ontarians while accessing government services through a web environment. This is followed by a discussion on strategies users can deploy in order to ensure they protect their own privacy.
Classification of Privacy-preserving Distributed Data Mining protocols	Recently, a new research area, named Privacy-preserving Distributed Data Mining (PPDDM) has emerged. It aims at solving the following problem: a number of participants want to jointly conduct a data mining task based on the private data sets held by each of the participants. This problem setting has captured attention and interests of researchers, practitioners and developers from the communities of both data mining and information security. They have made great progress in designing and developing solutions to address this scenario. However, researchers and practitioners are now faced with a challenge on how to devise a standard on synthesizing and evaluating various PPDDM protocols, because they have been confused by the excessive number of techniques developed so far. In this paper, we put forward a framework to synthesize and characterize existing PPDDM protocols so as to provide a standard and systematic approach of understanding PPDDM-related problems, analyzing PPDDM requirements and designing effective and efficient PPDDM protocols.
Achieving privacy and security in multi-owner data outsourcing	Existing solutions for data protection and privacy in data outsourcing scenario generally emphasize on the access control model integrated with the advanced cryptographic techniques. However, the complexity of key management is still a recurrent problem when the environment composes of enormous numbers of users and several resource owners. In addition, the administrative capabilities to control the policies enforced in the collaborative cloud environment where several owners and users have not been explicitly provided by the existing works. In this paper, we propose a privacy enhancing access control model to address the scalability and fine-grained access control for outsourced data in multi-owner setting. The focus is to serve the privacy and integrity of outsourced data as well as the accountability. To this end, we employ a PKI key management and access control scheme to serve the security and privacy for the data, policy, and communication. We employ multi-agent system to accommodate multi-policy enforcement and support parallel processing of authorization requests. Our model supports both read and write access control and integrity of all access operations is served by signature-based that enables a full accountability of all accesses.
A System to test malafide intension based on privacy violation detection	As a response to serious privacy concerns, various approaches have been proposed on privacy policy driven databases. However it is very difficult to provide robust privacy implementation. Privacy violation can still take place with some masquerading. In such a scenario, it is important to detect the violation. A solution for privacy violation detection based on malafide intension has been proposed recently. In this paper, we propose an architecture and implementation of a system to test the robustness of malafide intension based privacy violation detection.
Chain ontology based: A model for protecting personal information privacy	Privacy and personal information have penetrated all forms of todaypsilas business transactions such as banking and e-commerce to new forms of socializing online such as Facebook, to ones own health records. In protecting such sensitive & private data several initiatives have been created in various forms from legislation, PIPEDA to policies such as P3P. Unfortunately, none of these enforce protection of data. Recent solutions have emerged to enforce data privacy & protection such as the Hippocratic database. But this solution has proved complex in purpose wide range decision making. In this paper wer bring forth a new idea that integrates personal information ontology with the concept of chains[1], in order to overcome the Hippocratic deficiencies. We demonstrate the idea with a prototype in the context of healthcare data management, a sector in which maintaining the privacy of individual information is of essential importance.
Privacy in context: Privacy issues in Ubiquitous Computing applications	This paper presents a review of privacy issues and guidelines for developing and assessing privacy-sensitive ubiquitous computing applications. Privacy is discussed to determine factors that affect peoples own privacy preferences in public and private environments. Ubiquitous environments based on invisible computers provide a particular challenge where limited user interfaces exist to inform users of the level of data collection and its usage. There is acceptance by designers of privacy-sensitive applications for a balance between control and feedback that is essential for systems to meet legal requirements for deployment to be successful. A survey of principles and design guidelines has been completed and these are used in the assessment of a context aware smart classroom environment. This paper aims to provide a foundation for developing and assessing privacy-sensitive applications.
Assuring security and privacy for digital library transactions on the Web: client and server security policies	Often an information source on the Web would like to provide different classes of service to different clients. In the autonomous, highly distributed world of the Web, the traditional approach of using authentication to differentiate between classes of clients is no longer sufficient, as knowledge of a client's identity will often not suffice to determine whether a client is authorized to use a service. In (Ching et al., 1996) we proposed the use of digital credentials to help solve this problem; but their use will in turn introduce a bevy of new problems associated with credential management. In this paper we propose the use of server security policies and client credential submission policies to aid in the management of a client's digital credentials. We propose a structure for such policies, and briefly describe an implementation of personal security assistants and server security assistants that embodies our proposed approach
Reversible watermarking with digital signature chaining for privacy protection of optical contactless captured biometric fingerprints - a capacity study for forensic approaches	The FRT-MicroProf 200 CWL (Chromatic White Light) sensor, typically used for the measurement of surface properties for quality assurance purposes, is adapted and used for the contactless, non-invasive lifting of latent fingerprint traces. To the resulting high-resolution biometric data, invertible fragile image watermarking is applied, to assure authenticity and integrity of the data in a forensic investigation. Privacy protection is added by encryption and substitution of the fingerprint area. The scheme is extended to be used in a digital signature chain scenario with hierarchical access for further forensic investigation and the generation and preservation of a chain of custody. The capacity of the introduced watermarking protocol is evaluated in theory and in practical tests using 90 image samples (16bit grayscale, 30 intensity fingerprint images: ├ÿ6.5bpp, 30 3d-topography fingerprint images: ├ÿ11.2bpp and 30 standard images: ├ÿ1.2bpp, different sizes and embedding areas) showing very high capacities especially for fingerprint images.
Privacy protection in social media networks a dream that can come true?	With the advent of Web 2.0 in the very recent years, we are witnessing an attitude change in the use of the World Wide Web, which is not used anymore to only retrieve information but to allow participation, communication, collaboration, and information sharing on the Web. This has led to the dramatic grow of social media networks, among other services. In this position paper the main privacy concerns related to the use of social media networks are highlighted and some procedural as well as technological privacy sympathetic approach to social multimedia networking are given.
Face recognition with biometric encryption for privacy-enhancing self-exclusion	Face recognition has been employed in various security-related applications such as surveillance, mugshot identification, e-passport, and access control. Despite its recent advancements, privacy concern is one of several issues preventing its wider deployment. In this paper, we address the privacy concern for a self-exclusion scenario of face recognition, through combining face recognition with a simple biometric encryption scheme called helper data system. The combined system is described in detail with focus on the key binding procedure. Experiments are carried out on the CMU PIE face database. The experimental results demonstrate that in the proposed system, the biometric encryption module tends to significantly reduce the false acceptance rate while increasing the false rejection rate.
Enabling Privacy in Pervasive Computing Using Fusion of Privacy Negotiation, Identity Management and Trust Management Techniques	Designing and composing pervasive systems of the next generation networks is a technological as well as social challenge due to its complexity and its unpredictable nature. In such environments a significant amount of information directly related to users are fetched, exchanged, processed and delivered as personalized services. Due to automation of infrastructure both users and services have many agents acting on their behalf. Respectively in pervasive systems one of the most problematic concerns arises on user right to maintain privacy. This paper is focused on instruments to enable and maintain privacy through a subtle fusion of different privacy enabling techniques. We present conceptual privacy enabling architecture of infrastructural pervasive middleware that uses trust management, privacy negotiation and identity management during the inter-entity communication lifecycle. Using this approach balance between the conflicting interest of pervasiveness on one hand and protecting privacy on the other is achieved.
Towards Organizational Privacy Patterns	Privacy has been a hot topic and received a lot of discussion in recent years. European legislation contains strong privacy oriented regulations and rules which are poorly understood and comprehended by European businesses. Unfortunately courts do not have enough practice to bring the privacy abuses to justice. In addition to all this privacy enhancing technologies (PETs) that exist today are not enough to solve the contradicting requirements of informational systems resulting from business environments and privacy regulations. A large gap exists between privacy regulations on one hand and available privacy technologies on the other. We believe that this gap could and should be bridged by organizational privacy patterns (OPP). OPPs are abstractions of real world situations and problems that businesses run into. Organizational Privacy Patterns capture the problem, the context of the generic problem and the proven solutions to the problem. In this paper we present a first set of privacy organizational patterns.
On Privacy Protection in Biometric Passports	In this paper we investigate issues related to biometric passports. First an overview of the current system is given. Then we present weaknesses associated with the hash functions designed for binary data used on bitmaps. After we show the possibility to use watermarking technologies to avoid storing the fingerprint in the passport but retaining the fingerprint check function.
Squaring the Circle of Smart Surveillance and Privacy	This paper finds that recent growth in investment in CCTV surveillance technology is in inverse proportion to its relatively very low rate of effectiveness in combating crime and terrorism. It maintains that the much-publicised failures of some smart surveillance technologies such as automated face recognition in the period 1997-2003 has led to investment in even ├é┬┐smarter├é┬┐ technologies of a type here categorised as MIMSI (Massively Integrated Multiple Sensor Installations) which link up optical-based technologies such as CCTV to other sensory detectors involving scent, sound and motion. After having outlined the risks inherent in new surveillance technologies and their applications, the paper moves on to examine the paucity of legal safeguards currently available for the protection of the privacy of citizens. This analysis serves as the context for the final part of the paper which focuses on the European Union's Council Framework Decision 2008/977/JHA of 27 November 2008 on the protection of personal data processed in the framework of police and judicial cooperation in criminal matters. The latter purports to provide a safer way in which personal data may be exchanged between the police and security forces of European Union states. This paper finds that the CFD 2008/977/JHA sets out an extremely important principle relevant to smart surveillance but then does nothing to actually provide concrete safeguards for citizen privacy.
Design for Controlling Media Privacy in SIP Conferencing Systems	We propose a new focus of research for multimedia conferencing systems which allows each user to flexibly select another participant or a group of participants to control media transmission. In a traditional conference system, participants' voices might by default be shared with all others, but a participant might want to select a subset of the conference members to send his/her media to or receive streams from. We review the concept of narrowcasting, a technique for limiting such information streams in a multimedia conference, and propose a design to use existing standard protocols (SIP and SDP) for controlling fine-grained narrowcasting sessions
Location Privacy in Chain-Based Protocols for Location-Based Services	Mobile communication devices have rapidly proliferated in all developed countries. Most of these devices can determine their location, and their computation and storage capacities have greatly increased in recent years. Therefore, location-based services (LBS) will become cornerstones of the new information society. Most of the time, LBS are provided by trusted companies such as telecommunications companies. However, the wide availability of these technologies can foster the appearance of alternative non-trusted providers. When location information is exchanged amongst untrusted parties,the privacy of the participants could be in jeopardy. Thus, some methods have been proposed in the literature to provide users with location privacy, and most of them rely on a trusted third party (TTP) that is used to centralise all location information prior to sending it to a non-trusted provider. Unfortunately, in many situations TTPs are not available. In this paper, we provide a brief overview of the state of the art of LBS privacy, we recall a novel TTP-free proposal and, finally, we analyse its robustness against the attack of several passive malicious users.
Generating power footprints without appliance interaction: An enabler for privacy intrusion	Appliance load monitoring (ALM) systems are systems capable of monitoring appliances' operation within a building using a single metering point. As such, they uncover information on occupants' activities of daily living and subsequently an exploitable privacy leak. Related work has shown monitoring accuracies higher than 90% achieved by ALM systems, yet requiring interaction with appliances for system calibration. In the context of external privacy intrusion, ALM systems have the following obstacles for system calibration: (1) type and model of appliances inside the monitored building are entirely unknown; (2) appliances cannot be operated to record power footprints; and (3) ground truth data is not available to fine-tune algorithms. Within this work, we focus on monitoring those appliances from which we can infer occupants' activities. Without appliance interaction, appliances' profiling is realised via automated capture and analysis of shapes, steady-state durations, and occurrence patterns of power loads. Such automated processes produce unique power footprints, and naming is realised manually using heuristics and known characteristics of typical home equipment. Data recorded within a kitchen area and one home illustrates the various processing steps, from data acquisition to power footprint naming.
HCPP: Cryptography Based Secure EHR System for Patient Privacy and Emergency Healthcare	Privacy concern is arguably the major barrier that hinders the deployment of electronic health record (EHR) systems which are considered more efficient, less error-prone, and of higher availability compared to traditional paper record systems. Patients are unwilling to accept the EHR system unless their protected health information (PHI) containing highly confidential data is guaranteed proper use and disclosure, which cannot be easily achieved without patients' control over their own PHI. However, cautions must be taken to handle emergencies in which the patient may be physically incompetent to retrieve the controlled PHI for emergency treatment. In this paper, we propose a secure EHR system, HCPP (Healthcaresystem for Patient Privacy), based on cryptographic constructions and existing wireless network infrastructures, to provide privacy protection to patients under any circumstances while enabling timelyPHI retrieval for life-saving treatment in emergency situations. Furthermore, our HCPP system restricts PHI access to authorized (not arbitrary) physicians, who can be traced and held accountable if the accessed PHI is found improperly disclosed. Last but not least, HCPP leverages wireless network access to support efficient and private storage/retrieval of PHI, which underlies a secure and feasible EHR system.
Privacy-Preserving Query over Encrypted Graph-Structured Data in Cloud Computing	In the emerging cloud computing paradigm, data owners become increasingly motivated to outsource their complex data management systems from local sites to the commercial public cloud for great flexibility and economic savings. For the consideration of users' privacy, sensitive data have to be encrypted before outsourcing, which makes effective data utilization a very challenging task. In this paper, for the first time, we define and solve the problem of privacy-preserving query over encrypted graph-structured data in cloud computing (PPGQ), and establish a set of strict privacy requirements for such a secure cloud data utilization system to become a reality. Our work utilizes the principle of "filtering-and-verification". We prebuild a feature-based index to provide feature-related information about each encrypted data graph, and then choose the efficient inner product as the pruning tool to carry out the filtering procedure. To meet the challenge of supporting graph query without privacy breaches, we propose a secure inner product computation technique, and then improve it to achieve various privacy requirements under the known-background threat model.
Privacy Preserving Group Ranking	Group ranking is a necessary process used to find the best participant from a group. Group ranking has many applications, including online marketing, personal interests matching and proposal ranking. In an online virtual environment, participants want to do group ranking without leaking any of their private information. In this work, we generalize this scenario as a privacy preserving group ranking problem and formulate the privacy requirements of this problem. We propose a fully distributed privacy preserving group ranking framework and prove its security in the honest but curious model. The core of our framework is a novel multiparty sorting protocol, which guarantees that an adversary cannot link the private information to its owner's identity as long as the owner's final ranking is hidden from the adversary. Our protocol is efficient in computational overhead and communication rounds compared to existing works, as demonstrated by our analysis and simulation.
Robust Overlays for Privacy-Preserving Data Dissemination over a Social Graph	A number of recently proposed systems provide secure and privacy-preserving data dissemination by leveraging pre-existing social trust relations and effectively mapping them into communication links. However, as we show in this paper, the underlying trust graph may not be optimal as a communication overlay. It has relatively long path lengths and it can be easily partitioned in scenarios where users are unavailable for a fraction of time. Following this observation, we present a method for improving the robustness of trust-based overlays. Essentially, we start with an overlay derived from the trust graph and evolve it in a privacy-preserving fashion into one that lends itself to data dissemination. The experimental evaluation shows that our approach leads to overlays that are significantly more robust under churn, and exhibit lower path lengths than the underlying trust graph.
PAAS: A Privacy-Preserving Attribute-Based Authentication System for eHealth Networks	Recently, eHealth systems have replaced paper based medical system due to its prominent features of convenience and accuracy. Also, since the medical data can be stored on any kind of digital devices, people can easily obtain medical services at any time and any place. However, privacy concern over patient medical data draws an increasing attention. In the current eHealth networks, patients are assigned multiple attributes which directly reflect their symptoms, undergoing treatments, etc. Those life-threatened attributes need to be verified by an authorized medical facilities, such as hospitals and clinics. When there is a need for medical services, patients have to be authenticated by showing their identities and the corresponding attributes in order to take appropriate healthcare actions. However, directly disclosing those attributes for verification may expose real identities. Therefore, existing eHealth systems fail to preserve patients' private attribute information while maintaining original functionalities of medical services. To solve this dilemma, we propose a framework called PAAS which leverages users' verifiable attributes to authenticate users in eHealth systems while preserving their privacy issues. In our system, instead of letting centralized infrastructures take care of authentication, our scheme only involves two end users. We also offer authentication strategies with progressive privacy requirements among patients or between patients and physicians. Based on the security and efficiency analysis, we show our framework is better than existing eHealth systems in terms of privacy preservation and practicality.
Privacy-Aware BedTree Based Solution for Fuzzy Multi-keyword Search over Encrypted Data	As Cloud Computing technology becomes more mature, many organizations and individuals are interested in storing more sensitive data e.g. personal health records, customers related information in the cloud. Such sensitive data needs to be encrypted before it is outsourced to the cloud. Typically, the cloud servers also need to support a keyword search feature for these encrypted files. Traditional searchable encryption schemes typically only support exact keyword matches. However, users sometimes have typos or use slightly different formats e.g. "data-mining" versus "data mining". Thus, fuzzy keyword search is a useful feature to have. Recently, some researchers propose using wild card based approach to provide fuzzy keyword search. They also propose a solution for multi-keyword search. Their approaches have some limitations, namely (a) their fuzzy keyword search solution consumes large storage size since it inserts every fuzzy keyword as a leaf node in the index tree, (b) their fuzzy single-keyword search solution does not support multi-keyword search, (c) the existing multi-keyword search scheme does not provide efficient incremental updates. In this paper, we propose a privacy-aware bed tree based approach to support fuzzy multi-keyword feature. Incremental updates can be easily done using our solution. We have implemented our solution. Our evaluation results show that our approach is more cost-effective in terms of storage size and construction time. Our search time is usually better than the wild card approach for multi-keyword queries where many encrypted files are returned using single-word queries for approaches that do not support multi-keyword queries.
Toward Privacy-Assured Cloud Data Services with Flexible Search Functionalities	User privacy has been a major concern against the widespread adoption of the cloud technology. A full-fledged cloud data service should effectively support data utilization tasks, especially flexible data search functionalities, while simultaneously achieve user privacy assurance and meet practical system-level performance requirements. In this position paper, we identify the importance and challenges of designing privacy-assured, textit{flexible} and textit{practically efficient} search mechanisms for outsourced cloud data services. In particular, we focus on two representative types of flexible search functionalities: ranked keyword search, and search over structured data. Although these functionalities are already prevalent in information retrieval in the plaintext domain, realizing them in the encrypted domain requires non-trivial effort and is relatively new. In light of this, we first describe several existing technical approaches proposed by us and other researchers, and identify their advantages and limitations. We also discuss the open research directions and provide some possible ideas for further investigation. We believe the presented results will inspire more research towards making privacy-assured search in the cloud practical and useful.
PDP: A Privacy-Preserving Data Provenance Scheme	Data provenance, which records the history of the ownership of a document, as well as the actions performed on it, has received great attention in recent years. However, the privacy issue in data provenance has not been well investigated. In this paper, to simultaneously protect the security of data provenance and achieve user privacy preservation, we propose a new privacy-preserving data provenance (PDP) scheme. With the proposed PDP scheme, users can anonymously access the remoter servers and execute the secure provenance operations. Detailed security analysis demonstrates the security of the proposed PDP scheme, In addition, extensive efficiency analyses have also been conducted to examine its superior efficiency in terms of secure provenance storage and verification costs.
A flexible, privacy-preserving authentication framework for ubiquitous computing environments	The proliferation of smart gadgets, appliances, mobile devices, PDAs and sensors has enabled the construction of ubiquitous computing environments, transforming regular physical spaces into "Active Information Spaces" augmented with intelligence and enhanced with services. This new exciting computing paradigm promises to revolutionize the way we interact with computers, services, and the surrounding physical spaces, yielding higher productivity and more seamless interaction between users and computing services. However, the deployment of this computing paradigm in real-life is hindered by poor security, particularly, the lack of proper authentication and access control techniques and privacy preserving protocols. We propose an authentication framework that addresses this problem through the use of different wearable and embedded devices. These devices authenticate entities with varied levels of confidence, in a transparent, convenient, and private manner, allowing the framework to blend nicely into ubiquitous computing environments.
Anonymizing geographic ad hoc routing for preserving location privacy	Due to the utilization of location information, geographic ad hoc routing presents superiority in scalability compared with traditional topology-based routing in mobile ad hoc networks. However, the consequent solicitation for location presence incurs severe concerns of location privacy, which has not been properly studied. In this paper, we attempt to preserve location privacy based on the idea of dissociating user's location information with its identity. We propose an anonymous geographic routing algorithm which includes three components to avoid the explicit exposure of identity and location in communication without compromising the efficiency guaranteed by geographic routing.
Provide privacy for mobile P2P systems	Nowadays privacy and anonymity have become an increasing requirement in wireless networks. However, current mobile peer-to-peer architectures have not taken into account anonymity, especially the mutual anonymity between two nodes. In this paper, we propose a mutual anonymity protocol, called secret-sharing-based mutual anonymity protocol (SMA), for mobile P2P networks. Our simulation results show that SMA achieves mutual anonymity in mobile P2P networks with a low cryptography processing overhead.
Preserving Source-Location Privacy in Energy-Constrained Wireless Sensor Networks	As wide applications of wireless sensor networks, privacy concerns have emerged as the main obstacle to success. When wireless sensor networks are used to monitor sensitive objects, the privacy about monitored object' locations becomes an important issue. When a sensor node reports a monitored object to base station by sending a series of packets through multiple hops, an adversary may trace back the source's location. Flooding-based phantom has a problem that message latencies become larger and energy costs become higher for protecting source-location privacy. In this paper, DROW (directed random walk) is proposed to make it difficult for an adversary to backtrack hop-by-hop to the origin of the sensor communication. In DROW, the source sensor sends out a packet, the packet is unicasted to its parent node. When intermediate node receives a packet, it forwards to one of its parent nodes in a directed random fashion. Compared to flooding-based phantom, DROW has smaller message latencies and lower energy costs. Especially, DROW has better safety period when intermediate node has multi-parent node.
Optimized User Revocation for Group Signature Based Privacy-Aware PKI	Privacy-aware public key infrastructure (PKI) can maintain user access control and yet protect user privacy, which is important for many applications. The applicability of privacy-aware PKI highly relies on the performance of user revocation. The requirements of user revocation are various in general, such as subscription expiration, violation of access policy, group changing, and key exposure. To satisfy different requirements, multiple revocation approaches may interact each other. In this paper, we study how to achieve optimized user revocation cost with respect to various revocation approaches. We also propose a practical scheme Delta -RL that can fulfill an optimal overall performance on the base of extensive analysis.
A Cluster-Based Protocol to Enforce Integrity and Preserve Privacy in Data Aggregation	Data fusion or information collection is one of the fundamental functions in the future cyber-physical systems. But, privacy concerns must be addressed and security must be assured in such systems. It is very challenging to achieve the synergy of privacy and integrity, because privacy preserving schemes try to hide or interfere with data, while integrity protection usually needs to enable peer monitoring or public access of the data. Therefore, privacy and integrity can be the conflicting requirements, one may barricade the implementation of the other.In this paper, we address both privacy of individual sensory data and integrity of aggregation result simultaneously by proposing a protocol called iCPDA, which piggybacks on a cluster-based privacy-preserving data aggregation protocol(CPDA). We implement the add-on feature to protect integrity of aggregation result. To show the efficacy and efficiency of the proposed scheme, we present simulation results. To the best of our knowledge, this paper is among the first protocols to preserve privacy and integrity in data aggregation.
Routing through the mist: privacy preserving communication in ubiquitous computing environments	Ubiquitous computing is poised to revolutionize the way we compute and interact with each other. However, unless privacy concerns are taken into account early in the design process, we will end up creating a very effective distributed surveillance system, which would be a dream come true for electronic stalkers and "big brothers". We present a protocol, which preserves the privacy of users and keeps their communication anonymous. In effect, we create a "mist" that conceals users from the system and other users. Yet, users will still be able to enjoy seamless interaction with services and other entities that wander within the ubiquitous computing environment.
Location Privacy in Mobile Systems: A Personalized Anonymization Model	This paper describes a personalized k-anonymity model for protecting location privacy against various privacy threats through location information sharing. Our model has two unique features. First, we provide a unified privacy personalization framework to support location k-anonymity for a wide range of users with context-sensitive personalized privacy requirements. This framework enables each mobile node to specify the minimum level of anonymity it desires as well as the maximum temporal and spatial resolutions it is willing to tolerate when requesting for k-anonymity preserving location-based services (LBSs). Second, we devise an efficient message perturbation engine which runs by the location protection broker on a trusted server and performs location anonymization on mobile users' LBS request messages, such as identity removal and spatio-temporal cloaking of location information. We develop a suite of scalable and yet efficient spatio-temporal cloaking algorithms, called CliqueCloak algorithms, to provide high quality personalized location k-anonymity, aiming at avoiding or reducing known location privacy threats before forwarding requests to LBS provider(s). The effectiveness of our CliqueCloak algorithms is studied under various conditions using realistic location data synthetically generated using real road maps and traffic volume data
Enhancing Source-Location Privacy in Sensor Network Routing	One of the most notable challenges threatening the successful deployment of sensor systems is privacy. Although many privacy-related issues can be addressed by security mechanisms, one sensor network privacy issue that cannot be adequately addressed by network security is source-location privacy. Adversaries may use RF localization techniques to perform hop-by-hop traceback to the source sensor's location. This paper provides a formal model for the source-location privacy problem in sensor networks and examines the privacy characteristics of different sensor routing protocols. We examine two popular classes of routing protocols: the class of flooding protocols, and the class of routing protocols involving only a single path from the source to the sink. While investigating the privacy performance of routing protocols, we considered the tradeoffs between location-privacy and energy consumption. We found that most of the current protocols cannot provide efficient source-location privacy while maintaining desirable system performance. In order to provide efficient and private sensor communications, we devised new techniques to enhance source-location privacy that augment these routing protocols. One of our strategies, a technique we have called phantom routing, has proven flexible and capable of protecting the source's location, while not incurring a noticeable increase in energy overhead. Further, we examined the effect of source mobility on location privacy. We showed that, even with the natural privacy amplification resulting from source mobility, our phantom routing techniques yield improved source-location privacy relative to other routing methods
Temporal Privacy in Wireless Sensor Networks	Although the content of sensor messages describing "events of interest" may be encrypted to provide confidentiality, the context surrounding these events may also be sensitive and therefore should be protected from eavesdroppers. An adversary armed with knowledge of the network deployment, routing algorithms, and the base-station (data sink) location can infer the temporal patterns of interesting events by merely monitoring the arrival of packets at the sink, thereby allowing the adversary to remotely track the spatio-temporal evolution of a sensed event. In this paper, we introduce the problem of temporal privacy for delay- tolerant sensor networks and propose adaptive buffering at intermediate nodes on the source-sink routing path to obfuscate temporal information from an adversary. We first present the effect of buffering on temporal privacy using an information-theoretic formulation and then examine the effect that delaying packets has on buffer occupancy. We evaluate our privacy enhancement strategies using simulations, where privacy is quantified in terms of the adversary's estimation error.
Compromising Location Privacy inWireless Networks Using Sensors with Limited Information	We propose a methodology to identify nodes in fully anonymized wireless networks using collections of very simple sensors. Based on time series of counts of anonymous packets provided by the sensors, we estimate the number of nodes using principal component analysis. We then proceed to separate the collected packet data into traffic flows that, with help of the spatial diversity in the available sensors, can be used to estimate the location of the wireless nodes. Our simulation experiments indicate that the estimators show high accuracy and high confidence for anonymized TCP traffic. Additional experiments indicate that the estimators perform very well in anonymous wireless networks that use traffic padding.
Efficient Privacy-Preserving k-Nearest Neighbor Search	We give efficient protocols for secure and private k-nearest neighbor (k-NN) search, when the data is distributed between two parties who want to cooperatively compute the answers without revealing to each other their private data. Our protocol for the single-step k-NN search is provably secure and has linear computation and communication complexity. Previous work on this problem had a quadratic complexity, and also leaked information about the parties' inputs. We adapt our techniquesto also solve the general multi-step k-NN search, and describe a specific embodiment of it for the case of sequence data. The protocols and correctness proofs can be extended to suit other privacy-preserving data mining tasks, such as classification and outlier detection.
A Sophisticated Privacy-Enhanced Yet Accountable Security Framework for Metropolitan Wireless Mesh Networks	Recently, multi-hop wireless mesh networks (WMNs) have attracted increasing attention and deployment as a low-cost approach to provide broadband Internet access at metropolitan scale. Security and privacy issues are of most concern in pushing the success of WMNs for their wide deployment and for supporting service-oriented applications. Despite the necessity, limited security research has been conducted towards privacy preservation in WMNs. This motivates us to develop PEACE, a soPhisticated privacy-Enhanced yet Accountable seCurity framEwork, tailored for WMNs. At the one hand, PEACE enforces strictuser access control to cope with both free riders and malicious users. On the other hand, PEACE offers sophisticated user privacy protection against both adversaries and various other network entities. PEACE is presented as a suite of authentication and key agreement protocols built upon our proposed short group signature variation. Our analysis shows that PEACE is resilient to a number of security and privacy related attacks.
CAP: A Context-Aware Privacy Protection System for Location-Based Services	We address issues related to privacy protection in location-based services (LBS). Most existing research in this field either requires a trusted third-party (anonymizer) or uses oblivious protocols that are computationally and communicationally expensive. Our design of privacy-preserving techniques is principled on not requiring a trusted third-party while being highly efficient in terms of time and space complexities. The problem has two interesting and challenging characteristics: First, the degree of privacy protection and LBS accuracy depends on the context, such as population and road density, around a user's location. Second, an adversary may violate a user's location privacy in two ways: (i) based on the user's location information contained in the LBS query payload, and (ii) by inferring a user's geographical location based on its device's IP address. To address these challenges, we introduce CAP, a Context-Aware Privacy-preserving LBS system with integrated protection for data privacy and communication anonymity. We have implemented CAP and integrated it with Google Maps, a popular LBS system. Theoretical analysis and experimental results validate CAP's effectiveness on privacy protection, LBS accuracy, and communication Quality-of-Service.
The Digital Marauder's Map: A New Threat to Location Privacy	"The Marauder's Map" is a magical map in J. K. Rowling's fantasy series, "Harry Potter and the Prisoner of Azkaban". It shows all moving objects within the boundary of the "Hogwarts School of Witchcraft and Wizardry". In this paper, we introduce a similar attack to location privacy in wireless networks. Our system, namely the digital Marauder's map, can reveal the locations of WiFi-enabled mobile devices within the coverage area of a single high-gain antenna. The digital Marauder's map is built solely with off-the-shelf wireless equipments, and features a mobile design that can be quickly deployed to a new location and instantly used without training. We present a comprehensive set of theoretical analysis and experimental results which demonstrate the coverage and localization accuracy of the digital Marauder's map.
Synthetic and privacy-preserving visualization of video sensor network outputs	We propose a complete framework for people tracking in video surveillance networks that preserves privacy by mapping people recorded by a video sensor network in the map of the corresponding surveilled areas. Thanks to this approach, it is possible (1) to synthesize multiple video outputs into a unique picture, and (2) to control privacy by offering the possibility to filter information to viewers. A set of physical attributes, namely soft biometric characteristics, is used to provide the system with tracking capabilities. We demonstrate the feasibility of our approach by showing a real case application scenario.
Fraudulent Online Identity Sanctions Act: empowering law enforcement or limiting privacy?	The government plays a greater role in punishing those who conceal their identities online, particularly when they do so in furtherance of a serious criminal offense or in violation of a federally protected intellectual property right. The Fraudulent Online Identity Sanctions Act proposes increased prison time for those who provide false contact information to a domain name registrar and then use that online location in committing a trademark or copyright infringement felony.
Preservative License Plate De-identification for Privacy Protection	Advances in imaging devices and web technologies have brought dramatic improvements in collecting, storing, and sharing images. The leakage of privacy information in the process becomes an important issue that has started drawing attention from both academia and industry. In this work, we study the problem of privacy preserving with focus on license plate number protecting in imagery. Specifically, we present a novel method for de-identifying license plate images with the least degradation in image visual quality for privacy protection. Unlike previous de-identification methods that pay little attention to the image quality preservation, our method, named inhomogeneous principal component blur (IPCB), adaptively blurs different pixels of a license plate by taking into account the prior distribution of sensitive information. We tested the proposed method on a public dataset in comparison with several popular de-identification methods. The evaluation shows that our method successfully de-identified the privacy information with the least damage of image quality when compared with several other solutions.
The state of the art and tendency of privacy preserving data mining	As a new branch of data mining, privacy preserving data mining has become more and more important in the information security field. This paper first presents an insight into the principles of privacy preserving data mining, and then marks out the difference with normal data mining through three stages, including single data record methods, centralized dataset mining technology and secure multiparty computation problem. By studying and analyzing privacy preserving data mining methods, the present problems and directions for future research are discussed.
Research on the protection algorithm and model of personal privacy information in internet of thing	With the development of information and communication technology, network age coming silently, it will be caused a new personal information leakage risk by the Ubiquitous Computing applications. This paper introduces the individual privacy information forms of expression in networking technology, and then puts forward with the secure multi-party computation to achieve personal information protection. Otherwise, we describe the process and the algorithm of implement. At last, we build in a conceptual model according to the layered theory of the network information on privacy protection.
Factor analysis of E-commerce usage basing on Internet privacy	Usually consumers need to provide private information when using E-commerce service. While this special information is vulnerable to leak, resulting from Internet operators' deregulation or government's surveillance and the potential venture blocks the development of E-commerce. Basing on Internet consumers' concerns about privacy violation, this paper establishes a structural equation model of the factors of Ecommerce usage which is testified through empirical research. Then we discuss the relationship of Internet industry self-regulation, concerns about government surveillance and concerns about privacy, and their effect on consumers' E-commerce usage.
Use of Wiki systems in Archaeology: Privacy, security and data protection as key problems	Wikis are powerful, collaborative tools and can be used for educational purposes in many ways. The original idea of a Wiki is to make information accessible to all. However, it is very interesting that experiences in the use of Wikis in educational settings showed that security and data protection of wiki contents is definitely an issue. In this paper, we discuss problems and solutions on the basis of use cases from archaeological education. Interestingly, archaeologists are extremely worried about online accessible information due to the serious danger of archaeological looting. ΓÇ£Tomb raidersΓÇ¥, i.e. people who excavate artefacts of cultural heritage on the basis of information stored in Geowikis, so called archaeological looters, are not aware of the value of cultural heritage, are interested only in the artefacts and destroying the cultural context, which is of enormous interest for archaeological research. Consequently, the protection of archaeological information is one of the most urgent tasks in the preservation of cultural heritage.
The Tradeoff between Personalized Service and Privacy: An Empirical Analysis of 3G Adoption	3G is the primary trend of mobile service in the future, users face a tradeoff between personalization and privacy in the 3G adoption process. The extended valence framework can be used in this paper to explain that how this tradeoff influence user's usage intention of 3G service.
Privacy Preservation in E-government	The hot demand for e-government makes it vitally important to provide a solution to privacy preservation. This paper discusses in depth the key concerns and implementation techniques related to privacy preservation in e-government, before providing a solution which best tradeoffs the demand for information disclosure and the concerns about privacy preservation.
Privacy-Preserving Segment-Ellipse Intersect-Determination Protocol	Privacy-Preserving Computational Geometry is a kind of special secure multi-party computation problem. As a special privacy-preserving computational geometry problem, Privacy- Path Determination may be applied in many fields such as military field and commerce field. In this paper, a privacy-preserving line-ellipse position relation determination protocol is developed and based on this protocol, a private-preserving segment-ellipse intersect-determination protocol is presented, and their correctness, security and complexity are analyzed.
A Privacy Data Release Method Based on Game Theory	The current privacy-preserving researches focus on the privacy release control method. However, the current release control methods only consider the protection of privacy without taking the usability of privacy into account. In this paper, a release method based on game theory is proposed to ensure both the protection and the usability of privacy.
Multi-Attribute Generalization Method in Privacy Preserving Data Publishing	K-anonymization is a technique that prevents linking attacks by generalizing and suppressing portions of the released raw data so that no individual can be uniquely distinguished from a group of size of k. In this paper, we study single-attribute generalization for preserving privacy in publishing of sensitive data, and present multi-attribute generalization definition in process of generalization based Datafly algorithm. Besides we describe how to generate multi-attribute attribute generalization hierarchy. A key question is how to anonymize the microdata so that it can be multi-attribute attribute generalization hierarchy. We introduce the join, pune and create edge, as a way to reduce search space of k-anonymization, and propose a scalable and practical solution.
A Survey on Anonymity-Based Privacy Preserving	In recent years, with the development of information technology, the operation of enterprises has gone through a drastic revolution. Data information flow became the lifeblood of enterprises. However, in such a situation, people would worry about disclosure of privacy and are likely to provide phony information rather than the authentic. So with the development of data analysis and processing technique, the privacy disclosure problem about individual or company is inevitably exposed when releasing or sharing data to mine useful decision information and knowledge, then give the birth to the research field on privacy preserving. The technology of privacy preserving has become the focus of the researcher home and abroad in recent years. In order to protect individuals' privacy, the technology of anonymity has been proposed to protect sensitive attributes from the corresponding identifiers. This paper intends to reiterate several anonymity-based privacy preserving technologies clearly and then proceeds to analyze the merits and shortcomings of these technologies.
Privacy Protection Model for Distributed Service System in Converged Network	Network convergence, as a representative of network integration of Internet, telecommunication network and cable television network, is the general trend of development of the information society. Also, it becomes a hotspot of recently research. Converged network is a full service network, which means it has the ability to provide various bandwidth, wire or wireless services and applications, including voice, data, video, streaming media, Internet access, digital TV broadcasting, and so on. Also, it provides open service interfaces, which makes it possible for multiple service providers to construct and provide services. Therefore, openness is a distinctive feature in distributed service system of converged network. It means that more privacy and security issues should be faced and solved. In order to make the distributed service system of converged network can provide safe and reliable services, based on the study in characteristics of distributed service system in converged network and existing privacy protection mechanism, this paper puts forward a privacy protection model suitable for the distributed service system of converged network.
Privacy Preserving Outlier Detection over Vertically Partitioned Data	Outlier detection has numerous useful applications such as detecting criminal activities in electronic commerce, terrorism prediction and exceptional cases in many areas. Privacy and security concerns, however, arise while performing mining for outliers on distributed data. In this paper, we present two privacy preserving distance-based outlier detection algorithms over vertically partitioned data, not disclosing any private information to any participant. The first is between two parties and the second among multi-parties. The security and performances such as computation and communication complexities are analyzed for both of the two privacy preserving algorithms.
An Approach in Security and Privacy for Service Governance Framework	Service Oriented Architecture (SOA) is a modern methodology for developing software. In a short period of time, SOA is being adopted by many companies because of the extensive advantages it guarantees. Service governance plays a vital role in determining the success and failure of a SOA project. Service governance can be defined as the process which governs the mechanisms applied in SOA. It is a vast field that has various branches. This paper focuses on the current security and privacy issues which prevail in the governance of SOA projects. Security and privacy are critical aspects of SOA. SOA projects with good quality attributes but with weaknesses in these two areas still can make the project a failure. Thus security and privacy are vital factors that have to be considered while developing a SOA project. After identifying the security and privacy issues, we propose an approach to address these issues. This approach acts as a solution for security and privacy problems faced by SO A projects in the service governance context. The paper gives an approach for service governance framework that deals with the security an problems of SOA. Furthermore the derived approach is implemented in a healthcare website application for demonstrating how security issues are tacked.
Mobile-Aware Anonymous Peer Selecting Algorithm for Enhancing Privacy and Connectivity in Location-Based Service	Privacy preserving in location-based service (LBS) has been an important issue in Vehicular Ad hoc Network (VANET). Traditional k-anonymity algorithm dealing with location privacy protecting problem does not consider vehicle's mobility and inner collaborator. In this paper, we propose a new algorithm which uses dynamic and mobile aware anonymous peer selecting algorithm to improve the anonymity and connectivity in a mobile environment. We also give out detailed analysis and show experimentally that better privacy and connectivity can be achieved with this method.
A Privacy Reinforcement Approach against De-identified Dataset	Protection of individual privacy has been a key issue for the corresponding data dissemination. Nowadays powerful search utilities increase the re-identification risk by easier information collection as well as validation than before. Despite there usually performs certain de-identified process, attackers may recognize someone from released dataset with which attacker-owned information is matched. In this paper, we propose an approach to mitigate the identity disclosure problem by generating plurals in a given dataset. The approach leverages decision tree to help selection of quasi-identifier and several masking techniques can be employed for privacy reinforcement. In addition to different privacy metrics applicability, the approach can achieve better trade-off between data integrity and privacy protection through flexible data masking.
k*NNCA: A Location Privacy Preserving Method for Semi-honest Mobile Users	Privacy preservation has recently received considerable attention in location-based services. A large number of location cloaking algorithms have been proposed for protecting the location privacy of mobile users. However, most of existing cloaking approaches assume that mobile users are trusted. And exact locations are required to protect location privacy, which are just the information mobile users want to hide. In this paper, we propose a p-anti-conspiring privacy model to anonymize over semi-honest users. Furthermore, a k*NNG-based cloaking algorithm k*NNCA is proposed to protect the location privacy without exact locations. The preliminary experimental results show the effectiveness of the proposed algorithm.
From Commodity to Value: A Privacy-Preserving e-Business Architecture	Privacy has been recognized as a very important issue in electronic commerce. However, many privacy techniques were not adopted and many online anonymity services failed. In this paper we propose treating privacy as a "value" that is to be added to other services to avoid the adoption pitfall. We present an architecture that anonymizes online transactions and makes them unlinkable to any customer or to each other. Our scheme guarantees fair payment to the vendor and provides efficient fraud detection and tracing mechanisms. With minimal change to existing delivery services, it can also protect transactions that require delivery of physical items. Moreover, our system could give the vendor accurate aggregate information about customers' usage pattern, which can be very valuable for its business operation. Our scheme utilizes existing financial infrastructure thus has very low adoption cost
A Privacy Protection Method for P2P-based Web Service Discovery	Peer-to-Peer based Web service discovery systems have shown the high scalability and availability provided by high connectivity and dynamic accommodation. However, a serious difficulty in concurrent designing of such unauthoritative and decentralized controlled systems is how to deal with the privacy concerns and policy enforcement in such systems which may contain a considerable ratio of dishonest and unavailable peers. We present a privacy protection method implementing authorization model in the broker peers' platform with the supporting of Web service description composition algorithms and discovery protocols especially designed for privacy policy enforcement in P2P environments. We exploit the statistical stability of a large number of peers and analyze the quantitative result of privacy policies being betrayed and obeyed, as well as how to leverage the privacy assurance and availability to desired levels by adjusting the parameters of composition algorithms.
How to Trust DRE Voting Machines Preserving Voter Privacy	While many experts believe that the e-voting system offers prominent advantages over plain paper voting system, others express concerns about the potential for large-scale fraud. Many current e-voting systems are not based on the cryptographic technologies and require voters to trust them. Voters cannot be assured that the votes cast accurately reflects their intent because the mechanism for recording votes is hidden in the code for the machine. In this paper, we propose a practical voter-verifiable e-voting scheme using a paper receipt based on cryptographic technologies.
Towards Practical Privacy Preserving Technology Adoption Analysis Service Platform	Technology adoption analysis is one of the key exercises in managing technology innovation and diffusion. In this paper, we present a service platform for technology adoption analysis, with aim tailored to provide service provisioning to potential technology users and providers. With two service models provided in this platform, a practical privacy preserving framework is developed to help relieve privacy concerns of the platform participants. To illustrate the feasibility of the privacy preserving framework of this platform, an adoption process for RFID technology adoption analysis in logistics and supply chain management is presented to identify key sensitive attributes for background knowledge leading to unique identification of an individual or company.
PGMAP: A Privacy Guaranteed Mutual Authentication Protocol Conforming to EPC Class 1 Gen 2 Standards	To resolve the security vulnerabilities and comply with EPC class 1 Gen 2 UHF RFID (EPC C1G2) Standard at the same time, we present a privacy guaranteed mutual authentication protocol (PGMAP). By utilizing the existing functions and memory bank of tag, we amend the processing sequence based on current EPC architecture. An auto-updating index number IDS is enrolled to provide privacy protection to EPC code and a set of light weight algorithms utilizing tagpsilas PRNG are added for authentication. Several attacks to the existing security solutions can be effectively resolved in our protocol.
Privacy Preserving in Ubiquitous Computing: Challenges & Issues	Privacy preservation is crucial in ubiquitous computing environment. Without this, users feel uneasy to use and live in the UC environment. The implementation of privacy safeguard or privacy enhancing technologies is going to be a long road. Understanding the challenges & issues of privacy protected in ubiquitous computing, is helpful to design and implement privacy aware system. In this paper, we try to describe privacy in ubiquitous computing briefly. The challenges, which are different from usually system, are presented. In the implementation view, some issues are addressed.
Trust and Privacy in Dissemination Control	Dissemination control is concerned with controlling electronic resources even after they have been delivered to a legitimate recipient. This paper proposes a secure resource dissemination system framework in which resource providers and recipients are interacted mutually in an anonymous, accountable, and trustworthy way, while security constraints on diverse resources can be continuously protected along resource distribution. We specify the three-party context-aware trust management and privacy protection mechanism based on part behavior using Dempster-Shafer (D-S) theory. We also discuss main logic functions and procedures in the resource dissemination and usage transaction process.
Trust-Based Access Control for Privacy Protection in Collaborative Environment	Privacy has been acknowledged to be a critical requirement for many business environments. A variety of uncertainty and mutability poses challenges when sharing resources must happen in collaborative environment. Therefore, the definition of an efficient access control model, based on which privacy policies can be specified, is crucial. In this work, we propose a trust-based access control model to protect privacy in collaborative environment. First, a trust value is evaluated based on both histories and peer recommendations. Second, purposes, obligations, and conditions are discussed in this paper, which leads our trust-based access control model to meet the requirements of modern corporation regulations and privacy laws. Third, our model handles uncertainty and mutability by dynamically re-evaluating the requester' trust and revoking the granted on-going access if access control rules are no longer met.
Personalization and Privacy in Ubiquitous Computing - Resolving the Conflict by Legally Binding Commitments	Ubiquitous computing technologies (UC) open up new possibilities for stationary retail as well as for e-commerce to realize personalized services. Customer acceptance of such services is generally put at risk because the potential quantity and quality of data collected poses new threats to privacy. Based on economic agency theory, this paper discusses legally binding commitments of the retailer as a promising approach to actively oppose this privacy problem. The analysis indicates that an adoption of this strategy is only rational for "honest" retailers and thus provides an effective possibility to distinguish them from "dishonest" ones. The success of this approach is dependent on an effective provision of "privacy evidences" proving compliance as well as non-compliance. In regard to computer science, the provision of such evidences is discussed as a challenge to a new kind of privacy-enhancing technologies.
PLUTO - A Privacy Control Protocol for e-Commerce Communities	Although e-commerce systems have progressed over the past few years, they lack important aspects such as building long-term and profitable relationships with customers and facilitating an environment that encourages buyers to buy more. The actual execution of e-commerce today is too different from its real-life counterpart, and for the most part it's a "Web page" with listing of items and prices. Providing an e-commerce system that brings on-line shopping closer to the actual experience that people have in a real life environment would bring the system closer to the concept of 'e-communities'. In privacy-preserved communities, the system adheres to basic user protection and privacy principles along existing legal norms. This paper presents a Kerberos-based protocol for controlling and accessing privacy-preserved information from networked applications. Our approach is novel in that it incorporates a number of legal privacy requirements into the technical design of the system itself. To our knowledge this work is the only e-commerce e-community based solution built specifically to meet the requirements of privacy legislation, and designed to be controlled by a third commonly trusted application.
Enforceable Privacy Promises	An increasing number of enterprises need access to private data of their customers. To gain these data they usually make privacy promises to customers in many different ways. The point card is one of the most well-known examples of such a privacy promise. Even if customers agree to the collection they do know if the collected data are misused. Only a few of these privacy promises can be automatically enforced. This limits the application of privacy technology, and may prevent the full exploitation of e-commerce. This talk argues that most existing privacy enhancing technology (PET) will fail, since the real threat is not the control of access but the control of the usage of collected data. While "access control" section of security and privacy is well understood, it is unclear of how to do "usage control". A solution for usage control will be explained by elaborating on the data collected with a point card. role. Point cards encompass a "black and while" and one-sided privacy policy which the issuer has decided to comply with. Some policies are subject to slightly different privacy regulations in Europe, as well as in Japan and the US. In its technical challenges these regulations resemble the efforts for compliance, where promises to shareholders, employees and customers regarding transparency of financial behaviour have to be made transparent for later audit. While all efforts of access control technology are directed to the past, the technologies to enforce the provisions now and in the future are called obligations. Present day privacy technologies ensure provisions to a very good extend, they fail however as far as obligations are concerned. Concepts for a life cycle management system for collecting and handling private data are shown as well as the at present algebraically complete privacy tool, called ExPDT (extended privacy definition tool) which forms the guidelines for the enforcement of privacy promises in the "future store" of a large retailer. Compariso- - n of policies, for example, allows the customer to move from one store to another. Conjunction, composition and reasoning based upon policy provisions and obligations allows the observation of sophisticated privacy policies.
On Providing One-to-One Marketing with Customers' Privacy in Stationary Retail	Electronic commerce has provided retailers with effective instruments to deploy one-to-one marketing over the internet. While the increasing use of sensors, RFID tags and other technologies enables the deployment of one-to-one marketing also in stationary retail stores, ini-tial experiments in realizing personalization in this setting have shown that customers' acceptance is low, as services require personal data to be collected, thereby raising imminent privacy concerns.In this paper, we argue that one-to-one marketing in stationary retail and privacy do not constitute a dichotomy, but can be brought together by focusing on individualized services solely built upon context information and techniques to allow customers to control the collection and usage of such context information.
Automating Privacy Compliance with ExPDT	Today, personalized services are lucrative for service providers and their customers. With their increasing pervasiveness and interconnection, however, customers show concerns about their privacy. If customers were to refuse the processing of their personal data in general, the economic potential of personalized services could not be realized. We claim that such scepticism is a direct consequence of incomplete control mechanisms. To be in line with laws and to help users to control the usage of their personal data, we propose the Extended Privacy Definition Tool (ExPDT) that not only provides customers as well as service providers with a formal language to specify and to compare different policies, but also providers with a monitor tool to enforce the policies within their services.
A proxy signature scheme with proxy signer's privacy anonymity	A proxy signature scheme is proposed with the property that the proxy signers can sign messages on behalf of the original signer while providing anonymity to protect their privacy. The anonymity can be revoked when it is needed to identify the proxy signer who actually generated the proxy signature. Moreover, the proxy signing power can be recalled according to original signer's need in the scheme
An approach to security and privacy of RFID system for supply chain	Radio frequency identification (RFID) is expected to become pervasive and ubiquitous, as it can be embedded into everyday items as smart labels. A typical scenario of exploiting RFID is supply chain. The RFID based supply chain management yields convenience, efficiency and productivity gains. However, RFID systems create new risks to security and privacy. We briefly present the current solutions to RFID security and privacy. A new approach is then proposed, which exploits randomized read access control and thus prevents hostile tracking and man-in-the-middle attack. In addition, compared with current schemes that achieve the similar security level, the proposed approach dramatically decreases the computation load. Another benefit is that it is suitable for RFID systems with a large number of tags
Algorithms for automated negotiations and their applications in information privacy	Automated negotiations have been an active research topic for many years. Most of the research work on this area focuses either on the abstract and theoretical models or on the system architectures for standalone negotiation applications. There is little work on identifying and studying practical algorithms for automated negotiations. In this paper, two algorithms have been proposed and their innovative applications have been discussed. The first algorithm guarantees that negotiation results are Pareto optimal solutions. The second algorithm guarantees that an agreement can be agreed upon after a certain number of proposal/counterproposal exchanges. These two algorithms can be used in the two-phase model for the automated negotiation process. In addition to these algorithms, their applications in information privacy negotiation have been described. In the information privacy management domain for service industries, it is critical for service requestors to only reveal the absolute necessary private information to the service providers. Traditionally, service requestors usually give whatever private information service providers have asked for. The grave consequence is that service providers may misuse the private information provided by service requestors, even though the service providers may have promised not to reveal it. Algorithms described in this paper can facilitate the privacy negotiation process. In order to show the concept of negotiation in information privacy, credit card information has been used to illustrate the application of algorithms.
SIMT - a privacy preserving Web metrics tool	Consumer metrics for analyzing the success of customer relationship management (CRM) are gaining increasing importance. CRM software packages have become commonplace. However, two major shortcomings exist. First, most software solutions are not offered as a Web service on the Internet. Second, privacy restrictions need to be integrated into an overall framework of success indicators for consumer analysis. Whereas the first aspect can be addressed with standardized developer software for Web services, the second must consider privacy legislation, privacy specifications on Web sites (P3P), and data re-identification problems. To address these problems, we have developed a web service - called SIMT - that automatically adapts CRM indicators to an online retailer's P3P policy. It is based on a declarative specification of privacy constraints, and syntactically extends P3P. This paper presents the prototype and describes how inference problems and legal restrictions have been addressed. The system has been tested on data from a large multi-channel retailer.
Better privacy and security in e-commerce: using elliptic curve-based zero knowledge proofs	We propose an approach using elliptic curve-based zero-knowledge proofs in e-commerce applications. We demonstrate that using elliptic curved-based zero-knowledge proofs provide privacy and more security than other existing techniques. The improvement of security is due to the complexity of solving the discrete logarithm problem over elliptic curves.
Evaluation of user intervention mechanisms for privacy on SME online trust	This paper describes empirical results that quantitatively show that user intervention tools for privacy significantly contribute towards online trust. We extend a seminal, validated measurement scale for online trust by adding measurement items for 5 user intervention (UIVs) mechanisms for trust: P3P, cookie crushers, encryption, pseudonymizer, and anonymizing tools. From analysis of 242 valid user responses collected in fall 2003, we find that those users willing to adopt user intervention mechanisms have statistically significant higher mean online trusting intentions. These users' mean trusting beliefs in small and medium size e-business is stronger than non-adopters and those undecided users sitting on the fence. Finally, we show our amendments to online trust theory to be plausible using the structural equation modeling technique and data for all groups of users.
Increasing user privacy in online transactions with X.509 v3 certificate private extensions and smartcards	Security and privacy are central issues for the acceptance of online payment methods in particular and growth of the Internet market in general. Public key infrastructure and X.509 certificates have been established as the most trustworthy methods for assuring security in online transactions. This paper proposes a new approach for increasing security by avoiding privacy violation using X.509 version 3 certificate private extensions and storing the certificate and its corresponding private key in the smartcard. The private key never leaves the smartcard and can be used for decryption and signing only after successful personal identification number presentation. The proposed approach is compared with secure electronic transaction (SET) protocol.
Towards an integrated privacy framework for HIPAA-compliant Web services	A Web service is a software system designed to support interoperable application-to-application interaction over the Internet. Web services are based on a set of XML standards, such as universal description, discovery and integration (UDDI), Web services description language (WSDL), and simple object access protocol (SOAP). Based on prior studies, this paper proposes a vocabulary-based Web services privacy framework for protecting health data privacy under the Health Insurance Portability and Accountability Act of 1996 (HIPAA).
Privacy enhanced electronic cheque system	With the introduction of Check 21 law and the development of FSTC's echeck system, there has been an increasing usage of e-cheque conversions and acceptance among retailers, banks, and consumers. However, the current e-cheque system does not address issues concerning privacy, confidentiality, and traceability. We highlight the issues concerning the current electronic cheque system and provide a solution to overcome those drawbacks.
Security and privacy using one-round zero-knowledge proofs	A zero-knowledge proof (ZKP) is an interactive proof that allows a prover to prove the knowledge of a secret to a verifier without revealing it. ZKPs are powerful tools to deal with critical applications in security e-commerce. Existing ZKPs are iterative in nature; their protocols require multiple communication rounds. The cost of iteration makes ZKPs unsuitable in practice. We propose a new protocol that meets all the requirements of ZKPs, yet runs in one round. The new approach substantially reduces computation and communications costs. It makes ZKPs more suitable for practical cryptographic systems for both government and commercial applications.
Implementing privacy negotiation techniques in e-commerce	This paper examines how service providers may resolve the trade-off between their personalization efforts and users' individual privacy concerns through negotiations. The analysis includes the identification of relevant and negotiable privacy dimensions for different usage domains. Based on a formalization of the user's privacy revelation problem, we model the negotiation process as a Bayesian game where the service provider faces different types of users. Finally an extension to P3P is proposed that allows a simple expression and implementation of negotiation processes.
A Privacy-Aware Service-oriented Platform for Distributed Data Mining	Customer data privacy is known to be a factor which makes just-in-time data sharing and mining among enterprises challenging. Learning-from-abstraction is a recently proposed paradigm for privacy preserving distributed data mining where distributed local data sources are protected by probabilistic data abstraction. In this paper, we investigate the use of a normalized negative log likelihood together with the paradigm for quantifying the level of privacy protection, and studied theoretically the change of the privacy levels of the local data abstractions after being aggregated for global data analysis. Experiments on distributed data clustering with a synthetic data set were conducted on a service-oriented BPEL platform. The promising results obtained demonstrates the effectiveness of the adopted privacy measure
Modeling and Measuring Privacy Risks in QoS Web Services	The privacy issue for QoS Web services is considered. As more Web services are constructed and deployed, many of our personal needs may be served by more than one service providers regardless of their platforms and implementation technologies. Service selection is performed by comparing the QoS attributes of all candidate services. Releasing private data without due control may raise the risk of allowing potential adversaries to collect, reveal or utilize one's data in undesirable ways. We propose a QoS model that quantifies a user's privacy risk in order to make the service selection process manageable. The privacy risk is derived using the percentage of the private data set to be released, and user-defined context-oriented weights that quantify the potential damage of privacy leaking in a specific context. We have included privacy risk cost as one of the QoS parameters by extending the end-to-end QoS composition algorithms developed previously
Imposing holistic privacy and data security on person centric ehealth monitoring infrastructures	Telemetric monitoring of vital parameters of patients with chronic diseases is recognized to improve their medical condition and hence their quality of life. It also improves treatment adjustments, reaction time in acute cases and helps to reduce duration and costs of hospitalization. As a result of this, there are plenty of products and solutions for personal health monitoring available today that acquire physiological data in real-time. In order for such systems to be widely acceptable and utilized by the medical community and the patients, they must be developed satisfying the security requirements imposed by real-time data communication and protection of sensitive physiological data and measurements, data integrity and confidentiality, and protection of the monitored patient's privacy. The work presented in this paper intends to fill the security gap, which makes these devices and the data acquired by them, vulnerable to any kind of attacks. By utilizing MPEG-21 standard's primitives, we show that protection of transmitted medical information and enhancement of patient's privacy is accomplished, since there is selective and controlled access to medical data that sent toward the hospital's servers.
Privacy Management in Consumer e-Health	Healthcare organizations are moving towards more diversified channels to provide the healthcare services. The increasing dependency on the Internet to provide the healthcare services opens up a whole gamut of privacy concerns of consumers and providers. The misuse of personally identifiable information could drag the patient to vulnerability, humiliation, discrimination, economic hardship. There is a need for tools to improve transparency and awareness of information security practices in the context of Internet based consumer e-health systems. This paper presents a cooperative management methodology for the development of privacy solutions for consumer e-health.
iPAT: Intelligent privacy-preserving administration tool for IRB applications	Supported by maturing information and communication technology (ICT) technologies, the medical care industry entered its digitization age. However, medical information is highly confidential and involves privacy; even legitimate access can cause privacy infringements. Under the current medical administration system, no established application systems conform to the IRB (Institutional review board) to protect privacy in human subject research. To prevent the privacy of research subjects from being disclosed unintentionally, and to meet the ΓÇ£need-to-knowΓÇ¥ demands of information management, this study proposes an intelligent privacy-preserving administration tool (iPAT) designed to facilitate human subject research. This study provides the principle and feasibility of iPAT that are introduced and verified through a use case conducted by the head of the research project.
A framework for privacy-preserving healthcare data sharing	As healthcare data is quite valuable to many organizations for scientific research or analysis, the demand of sharing healthcare data have been growing rapidly. Nevertheless, health care data usually contains a lot of patient privacy. Sharing that data directly would bring huge threaten to patient privacy. It's necessary to develop practical methods to balance health care data sharing and privacy protection. Although many approaches have been developed to deal with these problems, most of them are focusing on a small scope of the problem with single theory. In this paper, we'd like to introduce a framework for privacy preserving data sharing with the view of practical application in more comprehensive way. The framework focuses on three key problems of privacy protection during data sharing which are privacy definition and detection, privacy protection policy management, privacy preserving health care data sharing. And solutions to these three problems are discussed in details. A simple implementation of the framework would be introduced to solve the problems of privacy-preserving electronic medical records publishing.
I am not a goldfish in a bowl: A privacy preserving framework for RFID based healthcare systems	RFID has received considerable attention within the healthcare for almost a decade now. The technology's promise to efficiently track hospital supplies, medical equipment, medications and patients is an attractive proposition to the healthcare industry. However, the prospect of wide spread use of RFID tags in healthcare has also triggered discussions regarding privacy, particularly because RFID data in transit may easily be intercepted. In a nutshell, this technology has not really seen its true potential in healthcare since privacy concerns raised by the tag bearers are not properly addressed by existing protocols and frameworks. The two major types of privacy preservation techniques that are required in an RFID based healthcare are: 1) a privacy preserving authentication protocol is required while sensing RFID tags for different identification and monitoring purposes 2) a privacy preserving access control mechanism is required to restrict unauthorized access of private information while providing healthcare services using the tag ID. In this paper, we propose a component based framework (PriSens-HSAC) that makes an effort to address the above mentioned two privacy issues. To the best of our knowledge, this is the first framework to provide better privacy in RFID based healthcare systems, using authentication and access control technique.
Privacy-preserving electronic health record linkage using pseudonym identifiers	Accurate and reliable information sharing is essential in the healthcare domain. Currently, however, information about individual patients is held in isolated medical records maintained by numerous separate healthcare providers. Accurately linking this information is necessary for planned nationwide Electronic Health Record systems, but this must be done in a way that not only satisfies traditional data confidentiality requirements, but also meets patientspsila personal privacy needs. Here we present an architecture for linking electronic medical records in a way that gives patients control over what information is revealed about them. This is done through the use of indirect pseudonym identifiers. We then explain how this architecture can be implemented using existing technologies. A case study is used to show how our architecture satisfies data accuracy needs and patientspsila privacy requirements.
A web-based wireless mobile system design of security and privacy framework for u-Healthcare	The research project aims at designing and implementing a Web based wireless mobile system security and privacy framework that is centered on the concepts of ubiquitous healthcare services provided to the patients in rural or remote areas from distant hospitals. With this system framework, a physician can securely access and carry the patient information from a mobile device, update the patient information offline on the mobile device and synchronize the data with the server at a later time. The system provides high security to the highly sensitive patient health records. It provides various layers of security and privacy controls to access the patient information. This framework also maintains security levels both at system level and user level to constrain any attacks on the system. Data on the mobile device also is protected from being tampered or hacked using password protections and encryption. This application framework demonstrates a multi-tiered SOA (service oriented architecture) involving mobile client, Web services, security agents, business logic layer, data access layer and database in secured environments. This framework uses SAML (Security Assertion Markup Language) security assertions for exchanging the secured user identification information between the server and mobile clients. Due to the length of the paper for the entire research project, the original paper is divided into two papers; the first paper emphasizes the system architecture and design and the second paper emphasizes the implementation and performance evaluation.
The Maximum Greedy Algorithm on Privacy Protection Based on Social Network	The flow of information in the network currently existing attacks and malicious damage, a privacy protection algorithm based on the maximum greedy is proposed, the data privacy acts as weights between nodes in network diagram , change these weights to achieve the protection of important data, by obtaining the shortest path way to ensure that efficiency is not influenced ,the experimental results show that this algorithm not only protects data privacy but also efficiently ensures the effectiveness of data.
Anonymous Credentials for Privacy-Preserving E-learning	E-learning systems have made considerable progress within the last few years. Nonetheless, the issue of learner privacy has been practically ignored. Existing E-learning standards offer some provisions for privacy and the security of E-learning systems offers some privacy protection, but remains unsatisfactory on several levels. On the other hand, privacy preserving solutions that are appropriate and used in E-commerce environments are inadequate and unsuitable to the context of E-learning. Indeed, while in most E-commerce applications different transactions between the client and the system are pretty much independent, in E-learning the interactions between the learner and system are intertwined into a developing process that depends heavily on the path the leaner is following. In this paper, we introduce the anonymous credentials for E- learning systems (ACES), a set of protocols to preserve learner's privacy in E-learning environments. In particular, the ACES allows learners to provide anonymous credentials throughout the learning process, such as when they need to prove that they possess the necessary requirements to register for a course, and/or to prove that they are the legitimate owners of an anonymous transcript or an anonymous degree. Although the concept of anonymous credentials is not novel, ACES takes into account the specificities of E-learning. Moreover, in order to prevent the misuse of privacy, ACES prevents the possibility of sharing credentials between learners.
Trust and privacy in electronic commerce	Trust and privacy have been widely recognized as important issues in the field of electronic commerce. We propose a research model with trust and privacy as two endogenous variables along with other exogenous variables like independent self-construal, interdependent self-construal, technological knowledge, and Web site quality, that are expected to effect Internet consumers' trust level and privacy concerns.
A privacy-friendly loyalty system for electronic marketplaces	Loyalty systems provide an interesting possibility for vendors in customer relationship management. This holds for both real world and online vendors. Beside potential benefits of loyalty systems, customers may fear an invasion of privacy, and thus often refuse to participate in such programs. We present two variants of a privacy-friendly loyalty system to be used by online vendors for issuing loyalty points. The systems prevent vendors from exploiting data for the creation of customer profiles by providing unconditional unlinkability of loyalty points with regard to purchases. We propose a simple token-based approach and a counter-based approach which is much more efficient while preserving the privacy and security properties. Furthermore, the counter-based loyalty system prevents pooling of loyalty points issued to distinct customers.
Mobile agents for secure electronic commerce transactions with privacy protection of the customers	It is believed that the mobile agent technology is going to play an important role in future electronic commerce due to the characteristics of mobility and autonomy of the agents, which make it ideal for electronic commerce applications in open network environment. However, a couple of security issues need to be tackled before we can employ mobile agents in real life commercial applications. Some schemes have been proposed to solve the security problems in mobile agent paradigm, such as the undetachable signature scheme, the secure agent scheme using proxy signature and others. Most of the current work, however, mainly focus on the protection of the private key of the customer from the malicious servers, while the other related security issues in electronic commerce, say, privacy protection of the customer, are seldom considered. In this paper, we summarize the security requirements for mobile agent-based electronic transactions and propose a new secure mobile agent scheme for electronic commercial transactions with privacy protection of the customer. With a security analysis, we show that the proposed scheme satisfies all security requirements.
Maturing e-Privacy with P3P and context agents	Mediating privacy mechanisms on the client-side aid in next generation e-transformation as they enhance users' perception of online trust in an organization. We propose a collaboration, between a context agent and a P3P agent, which results in the application of context-specific privacy rules during a user's electronic commerce transaction with an organization's Web site or Web service. The context agent manages dynamic changes of the context, inform the user about the current privacy-related context for decision support, and automatically generate user preferences. Fully compliant to the P3P privacy platform, the context management system supports the storage, index, retrieval, and switch of user contexts. Test cases using real Web sites' P3P policies demonstrate the functionality and utility of the context manager agent. Delays are in the range of less than one second to 7 seconds depending on activities such as a context switch or P3P comparison.
Code of conduct for FP7 researchers in medical and biometric data privacy	In FP7 research projects, medical or/and biometric data is used for research reasons. Researchers should be aware of the privacy issues arising from improper or not-existent disclosure control in the collection, use, storage and disposal of medical and/or biometric data that has been accumulated during the implementation an FP7 project. The articulation of code of conduct for FP7 researchers in medical and biometric data privacy is necessary as to provide guidance in practical terms.
Privacy Issues in Middleware for Service-oriented Applications	Privacy helps to establish personal autonomy and create individualism. Privacy is a state or condition of limited access to a person. In particular, information privacy relates to an individual's right to determine how, when, and to what extent information about the self will be released to another person or to an organization. It can be said that privacy is a much broader concept than security; privacy protection is based on security protection. Security may enable privacy protection from authorized access, but security alone cannot provide privacy. Service-Oriented Computing (SOC) has recently gained a lot of attention both in industry and academic areas. However, its characteristics can not be easily solved using existing distributed computing technologies. The composition and interaction issues have been the central concerns because service-oriented applications are composed of autonomous, heterogeneous, and distributed processes. Middleware is thus proposed to serve as a solution to manage and provision service-oriented applications. Middleware is computer software that connects software components or applications in a distributed environment. Middleware includes different systems to support application development and delivery such as Web servers, application servers, and content management systems. To tackle the complexity of the interactions among services from various organizations, complex process requirements can be decomposed into different types of information flows, such as control, and data. This talk will give an overview of the research on privacy issues in this context and discuss the future research directions.
Towards a Privacy Policy Enforcement Middleware with Location Intelligence	Information privacy is usually concerned with the confidentiality of personally identifiable information (PII), such as electronic medical records. Nowadays, Web services are used to support different applications which may contain PII, such as healthcare applications. Thus, the information access control mechanism for Web services must be embedded into privacy-enhancing technologies. Further as application goes mobile and ubiquitous, location become an important determinant for enforcing privacy constraints. On the other hand, role-based access control (RBAC) model has been widely investigated and applied into various applications for a period of time. This paper presents a privacy access control policy enforcement model extended from RBAC with location intelligence for Web services-based applications. In addition, we illustrate the realization of this model with a middleware architecture. This paper also illustrates our proposed mechanism in the context of extensible access control markup language (XACML) and WS-policy constraints.
Privacy Access Control Model for Aggregated e-Health Services	Information privacy typically concerns the confidentiality of personal identifiable information (PII) and protected health information (PHI) such as electronic medical records. Thus, the information access control mechanism for e-health services must be embedded with privacy-enhancing technologies. Role-based access control (RBAC) model has been widely investigated and applied to various applications for a period of time. This paper presents an extended framework of RBAC with privacy-based extensions to tackle such a need. With the context of e-health care informatics, this paper proposes an aggregation decision-making layer interacted with a set of autonomous RBAC models to aggregate PHI.
Learning by challenging: A social network and privacy based approach	Considerable research in the field of Intelligent Tutoring Systems (ITS) has focused on helping students increase learning by taking advantage of technological progress. As the use of social media by learners continues to increase, however, ITS should go beyond teaching based on isolated environments (platforms) and turn toward community-based learning within social networks. In this paper we introduce a new approach to learning based on social networks. This approach takes advantage of the increasing enthusiasm among learners for spending time in social networks. The goal is to use some of that time for learning, by replacing one of the various social game applications with an Intelligent Tutoring Systems (ITS). During a learning session, learners are encouraged to improve their scores by challenging either a score predefined by the system or the scores posted by their Facebook friends. In this paper, we describe a new system called LBC (Learning By Challenging) that enables the user to learn and to share their knowledge and resources in a social environment. It also provides an environment that protects the learner's privacy if he or she so desires.
Model of efficient Assessment System with accent on privacy, security and integration with E-University components	Research on Computer-based Assessment (CBA) in the past decade resulted in many improvements in every aspect of assessment process. Research on unification and integration of Assessment System (AS) with other components of eLearning platform has not been covered entirely and in this paper, we present an efficient and unified model, based on the experience from Faculty of Information Technology (FIT). Our AS consists of: Question Management, Test Management, Auto Grading, Collaboration, Recommendation, Monitoring and Reporting module. With growing needs for information exchange between other systems in E-Learning Environment (E-LE), AS became a component of E-University System (EUS). Integration with EUS, offers new functionalities, improves usability and reliability of AS. Implementation of information security governance, policies, procedures and countermeasures and use of Hippocratic Database Structures, solves security and privacy issues.
A New Scheme on Privacy-Preserving Distributed Decision-Tree Mining	Privacy-preserving data mining is discovering accurate patterns and rules without precise access to the original data. This paper focuses on privacy-preserving research in the situation of distributed decision-tree mining, and presents a decision-tree mining algorithm based on homomorphic encryption technology, which can get accurate mining effect in the premise of no sharing of private information among mining participators. Theoretical analysis and experiment results show that this algorithm can provide good capability of privacy-preserving, accuracy and efficiency.
Privacy-Preserving Approximate Convex Hulls Protocol	Secure multi-party computation has been a research focus for more than two decades. The convex hulls problem is a special case of secure multi-party computation. However, the precise convex hulls will certainly expose every vertex and even bring about unfairness. As a result, the practical approximate convex hulls are in need. In this paper, we summarize and discuss the convex hulls problem, and then we present a new more effective protocol to privately find the approximate convex hulls. Furthermore, we analyze the correctness, security, efficiency and performance of the protocol, and compare the new scheme with other privacy-preserving convex hulls protocols. We show that the privacy-preserving approximate convex hulls protocol is more effective than the previous privacy-preserving convex hulls ones, and the new protocol is practical enough in many aspects. Perfectly keeping privacy preserving and eliminating unfairness are the great advantages of our scheme.
Research on Suspicious Financial Transactions Recognition Based on Privacy-Preserving of Classification Algorithm	Classification basing on Privacy-preserving is one of the hottest spots in the field of data mining in recent years. This paper studies how to identify suspicious financial transactions under the privacy-preserving of classification algorithm. The research is studied on multi-data that from several parts by using Scalar Product Protocol under the privacy-preserving. The experimental results show that this method is a effective way for financial institutions to improve the efficiency of identify Money-laundering transactions.
A Convex Hull Algorithm for Planar Point Set Based on Privacy Protecting	Research on secure multi-party computation is of great interest in the field of information security. To determine convex hull algorithm for planar point set or polygons may be applied in a large number of research fields, and at present, there are a lot of methods to solve this problem. In this paper, a protocol is schemed out to determine a line by two secret points. The method is applied to determine the whole convex hull of two secret planar point sets. The corresponding security and complexity are analysed.
Risk-based modelling for managing privacy protection	Privacy is one of the challenges in Cooperative Distributed Systems (CDSs) in open environments where entities can desirably work collaboratively. One way of dealing with this challenge is to evaluate the negative risk of operations on shared information in a collaborative setting. In this paper, we propose a Hierarchical Fuzzy Inference System (HFIS) to assess risk of privacy violation during the interaction among entities. In this work, we have identified and categorized major influential elements of privacy and adapted them as the base for the proposed HFIS. The accuracy of the risk assessment system in managing privacy situations is verified and validated against predefined privacy violation scenarios.
Privacy Negotiation using a Mobile Agent	One major limitation of platform for privacy preferences (P3P) is that no support is given within the specification for negotiation of privacy preferences between a user and a Web site. In this paper, we present a novel architecture to address this limitation, focusing on the use of mobile agents with an XPath-based preference language (XPref) for privacy negotiation. So far in the literature there appears to be no working mobile agent mechanism that does privacy policy negotiation, particularly in the context of P3P. We envision the use of this architecture in a scenario where the user device has limited resources (i.e., processing power and bandwidth) and cannot negotiate directly with desired Web sites, but less constrained user devices would also benefit from this work. Despite the advantages of a mobile-agent-based architecture, there are several challenging issues which hinder the deployment of mobile agents in real life scenarios. Two major security concerns that need to be addressed are malicious agents and malicious hosts. In this paper, we address the malicious host threat by extending a protocol proposed by Maggi and Sisto [2003] to improve truncation resilience, which is argued as one of the major problems with most of the mechanisms that have been proposed in the literature
On Data Distortion for Privacy Preserving Data Mining	Because of the increasing ability to trace and collect large amount of personal information, privacy preserving in data mining applications has become an important concern. Data perturbation is one of the well known techniques for privacy preserving data mining. The objective of these data perturbation techniques is to distort the individual data values while preserving the underlying statistical distribution properties. Theses data perturbation techniques are usually assessed in terms of both their privacy parameters as well as its associated utility measure. While the privacy parameters present the ability of these techniques to hide the original data values, the data utility measures assess whether the dataset keeps the performance of data mining techniques after the data distortion. In this paper, we investigate the use of truncated non-negative matrix factorization (NMF) with sparseness constraints for data perturbation.
Privacy Management in e-Commerce Communities	Providing an e-Commerce system that brings on-line shopping closer to the actual experience that people have in a real life environment would bring the system closer to the concept of 'e-communities'. In privacy-preserved communities, the system adheres to basic user protection and privacy principles along existing legal norms. This paper discusses a topology and protocol for controlling and accessing privacy-preserved information from networked applications. Our approach is novel in that it incorporates a number of legal privacy requirements into the technical design of the system itself.
A Privacy-Preserving 3rd-Party Proxy for Transactions that Use Digital Credentials	In this paper we propose modifications and extensions to the digital credentials issuing and showing protocols to make them appropriate for an e-commerce environment in which the user has only a hand-held constrained device (such as a PDA or a cell phone), with limited memory and processing power. In particular, this device does not hold the digital credentials or conduct the corresponding protocols; this is done by a 3rd party (a proxy) on behalf of the user, who simply needs to authorize the transaction once it is complete. Our proposal frees the user from having to carry the digital credentials and protocol engine with him/her at all times (which may be unrealistic in some environments), while retaining the desired privacy properties (e.g., the 3rd party proxy performs computations on the user's behalf and participates in the required protocols without learning any of the user's private information). The complete architecture that we describe also includes mechanisms to prevent the following three forms of attack: password cracking, betrayal, and collusion.
Anonymous authentication-oriented vehicular privacy protection technology research in VANET	Vehicular Ad hoc Networks (VANET) consists of several vehicular nodes and uses 802.11p protocol for communication. Because of its unique characteristics, such as fast speed, serious Doppler effect, large node number etc, VANET is vulnerable to be affected by a variety of security threats. In this paper, we firstly introduce the system architecture, applications and categories of attacks in VANET. Then we summarize several types of anonymous authentication techniques which aim at protecting the privacy of vehicular nodes, then discuss and compare the typical anonymous authentication schemes of each type. Finally, we present the problems which should be considered in the next step of research.
An approximation algorithm for privacy preservation of associative classification	Privacy is one of the most important issues when the data are to be processed. Typically, given a dataset and a data processing goal, the privacy can be guaranteed by the pre-specified standard by applying privacy data-transformation algorithms. Furthermore, the utility of the dataset must be considered while the transformation takes place. Such data transformation problem such that a privacy standard must be met and the utility must be optimized is an NP-hard problem. In this paper, we propose an approximation algorithm for the data transformation problem. The focused data processing addressed in this paper is classification using association rule, or associative classification. The proposed algorithm can transform the given datasets with O(k log k)-approximation utility comparing with the optimal solutions. The experiment results show that the algorithm can work effectively comparing with the optimal algorithm and the other heuristic algorithm. Also, the proposed algorithm is very efficient.
Routing-based source-location privacy protection in wireless sensor networks	Wireless sensor networks (WSN) have the potential to be widely used in many areas for unattended event monitoring. Mainly due to lack of a protected physical boundary, wireless communications are vulnerable to unauthorized interception and detection. Privacy is becoming one of the major issues that jeopardize the successful deployment of wireless sensor networks. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address the source-location privacy. For WSN, source-location privacy service is further complicated by the fact that the sensor nodes consist of low-cost and low-power radio devices. Therefore, computationally intensive cryptographic algorithms (such as public-key cryptosystems) and large scale broadcasting-based protocols are not suitable for WSN. In this paper, we propose a scheme to provide both content confidentiality and source-location privacy through routing to randomly selected intermediate nodes. While being able to provide source-location privacy for WSN, our simulation results also demonstrate that the proposed scheme is efficient and can be used for practical applications.
A Privacy-Preserving Integrity Measurement Architecture	TCG's Trusted Platform Modules provide the functionality of remote attestation, which based on the integrity of software components in a specific platform configuration. Integrity Measurement Architecture(IMA) is the accredited remote attestation methods which formulates the integrity measurement process and integrity reporting protocol. However, as a binary attestation, all integrity measurements must be exposed to remote party-verifier. This can disclose the privacy of attesting platform. In this paper, We slightly adapt the Integrity Measurement Architecture (IMA) to provide privacy preserving. System configuration is partitioned into privacy-relevant tasks based on the measurement relationships and dependency relationships between components. During integrity reporting in remote attestation, only the measurements of task-relevant software components are released to verifier. Shield factors are introduced to hide integrity measurements during measurement process and hide the task-irrelevant integrity measurement during integrity report.
Preservation of Privacy in Publishing Social Network Data	This paper consider the privacy disclosure in social network data publishing. We assume that adversaries know the degree of a target individual and the target's immediate neighbors, and identify an essential type of privacy attacks: background knowledge attacks. We propose a practical solution to defend against background knowledge attacks. The experimental results confirm that the anonymized social networks obtained by our method can still be used to answer aggregate network queries with high accuracy.
E-Mail Address Privacy via PEA's (Proxy E-Mails Accounts)	Doing business electronically is a major tendency among customers and businesses but there is always a threat about personal information privacy. E-mail address is one thing about which customers expect that e-businesses will not misuse it. Most e-businesses have privacy policy but that usually changes with time. And in case of violating privacy it is difficult to find the original source of violation. A lot of research work has been done to protect mailboxes from spam messages and to make E-mail addresses difficult to be harvested. However, these methods do not prove helpful in finding the original source of violation and those that do exist often require modification in either mail server or mail client which our proposed does not require. The main feature of our proposed system is to help users detect the exact source from where E-mail address was misused and to find the violators who violated the E-mail privacy policy by sending spam messages or selling E-mail addresses to third parties. Finding the exact privacy policy violators enables us to take legal action against them. And after finding a specific source, through this system a user can easily cut-off his relationship with them and by doing so they will not be able to send E-mails in future. So, people will not have to change their E-mail addresses again and again. If e-mail address is placed at ldquonrdquo different places and is misused from one place then instead of making and redistributing new E-mail address to all correspondents, the exact correspondent is found out and dealt with, and for others the E-mail address does not change. It also indirectly helps the e-businesses in making the decision to change the format of placing E-mail addresses on site to make it difficult for harvesting. The Proposed system can be installed easily and does not need any change in the current infrastructure.
Privacy Compliance Engineering Process	For successful privacy engineering, it is critical to guarantee the alignment and compliance among privacy artifacts produced during privacy-aware software development. In this paper, we propose a privacy compliance engineering flow in which we discuss the involved privacy artifacts and their alignment, refinement, and compliance verification. Within a case study, we identify the privacy artifacts in the refinement flow and analyze their compliance verification.
A Survey on the Privacy Preserving Algorithm of Association Rule Mining	We provide an overview of privacy preserving association rule mining, which is one of the most popular pattern-discovery methods in the new and rapidly emerging research area of privacy preserving data mining. Various proposals and algorithms have been designed for it in recent years. In this paper, we summarize them and survey current existing techniques, and analyze their advantage and disadvantage. We divide the proposals of privacy preserving association rule mining into three categories: heuristic-based techniques, reconstruction-based techniques, cryptography-based techniques. Then we give a simple review of the work accomplished. Finally, we conclude further research directions of privacy preserving algorithms of association rule mining by analyzing the existing work.
Privacy promises, access control, and privacy management. Enforcing privacy throughout an enterprise by extending access control	Regulations and consumer backlash force many organizations to re-evaluate the way they manage private data. As a first step, they publish privacy promises as text or P3P. These promises are not backed up by privacy technology that enforces the promises throughout the enterprise. Privacy tools cover fractions of the problem while leaving the main challenge unanswered. This article describes a new approach towards enterprisewide enforcement of the privacy promises. Its core is a new framework for managing collected personal data in a sensitive, trustworthy way. The framework enables enterprises to publish clear privacy promises, to collect and manage user preferences and consent, and to enforce the privacy promises throughout the enterprise. This article shows how this new approach extends the traditional view of access control to provide a more complete coverage of privacy management issues.
Privacy consideration for trustworthy vehicular ad hoc networks	For increasing safety of driving, intelligent vehicles in vehicular ad hoc networks (VANETs) communicate with each other by sending announcements. The existence of a system that guarantees the trustworthiness of these announcements seems necessary. The proposed approach generating announcements should be preserved from internal and external attackers that attempt to send fake messages. In this paper, we use a group-based endorsement mechanism based on threshold signatures against internal attackers. We choose NTRUSign as a public key cryptosystem for decreasing signature generation and verification times. This approach optimizes the network overhead and consequently its performance. In this scheme, also the privacy of signers and endorsers that generate or endorse trustworthy announcements is preserved.
Communication privacy using digital techniques	Scrambling of speech information has been in existence for many years, but new techniques in circuit design and the associated growth of digital communication are causing significant changes to be made
Computer-privacy scheme criticised	
A privacy preserving repository for securing data across the cloud	Popularity of cloud computing is increasing day by day in distributed computing environment. There is a growing trend of using cloud environments for storage and data processing needs. Cloud computing is an Internet-based computing, whereby shared resources, software, and information are provided to computers and other devices on demand. However, adopting a cloud computing paradigm may have positive as well as negative effects on the data security of service consumers. This paper primarily highlights some major security issues existing in current cloud computing environments. The primary issue that has to be dealt with when talking about data security in a cloud is protection of the data. The idea is to construct a privacy preserving repository where data sharing services can update and control the access and limit the usage of their shared data, instead of submitting data to central authorities, and, hence, the repository will promote data sharing and privacy of data. This paper aims at simultaneously achieving data confidentiality while still keeping the harmonizing relations intact in the cloud. Our proposed scheme enables the data owner to delegate most of computation intensive tasks to cloud servers without disclosing data contents or user access privilege information.
An improved three-factor authentication scheme using smart card with biometric privacy protection	Chun-I-Fan and Yi-Hui-Lin proposed a remote three-factor authentication scheme in 2009 based on smart card, password and biometric. The scheme emphasized mainly on the privacy protection of biometrics This paper emphasizes on the flaws of their scheme as well as proposes an improved secure three-factor authentication protocol which addresses the concerns of user's privacy, template protection and trust issues. This protocol is provably secure because it reveals only the identity of the user and no additional information about the user or the biometrics to the server.
Analysis of encryption algorithms to basic operations on outsourced B<sup>+</sup> trees for data privacy	Shared data systems have grown in numbers, many of these are critical in nature. As a recent trend, there has been growing interest in outsourcing database services in both the commercial world and the research community. In the outsourced database service (ODBS) model, clients rely upon the service provider, which include hardware, software and manpower, for the storage, maintenance, and retrieval of their data. Hence, it tends to variety of security challenges involved in it. The outsourced B+ index trees and data are encrypted and stored at some un-trusted server. Here, we discuss implementation of data security issues on outsourced B+ index trees and ensure security in the execution of basic operations like search and updates (insert, delete) on the un-trusted server. Our proposed work aims at presenting the results after implementing basic operations on outsourced B+ index trees with the help of various encryption algorithms to ensure data privacy.
Hardware security for software privacy support	The security level in existing workstation and server systems is not sufficient for most applications in a network environment. The processors only provide basic multitasking support, and any other security enforcement has to be carried out in the software layers. It is shown why stronger hardware security must be provided by the processor, and how it can be realised to limit the execution time overhead to 2%. This overhead is only required for the critical parts of the code that need strong protection
Privacy amplification against active attacks with strong robustness	An improvement is made to a recently proposed protocol by Wolf (1998). Privacy amplification is achieved for communication over an insecure and non-authentic channel for sufficiently large n, the size of string S shared by the two parties, when the adversary's Renyi entropy about S exceeds only n/2 rather than 2n/3
Prediction restricted H.264/AVC video scrambling for privacy protection	Drift error is a critical issue in video scrambling which is widely used to protect privacy in surveillance video. However, how to improve video coding efficiency while preventing drift error in video scrambling has not been covered in most studies. Proposed is a prediction restricted scheme for H.264/AVC privacy protected video scrambling. Experiments show that the proposed scheme dramatically raises coding efficiency.
Privacy enhanced access control mechanism for home networks	In this paper, we propose an access control mechanism for home networks. First, we examine existing access control mechanisms and summarize their shortcomings, such as bottleneck, single point of failure, and inconvenience of configuration. Then, we introduce new access control mechanism dealing with the defects. In the proposed mechanism, we classify the services into three groups based on their security sensitivity level, and provide different access control schemes to each security level service to make a difference among the protection levels of each service (i.e. to provide more secure access control mechanism to more important services.) Finally, we describe how the security and convenience are enforced by using our mechanism. Proposed access control mechanism is based on the authority delegation scheme of SPKI/SDSI (Simple Public Key Infrastructure /Simple Distributed Security Infrastructure.).
Trustworthiness: safety, security and privacy issues	The paper presents the Angel approach to analyzing and demonstrating trustworthiness in the context determined by the selected set of application scenarios. The focus is on safety, security and privacy issues. The analysis is based on two `pillars': the analysis of risks in the context of Angel scenarios and the analysis of the requirements derived from the relevant standards. The way Angel addresses the risks and requirements is represented in the Angel trust case - a structured argument which integrates all the trustworthiness supporting evidence. The article gives more detail on the approach taken during the safety, security and privacy related analysis and explains the idea of Angel trust case.
Investigation and management solution for privacy identification and electrical energy theft	This paper discusses a system to determine the identification request for a given person already exists. The check is performed by comparing Applicant attributes (except for signature) against the registration database. For biometric information searches, a Biometric Identification System (BIS), which is an Automated Fingerprint Identification System (AFIS) Database, is searched against the captured biometric data on the application record. If a matched record already exists or a number of partially matched records exist, then application processing is routed to the ΓÇ£Resolve DuplicateΓÇ¥ process. The Fraud Investigation application is built on Privacy Identification and Management Solutions (PRIMS) framework which is based on Identification and Credentialing solutions. The solutions are structured to capture biographic and biometric data in real-time with immediate checks on a person's identity, and produce e-ID cards and passports using this framework. The PRIMS framework supports identity management such as personnel enrolment and application processing, identity verification, secure document production and card inventory control, issuance and post-issuance management, authentication/authorization at point-of-service. The PRIMS framework is built with a flexible, component-based, service-oriented architecture. The PRIMS framework integrates a number of functions required to manage end-to-end life cycle of registered persons and secure documents. PRIMS provides a highly configurable workflow and business rules engine and allows for significant variability to support unique client requirements in the areas of enrolment processing, different technologies for secure documents, and different solutions and uses of biometrics.
A Security and Privacy Survey for WSN in e-Health Applications	Wireless sensors networks (WSN) are getting a special place in the development of e-Health application, due to its characteristics such as: not intrusive design, low energy consumption, low price and its flexibility to integrate into health care environments. However, the use of WSN in these kind of environments must consider those security and privacy mechanisms required by applicable personal data protection legislations to provide end-to-end guarantees to the patient's information. Applications and research projects are taking place to offer e-Health solutions with these features, however still there is not framework or standard to support interoperability among these or to provide a design criteria for future developments. Towards this goal, in this paper we survey a set of e-Health proposals for WSN, focusing on the mechanisms used to provide security and privacy to support real-time and multimedia data transmission in WSN.
A Security, Privacy and trust architecture for Wireless Sensor Networks	In this paper the authors propose a cross-layer security management plane, with a main actor security, privacy and trust manager, which addresses: a) the defined requirements taking into account the diverse application spaces and their scenarios, b) the diverse node capabilities which is a characteristic for wireless sensor networks architecture and c) the change of the context and preferences of the user in the scenarios where end user is heavily involved. Being context aware the framework assures secure interactions, providing adaptability and flexibility. The solution is presented along with a medical care scenario example, to better explain the functionality of the blocks forming the simplified architecture and their interactions, which are also depicted through several communication diagrams.
Privacy Protection Technology in Video Surveillance System	Since the increase of terrors and crimes, the demand of the video surveillance system is increasing. The video surveillance system has been operated for public interest by the police and local government. However private information such as faces or behavior patterns can be recorded in CCTV, it may cause the invasion of privacy. This paper proposes a video surveillance system that satisfies both functions of privacy protection and surveillance. The proposed system operates multiple surveillance cameras with a single RFID system. The RFID system is used in order to recognize internal or external personnel of object at entrance and cameras are used to extract features such as height and clothing-colors of the object. The proposed system can reduce invasion of privacy by intensity of scrambling according to access levels. Based on the experimental results, we are able to confirm that surveillant can classify personnel information fast and exactly in the display.
Privacy-Aware Communication for Smartphones Using Vibration	We propose a novel communication method between smart devices using a built-in vibrator and accelerometer. The proposed approach is ideal for low-rate private communication and its communication medium is an object on which smart devices are placed, such as tables and desks. When more than two smart devices are placed on an object and one device wants to transmit a message to the other devices, the transmitting device generates a sequence of vibrations. The vibrations are propagated through the object on which devices are placed. The receiving devices analyze their accelerometer readings to decode incoming messages. Unlike radio-based wireless communication where eavesdropping of private communication is possible without the knowledge of the user, the proposed method can guarantee privacy as long as the object used for communication is secured. The proposed method is implemented on Android smart phones and comprehensive experiments are conducted to show its feasibility.
A Privacy Preserving Access Control Scheme using Anonymous Identification for Ubiquitous Environments	Compared to all emerging issues, privacy is probably the most prominent concern when it comes to judging the effects of a wide spread deployment of ubiquitous computing. On one hand, service providers want to authenticate legitimate users and make sure they are accessing their authorized services in a legal way. On the other hand, users prefer not to expose any sensitive information to anybody. They want to have complete control on their personal data, without being tracked down for wherever they are, whenever and whatever they do. In this paper, we introduce an anonymous identification authentication and access control scheme to secure interactions between users and services in ubiquitous environments. The scheme uses anonymous user ID, sensitive data sharing method, and account management to provide a lightweight authentication while keeping users anonymously interacting with the services in a secure and flexible way.
Security of the TCG Privacy-CA Solution	The privacy-CA solution (PCAS) is a protocol designed by the Trusted Computing Group (TCG) as an alternative to the Direct Anonymous Attestation scheme for anonymous authentication of Trusted Platform Module (TPM). The protocol has been specified in TPM Specification Version 1.2. In this paper we offer a rigorous security analysis of the protocol. We first design an appropriate security model that captures the level of security offered by PCAS. The model is justified via the expected uses of the protocol in real applications. We then prove, assuming standard security notions for the underlying primitives that the protocol indeed meets the security notion we design. Our analysis sheds some light on the design of the protocol. Finally, we propose a strengthened protocol that meets a stronger notion of security where the adversary is allowed to adaptively corrupt TPMs.
Identity Privacy Protection by Delayed Transmission in Pocket Switched Networks	Transmission through short-range and short-term connected pocket switched Networks (PSN) would become more and more popular. In this paper, we study how a mobile wireless device achieves anonymous broadcasting in PSN. We split an original message into many segments and broadcast them at different times. These segments will be received, saved in buffer and forwarded by other devices with time delay. As the time difference of arrival of these segments of a message is caused by delayed transmission and users' movements, not by the difference of geography distance, the adversary server is not able to utilize TDOA algorithm to localize the originator's real location. In the way, the originator hides its identity and location.
Secure Message Distribution Scheme with Configurable Privacy for Heterogeneous Wireless Sensor Networks	Security and privacy of wireless sensor networks are key research issues recently. Most existing researches regarding wireless sensor network security consider homogenous sensor networks. To achieve better security and performance, we adopt a heterogeneous wireless sensor network (HWSN) model that consists of physically different types of sensor nodes. This paper presents a secure message distribution scheme with configurable privacy for HWSNs, which takes advantage of powerful high-end sensor nodes. The scheme establishes a message distribution topology in an efficient and secure manner. The sensor node can only generate one signature for all the messages for all the users, which can greatly save the communication and computation costs of the sensor node. On the other hand, the user can only know the messages intended for him based on a pre-set policy, which can meet the requirement of the privacy. We show that the scheme has small bandwidth requirements and it is resilient against the node compromise attack.
Analyzing Privacy Designs of Mobile Social Networking Applications	The combined advances of open mobile platforms and online social networking applications (SNAs) are driving pervasive computing to the real-world users, as the mobile SNAs are expected to revolutionize wireless application industry. While sharing location through mobile SNAs is useful for information access and user interactions, privacy issues must be addressed at the design levels of mobile SNAs. In this paper, we survey mobile SNAs available today and we analyze their privacy designs using feedback and control framework on information capture, construction, accessibility, and purposes. Our analysis results suggest that today's mobile SNAs need better privacy protection on construction and accessibility, to handle increasingly popular mash-ups between different SNA sites. We also identify two unexpected privacy breaches and suggest three potential location misuse scenarios using mobile SNAs.
User-Directed Privacy Protection in the Ubiquitous Environment	In the ubiquitous environment, when a user obtains services from a domain and goes between domains, there is a need to move freely and have services provided continuously. Also, the service provider wants to authenticate a user easily. But a serious problem exists: How can a user's personal information be protected and how can a user control their information? In this paper, we propose a system to authenticate a user and protect personal privacy by securing personal data. This system can gather personal access records from the service provider and deliver them to the home domain server. In addition, the service provider can obtain user information by a legal process when necessary.
Towards Successive Privacy Protection in Sensor Networks	With the emerging embedding of the sensor networks into the pervasive environment, our capabilities on location information gathering and processing have been greatly improved. Although this information is very useful, it also brings great challenges for protecting the privacy. Currently, most research efforts focus on protecting current location, and ignore the internal relationship among the successive locations information. To date, there are many techniques to infer a location when the related successive information is published, and which brings in serious privacy and security concerns. In this paper, we for the first time consider this kind of relationship, and identify a novel successive privacy threat. We then formulate a generic model for protecting the successive privacy. Under this model, there is a trade-off between the number of data to be published and the privacy protecting level, and which brings a novel maximum publishable location privacy problem. As this problem is intractable, we develop several heuristics. Extensive simulations demonstrate the effectiveness of our schemes.
Privacy Engine for Context-Aware Enterprise Application Services	Satisfying the varied privacy preferences of individuals, while exposing context data to authorized applications and individuals, remains a major challenge for context-aware computing. This paper describes our experiences in building a middleware component, the context privacy engine (CPE), that enforces a role-based, context-dependent privacy model for enterprise domains. While fundamentally an ACL-based access control scheme, CPE extends the traditional ACL mechanism with usage control and context constraints. This paper focuses on discussing issues related to managing and evaluating context-dependent privacy policies. Extensive experimental studies with a production-grade implementation and real-life context sources demonstrate that the CPE can support a large number of concurrent requests. The experiments also show valuable insight on how context-retrieval can affect the privacy evaluation process.
Privacy-Protection in Real-Time Video Communication	Nowadays, video communication of people such as video-phone and video conferencing systems must protect privacy, especially when these applications are based on open IP-network. In this paper, symmetric key encryption and public-key encryption techniques are used to ensure privacy information security. At the same time, a real-time scrambling approach to conceal video information is presented. The sign of transform coefficients for Intra macro-block is pseudo randomly flipped, and so only the authorized persons are allowed to correctly decode the code-stream. Simulation results based on MPEG-4 show that the proposed end-to-end security scheme is feasible. Furthermore, this is achieved with a small impact on coding performance and negligible computation complexity increase.
Design of an extended privacy homomorphism algorithm	In the paper, an extended privacy homomorphism algorithm is designed first, and then its application system is constructed too. Moreover, performance of the extended algorithm is tested perfectly by experiments on the safe application system. Anyhow, besides providing the safe access service of the database information to ensure data confidentiality, integrity, availability, consequently, and guaranteeing the legal rights and interests of the owners and users, the new algorithm can ensure the security of database of application system, at the same time it can improve the speed of index and selection on the encrypted database directly without decryption, so the extended privacy homomorphism algorithm has an practical significant business prospect on safe application system especially (such as information system, emergency system, on-line computation system and data mining) on the Internet of Things.
Privacy and Consequences: Legal and Policy Structures for Implementing New CounterTerrorism Technologies and Protecting Civil Liberty	This chapter contains sections titled: <br> Introduction <br> A Conception of Privacy and Liberty <br> Building the Legal and Policy Structures <br> The Nature of Privacy in the Post-9/11 World This chapter contains sections titled: <br> Summary
Security and privacy: EAIT 2012	Start of the above-titled section of the conference proceedings record.
Customized Profile Accessibility and Privacy for Users of Social Networks	Social networking applications have become a very popular means of communication and interaction in recent times and user participation has increased tremendously. It has become a norm that personal information is constantly shared with other social network users. The types of data uploaded and shared on user profiles also include sensitive information that one would rather it was accessible to a select few. The issues of security and privacy although very important seem to be a secondary consideration in the development and extensive usage of social networks. This paper highlights the potential attacks owing to the vast amount of user personal information available on social networks. The paper is concluded with proposing a theoretical model aimed at resolving the problems associated with the current default privacy and wider accessibility design implemented by most social networks.
Modeling Role-Based Privacy in Social Networking Services	As social networking services are getting more and more common, the need for privacy enhancing options, sophisticated identity management and anonymity emerges. In this paper the authors propose using role-based privacy as a response for these needs and introduce a novel model called nexus-identity network that is capable of describing services extended with such functionality. The concerned principles of role-based privacy are conferred in the paper and criteria are presented for anonymity. Conforming to the criteria the authors suggest storing the profiles of different identities in a tree hierarchy in a user-friendly manner. The analysis of anonymity shows that the network has a structure that can be easily interpreted similarly to graphs representing connections in regular social networks. The ease of profile management and network visualization are advantages of the nexus-identity model which can make a social networking service privacy and user-friendly as well.
Using Object-Oriented Concepts to Develop a High-Level Information Privacy Risk Management Model	In this paper we present a conceptual model for the management of information privacy risk in large organisations. The model is based on the similarities between the concepts of departments in large organisations and the object-oriented computer paradigm. It is a high-level model that takes a holistic view of information privacy risk management, and, as such, identifies risk in both manual and automated processes during the acquisition, processing, storage and dissemination of information. While conceptual in nature, the model is well suited to practical implementation due to the structure it derives from the object-oriented paradigm. The practical application of the model is demonstrated by way of an example scenario. This paper contributes by addressing the absence in the literature of freely available models for the holistic management information privacy risk in large organisations.
Criteria for Evaluating the Privacy Protection Level of Identity Management Services	Identity management is the one of Web services that manages the digital identity and the personally identifiable information of the user who subscribed for various Web services in Internet. It was developed to provide user with an easy way to use and manage various user's digital identities that were provided from each Web service. If the user subscribes to an identity management service, the user can access the other Web sites affiliated with the identity management service and use their Web services by using the identity issued by the identity management service. And the user can manage the user's personally identifiable information distributed among various Web sites in an integrated way through this service. However, if the identity provider, which provides this identity management service, discloses the user's identity and personal identifiable information, identity theft can happen throughout the entire affiliated web sites. As a result, the privacy protection level of the identity provider, that is, the level of protection for personally identifiable information, is the critical factor of successful identity management service. Therefore, identity provider should provide an easy way to the internal or external auditor of them for assessing the privacy protection level. This paper describes privacy threats for each identity life cycle, such as identity provision, propagation, use and maintain, and destruction, and proposes the criteria that evaluate the privacy protection level provided by the identity provider as a countermeasure against these threats. The internal or external auditor can use the criteria described in this paper, as a way of assessing the privacy protection level of identity provider.
Semantically supported Authentication and Privacy in Social Networks	Service access in a ubiquitous computing and pervasive Internet environment has reached a new dimension. It is not longer a question of enabling services for customers, but to design a convenient and trusted service usage. While semantic services open for a description of user preferences, profiles and social groups, privacy handling is not addressed so far. Social communities based on friend of a friend (foaf) principles, Linkedln, or Facebook are open for all registered users, thus data about yourself are spread all-around. This paper presents an architecture to enable social networks to enable privacy, based on the identity of the user. Focus is on the semantic description of user's role in social networks and on securing the access through appropriate authentication mechanisms. Depending on the security requirements of the user, Internet trust mechanisms or mobile-based key exchange mechanisms can be applied. The user-centric approach will enable the user to select an identity provider for the trusted management. A prototype using semantically defined social relationships demonstrates the capabilities of the suggested approach.
Classification of Privacy Enhancing Technologies on Life-cycle of Information	Recently, studies on privacy enhancing technologies have been actively carried out, as the importance of enterprise information, as well as privacy information, is becoming increasingly emphasized. Several organizations and enterprises have been conducting researches sporadically on privacy information technology. However, concept of privacy enhancing technology is not defined yet and there is no particular technology but P3P so far. Therefore, this paper provide classification mythology of privacy enhancing technology based on privacy information life-cycle. Privacy enhancing technology are classified into 3 technologies, which are operation technology, common based technology and policy/management technology. This technological classification can be break down more specifically by privacy information life cycle.
A security architecture for data privacy and security	Data access and software exchange are often achieved over insecure networks such as the public Internet. System designers are therefore forced to be proactive with regard to verifying the identity of both human users and software processes that request access to protected resources such as factory data. In this paper we show a new security architecture based upon Web services that supports authentication, authorization, and federation. Authentication verifies identity and generates a security token; authorization determines which privileges are allowed to which users; federation permits secure and reliable exchanges of identity across disparate trust domains. We illustrate how these ideas can be used to secure access to a factory Web portal and its underlying database of process data
Privacy preserving C4.5 using Gini index	Now-a-days privacy has become a major concern; the goals of security like confidentiality, integrity and availability do not ensure privacy. Data mining is a threat to privacy. Researchers today focus on how to ensure privacy while performing data mining task. As Data mining algorithms are typically complex and furthermore the input usually consists of massive data sets, the generic protocols in such a case are of no practical use and therefore more efficient protocols are required. This paper focus on the problem of decision tree learning with the popular C4.5 algorithm. C4.5, an extension of ID3 is a very popular decision tree building method in data mining. Entropy and Gini index are two different criteria used in ID3. While there is quite little work in privacy preserving ID3 using entropy and not much has been done for Gini index. This paper propose modified protocols based on secure multiparty computation for privacy preserving C4.5 using Gini index over distributed partitioned data, where the protocols do not require any third party server. However, some communication overhead is necessary so that the parties can carry out the secure protocols. The result like ROC(Receiver Operating characteristic) graph and detail accuracy through cost counting index is shown.
PEPPDA: Power efficient privacy preserving data aggregation for wireless sensor networks	Energy efficient privacy preserving data aggregation is important in power constrained wireless sensor networks. Existing hop by hop encrypted privacy preserving data aggregation protocols does not provide efficient solutions for energy constrained and security required WSNs due to the overhead of performing power consuming decryption and encryption at the aggregator node for the data aggregation and the increased number of transmissions for achieving data privacy. The decryption of data at the aggregator node will increase the frequency of node compromise attack. Thereby aggregator node reveals large amounts of data to adversaries. The proposed privacy homomorphism based privacy preservation protocol achieves non delayed data aggregation by performing aggregation on encrypted data. Thereby decreases the node compromise attack frequency. So high chance to get accurate aggregated results at the sink with reduced communication and computation overhead. The PEPPDA technique is best suited for time critical, secure applications such as military application, since it achieves privacy, authenticity, accuracy, end to end confidentiality, data freshness and energy efficiency during data aggregation. Our main aim is to provide a secure data aggregation scheme which guarantees the privacy, authenticity and freshness of individual sensed data as well as the accuracy and confidentiality of the aggregated data without introducing a significant overhead on the battery limited sensors.
Privacy Maintenance Collaborative Data Mining - A Practical Approach	Privacy is an important issue in data mining and knowledge discovery due to the increase in sharing of sensitive data through networks among business, governments and other parties. Data collection is a necessary step in data mining process. Due to privacy reasons, collecting data from different parties becomes difficult. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. The challenge behind this paper is that multiple parties should collaboratively conduct data mining without breaching data privacy. The objective of this paper is to provide solutions for privacy-maintaining collaborative data mining problems. In this paper the study of privacy preserving Add and Multiply Exchange Technology is given and proposed as an approach of Add To Multiply protocol based on homomorphic encryption techniques is defined to exchange the data while keeping it private.In this paper Privacy-maintaining Naive Bayesian classification is demonstrated which is one of the data mining tasks. A secure protocol for multiple parties to conduct the desired computation is developed. The solution is distributed, i.e., there is no central, trusted party having access to all the data.
Privacy Preserving Data Communication Model	Encryption has been a widely used technology for protecting secure data. However, recent threats show that encrypted data are being hacked and decrypted. A 128-bit encryption can be broken by a few weeks of supercomputing processing. These data are very critical to an organization and could be lethal if accessed by unauthorized group. Here a new transmission model is proposed for securing structured data over sensitive networks. The model uses simple mathematical operations to secure data segments, obtained after segregating the whole data and transmitting the segment in parts.
Congestion Control during Data Privacy in Secure Multiparty Computation	In this paper, we propose the methodology and design an algorithm to control congestion during Secure Multiparty Computation (SMC). As per our literature serve a lot of work has been done in SMC but they have worked only the main part of the SMC, privacy and correctness. Congestion control is one of the important components for the performance of the network and also is the most challenging one. This paper deals with the way of shaping the traffic to improve quality of service (QoS) in SMC. Under the congestion situation, the queue length may become very large in a short time, resulting in buffer overflow and packet loss. So congestion control is necessary to ensure that users get the negotiated QoS. The objectives of traffic control and congestion control for SMC are: Support a set of QoS parameters and minimize network and end-system complexity while maximizing network utilization. In our paper we carried out experiments for computing the FIFO length that ensures zero packet loss for different clock rate of the router.
Wavelet Transform Based Data Perturbation Method for Privacy Protection	Data mining techniques are able to derive highly sensitive knowledge from unclassified data that is not even known to database holders. Usually, data mining contains the secured information such as financial and healthcare records. To handle such large private database with, data mining algorithms with privacy is required. The privacy preserving becomes important concern when we dealing security related data. Data perturbation is one of the well known methods for avoiding such kinds of privacy leakage. The objective of data perturbation method is to distort the individual data values while preserving the underlying statistical distribution properties. These data perturbation methods are assessed in terms of both their privacy parameters as well as its associated utility measure. Privacy parameters are used to measure the degree of privacy protection while data utility measures assess whether the dataset keeps the performance of data mining techniques after the data distortion. In this paper we present wavelet transformation for data perturbation. The experimental results show that wavelet transformation is a very promising data perturbation method.
Preserving Privacy through Data Control in a Cloud Computing Architecture Using Discretion Algorithm	Cloud computing is an On-demand self-service Internet infrastructure where a customer can pay and use only what is needed, managed by an API. The SP plays an active role in transmitting information across the cloud. Privacy for the information through authentication is being considered important. Providing security requires more than user authentication with passwords or digital certificates. The discretion algorithm has been designed and the IDS provide passive security solution. Since the context data is stored by the service provider the control of the data propagate to the whole cloud chain.
Context Honeypot: A Framework for Anticipatory Privacy Violation	Honeypots have been studied in the network domain for detection and information collection against external threats in the past few years. They lure a potential attacker by simulating resources having vulnerabilities and observing the behavior of a potential attacker to identify him before a damaging attack takes place. A lot of work has been done in the area of privacy and security in databases. Though the number of attacks and complexity for database attacks are increasing day by day, there has been no attempt to design honeypots for privacy enforcing databases. The use of honeypots for databases would help in confirming the suspicion (malafide intention) of a suspicious user without leaking the target information (information which would fulfill the malafide intention) to the attacker. We propose a framework for database honeypots for certain types of attacks in privacy context. The proposed honeypots for databases are termed as context honeypots.
Privacy-enhanced desktop meeting system	The paper presents a model of a secure collaborative application for conducting real-time electronic meetings from remote locations. The application consists of a set of tools, enabling common meeting tasks to be accomplished. The tools can be enhanced with security services at will. The security architecture comprises the standardized communication security services as well as the ΓÇ£group orientedΓÇ¥ security services which we defined earlier. Such security architecture is especially suitable for enterprises with a defined internal organizational policy, which has to be supported and enforced by adequate security mechanisms
Privacy-enhanced access control by SPKI and its application to Web server	For providing a privacy-enhanced access only for an appropriate user, anonymous access such as anonymous FTP is too weak because a service provider cannot know about a client, while authentication-based access control such as PKIX (Public Key Infrastructure with X.509) is too strong because ID information on a client is exposed to a service-provider. Instead, we present a new access control scheme by using SPKI (Simple Public Key Infrastructure), since an authorization certificate based on SPKI does not carry any ID information. This scheme needs additional mechanism for the server and clients such as issuing, delegating, validating, and revoking certificates. A web-based privacy-enhanced access control is designed on the basis of the proposed scheme and implemented by Java. The resulting system shows that the proposed scheme works well with a small amount of overheads being introduced into a normal web server
A strong proxy signature scheme with proxy signer privacy protection	Mambo et al. (1996) discussed the delegation of signature power to a proxy signer. Lee et al. (2001) constructed a strong non-designated proxy signature scheme in which the proxy signer had strong non-repudiation. In this paper, we present an enhancement to their scheme such that the identity of the proxy signer is hidden behind an alias. The identity can be revealed only by the alias authority. We also discuss other applications of this technique.
A mobile agent clone detection system with itinerary privacy	We propose a system for the detection of unauthorized cloning of mobile agents by malicious hosts. The system can detect clones after the fact, identify the culprit, and then seek penalties. The agent migration protocol is offline (non-centralized). The itinerary of an agent is privacy-protected. Our scheme is based on H.Y. Wong's (2001) transferable extension of N. Ferguson's (1993) single-term offline untraceable e-cash. The main technique is to map the clone detection problem to the double-spending problem in transferable e-cash, and then adopt and adapt existing solutions from the latter field.
Privacy-Aware and Highly-Available OSN Profiles	The explosive growth of online social networks (OSNs) and their wide popularity suggest the impact of OSNs on today's Internet. At the same time, concentration of vast amount of personal information within a single administrative domain causes critical privacy concerns. As a result, privacy-conscious users feel dis-empowered with today's OSNs. In this paper, we report on an on-going research work and introduce a privacy-aware decentralized OSN called porkut. Our system exploits trust relationships in the social network for decentralized storage of OSN profiles and their content. By taking users' geographical locations and online time statistics into account, it also addresses availability and storage performance issues. We finally advocate indexing of social network content and present an approach for indexing in a privacy-preserving manner.
Technology versus privacy?	├é┬┐You have zero privacy; GET OVER IT.├é┬┐ So said Scott McNeally, chief executive officer of Sun Microsystems back in 1999. For the greater part of last century we have been worried that expansion of technology will mean by default the extinction of privacy.
Business privacy - age of consent	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04237035.png" border="0">
Security, privacy and trust oriented requirements modeling for examination system	The requirement engineering phase of Software Engineering (SE) deals with various activities starting from customer interaction to specifications of the requirements for the designing initiative. Now-a-days security, privacy and trustworthiness have become additional set of crucial requirements in view of the fact that software is vulnerable to various attacks. Many existing paradigms of SE deal with requirements, but less attention has been paid to address the issues of security, privacy and trust implementations. In practice, major attention is given to incorporate security aspects during coding and testing phases. Some paradigms address these issues, but they consider either security or privacy or trust requirements but not all of them together. We believe that security, privacy and trust requirements must be well collected, analyzed and specified through various stages of Requirement Engineering (RE) itself. This paper attempts to model RE activities incorporating security, privacy and trust requirements in effective way during all sub stages of RE phase. The activities of requirements modeling are well detailed and supported with case study of an online examination system of higher education (like University).
IEEE Security & Privacy	
Automated fall detection on privacy-enhanced video	A privacy-enhanced video obscures the appearance of a person in the video. We consider four privacy enhancements: blurring of the person, silhouetting of the person, covering the person with a graphical box, and covering the person with a graphical oval. We demonstrate that an automated video-based fall detection algorithm can be as accurate on privacy-enhanced video as on raw video. The algorithm operated on video from a stationary in-home camera, using a foreground-background segmentation algorithm to extract a minimum bounding rectangle (MBR) around the motion in the video, and using time series shapelet analysis on the height and width of the rectangle to detect falls. We report accuracy applying fall detection on 23 scenarios depicted as raw video and privacy-enhanced videos involving a sole actor portraying normal activities and various falls. We found that fall detection on privacy-enhanced video, except for the common approach of blurring of the person, was competitive with raw video, and in particular that the graphical oval privacy enhancement yielded the same accuracy as raw video, namely 0.91 sensitivity and 0.92 specificity.
Security and Privacy Issues with Health Care Information Technology	The face of health care is changing as new technologies are being incorporated into the existing infrastructure. Electronic patient records and sensor networks for in-home patient monitoring are at the current forefront of new technologies. Paper-based patient records are being put in electronic format enabling patients to access their records via the Internet. Remote patient monitoring is becoming more feasible as specialized sensors can be placed inside homes. The combination of these technologies will improve the quality of health care by making it more personalized and reducing costs and medical errors. While there are benefits to technologies, associated privacy and security issues need to be analyzed to make these systems socially acceptable. In this paper we explore the privacy and security implications of these next-generation health care technologies. We describe existing methods for handling issues as well as discussing which issues need further consideration
Homecare and Disease Prevention: Reviewing a Decade of Evolution - Privacy Still the Biggest Hurdle	Over a decade ago, while at the Agency for Health Care Policy and Research (AHCPR), now known as the Agency for Health Research and Quality (AHRQ), a vision was created by the author that projected two different concepts. One was the use of telemedicine in a homecare environment (in urban, suburban and rural areas) to offer particularly to the elderly population, suffering from a number of chronic conditions an environment which would allow to improve the quality of services while decreasing the costs of the (then and projected) "current" system. The second theme involved the potential use of genetic-related discoveries with personal health records for disease prevention purposes. While the homecare - telemedicine environment for the elderly with chronic diseases (has and) is evolving, the outcomes (cost and medical effectiveness) are not completely clear. The result is that what may be cost-effective in one country may not be in another one. The second premise, which involves the use of electronic health records, genetic discovery and intelligent agents, has moved much slower (if at all) than anticipated. In the US, at least, most of the barriers have been related to fears of privacy breaches. The combinations of Radio, Television, Computers and Telephones have become increasingly complex systems. These systems allow us to do a variety of actions that include: tele-banking, e commerce, tele-education, tele-work, tele-health, tele shopping, entertainment on demand, etc. In other words a family could stay home, get the food and water delivered, as well as any product bought from any store. While kids or adults could take courses at a distance, others in the family could tele-commute (i.e., work from home). A health care worker could visit any member of the family, or the family member could decide to visit specialist because of a specific condition/symptom or circumstance. So far, very few of these segments are interconnected and therefore most of these applications - - exist as silos. For example, many cable or satellite TV services have bidirectional communications. The services they provide today are multiple but mainly they have expanded the entertainment industry. The combination could result in a very powerful tool for the 21 century. The constant advancement in the areas of science and technology will allow us to reach new heights by helping humanity deal more effectively both medically and economically with all these diseases. A major challenge that we need to resolve is securing the privacy of the personal information
Maintaining Security and Privacy of Patient Information	As the global Internet evolves into today's more highly mobile and broadband service offerings, it is anticipated that the applications of new services to support telemedicine and eHealth operations using these offerings will result in increasing healthcare benefits for all and generally a lower cost. The one concern that must be addressed when making these changes is to ensure that security technology keeps up with the changes and provides the means by which satisfaction of HIPAA's privacy regulations can be assured. Consider the application of Wireless Communications in connecting medical professionals and patients through the ubiquitous web access arrangements. New products offered to patients and physicians alike are capable of transmitting vital signs, key blood test results for diabetics, blood pressure data, as well as the higher data requirements of X-Rays, MRIs, ultrasounds, CAT scans, and more. But now things are changing. Cell phones, hotspots (802.11 access arrangements) offer opportunities for others to intercept private information if not protected adequately. Today's security offering for wireless hotspots such as the Wired Equivalent Privacy (WEP) offers some security and privacy but it is known to be broken and useful only temporarily and not for protection of vital medical information protection. Currently, chips are being developed that will offer a much stronger protection for personal wireless networks. This recommended standard, referred to as 802.11i's WPA, is already supported within the Microsoft XP Operating System, and it will be enhanced and approved shortly by the latest recommended version of the standard offering WPA2 - for enterprise applications. The final version of 802.11i (WPA2) addresses practically all the vulnerabilities of WEP and more. However, now things are changing once more. A wideband wireless capability that in all likelihood will supercede WIFI within the next five years will allow up to 75 Mbps data transfer rates- - and support connections to systems in the range of 30 miles or more under the right conditions. In addition, speeding ambulances and cars traveling at speeds in excess of 70 MPH will be more readily capable of interfacing at the higher data rates WIMAX, the much-awaited technology that is expected to provide wireless broadband services on a Metropolitan Area Network (MAN) scale is going to be the next wave of evolution (802.16). Once more, as was the case for WIFI, where is the security? Will the WIFi security offerings support that needed at these higher rates? All of this is yet to be assured. Thus privacy is once again of concern if the standards are not adequate. As planned however, it is my understanding that the new WPA2 will support both WiFi and WIMax security needs. As technology evolves, security must evolve. And if the manufacturers of products can settle on non-proprietary representative devices to support the needs of the medical field, then all will be fine. If they can't, or won't, then delays will occur. My presentation and discussion today will address some of the detail of this security and the issues yet to be faced in protecting medical and patient information
The Need for Technical Solutions for Maintaining the Privacy of EHR	Electronic Health Records (EHR)/Electronic Patient Records (EPR)/Electronic Medical Records (EMR) provide the basis for e-Health services. Since information in these records (containing patient healthcare information) need to be shared amongst multiple healthcare providers and healthcare professionals, privacy issues of EHR have been a major inhibitor in the implementation of EHR/EMR/EPR systems. This paper presents EHR privacy requirements in the context of two major e-Health frameworks, namely HealthLink in Australia and HIPAA in USA. The paper concludes with a discussion of some evolving Web-based solutions
Privacy and social implications of distinct sensing approaches to implementing smart homes for older adults	Two distinct approaches to smart home design, namely Distributed Direct Sensing (DDS) and Infrastructure Mediated Sensing (IMS), have distinguishing features and implications resulting from their implementation. These two distinct smart home approaches have not been directly compared pertaining to their technical performance or their acceptance by the end users. It is also unclear what the perceived privacy and obtrusiveness concerns are when it comes to the implementation of these two different approaches in homes. The study presented here aimed to evaluate acceptance of these two sensing approaches by older adults and assess the perceived privacy and obtrusiveness concerns and ultimately define their social implications.
Assessing the HIPAA standard in practice: PHR privacy policies	Health service providers are starting to become interested in providing PHRs (Personal Health Records). With PHRs, access to data is controlled by the patient, and not by the health care provider. Companies such as Google and Microsoft are establishing a leadership position in this emerging market. A number of benefits can be achieved with PHRs, but important challenges related to security and privacy must be addressed. This paper presents a review of the privacy policies of 20 free web-based PHRs. Security and privacy characteristics were extracted and assessed according to the HIPAA standard. The results show a number of important differences in the characteristics analyzed. Some improvements can be made to current PHR privacy policies to enhance the audit and management of access to users' PHRs. A questionnaire has been defined to assist PHR designers in this task.
Privacy versus autonomy: A tradeoff model for smart home monitoring technologies	Smart homes are proposed as a new location for the delivery of healthcare services. They provide healthcare monitoring and communication services, by using integrated sensor network technologies. We validate a hypothesis regarding older adults' adoption of home monitoring technologies by conducting a literature review of articles studying older adults' attitudes and perceptions of sensor technologies. Using current literature to support the hypothesis, this paper applies the tradeoff model to decisions about sensor acceptance. Older adults are willing to trade privacy (by accepting a monitoring technology), for autonomy. As the information captured by the sensor becomes more intrusive and the infringement on privacy increases, sensors are accepted if the loss in privacy is traded for autonomy. Even video cameras, the most intrusive sensor type were accepted in exchange for the height of autonomy which is to remain in the home.
RFID Privacy Issues and Technical Challenges	This publication contains reprint articles for which IEEE does not hold copyright. Full text is not available on IEEE Xplore for these articles.
The Moderating Effects of Privacy Restrictiveness and Experience on Trusting Beliefs and Habit: An Empirical Test of Intention to Continue Using a Social Networking Website	While some online social networking (OSN) websites, such as Facebook, have reported sustained growth, others, such as Bebo, have not. This study investigates the factors that influence users' intentions to continue using these websites. We adapt the theory of reasoned action and develop a model depicting how trusting beliefs, habit, attitude, and subjective norm lead to continuance intention. We propose that trusting beliefs and habit will have differential effects depending on the levels of privacy restrictiveness and site experience. An analysis of data collected from Facebook users shows that the effects of trusting beliefs on continuance intention diminish as OSN users become more experienced, yet, do not diminish when users set privacy controls high. The latter finding contradicts theory positing control and trusting beliefs are substitutes. The finding that the trusting belief-continuance intention relationship is not significant when experience is high demonstrates that trusting beliefs and experience interact. We also show that habit is a stronger predictor when users restrict their personal information. However, contrary to predictions, habit shapes intention among users with both high and low experience. These findings explain how habit and trusting beliefs predict continuance intention in the new OSN environment and have both practical and research implications.
An Empirical Study of Consumer Perceptions and Comprehension of Web Site Privacy Policies	<para> The U.S. legislation at both the federal and state levels mandates certain organizations to inform customers about information uses and disclosures. Such disclosures are typically accomplished through privacy policies, both online and offline. Unfortunately, the policies are not easy to comprehend, and, as a result, online consumers frequently do not read the policies provided at healthcare Web sites. Because these policies are often required by law, they should be clear so that consumers are likely to read them and to ensure that consumers can comprehend these policies. This, in turn, may increase consumer trust and encourage consumers to feel more comfortable when interacting with online organizations. In this paper, we present results of an empirical study, involving 993 Internet users, which compared various ways to present privacy policy information to online consumers. Our findings suggest that users perceive typical, paragraph-form policies to be more secure than other forms of policy representation, yet user comprehension of such paragraph-form policies is poor as compared to other policy representations. The results of this study can help managers create more trustworthy policies, aid compliance officers in detecting deceptive organizations, and serve legislative bodies by providing tangible evidence as to the ineffectiveness of current privacy policies. </para>
Examining Internet privacy policies within the context of user privacy values	Internet privacy policies describe an organization's practices on data collection, use, and disclosure. These privacy policies both protect the organization and signal integrity commitment to site visitors. Consumers use the stated website policies to guide browsing and transaction decisions. This paper compares the classes of privacy protection goals (which express desired protection of consumer privacy rights) and vulnerabilities (which potentially threaten consumer privacy) with consumer privacy values. For this study, we looked at privacy policies from nearly 50 websites and surveyed over 1000 Internet users. We examined Internet users' major expectations about website privacy and revealed a notable discrepancy between what privacy policies are currently stating and what users deem most significant. Our findings suggest several implications to privacy managers and software project managers. Results from this study can help managers determine the kinds of policies needed to both satisfy user values and ensure privacy-aware website development efforts.
Research on individual privacy information protection in process of information resources commercialization	Defined the concept of information resources commercialization, depicted commercialization process of information resources, analyzed the driving factors of information resources commercialization. Realistic cases and survey results show that the security situation of individual privacy information during the process of information resources commercialization is worrying. The analysis on the behaviors which invades individual privacy information in the information resources collection and development and utilization shows that information resources commercialization process aggravates the individual privacy information leakage. In order to protect the individual privacy information safe, we gave out four important measures: to establish and improve relevant laws and regulations, to strengthen industry self-discipline and of information resources development and utilization norms, to improve individual citizen's awareness and skills of protecting individual privacy information, to strengthen construction of social credit system, to implement open credit rating system.
Study on Chinese university students' privacy protection from intercultural perspective	Privacy protection arouses a prevailing concern among intercultural communication scholars and educators in the globalization age. Privacy protection is of great significance in keeping harmony between administrators and students in Chinese universities. Collectivism value orientation and the benevolence idea influence Chinese social behaviors which are characterized by the neglects of individual's privacy protections. Defects of Chinese legislation in privacy and lacks of legal consciousnesses for both administrators and students are major causes resulting in privacy invasions in Chinese universities. University administrators are supposed to insist the proper legal administrations and take students' privacy protections into considerations for the sake of scientific, humanized and institutionalized administration.
Privacy Preservation Approach in Service Ecosystems	Emergence of business networking and social networking increases the exchange of sensitive information and creation of behaviour traces in the network. However, the current computing and communication solutions do not provide sufficient conceptual, architectural or technical facilities to preserve privacy while collaborating in the network. This paper enhances definition on privacy-related concepts to become sufficient for open service ecosystems, and finally introduces a privacy-preservation architecture with emphasis on usability, sustainability against threats, and reasonable cost of establishment and utilisation. As this architecture introduces new categories of tools for privacy preservation, it is significant also as a roadmap or maturity model.
Industrial Privacy in RFID-based Batch Recalls	Batch recalls are an important topic for manufacturers and producers. Especially in the food and in the pharmaceutical industry, producers are obliged to implement recalls in order to comply with legislation. In extreme cases, non-compliance can cause loss of life, e.g. when perished food or medicine reaches the consumer. Current batch recall practice is expensive and difficult, since many supply chain partners need to combine the data from their ERP systems. Radio frequency identification (RFID) can be used to efficiently implement batch recalls, e.g. by storing batch numbers from the parts/ingredients used in all manufacturing steps. But this raises concerns on industrial privacy, since competitors could use this information to gain insight into the whole supply chain. We overcome this problem by storing tracing information on RFID tags and encrypting the information, such that it is only available in case of a recall. We encrypt the information using identity based encryption and furthermore allow universal re-encryption along the supply chain to prevent information leakages from the ciphertexts.
Automated Privacy Audits Based on Pruning of Log Data	This paper presents a novel approach to automated audits based on the pruning of log data represented as trees. Events, recorded as a sequential list of entries, are interpreted as nodes of a tree. The audit consists in removing the nodes that are compliant with the policy, so that the remaining tree consists only of the violations of the policy. Besides presenting the method, this paper demonstrates that the resultant method is more efficient than usual audit approaches by analyzing its theoretical complexity and the runtime figures obtained by a proof of concept.
Scalable, accountable privacy management for large organizations	Accountability is emerging as an important theme within the regulatory privacy community. For global corporations, demonstrating accountability is no easy task due to the potentially large number of projects that have privacy sensitive aspects, privacy oversight being a mostly manual process and privacy staff typically being small. So how can a company present proof points that its projects comply with its privacy promises and obligations? In this paper we address this problem by introducing a technology based solution for scalable, accountable privacy management across an organization. We present an Accountability Model Tool (AMT) that addresses the problem of capturing data about business processes in order to determine their privacy compliance. AMT utilizes an intelligent questionnaire with good completeness properties and is based on an augmented rule engine.
Editorial to the second workshop on Security and Privacy in Enterprise Computing (InSPEC09)	The goal of the International Workshop Series on Security and Privacy in Enterprise Computing (InSPEC) is to provide a forum for the discussion of novel research directions and challenges in security and privacy in enterprise computing among the experts from academia and industry. The following introduces the second edition of the workshop in conjunction with the 13th IEEE International EDOC Conference in Auckland, New Zealand.
Building a Privacy-Preserving Benchmarking Enterprise System	Benchmarking is the process of comparing one's own performance to the statistics of a group of competitors, named peer group. It is a common and important process in the business world for many important business metrics, called key performance indicators (KPI). Privacy is of the utmost importance, since these KPIs allow the inference of sensitive information. Therefore several secure multiparty computation (SMC) protocols for securely and privately computing statistics of KPIs have recently been developed. These protocols are the basic building block for a privacy-preserving benchmarking system, but in order to complete an enterprise system that offers a benchmarking service to its customers more problems need to be solved. This paper addresses two remaining problems: peer group formation and protocol orchestration. We first analyze how peer group participation impacts privacy and vice-versa. Given current network performance limitations we conclude that in order for KPIs to remain private one subscriber can participate in at most one peer group. Peer group formation is the process of forming sensible peer groups out of the set of subscribers. A sensible peer group is one that is useful for benchmarking, i.e. a group of similar companies, under the constraint that one subscriber can participate in at most one peer group. We characterize subscribers by a set of discrete criteria and therefore view the automatic peer group formation as a data clustering problem. A data clustering algorithm customized for automatic peer group formation is required to build clusters whose size does not fall below a minimum threshold. We present a high-performance modification of k-means clustering that takes the minimum cluster size as an additional parameter which might be of independent interest. In a simulation we evaluate its practical applicability to automatic peer group formation. Our final approach is the first automatic peer group formation algorithm for an enterprise benchma- rking system. Polling-based protocol orchestration allows the subscribers to remain passive clients, i.e. require no inbound connection, e.g. through a company firewall. We show through simulation that such a polling-based orchestration can be expected to complete within one polling interval.
Protecting the Privacy Based on Reasoning in E-business Using Anonymous	Nowadays, the E-Commerce plays a very important role in peoples' life; many people like to shop on Internet. At the same time, people left so much information in Internet, which include the privacy information. Malicious users in Internet can get users' privacy information with directly or indirectly way. Traditional way is to protect the directly privacy. In this paper, we proposed a schema to prevent malicious users reasoning privacy information with the information which considered as security information on Internet. In this schema, the single information set and multiple information sets are taken into count, based on the relations of the information, some information will be hidden, which can protect the privacy information. This schema will loss some information, but the privacy will protected.
Encryption, Law Enforcement, and Privacy	This chapter contains sections titled: <br> Introduction <br> Rise and Fall of the Data Encryption Standard <br> Evolution of Wiretaps and the ├é┬┐Right to Privacy├é┬┐ <br> Development of Public Key Encryption <br> Government Policy Toward Encryption <br> Current Social Conflicts and Ethical Issues <br> Case Study This chapter contains sections titled: <br> Worksheet├é┬á-├é┬áReview of Encryption Concepts <br> Worksheet├é┬á-├é┬áLegal Challenges to Encryption Export Regulations <br> Worksheet├é┬á-├é┬áThe Importance of Not Being Different <br> Worksheet├é┬á-├é┬áIs Staying With the Herd Really Best? <br> Additional Assignments <br> References <br> Cryptography: The Importance of Not Being Different <br> Cryptography: Is Staying with the Herd Really Best?
Privacy and usability in SMS-based G2B/B2G m-Government: STK and SMS: Balancing privacy and usability	The provision of sensitive information over SMS has been held back due to the inherent privacy problems of SMS. Sending messages as plain-text carries multiple risks. SMS encryption is one solution to this problem. However software written for specific devices might affect the User Experience (UX) while impacting existing investments. Also, using the phone's memory as a data store provides no guarantees against intrusion attacks. A standards-based STK (SIM Toolkit) application has been adopted in order to strike a balance between usability and mobility. An 8-bit microcontroller was used as the main platform for this security application, implementing Twofish symmetric encryption to enhance privacy and confidentiality. Creating synergy between Security and Usability is a challenge, and this paper discusses the role of STK and SMS in G2B m-Government.
A Proxy for Privacy: the Discreet Box	The issue of user privacy is constantly brought to the spotlight since an ever increasing number of online services collects and processes personal information from users, in the context of personalized service provision. Although technology makes the collection of data easy, their protection against abuse is left to data protection legislation. However, the privacy requirements, other than being general and abstract terms to be regarded as legislature issues, should be brought down in the technological reality and carefully accounted for in devising technical solutions. In order to limit the disclosure and avoid the misuse of personal data, this paper discusses an architectural proposal for a middleware system that will enforce protection of user privacy through technical means. This goal is facilitated by a combination of a policy framework, a sensible interpretation of regulations into policies and the introduction of a privacy broker, named the discreet box.
Legal and Privacy Issues: 19992004	This chapter provides a full examination of the unique legal and privacy issues that MVEDRs have raised. The issues are discussed from a number of important reports including: 1. Office of Technology Assessment (OTA), 2. Intelligent Transportations Systems (ITS) conference, 3. NHTSA EDR Working Group, 4. Privacy Act of 1974, 5. Court decisions, 6. A National Academy of Sciences (NAS) study, 6. Privacy Issues, 7. Voluntary consensus standards vs. federal rulemaking, 8. California Privacy Law, 9. U.S. 9th Circuit case, 10. Canadian case law, 11. Public perspectives on privacy issues, 11. MVEDR case law, 12. Safety Culture, and 13. Pennsylvania EDR legislation.
Hardware acceleration and data-utility improvement for low-latency privacy preserving mechanism	With the recent growth in the quantity and value of data, data holders have come to realize the importance of being able to utilize information that is otherwise abandoned or concealed. In this situation, they face the difficulty of publishing data without revealing private information. One of the methods used to protect private information when publishing data is privacy-preserving method based on constraints known as k-anonymity and l-diversity. In this paper, we propose a hardware architecture composed of Ternary Content Addressable Memory (TCAM) and a cache mechanism to efficiently reduce the time required for executing the methods. An evaluation proves that an implementation of the proposed architecture on a reconfigurable device performs approximately 10-50 times faster than a RAM-based architecture and up to 60% of the information loss can be eliminated by using the cache mechanism.
Boosting and Differential Privacy	Boosting is a general method for improving the accuracy of learning algorithms. We use boosting to construct improved privacy-pre serving synopses of an input database. These are data structures that yield, for a given set Q of queries over an input database, reasonably accurate estimates of the responses to every query in Q, even when the number of queries is much larger than the number of rows in the database. Given a base synopsis generator that takes a distribution on Q and produces a "weak" synopsis that yields "good" answers for a majority of the weight in Q, our Boosting for Queries algorithm obtains a synopsis that is good for all of Q. We ensure privacy for the rows of the database, but the boosting is performed on the queries. We also provide the first synopsis generators for arbitrary sets of arbitrary low-sensitivity queries, i.e., queries whose answers do not vary much under the addition or deletion of a single row. In the execution of our algorithm certain tasks, each incurring some privacy loss, are performed many times. To analyze the cumulative privacy loss, we obtain an O(╬╡<sup>2</sup>) bound on the expected privacy loss from a single e-differentially private mechanism. Combining this with evolution of confidence arguments from the literature, we get stronger bounds on the expected cumulative privacy loss due to multiple mechanisms, each of which provides e-differential privacy or one of its relaxations, and each of which operates on (potentially) different, adaptively chosen, databases.
A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis	We consider statistical data analysis in the interactive setting. In this setting a trusted curator maintains a database of sensitive information about individual participants, and releases privacy-preserving answers to queries as they arrive. Our primary contribution is a new differentially private multiplicative weights mechanism for answering a large number of interactive counting (or linear) queries that arrive online and may be adaptively chosen. This is the first mechanism with worst-case accuracy guarantees that can answer large numbers of interactive queries and is efficient (in terms of the runtime's dependence on the data universe size). The error is asymptotically optimal in its dependence on the number of participants, and depends only logarithmically on the number of queries being answered. The running time is nearly linear in the size of the data universe. As a further contribution, when we relax the utility requirement and require accuracy only for databases drawn from a rich class of databases, we obtain exponential improvements in running time. Even in this relaxed setting we continue to guarantee privacy for any input database. Only the utility requirement is relaxed. Specifically, we show that when the input database is drawn from a smooth distribution - a distribution that does not place too much weight on any single data item - accuracy remains as above, and the running time becomes poly-logarithmic in the data universe size. The main technical contributions are the application of multiplicative weights techniques to the differential privacy setting, a new privacy analysis for the interactive setting, and a technique for reducing data dimensionality for databases drawn from smooth distributions.
The Limits of Two-Party Differential Privacy	We study differential privacy in a distributed setting where two parties would like to perform analysis of their joint data while preserving privacy for both datasets. Our results imply almost tight lower bounds on the accuracy of such data analyses, both for specific natural functions (such as Hamming distance) and in general. Our bounds expose a sharp contrast between the two-party setting and the simpler client-server setting (where privacy guarantees are one-sided). In addition, those bounds demonstrate a dramatic gap between the accuracy that can be obtained by differentially private data analysis versus the accuracy obtainable when privacy is relaxed to a computational variant of differential privacy. The first proof technique we develop demonstrates a connection between differential privacy and deterministic extraction from Santha-Vazirani sources. A second connection we expose indicates that the ability to approximate a function by a low-error differentially private protocol is strongly related to the ability to approximate it by a low communication protocol. (The connection goes in both directions).
The Promise of Differential Privacy: A Tutorial on Algorithmic Techniques	Differential privacy describes a promise, made by a data curator to a data subject: you will not be affected, adversely or otherwise, by allowing your data to be used in any study, no matter what other studies, data sets, or information from other sources is available. At their best, differentially private database mechanisms can make confidential data widely available for accurate data analysis, without resorting to data clean rooms, institutional review boards, data usage agreements, restricted views, or data protection plans. To enjoy the fruits of the research described in this tutorial, the data analyst must accept that raw data can never be accessed directly and that eventually data utility is consumed: overly accurate answers to too many questions will destroy privacy. The goal of algorithmic research on differential privacy is to postpone this inevitability as long as possible.
Privacy Amplification and Non-malleable Extractors via Character Sums	In studying how to communicate over a public channel with an active adversary, Dodis and Wichs introduced the notion of a non-malleable extractor. A non-malleable extractor dramatically strengthens the notion of a strong ex- tractor. A strong extractor takes two inputs, a weakly-random x and a uniformly random seed y, and outputs a string which appears uniform, even given y. For a non-malleable extractor nmExt, the output nmExt(x,y) should appear uniform given y as well as nmExt(x, A(y)), where A is an arbitrary function with A(y) Γëá y. We show that an extractor introduced by Chor and Goldreich is non-malleable when the entropy rate is above half. It outputs a linear number of bits when the entropy rate is 1/2 + ╬▒, for any ╬▒ >; 0. Previously, no nontrivial parameters were known for any non-malleable extractor. To achieve a polynomial running time when outputting many bits, we rely on a widely-believed conjecture about the distribution of prime numbers in arithmetic progressions. Our analysis involves a character sum estimate, which may be of independent interest. Using our non-malleable extractor, we obtain protocols for "privacy amplification": key agreement between two parties who share a weakly-random secret. Our protocols work in the presence of an active adversary with unlimited computational power, and have asymptotically optimal entropy loss. When the secret has entropy rate greater than 1/2, the protocol fol- lows from a result of Dodis and Wichs, and takes two rounds. When the secret has entropy rate ╬┤ for any constant ╬┤ >; 0, our new protocol takes a constant (polynomial in 1/╬┤) number of rounds. Our protocols run in polynomial time under the above well-known conjecture about primes.
Testing and Reconstruction of Lipschitz Functions with Applications to Data Privacy	A function f:D ΓåÆ R has Lipschitz constant c if d<sub>R</sub>(f(x), f(y)) Γëñ c┬╖d<sub>D</sub>(x, y) for all x, y in D, where d<sub>R</sub> and d<sub>D</sub> denote the distance functions on the range and domain of f, respectively. We say a function is Lipschitz if it has Lipschitz constant 1. (Note that rescaling by a factor of 1/c converts a function with a Lipschitz constant c into a Lipschitz function.) In other words, Lipschitz functions are not very sensitive to small changes in the input. We initiate the study of testing and local reconstruction of the Lipschitz property of functions. A property tester has to distinguish functions with the property (in this case, Lipschitz) from functions that are ╧╡-far from having the property, that is, differ from every function with the property on at least an ╧╡ fraction of the domain. A local filter reconstructs an arbitrary function f to ensure that the reconstructed function g has the desired property (in this case, is Lipschitz), changing f only when necessary. A local filter is given a function f and a query x and, after looking up the value of f on a small number of points, it has to output g(x) for some function g, which has the desired property and does not depend on x. If f has the property, g must be equal to f. We consider functions over domains of the form {1, Γï», n}<sup>d</sup> equipped with Γäô<sub>1</sub> distance. We design efficient testers of the Lipschitz property for functions of the form f:{1, 2}<sup>d</sup> ΓåÆ ╬┤Z, where ╬┤ Γêê (0, 1] and ╬┤Z is the set of integer multiples of ╬┤, and of the form f:{1, Γï», n}<sup>d</sup> ΓåÆ R, where R is (discretely) metrically convex. We also present an efficient local filter of the Lipschitz property for functions of the form f:{1, Γï», n}<sup>d</sup> ΓåÆ R. We give corresponding lower bounds on the complexity of testing and local reconstruction. The - lgorithms we design have applications to program analysis and data privacy. The application to privacy is based on the fact that a function f of entries in a database of sensitive information can be released with noise of magnitude proportional to a Lipschitz constant of f, while preserving the privacy of individuals whose data is stored in the database (Dwork, McSherry, Nissim and Smith, TCC 2006). We give a differentially private mechanism, based on local filters, for releasing a function f when a purported Lipschitz constant of f is provided by a distrusted client. We show that when no reliable Lipschitz constant of f is given, previously known differentially private mechanisms have either a substantially higher running time or a higher expected error, for a large class of symmetric functions f.
The Privacy of the Analyst and the Power of the State	We initiate the study of "privacy for the analyst" in differentially private data analysis. That is, not only will we be concerned with ensuring differential privacy for the data (i.e. individuals or customers), which are the usual concern of differential privacy, but we also consider (differential) privacy for the set of queries posed by each data analyst. The goal is to achieve privacy with respect to other analysts, or users of the system. This problem arises only in the context of stateful privacy mechanisms, in which the responses to queries depend on other queries posed (a recent wave of results in the area utilized cleverly coordinated noise and state in order to allow answering privately hugely many queries). We argue that the problem is real by proving an exponential gap between the number of queries that can be answered (with non-trivial error) by stateless and stateful differentially private mechanisms. We then give a stateful algorithm for differentially private data analysis that also ensures differential privacy for the analyst and can answer exponentially many queries.
The Johnson-Lindenstrauss Transform Itself Preserves Differential Privacy	This paper proves that an "old dog", namely - the classical Johnson-Lindenstrauss transform, "performs new tricks" - it gives a novel way of preserving differential privacy. We show that if we take two databases, D and D', such that (i) D'-D is a rank-1 matrix of bounded norm and (ii) all singular values of D and D' are sufficiently large, then multiplying either D or D' with a vector of iid normal Gaussians yields two statistically close distributions in the sense of differential privacy. Furthermore, a small, deterministic and public alteration of the input is enough to assert that all singular values of D are large. We apply the Johnson-Lindenstrauss transform to the task of approximating cut-queries: the number of edges crossing a (S, S)-cut in a graph. We show that the JL transform allows us to publish a sanitized graph that preserves edge differential privacy (where two graphs are neighbors if they differ on a single edge) while adding only O(|S|╧╡) random noise to any given query (w.h.p). Comparing the additive noise of our algorithm to existing algorithms for answering cut-queries in a differentially private manner, we outperform all others on small cuts (|S| = o(n)). We also apply our technique to the task of estimating the variance of a given matrix in any given direction. The JL transform allows us to publish a sanitized covariance matrix that preserves differential privacy w.r.t bounded changes (each row in the matrix can change by at most a norm-1 vector) while adding random noise of magnitude independent of the size of the matrix (w.h.p). In contrast, existing algorithms introduce an error which depends on the matrix dimensions.
Non-malleable Extractors, Two-Source Extractors and Privacy Amplification	In [1], Dodis and Wichs introduced the notion of a non-malleable extractor. A non-malleable extractor is a much stronger version of a seeded extractor. Dodis and Wichs showed that such an object can be used to give optimal privacy amplification protocols with an active adversary. Previously, there are only two known constructions of nonmalleable extractors [2], [3]. Both constructions only work for (n, k)-sources with k >; n/2. Interestingly, both constructions are also two-source extractors. In this paper, we present a strong connection between nonmalleable extractors and two-source extractors. The first part of the connection shows that non-malleable extractors can be used to construct two-source extractors. This partially explains why previous constructions of non-malleable extractors only work for entropy rate >; 1/2, and why explicit non-malleable extractors for small min-entropy may be hard to get. The second part of the connection shows that certain two-source extractors can be used to construct non-malleable extractors. Using this connection, we obtain the first construction of non-malleable extractors for k <; n/2. Finally, despite the lack of explicit non-malleable extractors for arbitrarily linear entropy, we give the first 2-round privacy amplification protocol with asymptotically optimal entropy loss and communication complexity for (n, k) sources with k = ╬▒n for any constant ╬▒ >; 0. This dramatically improves previous results and answers an open problem in [2].
Privacy and communication complexity	Each of two parties <e1>P</e1><sub>1</sub> and <e1>P</e1><sub>2 </sub> holds an <e1>n</e1>-bit input, <e1>x</e1> and <e1>y</e1>, respectively. They wish to compute privately the value of <e1>f</e1>(<e1>x</e1>,<e1>y</e1>). Two questions are considered: (1) Which functions can be privately computed? (2) What is the communication complexity of protocols that privately compute a function <e1>f</e1> (in the case in which such protocols exist)? A complete combinatorial characterization of privately computable functions is given. This characterization is used to derive tight bounds on the rounds complexity of any privately computable function and to design optimal private protocols that compute these functions. It is shown that for every 1&les;<e1>g</e1>(<e1>n</e1>)&les;2├ù2<sup>n</sup> there are functions that can be privately computed with <e1>g</e1>(<e1>n</e1>) rounds of communication, but not with <e1>g</e1>(<e1>n</e1>)-1 rounds of communication
Eavesdropping games: a graph-theoretic approach to privacy in distributed systems	We initiate a graph-theoretic approach to study the (information-theoretic) maintenance of privacy in distributed environments in the presence of a bounded number of mobile eavesdroppers (ΓÇ£bugsΓÇ¥). For two fundamental privacy problems-secure message transmission and distributed database maintenance-we assume an adversary is ΓÇ£playing eavesdropping games,ΓÇ¥ coordinating the movement of the bugs among the sites to learn the current memory contents. We consider various mobility settings (adversaries), motivated by the capabilities (strength) of the bugging technologies (e.g., how fast can a bug be reassigned). We combinatorially characterize and compare privacy maintenance problems, determine their feasibility (under numerous bug models), suggest protocols for the feasible cases, and analyze their computational complexity
Privacy and interaction in quantum communication complexity and a theorem about the relative entropy of quantum states	We prove a fundamental theorem about the relative entropy of quantum states, which roughly states that if the relative entropy, S(╧ü||╧â)╬ö=Tr ╧ü(log ╧ü-log ╧â), of two quantum states ╧ü and ╧â is at most c, then ╧ü/2<sup>O(c)</sup> 'sits inside' ╧â. Using this 'substate' theorem, we give tight lower bounds for the privacy loss of bounded error quantum communication protocols for the index function problem. We also use the 'substate' theorem to give tight lower bounds for the k-round bounded error quantum communication complexity of the pointer chasing problem, when the wrong player starts, and all the log n bits of the kth pointer are desired.
Mechanism Design via Differential Privacy	We study the role that privacy-preserving algorithms, which prevent the leakage of specific information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Specifically, we show that the recent notion of differential privacv, in addition to its own intrinsic virtue, can ensure that participants have limited effect on the outcome of the mechanism, and as a consequence have limited incentive to lie. More precisely, mechanisms with differential privacy are approximate dominant strategy under arbitrary player utility functions, are automatically resilient to coalitions, and easily allow repeatability. We study several special cases of the unlimited supply auction problem, providing new results for digital goods auctions, attribute auctions, and auctions with arbitrary structural constraints on the prices. As an important prelude to developing a privacy-preserving auction mechanism, we introduce and study a generalization of previous privacy work that accommodates the high sensitivity of the auction setting, where a single participant may dramatically alter the optimal fixed price, and a slight change in the offered price may take the revenue from optimal to zero.
Protecting privacy using the decentralized label model	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01264929.png" border="0">
A Practical Three-Dimensional Privacy-Preserving Approximate Convex Hulls Protocol	Convex hulls problem is a special case of privacy-preserving geometry problem in the inquiry of secure multi-party computation. In the past, only in two-dimensional space privacy-preserving convex hulls have been investigated, and there is little focus in the three-dimensional space. However, three-dimensional privacy-preserving convex hulls can be applied in many fields, such as researching and exploration of the space, military, corporately finding the union range based on sensitive data from two parties. Approximate convex hulls have more advantages than conventional convex hulls in the theme of secure multi-party computation because it can hide the private points on the vertices. In this paper, we first present a practical privacy-preserving protocol to solve the three dimensional approximate convex hulls problem; we also discuss the correctness, security, and performance of our protocol.
Privacy-Preserving Practical Convex Hulls Protocol	Secure multi-party computation has been a hot research topic of cryptograhy for about two decades, and the convex hulls problem is a special case of it. However, the precise convex hulls will certainly expose all vertexes and even bring about unfairness. Therefore the practical approximate convex hulls are in need. In this paper, we summarize and discuss the convex hulls problem, and then we present a more effective new protocol to compute the approximate convex hulls. Furthermore, we analyze the security, communication complexity and efficiency of the protocol, and compare the new scheme with other privacy-preserving convex hulls protocols through simulated experiments. It shows that our privacy-preserving approximate convex hulls protocol is more effective than the previous privacy-preserving ones, and the new protocol is practical enough in many situations. Perfectly keeping privacy preserving and eliminating unfairness are the great advantages of our scheme.
Information Assurance, Privacy, and Security in Ubiquitous Questionnaire	Ubiquitous questionnaire is to provide users with e-questionnaire services anytime and anywhere such that one can use e-questionnaire servers without even thinking about them. An e-questionnaire server for ubiquitous questionnaire should provide guarantees to satisfy any user-specified requirement on information assurance, privacy, and security because some questionnaires may concern organization secrets as well as personal privacy, and some questionnaires such as e-voting or e-testing must impose restrictions on and provide assurance to respondents, voters, and/or testees. Until now, there is no detail requirement analysis for information assurance, privacy, and security in ubiquitous questionnaire. To implement an e-questionnaire server for ubiquitous questionnaire, this paper presents a requirement analysis for information assurance, privacy, and security in ubiquitous questionnaire. The paper identifies all participants and their information assets in ubiquitous questionnaire with a general purpose e-questionnaire server that can be used not only an e-questionnaire server but also an e-voting server and an e-testing server, gives a threat analysis of and a requirement analysis for information assurance, privacy, and security, and investigates technical issues for implementing facilities satisfied the requirements.
The Internet: privacy, censorship, the first amendment, and transnational communications; what's at stake?	This paper examines some of the problems under debate concerning the Internet. Included in the discussion are concerns over privacy issues, obscenity, pornography, and child pornography, the protection of minors from undesirable material on the Internet, and who has ultimate responsibility for the content and regulation of the Internet. Legal issues are examined along with a brief discussion on current regulatory laws. Alternatives to broad regulatory laws are examined with respect to communication and social concerns
Work in Progress: Exploring Security and Privacy Concepts through the Development and Testing of the iTrust Medical Records System	University computer science and software engineering students must build reliability and security into their software applications from the start of development. A graduate-level Software Testing and Reliability course at North Carolina State University has a learning objective of using appropriate testing techniques for the development of a reliable and secure system. Beginning in Fall 2005, the semester project has involved the development and testing of the open source and freely-available iTrust Medical Records system prototype. Our vision is to build a community of educators, students, and medical professionals that can collaborate and use the iTrust project as a development platform and testbed for secure and reliable application development
Panel Session - Learning Modules for Security, Privacy and Information Assurance In Undergraduate Engineering Education	Computer trustworthiness continues to increase in importance as a pressing scientific, economic, and social problem. In today's environment, there is heightened awareness of the threat of well-funded professional cyber hackers and the potential for nation-state sponsored cyber warfare. An accelerating trend of the last decade has been the growing integration role of computing and communication in critical infrastructure systems that now have complex interdependencies rooted in information technologies. These overlapping and interacting trends force us to recognize that trustworthiness of our computer systems is not an IT issue any more; it has a direct and immediate impact on our critical infrastructure. Security is often a collective enterprise, with complicated interdependencies and composition issues among a variety of participants. This poses a challenge for traditional engineering education models and curricula. The panel will discuss experiences and strategies to establish curricular foundation elements providing CSET graduates with an understanding of the interaction between cyber security, critical infrastructure systems and public policy
An elective course in biometrics and privacy	In the aftermath of 9-11, the area of biometrics has taken on increased importance. There is a need for more graduates who are familiar with the principles of biometric technology, and with the social and ethical issues raised by use of this technology. This paper describes a course that covers the fundamentals of the major biometric technologies, as well as privacy and security concerns. Experience from teaching a first section of this course is discussed. Modules from this course could also be used in a more general social impact of computing course, or could be used in a pattern recognition or artificial intelligence course to introduce social and ethical issues.
A privacy data set release method for balancing privacy protection and usability	The current release control methods consider the balance between privacy protection and usability for individual privacy data, but that balance for a released data set is not considered. In this paper, a release method based on game theory is proposed to ensure both the protection and the usability of privacy for a released data set.
Wired Equivalent Privacy (WEP)	There are some demonstrable reasons for customers who like use from wireless technology and this is clear because there are various benefits for using wireless technology. The contrast between wireless usage and security techniques growing, show that the security is not adequate enough for this data growing. Itpsilas obvious that the hackers are able to monitor the transmitted data and hack whatever they want. So we see that these days Companies are investing more money on securing their wireless networks. There are three major type of security in wireless. In this paper, at first we try to completely explain the structure of WEP as a first wireless security technique and discuss about all versions of it. At the second step, we discuss about all problems of WEP and finally explain the solutions and improvements that done on this security technique. Then we are in the next plan which is to explain the structure of two other techniques (WPA, WPA2) and we hope that we will publish a completely comparison among wireless techniques in the near future.
UPM: User-Centered Privacy Model in Pervasive Computing Systems	The fact that pervasive systems are typically embedded or invisible, making it difficult for users to know when these devices are collecting data. So privacy appears as a major issue for pervasive computing applications. In this paper we propose a user-centered privacy model (UPM) which provides user control over data, identity, location, and time privacy with less than 10% of unobtrusiveness.
Privacy Management in a Mobile Setting	This paper is concerned with privacy management in mobile settings. We are also going to be looking at the type of applications that are starting to spin off from the Internet onto mobile phones, such as Messenger, Facebook and Twitter. Publication of the whereabouts and activities of the user is at the core of these systems. Many commentators worry about users forgetting that the social network may compromise their privacy, in the sense that information that is published may range farther and wider than the intentions. Withdrawal of personal information that is disseminated is hardly possible. This paper looks at various model of privacy, and examines some ideas related to trust and confidence from the literature.
A Dynamic Network Access Identifier Used for Location Privacy	Current wireless access authentication mechanisms are mostly based on the network access identifier. It may lead to the location privacy problem. This paper brings out the concept of dynamically generated network access identifier, and gives an example of authentication using the dynamically generated network access identifier. Also this paper proves the security of the authentication procedure using the BAN logic and analyzes the performance of the authentication mechanism based on DNAI.
A generic location-based mobile application framework supporting privacy-preserving end-user tailorability	Location is the fey factor in defining context information of today's mobile applications and services. As a matter of fact, location is increasingly used to stimulate collaboration in various ways and location-aware applications experienced a wide-spread usage. However, existing mobile services, even those which are Web enabled, do not support end-user tailorability. For example, at the level of defining community-specific points of interest of any type on both user interface (UI) and server-side level. In this paper, we identify the need for supporting such end-user tailorability based on performed analysis of various use cases related to collaborative location-based scenarios in mobile settings. We present a generic framework for collaborative mobile applications and services that support privacy respecting location-based scenarios. We demonstrate this with the means of an iOS based prototype. Our prototype allows different communities to define their own points of interests in a generic manner (at-runtime) by simultaneously supporting group collaboration functionality (e.g., communication, awareness, etc.). The distributed architecture can also be tailored according to privacy needs.
Enhancing privacy in collaborative scenarios utilising a flexible proxy layer	In this paper we present our approach for a flexible proxy layer, allowing the parallel use of anonymous and direct network communication depending on specific scenarios or user preferences. The requirements are derived from scenarios from the european research project di. me, targeting to support end users in keeping control of their personal data and digital footprints. In the targeted scenarios, the use of anonymous network communication is an essential prerequisite for certain use cases (e.g. like pseudonymous communication), because of the special architecture, where each user has its own server holding his private data. Especially, the presented approach solves linkability which could arise when using SSL certificates/x.509 certificates and addresses various potential attacks. A detailed specification is given and important implementation details are addressed.
The Influence of Perceived Privacy upon the Trust in E-commerce	Perceived privacy is an important variable to influence customerpsilas trust and loyalty in e-commerce. It is crucial to fully understand consumerspsila perceived privacy in online shopping for understanding consumerspsila online behavior and encouraging them and potential consumers to adopt e-commerce. Through literature analysis, this paper explores consumer perceived privacy in online shopping and consumer behavior.
Research on the Personalized Privacy Preserving Distributed Data Mining	In this paper we studied privacy preserving distributed data mining. The existing methods focus on a universal approach that exerts preservation in the same degree for all persons, without catering for their concrete needs. In view of this we innovatively proposed a new framework combining the secure multiparty computation (SMC) with K-anonymity technology, and achieved personalized privacy preserving distributed data mining based on decision tree classification algorithm. Compared with other algorithms our method could make a good trade-off point between privacy and accuracy, with high efficiency and low-overhead of computing and communication.
Cross layer privacy support for identity management	One of the most important objectives of Identity Management (IdM) Systems is to provide end user privacy. However, these concepts rarely extend beyond the application layer. In the IST SWIFT project a special attention is given to cross-layer Identity Management support, and in this paper we show why applying only IdM solutions is insufficient to preserve user privacy if network mechanisms are not considered. We present a solution to retain user privacy by using network pseudonyms closely coordinated with the IdM framework proposed by the SWIFT project. We include these concepts in the IdM framework and present the necessary architecture and functional mechanisms required to support the privacy extensions.
Security and privacy enablers for future Identity Management systems	In recent years, Identity Management (IdM) has gained a lot of attention in industry, standardisation and academia. In particular, a couple of research projects, like Daidalos or Prime, have invested considerable effort to bring IdM forward, to take advantage of features like improved usability and security. Nevertheless, there are important issues that have not been addressed so far. The SWIFT project leverages IdM as a key technology of the Future Internet, tackling problems like the integration of the network and application layer from an IdM perspective as well as the use of electronic identity cards. Moreover, aspects like the integration of several user devices, backward compatibility and a new access control infrastructure are required by future IdM solutions. We consider all these aspects by extending existing IdM solutions with six new security and privacy enablers that are part of the overall SWIFT framework. These enablers have been partially implemented towards a new IdM architecture. First evaluation results of the implementation are promising to pave the way towards future IdM solutions.
Evaluation of information loss for privacy preserving data mining through comparison of fuzzy partitions	In this paper, we focus on the problem of preserving the data confidentiality when sharing the data for clustering. This problem poses new challenges for novel uses of privacy preserving data mining (PPDM) techniques. Specifically, this paper considers the synthetic data generation as a way to preserve the data privacy. One of the state of the art synthetic data generators is the IPSO family of methods. It has been stated that the use of IPSO to generate synthetic data is appropriate when the user plans to apply clustering to the data. Moreover, this paper aims to associate the same property to the FCRM synthetic data generator, and at the same time, to assess the relationship between the information loss produced when generating synthetic data with FCRM and the clustering similarity between the original and synthetic data.
Full-scale privacy preserving for association rule mining	Privacy has become an important issue in Data Mining. Many methods have been brought out to solve this problem. This paper deals with the problem of association rule mining which preserve the confidentiality of each database. In order to find the association rule, each participant has to share their own data. Thus, much privacy information may be broadcasted or been illegal used. These issues can be divided into three categories: data hiding, knowledge hiding and data mining results publishing. This paper reviews the major method of privacy preserving on each category and choose some of them to complete our system. At the end, an improvement of sensitive rules hiding is proposed to make it more accuracy and security.
Privacy data preserving method based on fuzzy discretization	Protect data privacy is one of hot topic of database applications in recent years. This paper is concentrated on the issue of protecting the privacy attribute values when data publication and proposes a method based on fuzzy discretization. The method transforms sensitive attribute values to fuzzy values and publishes the data with fuzzy offset degree. This helps the end user of the data to make out the distinction between two attribute values, even though they are mapped to the same linguistic term. The experiments demonstrate that the method efficiently preserves privacy information and maintains the clustering model of primitive data wel1.
A traceable privacy-preserving authentication protocol for VANETs based on proxy re-signature	In this paper, based on a single hop proxy re-signature in the standard model, we introduce a traceable privacy-preserving communication protocol for VANETs. The proposed protocol has some appealing features: The Trusted Authority (TA) designates the Roadside Units (RSUs) translating signatures computed by the On-Board Units (OBUs) into one that is valid as for TA's public key. As a result, the potential danger that vehicles could be traced by the signatures on messages can be well deleted, and attacks are thwarted by using an endorsement mechanism based on signatures. The security analysis shows that the protocol can achieve good conditional privacy target of VANETs.
Privacy preserving spectral clustering over vertically partitioned data sets	Spectral clustering is one of the most popular modern clustering techniques that often outperforms other clustering techniques. When data owned by different parties are used for analysis, the cooperating parties may need to perform spectral clustering jointly, even if the parties may not be willing to disclose their private data to each other. In this paper we develop privacy preserving spectral clustering protocols over vertically partitioned data sets. Such protocols allow various parties to analyze their data jointly while protecting their privacy.
Privacy-preserving anomaly detection across multi-domain networks	A lot of traffic anomalies, such as flash crowds, denial-of-service attacks, port scans, can often span multiple ISP networks. Cooperatively detecting and diagnosing these anomalies is critical for network operators to choose the appropriate response. However, legitimate concerns about privacy, such as network topology and link loads, often inhibit network operators in collaborative detection. In this paper, we propose a privacy-preserving mechanism that allows ISPs to cooperatively detect anomalies without requiring them to reveal private traffic information. We design a ΓÇ£semi-centralizedΓÇ¥ architecture and use secure multiparty computation (SMC) protocol to make the Principal Component Analysis (PCA) based detection method privacy-preserving and at same time keep its scalability and accuracy. We evaluate our design at a simulated distributed environment by using traffic traces from the Abilene backbone network as well as synthetic traces. The results show that it performs well for network-wide anomaly detection and enable larger-scale ISPs cooperation without privacy concerns.
Towards privacy-preserving RFID-based location-based services	Nowadays, RFID technology is increasingly become popular and begin to enter many spheres of everyday life. In this paper, we present LocSafe, a ΓÇ£missed-connectionsΓÇ¥ service with privacy grantees based on RFID technology, in order to prove an encounter sharing among users in the past. LocSafe is comprised of three parts: RFID Tags, LE Collectors, and Social Service Provider. We use RFID technology to detect encounters, and use attribute-based encryption and broadcast encryption to establish trust and protect users' privacy. We evaluate LocSafe by an study of ΓÇ£missed-connectionsΓÇ¥ problems and analysis of system implementation.
Privacy-preservation association rules mining based on fuzzy correlation	Most existing techniques work on hiding association rules in Boolean data. Based on analyzing fuzzy correlation, we have introduced a new scheme for privacy-preservation in fuzzy association rules mining, named PPM-Scheme, which is able to achieve complete hiding of sensitive rules mined in quantitative data by using improved technique in which we replace the highest value of fuzzy item with zero. Experimental results show that the proposed scheme hides more sensitive rules with minimum number of modifications and maintains quality of the released data than those previous techniques.
On key issuing privacy in distributed online social networks	Recently, distributed online social networks (OSNs) are developed to address the security and privacy issues in centralized OSNs. Identity based cryptography (IBC) was introduced into distributed OSNs recently for better identity verification and authentication purposes. However, current IBC-based solutions in OSNs could not address the problem of secure private key issuing. In this paper we propose PEKING: a novel Pivacy Enhanced Key IssuiNG scheme for distributed online social networks using IBC. Our scheme adopts key generate center (KGC) and key privacy assistants (PAs) to issue keys to peers securely. In the scheme, PAs can be selected from users' friends. Neither KGC nor PAs can impersonate the users to obtain the private keys. Furthermore, to maintain the security of PAs, we develop a scheme to authenticate PAs using Byzantine fault tolerance protocol. The experimental results show that PEKING performs effectively and efficiently, and is able to support large scale networks.
An effective data transformation approach for privacy preserving similarity measurement	Data similarity measurement is an important direction for data mining research. This paper is concentrated on the issue of protecting the underlying attribute values when sharing data for the similarity of objects measurement and proposes a simple data transformation method: Isometric-Based Transformation (IBT). IBT selects the attribute pairs and then distorts them with Isometric Transformation. In the process of transformation, the goal is to find the proper angle ranges to satisfy the least privacy preserving requirement and then randomly choose one angle in this interval. The experiment demonstrates that the method can distort attribute values, preserve privacy information and guarantee valid similarity measurement.
Uncertain Privacy Decision about Access Personal Information in Pervasive Computing Environments	In pervasive computing environments, context- aware applications provide services for people by using personal information. People also make privacy decision about personal information disclosure as privacy concerns. Privacy decision depends on people's interaction situation. The trust of information collector and personal information sensitivity often enable people to make uncertain privacy decision. Therefore, we construct a fuzzy objective information system that consists of personal interaction situation history. The privacy disclosure policies are extracted from this information system under using rough set theory. The context-aware applications are assigned to an adequate privacy role with the privacy disclosure policies and situation of people's interaction. Finally, we provide a working example and the initial performance evaluation.
k-Anonymity via Clustering Domain Knowledge for Privacy Preservation	Preservation of privacy in micro-data release is a challenging task in data mining. The k-anonymity method has attracted much attention of researchers. Quasi-identifier is a key concept in k-anonymity. The tuples whose quasi-identifiers have near effect on the sensitive attributes should be grouped to reduce information loss. The previous investigations ignored this point. This paper studies k-anonymity via clustering domain knowledge. The contributions include: (a) Constructing a weighted matrix based on domain knowledge and proposing measure methods. It carefully considers the effect between the quasi-identifiers and the sensitive attributes. (b) Developing a heuristic algorithm to achieve k-anonymity via clustering domain knowledge based on the measure methods. (c) Implementing the algorithm for privacy preservation, and (d) Experiments on real data demonstrate that the proposed k-anonymous methods decrease 30% information loss compared with basic k-anonymity.
Video Security Algorithm Aiming at the Need of Privacy Protection	Aiming at the need of personal privacy protection in the image acquisition system, paper proposes a video security algorithm used in facial protection. It fixes on the facial area in the image by face detection algorithm, regards facial area image as characteristic watermark information (large capacity watermark) and embeds them into the original image using large capacity color image watermarking algorithm, then encrypts the facial area to achieve the need of face protection. Ultimately, experiments use numerous test images to show the proposed algorithm has favorable compatibility and robustness. The algorithm is effectively united by face detection, watermarking, and encryption, having the obvious value on theory and application.
Privacy-Preserving Query Checking in Query Middleware	With the development of the grid technology used in business field, it becomes more and more important to preserve privacy in information sharing field. This paper proposes a privacy-preserving query middleware PPQM based on credible third party in grid database, and fulfill privacy-preserving checking algorithm in PPQM to make privacy-preserving optimization of query plan before query assignment, through experiments, PPQM can effectively preserve private information and improve secure query efficiency in the application of commercial environment.
Homeland security and privacy sensitive data mining from multi-party distributed resources	Defending the safety of an open society from terrorism or other similar threats requires intelligent but careful ways to monitor different types of activities and transactions in the electronic media. Data mining techniques are playing an increasingly important role in sifting through large amount of data in search of useful patterns that might help us in securing our safety. Although the objective of this class of data mining applications is very well justified, they also open up the possibility of misusing personal information by malicious people with access to the sensitive data. This brings up the following question: Can we design data mining techniques that are sensitive to privacy? Several researchers are currently working on a class of data mining algorithms that work without directly accessing the sensitive data in their original form. This paper considers the problem of mining distributed data in a privacy-sensitive manner. It first points out the problems of some of the existing privacy-sensitive data mining techniques that make use of additive random noise to hide sensitive information. Next it briefly reviews some new approaches that make use of random projection matrices for computing statistical aggregates from sensitive data.
Privacy Protection in Social Network Data Disclosure Based on Granular Computing	Social network analysis is an important methodology in sociological research. Though social network data is very useful to researchers and policy makers, releasing such data to the public may cause an invasion of privacy. We generalize the techniques for protecting personal privacy in tabulated data, and propose some metrics of anonymity for assessing the risk of breaching confidentiality by disclosing social network data. We assume a situation of data publication, where data is released to the general public. We adopt description logic as the underlying knowledge representation formalism, and consider the metrics of anonymity in open world and closed world contexts respectively.
On intuitionistic fuzzy clustering for its application to privacy	Motivated by our research on specific information loss measures (in privacy preserving data mining) and our need to compare fuzzy clusters, we proposed in a recent paper a definition for intuitionistic fuzzy partitions. We showed how to define them in the framework of fuzzy clustering. That is, we introduced a method to define intuitionistic fuzzy partitions from the results of fuzzy clustering. In this paper we further study such intuitionistic fuzzy partitions and we extend our previous results with other types of fuzzy clustering algorithms.
Privacy Challenges and Methods for Virtual Classrooms in Second Life Grid and OpenSimulator	Mass adoption of virtual world platforms for education and training implies efficient management of computational resources. In Second Life Grid and OpenSimulator, commonly used for this purpose, a key resource is the number of servers required to support educational spaces. Educational activities can take place at different altitudes over the same virtual land, for different classes. This way a single virtual world server can sustain several different educational spaces/classes, reducing the number of servers needed to make available different classrooms or other educational spaces. One issue whose importance is emphasized in such conditions is that of class privacy, bearing in mind that most privacy-management features of these platforms are land-based, not space-based. In this paper, we provide an overview of the issues to consider when planning privacy in these platforms and the methodologies that can be developed and implemented to ensure it at an adequate level, including the extra privacy possible in OpenSimulator regarding Second Life Grid.
A Privacy Preserved Two-Party Equality Testing Protocol	Secure multiparty computation was firstly introduced by Yao in 1982. Two-party equality testing is a special case of secure multiparty computation. It enables two entities to compare the equality of their secret data without revealing the data to the other party. This kind of protocols has been wildly investigated in the literature. However, in most of the existing protocols, the testing result is known by only one entity (informer). The other entity is informed about the testing result by the informer so she must fully trust the informer about the result she received. In this paper, we propose a new two-party equality testing protocol. In our protocol, although the final result is still informed by the informer, we allow the entity being informed to verify the correctness of the final result. In this way, the two entities can make sure whether the secret information they preserved are equivalent or not without revealing it. We will also give the security analysis and show that this protocol does not leak any information about the secret value.
A Framework for the RFID Information Security and Privacy Protection	RFID in the Information Security and Privacy is hidden in a crisis. RFID Information Security and Privacy Protection using hardware ways to achieve the target is the best way, however, it is subject to the problem of Tag costs and capacity and is currently still unresolved issues. This study focus on the Information Security and Privacy Protection and put forth a EPC specifications to use the model of XOR logic operation with the method of CRC examining the computing, and simulating the shopping mall system which provides a Information Security and Privacy Protection system. We got the data after simulations to show that XOR computing to actual test of 8 bytes, the required time is 17.29 Ticks in average, the spend time is rather short. Follow-up our simulations to the test data of DES encryption methods, an average time of 8,039.41 Ticks is required, the two time required considerable differences. It was informed that this study through practical shows that we could provide a match hardware encryption methods of the specific solutions to achieve their personal privacy protection, confidentiality, confirmed, and the fulfillment of the Information Security and Privacy Protection.
Comments on a Secret-Key-Privacy-Preserving Authentication and Key Agreement Scheme	Lots applications need involved parties to share common session keys for specific requirements. For example, the shared key can be the seed to determine locations to hide secret data into an image. Wang et al. proposed an authentication scheme with key agreement based on the elliptic curve discrete logarithm problem in 2011. They claimed that their scheme had seven advantages. (1) A verification table is not required in the server. (2) The client's password can be changed easily, and the server cannot obtain the client's password. (3) Their scheme could resist all well-known security threats. (4) No time synchronization is needed. (5)The client and the server can share a common session key. (6) Their scheme is efficient and practical. (7) Their scheme can protect the privacy of the client's secret information. After we analyze Wang et al.'s scheme thoroughly, we find that their scheme suffers from three threats. In this paper, we will show the perceived security threats of Wang et al.'s scheme in detail.
Personal genome privacy protection with feature-based hierarchical dual-stage encryption	Personal Genomic information is becoming increasingly important to both scientific research and clinical practice. However, security breach, misuse, or unintended disclosure of this information may result in severe privacy breaches. Traditional privacy preservation of personal genome information is implemented in an ΓÇ£all-or-noneΓÇ¥ manner, i.e., an entire genome being controlled as either fully accessible or fully inaccessible. In this paper, we propose a new fine-grained privacy protection method for flexible multi-level genome information protection and access. The method can make use of any user-defined hierarchical knowledge structure to define privacy levels and control cryptography-based hierarchical access. It also implements dual-stage encryptions to allow efficient definition, addition, and update of feature-based privacy protections. The experiments show that it can be effectively implemented to deal with real personal genome data sets in the future.
The location privacy protection research in location-based service	The rapid development of wireless communications and mobile database technology promote the extensive application of Location Based Services (LBSs), and provide a greatly convenience for people's lives. In recent years, Location Based Services has played an important role in deal with public emergencies. It is possible to access mobile users' location information anytime and anywhere. But in the meantime, user location privacy security poses a potentially grave new threat, and may suffer from some invade which could not presuppose. Location privacy issues raised by such applications have attracted more and more attention. It has become the research focus to find a balance point between the location-based highly sufficient services and users' location privacy protection. Comprehensive and efficient services are accessed under the premise of less exposed locations, that is to say, allowed the location of exposure in a controlled state. K-anonymity technique is widely used in data dissemination of data privacy protection technology, but the method is also somewhat flawed. This paper analyses on existing questions of location privacy protection system in Location Based Services at the present time, including K-anonymity technique, quality of service, query systems, and generalize and summarize the main research achievement of location privacy protection technology in recent years. And some solutions have been proposed to deal with location privacy problem in Location Based Services. The paper also analyzes how to provide efficient location-based services and better protection users' location privacy in handle public emergencies. In the end, some study trends of Location Based Services and location privacy protection are given.
Efficient navigation for privacy-aware personal navigation services: Preliminary analysis	Location-based services require a mobile device that is able to detect the user's current position in order to return the service required. Hence, this makes the area of location privacy a growing area of social concern. Navigation systems are one example of location-aware services that track users' location information over time in order to generate navigation instructions, thus making an individual's location privacy difficult to protect. The aim of this research is to develop an algorithm that can protect users' location privacy, while generating efficient navigation instructions that ensure users reach their destination as directly as possible. The efficiency of the algorithms has been analyzed based on several performance measures, including the efficiency of the navigation instructions, and privacy protection analysis.
A secure and privacy enhanced LBS security elements based on KLP	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01525338.png" border="0">
A new ΓÇÿDirectionΓÇÖ for source location privacy in wireless sensor networks'	Preserving source location privacy in wireless sensor networks can be critical for several practical applications. Existing solutions proposed specifically for sensor networks rely on a combination of dynamic routing and dummy traffic to hide real event messages. While some privacy protection guarantees can be given, these solutions also tend to be expensive due to fake transmissions and non-shortest path routing overheads. In this paper, we propose a novel idea, of using a combination of directional antennas, transmit power control and information compression to provide lightweight and energy-efficient source location privacy. We discuss the adversary model extensively and then carefully layout characteristics of a realistic adversary. We show how use of directional antennas makes eavesdropping more costly for a realistic adversary and establish relationships between probability of compromise of location privacy, characteristics of directional antennas and size of the adversary's eavesdropping network. Finally, we show how a simple information compression measure can greatly reduce message latency and prolong battery life by conserving energy. Results of extensive simulations in NS2, with our realistic directional antenna add-on, show that compared to existing solutions, we can achieve comparable privacy protection, better message latency, delivery ratio and many orders of magnitude improvement in energy consumption.
VSLP: Voronoi-socialspot-aided packet forwarding protocol with receiver Location Privacy in MSNs	With the pervasive use of smart phones in the daily life, location privacy has become one of cruxes for the success of mobile social networks (MSNs). In this paper, we propose a Voronoi-social-spot-aided Location Privacy-preserving (VSLP) packet forwarding protocol to improve the packet forwarding efficiency and at the same time protect receiver's location privacy. In VSLP, we first identify the social spot locations according to the user mobility information, and then build a Voronoi diagram based on the defined social spots. On the edge of Delaunay triangulation over the Voronoi diagram, we deploy multiple storage devices to help receivers to temporarily store the packets. With the security analysis, we show that the location privacy can be achieved. Using extensive simulations, we show that VSLP can enhance the packet forwarding efficiency with improved packet delivery ratio and reduced average packet delay.
Distributed TDMA for privacy sensitive anonymous networks	This paper proposes a distributed TDMA slot allocation protocol that relies on absolutely no information exchange among the participating nodes. This novel property allows the protocol to work in restricted anonymous environments such as in privacy-sensitive body area networks and various military networks in which nodes may need to cooperate in distributed TDMA but are not allowed to explicitly exchange any information such as node-IDs in order to preserve their anonymity. This paper introduces an innovative approach of time-coded packet transmissions for implicitly exchanging slot timing information. It is shown that using such implicit information, together with a notion of interrupt control packets, the nodes are able to self-allocate collision-free TDMA slots in an anonymous manner. The protocol is evaluated and its performance has been shown using extensive simulation models.
Privacy-preserving and secure top-k query in two-tier wireless sensor network	In two-tier wireless sensor networks, resource-rich storage nodes at the upper tier collect sensing data from resource-poor sensor nodes at the low tier, and then answer queries from the user. Sensor nodes perform sensing task and submit sensing data in one time-slot to the nearest storage node while storage nodes answer and process the query from the network owner. However the storage nodes confront serious security concerns. Storage nodes may be compromised and leak the sensitive data as well as returning fake query result. Therefore, it is important to protect the privacy and verify the query results. In this paper, we define and solve the practical and challenging problem of privacy-preserving and verifiable top-k query processing performed on the time-slot sensing data set in two-tier sensor network, and establish a set of privacy and correctness requirements for such a secure top-k query scheme to become a reality. We propose the basic PriSecTopk scheme by using order-preserving encryption, and then improve it step by step to achieve various privacy requirements as well as the correctness requirements in three levels of threat models. Theoretical analysis and experiment on the real-world data set successfully validate the efficacy and efficiency of the proposed schemes.
Privacy- and integrity-preserving range query in wireless sensor networks	A large-scale wireless sensor network constructed in terms of two-tiered architecture, where cloud nodes take charge of storing sensed data and processing queries with respect to the sensing nodes and querists, incurs security breach. This is because the importance of cloud nodes makes them attractive to adversaries and raises concerns about data privacy and query result correctness. To address these problems, we propose an efficient approach, namely EQ (efficient query), which mainly prevents adversaries from gaining the information processed by or stored in cloud nodes, and detects the compromised cloud nodes when they misbehave. EQ can not only achieve the goals of data privacy and integrity preserving but also ensure the secure range query without incurring false positive. For data privacy preserving, EQ presents an order encryption mechanism by adopting stream cipher to encrypt/decrypt all sensed data such that a cloud node can only process issued queries over stored data in the encryption domain. For data integrity/completeness, we manipulate a data structure of XOR linked list (X2L), which allows a querist to verify the integrity of retrieved data via the socalled verification information, i.e., neighborhood difference in a storage-efficient manner. We demonstrate the feasibility and efficiency of EQ via experiments conducted on TelosB prototype sensor platform running TinyOS 1.1.15 and comparisons with state-of-the-arts.
Breaching location privacy in XMPP based messaging	Privacy is an increasingly important theme in communications. With increasing mobile users, previously neglected aspects as location privacy become important in our social life. Currently, Instant Messaging applications are considered to have a strong privacy model between users, because all communications are mediated by the service. In this paper, we analyse IM under the light of location privacy. We devise a set of potential attacks, and analyse the behaviour of many systems under these attacks. Our results show that while not all implementations are vulnerable, some popular IMs are breachable by one or more of these location privacy attacks. With browser based and mobile implementations being less vulnerable because they tend to provide a reduced set of features, thus reducing the attack surface.
Gmatch: Secure and privacy-preserving group matching in social networks	Groups are becoming one of the most compelling features in both online social networks and Twitter-like micro-blogging services. A stranger outside of an existing group may have the need to find out more information about attributes of current members in the group, in order to make a decision to join. However, in many cases, attributes of both group members and the stranger need to be kept private and should not be revealed to others, as they may contain sensitive and personal information. How can we find out matching information exists between the stranger and members of the group, based on their attributes that are not to be disclosed? In this paper, we present a new group matching mechanism, by taking advantage private set intersection and ring signatures. With our scheme, a stranger is able to collect correct group matching information while sensitive information of the stranger and group members are not disclosed. Finally, we propose to use batch verification to significantly improve the performance of the matching process.
Sacrificing the Plum Tree for the Peach Tree: A Socialspot Tactic for Protecting Receiver-Location Privacy in VANET	In this paper, to simultaneously protect the receiver-location privacy and improve the performance of packet delivery in VANET, we utilize ``Sacrificing the Plum Tree for the Peach Tree" - one of the Thirty-Six Strategies of Ancient China, to propose a socialspot-based packet forwarding (SPF) protocol, where each vehicle receiver only reveals a non-sensitive socialspot, e.g., a shopping mall, that he often visits as a relay node to help packet forwarding and protect his other sensitive locations privacy. Detailed security analysis demonstrates the security of the proposed SPF protocol. In addition, extensive simulations have also been conducted to examine its good efficiency in terms of packet delivery ratio and average delay.
Message Authentication with Non-Transferability for Location Privacy in Mobile Ad hoc Networks	Message authentication is an effective solution to prevent notorious bogus messages and worm-hole attacks in mobile ad hoc networks (MANET). However, it could also be a double-edge sword threatening mobile users privacy, e.g., location privacy, if the authenticity proofs used in message authentication were abused. In this paper, to prevent such kind of abuse, we first propose a novel efficient message authentication scheme, which can achieve not only users identity privacy but also non-transferability. We then introduce an information theoretical model to gauge the privacy level that the proposed scheme can attain. Extensive simulation results demonstrate the proposed scheme can significantly reduce the violation of mobile users' privacy in MANET.
Preserving Source-Location Privacy in Wireless Sensor Network Using STaR Routing	In wireless sensor networks (WSNs), providing source-location privacy through secure routing is one of the most prosperous techniques. In this paper, we propose a routing technique to provide adequate source-location privacy with low energy consumption. We introduce this technique as the Sink Toroidal Region (STaR) routing. With this technique, the source node randomly selects an intermediate node within a designed STaR area located around the SINK node. The STaR area is large enough to make it unpractical for an adversary to monitor the entire region. Furthermore, this routing protocol ensures that the intermediate node is neither too close, nor too far from the SINK node in relations to the entire network. While ensuring source location privacy, our simulation results show that the proposed scheme is very efficient and can be used for practical applications.
Privacy Preserving Group Nearest Neighbour Queries in Location-Based Services Using Cryptographic Techniques	Location-based services (LBS) are available on a variety of mobile platforms like cellphones, PDA''s, etc. and an increasing number of users subscribe to and use these services. One of the basic privacy issues with LBS is that a user may not necessarily want to disclose their own location whenever they inquire about the location of places of interest to them e.g., nearest gas station, restaurant etc. The privacy aspect of LBS has received attention recently with a number of privacy-preserving methodologies being proposed for the client-server model where a querying client requests a location-based server to return some location that is of interest to it without revealing its own location to the server. In this paper, we consider privacy issues in the peer-to-peer model of LBS, where a group of users jointly compute a common location of interest to them such as a restaurant where they could all meet. In such scenarios, all peers in the group would like to jointly find a common location but might not want to reveal their individual locations to each other due to trust issues. We model this problem in the secure multi-party computation framework of cryptography and present a solution where all the peers can jointly compute a common location without the need for any user to reveal its individual location to anyone else. To this end, we present two privacy-preserving models and experimentally evaluate the performance of each of them.
Preserving Privacy in Emergency Response Based on Wireless Body Sensor Networks	E-healthcare is becoming a vital part of our living environment and exhibits advantages over paper-based legacy systems. Wireless body sensor networks are indispensable in one application of e-healthcare, the remote monitoring or remote care services. However, privacy is the foremost concern of the patients and the biggest impediment of the deployment of e-healthcare systems. In addressing privacy issues, conflicts from the functional requirements must be taken into account. One such requirement is the efficient and effective response to medical emergencies. In this paper, we propose to solve these conflicting goals based on suitable cryptographic schemes. In addition, security enhancements are proposed which satisfy other fundamental security goals besides the privacy requirements.
FLIP: An Efficient Privacy-Preserving Protocol for Finding Like-Minded Vehicles on the Road	Vehicle chatting is one of the most promising applications in VANETs, which allows like-minded vehicles to chat on the topics of common interest on the road. However, there exist some newly emerging privacy challenging issues in vehicle chatting application, such as how to find a like-minded vehicle on the road and how to prevent one's interest privacy (IP) from others who are not like-minded? In this paper, to tackle these challenging issues, we propose an efficient privacy-preserving finding like-minded vehicle protocol (FLIP), and apply the provable security technique to demonstrate its security. In addition, extensive simulations are also conducted to examine its practical considerations, i.e., the relation between the expected IP-preserving level and the delay of finding like-minded vehicles on the road.
An Efficient Privacy-Preserving Publish-Subscribe Service Scheme for Cloud Computing	Cloud computing provides a novel computing paradigm for enterprises to store programs and data in the Cloud in a transparent manner, which poses the challenge of security and privacy. In this paper, based on homomorphic cryptography and Zero-Knowledge Proof, we present a novel privacy-preserving scheme for Cloud publish/subscribe service, which achieve efficient privacy-preserving authentication, data integrity, and publish-subscribe confidentiality. The performance evaluation and security analysis demonstrate the practice and validity of the proposed scheme.
Location Privacy Protection in Contention Based Forwarding for VANETs	Compared to traditional wireless network routing protocols, geographic routing provides superior scalability and thus is widely used in vehicular ad hoc networks (VANETs). However, it requires every vehicle to broadcast its location information to its neighboring nodes, and this process will compromise user's location privacy. Existing solutions to this problem can be categorized into two groups: 1) hiding user's location or 2) preserving user's identification information in routing protocols, which drastically reduce network performances. To address this issue, we proposed a dummy-based location privacy protection (DBLPP) routing protocol, in which routing decision is made based upon the dummy distance to the destination (DOD), instead of users' true locations. In this scheme, users' true locations and identification information are preserved, so the user's location privacy is protected. Compared to existing solutions, simulation results show that while DBLPP provides similar network performances as other routing protocols, it achieves a higher level of location privacy protection on vehicles in networks.
Privacy Exposure of Online Social Search	Online social search brings forth a new way to harness the Internet for answers. However, the personal and often sensitive information is unwittingly exposed to others when a person looks for an expert via the underlying social network. In this paper, we propose a model in which a node's behavior of looking for an expert is adjusted by his awareness of the potential expertise of his contacts. We derive the optimal distribution of nodes' awareness level that minimizes the system's privacy exposure, and prove that it corresponds to the unique Nash equilibrium. Our analysis shows that the optimal distribution over a posed question is inversely proportional to the square root of the corresponding expertise density.
Privacy Enhanced RFID Using Quasi-Dyadic Fix Domain Shrinking	Recently, Radio Frequency IDentification (RFID) systems are intensively studied and widely used in every-day applications, such as, retailing, supply chain management, and medical equipment management. Tags in RFID systems are highly efficient to be managed and tracked, but at the same time suffering from impersonation and privacy problems. Consequently, RFID systems are required to provide both efficient management, as well as authentication and privacy protection. In this paper, on the basis of fast and light-weight Niederreiter public-key cryptosystem, we propose an efficient RFID authentication protocol which satisfies the above requirements, and enjoys the following merits: 1) unlike most of the previous works that employ symmetric key cryptographic techniques, our proposal has a fast computation to find authenticated ID and needs no exhaustive search in database, which reduces the searching time significantly; 2) the memory size to store the key in RFID tags can be greatly reduced by our novel methods.
On the Privacy of Encrypted Skype Communications	The privacy of voice over IP (VoIP) systems is achieved by compressing and encrypting the sampled data. This paper investigates in detail the leakage of information from Skype, a widely used VoIP application. In this research, it has been demonstrated by using the dynamic time warping (DTW) algorithm, that sentences can be identified with an accuracy of 60%. The results can be further improved by choosing specific training data. An approach involving the Kalman filter is proposed to extract the kernel of all training signals.
A Protocol for Sink Location Privacy Protection in Wireless Sensor Networks	Due to the broadcasting nature of wireless sensor networks, it is relatively easy for an adversary to discover the sinks' location through traffic volume analysis. Traditional encryption and authentication methods are not effective to preserve privacy of a sink's location from a global adversary, capably of monitoring the traffic activity of the network. In this paper, we propose the Sink Location Privacy Protection Protocol (SLPP), which in addition to been effective in achieving its design objective it is also easy to implement. In order to confuse a local or global adversary, each node generates fake messages, the number of which is dependent on the number of the node's children. Simulation results demonstrate clearly that the SLPP protocol can hide effectively the sink's location. However, what is important and interesting is that although transmission of fake messages consumes additional energy from nodes, the network's lifetime is not impacted.
A Multi-Hop Privacy-Preserving Reputation Scheme in Online Social Networks	Online Social Networks (OSNs) are becoming immensely popular nowadays, and they change the ways people think and live. In this paper, we propose a novel reputation system which allows users to find potential connections between unfamiliar people based on the most updated friend list of each user in OSNs. To some extent, our scheme provides a way to judge people in OSNs without real interactions, but based on the existing overall attitudes on particular people. Moreover, our scheme can protect the confidentially of the potential relationships in which no one is able to acquire the detailed connections between two end nodes. Contrary to those which publish each individual's reputation online, we treat the reputation value in our system as a private issue that has been carefully guaranteed.
EPF: An Event-Aided Packet Forwarding Protocol for Privacy-Preserving Mobile Healthcare Social Networks	In this paper, we propose an event-aided packet forwarding (EPF) protocol, which enables patients to efficiently communicate with each other in privacy-preserving Mobile Healthcare Social Networks (MHSNs). Since patients with common illnesses often attend the same related activities, EPF makes use of these activities in forwarding illness-related messages to the target patients so that it can achieve high target patients coverage ratio. In addition, EPF also adopts predicate encryption to guarantee patient privacy and message confidentiality. Through security analysis, we demonstrate that EPF can effectively resist various attacks launched by adversaries, and ensure patient identity and illness privacy. Extensive simulations are also conducted to evaluate the performance of EPF in terms of average target patients coverage ratio, average number of packet copies, and average packet delay.
Combining Source-Location Privacy and Routing Efficiency in Wireless Sensor Networks	Wireless sensor networks (WSNs) have been widely used in various applications for continuous event monitoring and detection. The WSNs communication is generally event-driven. While confidentiality of the message content can be ensured through content encryption, it is much more difficult to adequately protect the source-location information of the event. For WSNs, source-location privacy service is further complicated by the fact that the sensor nodes consist of low-cost and low-power radio devices, computationally intensive cryptographic algorithms (such as public-key cryptosystems) and large scale broadcasting-based protocols are not suitable for WSNs. On the other hand, exposure of the source-location can jeopardize the successful deployment of WSNs. In this paper, we propose a scheme to provide both source-location privacy and routing efficiency through routing to an intermediate node selected from a hierarchical connected dominating set (CDS) of the network. The CDS represents the backbone of the network and the nodes in the CDS are located in different regions of the network. As a result, choosing nodes from the CDS can ensure the intermediate node to be away from the actual message source node. The selection of the intermediate node can effectively prevent the adversary from performing routing trace back attack to identify the message source node. In addition, this design guarantees a high message delivery ratio and a high message delivery efficiency.
Analysis of Privacy in Online Social Networks from the Graph Theory Perspective	The extremely widespread adoption of Online Social Networks (OSNs) raises many questions on privacy and access control. Regardless of the particular centralized or de-centralized nature of the OSN, the achievable security and privacy degree strongly depends on the graph-theoretical properties of the social graph representing the real friendship relations between the users. In this paper, we analyze the relationship between the social network graph topology and the achievable privacy. We observe three metrics, namely degree distribution, clustering coefficient and mixing time, and show that they give fundamental insights on the privacy degree of the OSN. We propose how to exploit these insight for the design of future privacy-friendly OSN.
Waypoint Routing: A Network Layer Privacy Framework	This paper presents a routing framework that embeds location and communication privacy into the routing mechanisms. It conceals endpoint identification by introducing waypoints, through encrypted routing hints, where each waypoint has knoweldge of the next hop, assuring network privacy over several waypoints. Based on IPv6 extension headers and Onion Routing techniques, the network waypoints comply with normal routing procedures, avoiding explicit tunneling or full packet encryption. By focusing on the network as a cooperative entity for privacy preservation, we propose a lightweight approach that can be easily deployed, establishing a good compromise between privacy and optimal routing.
A Privacy Preserving Handover Authentication Scheme for EAP-Based Wireless Networks	Extensible Authentication Protocol (EAP) is a framework which aims to provide a flexible authentication for wireless networks. Due to the involvement of an EAP server and several round trips between a mobile node (MN) and the EAP server, a full EAP authentication takes about 1000ms which is unacceptable in a handover process. This paper proposes a privacy preserving handover authentication scheme for EAP-based wireless networks. We use the proxy signature scheme to accomplish authentication between MN and an access point (AP) without involving the third party. The detailed security analysis shows that our scheme can achieve the privacy preserving and forward/backward security. In addition, we evaluate the latency performance of the proposed scheme by the analysis and simulation. The results demonstrate that our scheme is more efficient in terms of computation and communication overheads.
Credential-Based Privacy-Preserving Power Request Scheme for Smart Grid Network	A smart grid network adjusts power allocation by collecting information about the power usage of the customers in real-time. Authentication and user privacy preservation are the two major concerns on smart grid security. Authentication schemes that preserve users' privacy from third parties, but not from the power operator, have been proposed. In this paper, we propose a scheme that preserves users' privacy information, including their daily electricity usage pattern from third parties as well as from the power operator. At the same time, the scheme ensures that authentication can be properly done. These two properties are achieved by using anonymous credential under the principle of blind signature. Basically, a customer generates a set of credentials by himself and asks the control center to blindly sign them. When the customer needs to request more power later on, he presents the signed credential to the control center as proof of his identity. Implementation and analysis show that our scheme is feasible in terms of a number of performance measures such as the signing time and the credential collision rate.
Cooperative Sybil Attack Detection for Position Based Applications in Privacy Preserved VANETs	In this paper, we propose a security protocol to detect sybil attacks for position based applications in privacy preserved vehicular ad hoc networks (VANETs). Vehicles in our protocol identify sybil attacks locally in a cooperative way by examining the rationality of vehicles' positions to their own neighbors. The attack detection utilizes the characteristics of communication and vehicles' GPS positions which are included in the periodically broadcasted safety related messages. No extra hardware and little communication and computation overhead will be introduced to vehicles. Therefore, our protocol is very light weighted and suitable for real applications. Moreover, a smart attacker scenario in which a malicious vehicle may adjust its communication range to avoid detection and the malicious vehicles' collusion scenario are also considered. Simulation results based on NS2 are presented to demonstrate the performance of the proposed protocol.
Discriminatory Lossy Source Coding: Side Information Privacy	The Heegard-Berger problem models a case in which encoding at a source has to account for two decoders, one with and one without correlated side information when the same information is not available at the encoder. The Heegard-Berger encoding scheme is proved to be rate-optimal even when an additional constraint on the privacy of side information is imposed at the uninformed decoder. The results are illustrated for a binary source with erasure side information and Hamming distortion, a result which is also of independent interest.
Enhancing Mobile Social Network Privacy	Privacy is an important concern for location based services (LBSs). In this paper, we consider a specific type of LBS known as a mobile social network (MSN). We demonstrate a new type of attack, where an adversary can combine the location and friendship information found in a MSN, to violate user privacy. We propose a fake location reporting solution that does not require any additional trusted third party deployment. We use extensive simulations to determine the validity of our scheme.
Privacy and authentication on a portable communications system	The authors discuss technical options to achieve adequate privacy and fraud control for portable communication systems. As the goal is to provide privacy at least comparable to that provided by wireline, the authors concentrate on the privacy of conversations on the radio link only. A high-level description of the portable communications system is presented, which provides a basis for further discussion. Message encryption is considered, the process by which a cipher function is applied to the portable communications systems data streams in order to deter eavesdroppers. Some background on public-key cryptography and some information regarding implementation of public-key techniques in low-power portable units are given. Key agreement and authentication protocols are outlined
Law and privacy on the Internet	This paper examines the legal parameters that regulate Internet communications in the United States and includes the following arguments: Senate hearings on privacy, censorship and government control of Internet communications, the current debate regarding the exportation of encryption software and the laws that govern encryption as part of a national security measure, the United States constitution as it applies to the Internet, encryption, and transfer of information in an international setting
Coding for privacy with burst adaptive permutations	A formal treatment is presented for Al Jabri's (see IEE Electronics Letters, vol.32, no.24, p.2226-7, 1996 and 4th International Symposium on Communication Theory and Applications, Ambleside, Lake District, UK, 13-18, p.197-200, 1997) attack to reconstruct the permutation in secret-key schemes based on single-burst correcting codes. An extension of that technique to attack secret-key cryptosystems based on multi-burst correcting codes is presented and shown to be effective. A new encryption scheme is proposed, using burst-error correcting codes and adaptive permutations, which is resistant to known attacks and is specially tailored to counter Al Jabri's attack.
Authentication and payment protocol preserving location privacy in mobile IP	Mobile IP enables a mobile node (MN) to move around without losing their transport-layer connectivity by using resources in a foreign domain network. Mobile IP (MIP) is expected to be the core infrastructure of future mobile communication, but two services must be provided before the wide deployment of MIP. One is to provide secure communication and the other is to make payment. Security services, such as authentication and access control, have been considered since the birth of MIP, but little attention has been given to location privacy and anonymity services despite of their increased significance in wireless network. An incontestable payment protocol must be also developed, considering the usage of foreign domain network resources by the MN. As mix-network provides basic concept of location privacy protection, this paper proposes an authentication and payment protocol hiding location information, based on mix-network.
The Freiburg privacy diamond	Anonymity is a protection goal that helps to protect the privacy of users by ensuring that their identity remains unknown. Many mechanisms that enable anonymous actions exist. The Freiburg privacy diamond proposed in this contribution is a conceptual model which can be used to classify, analyze, and construct anonymizing mechanisms in respect of the type of mobility that is required for this anonymity mechanism.
A secure and privacy enhanced protocol for location-based services in ubiquitous society	This paper focuses on one of the future applications and services area of mobile communications. Mobile devices like mobile phones and PDAs would very soon allow us to interact with other smart devices around us, thus supporting a ubiquitous society. There would be many competitive service providers selling location-based services to users. To avail such services, a user's mobile device may need to handle many service providers. It should also he able to identify and securely communicate with only genuine service providers. But these tasks could create a huge burden on the low-computing and resource-poor mobile device. Our protocol establishes a convincing trust model through which secure key distribution is accomplished. Secure job delegation and use of cost-effective cryptographic techniques help in reducing the communication and computational burden on the mobile device. The protocol also provides user privacy protection, replay protection, entity authentication, and message authentication, integrity and confidentiality.
NETp1-08: Requirements and Challenges in the Design of Privacy-aware Sensor Networks	Sensor networks are set to become a truly ubiquitous technology that will affect the lives of the people in their application environment. While providing the opportunity for sophisticated, context-aware services, at the same time sensor networks impose great privacy risks. This paper discusses privacy issues in sensor networks, by identifying the requirements for privacy preserving deployments, analysing the challenges faced when designing them, and discussing the main solutions that have been proposed.
NXG01-5: Privacy through Virtual Hording	The wireless digital lifestyle comes to the expense of less privacy and security. This environment is prone to be monitored by rogue users, eager to learn from our lifestyle habits and use them for their own profit. The IP protocol provides very few mechanisms, in order to safeguard user privacy and impair efficient data-mining of user habits. This paper will address an identity architecture that makes use of both data (L2) and network (L3) layer identifiers in order to provide a pseudonimization function, based on virtual hoarding concepts. Our proposal is especially interesting when able to exploit the broadcast and promiscuous nature of wireless communications that usually is regarded as a security concern. A prototype implementation has been developed and tested.
Protecting Location Privacy with Dynamic Mac Address Exchanging in Wireless Networks	Location information of users can now be collected from most wireless communication using advanced wireless location tracking techniques. Providing location information can be advantageous in some situations. However, there are instances, where it may be critical to protect the location of the individual. Several protection strategies, such as periodically updating interface identifiers, have been proposed so that an adversary cannot track mobiles in long-term movements. In this paper, we introduce a new strategy, DMAS (Dynamical Mac Assignment with Shuffle), in which the mobile client dynamically exchanges its assigned Mac addresses with others.We present a security analysis to show this scheme can greatly secure a client's location privacy.
Preserving Privacy in Mobile Environments With Virtual Network Stacks	User privacy is a growing requirement in the evolution of communication networks. In this sense, the concept of virtual personae, which corresponds to different identities of the same user, starts getting much attention. However, to provide privacy and non-linkage between these virtual users, a cross-layer approach to identity needs to be supported. This paper proposes a solution to preserve the application layer privacy models by applying the virtual personae concept throughout the network stack. It also proposes mechanisms for non-correlation between identities in 4G mobile environments, and addresses the benefits of the evolving multi-homing characteristics of 4G networks to enrich the non-linkage between identities support of our privacy solution.
An Efficient Privacy-Preserving Scheme for Wireless Link Layer Security	In this paper, we propose an efficient privacy-preserving scheme for secure packet transmission at wireless link layer. The proposed scheme is constructed by using hash values in reverse hash chains as interface identifiers. It can successfully and efficiently resist the Media Access Control (MAC) address based attacks, such as flow tracking and traffic analysis, which are launched by either outside or even inside attackers. In addition, some optimization techniques are also introduced to further improve the efficiency of the proposed scheme. The extensive analysis and simulations demonstrate the enhanced security and efficiency of the proposed scheme.
Collaborated Camouflaging Mobility for Mobile Privacy	We present a collaborated camouflaging mobility algorithm to protect mobile hosts' mobility privacy. Our algorithm alters a mobile host's straight moving paths into Delta-shaped camouflaging paths, which cause its wireless transmissions to be distributed over a large area, and hence, reduce the probability of generating traceable wireless transmissions. Furthermore, on the premise of not affecting the mobile hosts' itineraries, our collaborated mobility algorithm clusters the motion paths of mobile hosts to make it difficult for an adversary to identify the mobile hosts. We model the objective of maximizing mobility privacy and minimizing the overhead (e.g. the extra travel distance) as a nonlinear constrained optimization problem and use the solution to the optimization problem as the collaborated mobility. Lastly, we analyze the calculation time of the collaborated camouflaging mobility and conduct simulations to evaluate the privacy improvements brought by the collaborated camouflaging mobility algorithm compared with non-covered mobility.
Privacy and Security As Assets: Beyond Risk Thinking to Profitable Payback	Notwithstanding all of the money already invested in security and privacy: privacy as surveyed is in decline and global communication infrastructure is increasingly insecure. Why is this so, and what can we do about it? Three concepts explain the problem of relating capital to security and illuminate the path to improved results: 1) definitions and outcomes of investments in privacy and security have been risk based and speculative. 2) expenditures for speculative risk abatement tend to compete poorly with alternative allocations, such as spending on quantified risks and spending for profit. 3) product budgeting has yet to fully embrace the notion that privacy and security are core to form and function. Security and privacy have not been monetized as elements of brand. This paper explains these concepts, relates them to the allocation of investment capital, and recommends actions for companies, their R & D executives, and boards to enhance success in the market.
On Privacy of Skype VoIP Calls	Skype is one of the most popular voice-over-IP (VoIP) service providers. One of the main reasons for the popularity of Skype VoIP services is its unique set of features to protect privacy of VoIP calls such as strong encryption, proprietary protocol, unknown codec, dynamic path selection, and constant packet rate. In this paper, we propose a class of passive traffic analysis attacks to compromise privacy of Skype VoIP calls. The proposed attacks are based on application-level features extracted from VoIP call traces. The proposed attacks are evaluated by extensive experiments over different types of networks including commercialized anonymity networks and our campus network. The experiments show that the proposed traffic analysis attacks can detect speaker and speech of Skype calls with 0.33 and 0.44 detection rate, about 30-fold and 15-fold improvement over random guess respectively.
Protecting user privacy in WiFi sharing networks	WiFi sharing communities are an interesting option for mobile Internet access. Today, however, users need to give up privacy in exchange for connectivity: they are required to expose their identity in order to be granted access. This information can be used to track users and to generate usage and movement profiles. We identify the challenges of providing a maximum level of privacy and anonymity in a WiFi community. From a discussion of privacy properties of existing architectures, we arrive at a privacy-aware WiFi sharing design for fully anonymous usage-without sacrificing any participant's security or legal safety. This system, like some previous designs, relays a mobile user's data via this user's home network; we discuss how and under which circumstances this contributes to privacy and anonymity. In order to enable users to remain fully anonymous in such a system, a means to locate the home network of a user without leaking permanent identifiers is needed. We introduce and evaluate volatile host names, a novel method to generate anonymized, non-persistent host names in standard DNS.
Using broadcast to protect user privacy in location-based applications	Most existing cloaking techniques are based on a three-tier architecture: mobile users, a trusted anonymizer server, and service providers. In this paper, we propose a new three-tier architecture, where the trusted anonymizer server also serves as a broadcast server. The trusted anonymizer server takes a proactive approach. It first groups mobile users into clusters. Then for each cluster, it fetches the most popular query results from service providers. The query results are then broadcast through an air channel to reach all mobile users. As a result, to get a query answered, a mobile user can first tune into the air channel to determine if the query result is available. If not, the mobile user just sends a traditional location-based query to the trusted anonymizer server. Other than the novel new three-tier architecture, we also propose two cell-based clustering algorithms, and a broadcast index to facilitate the download of query results. The proposed techniques are compared using simulation against the improved Interval Cloak technique under the traditional three-tier architecture. The extensive results show that our system is better in reducing communication cost and protecting user privacy.
ESAP: Efficient and scalable authentication protocol with conditional privacy for secure vehicular communications	Security mechanisms such as authentication, message integrity, and non-repudiation are extremely important features for both vehicle-to-vehicle and vehicle-to-infrastructure communications in vehicular ad hoc networks. This paper proposes an Efficient and Scalable Authentication Protocol (ESAP) that provides anonymity and conditional privacy for vehicular ad hoc networks based on the self-generated certificates. The proposed ESAP provides all required security services such as authentication, message integrity, non-repudiation and revoking malicious vehicles in an efficient and scalable manner while supporting user anonymity, location privacy and conditional privacy. Moreover, accuracy of this protocol does not depend on the availability of Road Side Units.
Preserving privacy while reducing power consumption and information loss in LBS and participatory sensing applications	Participatory sensing systems rely on the willingness of mobile users to participate in the collection and reporting of data using a variety of sensors either embedded or integrated in their cellular phones. Users agree to use their cellular phone resources to sense and transmit the data of interest because these data will be used to address a collective problem that otherwise would have been very difficult to solve. However, this new data collection paradigm has not been very successful yet mainly because of privacy concerns. Without adequate privacy-preserving mechanisms most users are not willing to participate. Although several schemes have been proposed in the literature, none of them offers a complete solution, and instead, trade offs exist. For example, anonymization-based schemes change the real location of the users, and therefore preserve their privacy, but they might not be precise enough for certain applications. On the other hand, encryption-based schemes, since they do not modify the real location of the user, are very accurate and serve well all applications; however, they are very costly in terms of energy consumption. In this paper we present a scheme that combines the good properties of both approaches to reduce the energy consumption of encryption-based schemes as well as the noise added by anonymization-based schemes. Our simulation results show that the proposed scheme in fact achieves the desired objectives of reducing the energy consumption and information loss while allowing the application to track the users accurately.
Anybody home? Keeping user presence privacy for advanced metering in future smart grid	Smart metering, the gateway between power users and power utilities, is one of the key devices in smart grid. In order to decrease the data volume for power consumption report sent from smart meters to power utilities, it is more desirable to use differential transmission scheme, in which a smart meter transmits data only when power consumption is changed. However, such a scheme incurs vulnerabilities. Since, in the differential transmission scheme, the corresponding radio activity is proportional to the power activity. This information can be used by attacker to detect whether the power user is at home. In this paper, we study the privacy of power user for the transmission scheme. When the power user is not present, two defense plans are proposed to generate null packets during idle time to emulate the packet transmission during busy time in order to elude the attacker. Then, Kolmogorov-Smirnov statistic based attack methods are proposed to combat the defense plan. Numerical results are used to illustrate the efficiency of the proposed defense plans.
Privacy-preserving license plate image processing	Advances in license plate detection and recognition software severely threaten privacy. Intended originally for video surveillance such as the law enforcement at automatic toll booths, license plate recognition software becomes so powerful that it can identify license plates from low-resolution and blurred images illegible to the human eye. However, the technology can be adversely used to track individuals regardless of suspicion, violating privacy, through ever present webcams, in Traveler Information Systems, for instance. This paper introduces a novel engineering solution to privacy-preserving license plate recognition. A trivial solution to protect the privacy of individuals in video surveillance data is to black out each license plate; it effectively thwarts license plate recognition but renders no practical use as all information being obscured. The new system presented in this paper enables privacy preservation in the images containing license plates as well as car features while allows identification of particular license plates with legitimacy similar to a specific search warrant. Such dual purposes are fulfilled with an orchestra of information technologies. Pseudo-anonymity, a disguised identity held by many individuals, preserves privacy by ensuring the failure of license plate recognition. Steganography, security through obscurity or information hiding, reveals the license plate of a suspect by a protocol of synchronized pseudo random number generation. The synchronization protocol is superior over both symmetric encryption problematic with key distribution and asymmetric schemes involving expensive computation. Experiments are conducted on a real world Traveler Information System with favorable results.
A lightweight privacy-preserving mutual authentication protocol for RFID systems	In this paper we propose a novel privacy-preserving mutual authentication protocol for RFID systems using the recently proposed ultra-lightweight cryptographic algorithm Hummingbird-2. The new protocol is resistant to the most common attacks against the security and privacy of RFID systems. Furthermore, we also address efficient implementation of the proposed protocol on a batteryless, MSP430-based WISP tag, and investigate the performance of the key search process on a laptop. Our experimental results demonstrate that the Hummingbird-2 mutual authentication protocol provides a highly effective and efficient security and privacy solution for low-cost passive RFID tags.
Empowerment: Enabler for Personalized Security and Privacy	Personal Networks - is prominent network architecture in realization of the next generation wireless communication systems due its built-in user-centriness. As end-users most often desire control, having strong privacy constrains and technology-oriented approaches are not often usable. The engineers should think their solutions as a white box, not as a black-box solution, of which the end-user sees only the input and the output. This paper highlights the empowerment as an essential tool-box in building end-user trust for personalized security and privacy solution and thus speeding up the use of the 4G networks.
Privacy in the Digital Age: States, Private Actors, and Hybrid Arrangements	This chapter contains sections titled: Evolution of the Privacy Debate and International Institutions, Current Debates on Privacy, Recommendations, Conclusion, Notes, References
Privacy homomorphisms for e-gambling and mental poker	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01635918.png" border="0">
Attribute-oriented Granulation for Privacy Protection	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01635904.png" border="0">
Zero-knowledge test of vector equivalence granulation of user data with privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01635903.png" border="0">
Privacy in Statistical Databases: k-Anonymity Through Microaggregation	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01635915.png" border="0">
Privacy in the Information and Communications Technologies	Information and communications technologies (ICT) are fostering the appearance of a plethora of new services and applications. On the one hand, ICT will improve the efficiency of a variety of processes (e.g. supply chains, e-commerce, etc.) and they will make easy the development of new services. On the other hand, the massive deployment of these new technologies may lead to the invasion of users privacy. In this article, we analyse four of the main technologies which can put the privacy of their users in jeopardy: Internet browsing, location-based services, RFID technology and statistical databases.
Enhancing Privacy of Released Database	With advanced information techniques, organizations want to make their database public for different purposes. It is important to do some data transformations that prevent private information to be revealed before publishing the database. In this paper, we introduce a combined approach to enhance the privacy of the databases to be released. The combination of two existing techniques, k-anonymity and randomization, provides better privacy protection than only applying one of two approaches and still reserves certain data utility. The experiments on real-world dataset show that our privacy breach prevention algorithm enhances the privacy with small cost increase compared to the k-anonymity approach.
Privacy Preserving Collaborative Filtering Using Data Obfuscation	Collaborative filtering (CF) systems are being widely used in E-commerce applications to provide recommendations to users regarding products that might be of interest to them. The prediction accuracy of these systems is dependent on the size and accuracy of the data provided by users. However, the lack of sufficient guidelines governing the use and distribution of user data raises concerns over individual privacy. Users often provide the minimal information that is required for accessing these E-commerce services. In this paper, we propose a framework for obfuscating sensitive information in such a way that it protects individual privacy and also preserves the information content required for collaborative filtering. An experimental evaluation of the performance of different CF systems on the obfuscated data proves that the proposed technique for privacy preservation does not impact the accuracy of the predictions. The proposed framework also makes it possible for multiple E-commerce sites to share data in a privacy preserving manner. Problems such as the cold-start scenario faced by new E-commerce vendors, and biased results due to insufficient users, are resolved by using a shared CF server. We describe a centralized CF server model in which a centralized CF server makes recommendations by consolidating the information received from multiple sources.
Towards Mobile Internet: Location Privacy Threats and Granular Computation Challenges	The bulk of contents out on the Internet continue to grow at an astounding pace. As computing and communications become ubiquitous, we are entering the mobile Internet computing era, where people, devices, and vehicles are connected at all time and the Internet access capability is being embedded in billions of wireless devices such as PDAs, cellular phones, and computers embedded in vehicles (e.g., navigational systems on cars). By extending the Internet through mobile information access, the mobile Internet is on a trajectory to offer all of the same features and value propositions as the traditional Internet, with the promise of greater information access opportunity, richer and device-spanning Internet services and experiences, thanks to continuous availability and location awareness.
Improved Customers' Privacy Preference Policy	Companies tend to collect more and more data about their customers. This data is seen as useful for the company, but often customers do not wish to share it. Methods such as P3P for verifying a company's privacy policy are available, however these do not provide much choice for the customer and they provide an all-or-nothing approach. In this paper, we improve the privacy preference policy approach to give customers more choices to make decisions on disclosing private information and make online companies more careful on their collection of customers' private information.
Granular computing in privacy-preserving data mining	Granular computing is an emerging computing paradigm of information processing. It concerns the processing of complex information entities, called ldquoinformation granulesrdquo, which appear in the process of data abstraction and derivation of knowledge from information. The granular computing paradigm has been applied to many applications and we will address the application of granular computing in privacy-preserving data mining. We will use privacy-preserving association rule mining and privacy-preserving k-nearest neighbor classification to illustrate how the paradigm of granular computing has been applied.
Towards efficient privacy-preserving collaborative recommender systems	Recommender systems use various types of information to help customers find products of personalized interest. To increase the usefulness of recommender systems in certain circumstances, it could be desirable to merge recommender system databases between companies, thus expanding the data pool. This can lead to privacy disclosure hazards that this paper addresses by constructing an efficient privacy-preserving collaborative recommender system based on the scalar product protocol.
A Clustering-Based Location Privacy Protection Scheme for Pervasive Computing	In pervasive computing environments, Location-Based Services (LBSs) are becoming increasingly important due to continuous advances in mobile networks and positioning technologies. Nevertheless, the wide deployment of LBSs can jeopardize the location privacy of mobile users. Consequently, providing safeguards for location privacy of mobile users against being attacked is an important research issue. In this paper a new scheme for safeguarding location privacy is proposed. Our approach supports location K-anonymity for a wide range of mobile users with their own desired anonymity levels by clustering. The whole area of all users is divided into clusters recursively in order to get the Minimum Bounding Rectangle (MBR). The exact location information of a user is replaced by his MBR. Privacy analysis shows that our approach can achieve high resilience to location privacy threats and provide more privacy than users expect. Complexity analysis shows clusters can be adjusted in real time as mobile users join or leave. Moreover, the clustering algorithms possess strong robustness.
Privacy Settings on Facebook: Their Roles and Importance	This explorative study aims to gain insight about which privacy settings and features on the interfaces are commonly used by Facebook users. User data was collected using an online survey. Based on the survey data, a set of the commonly used privacy strategies on Facebook were identified. We found that these strategies were mainly used to manage three types of privacy concerns: 1) personal profile visibility, 2) personal networking boundary, and 3) personal privacy awareness. A point-biserial correlation analysis revealed that only networking privacy strategies were significantly correlated with the feeling of control users felt in mitigating hackers, blackmailers, stalkers as well as compromising relations and job positions. Hence, when the goal of the sites is to empower users for protecting their privacy, it is important to understand how users make decisions with the help of these privacy settings and features on user interfaces. Implications of these findings as well as suggestions for future research are discussed.
Requirements Model for a High-Privacy Decentralized Carbon Emissions Trading Platform	This paper elicits and models the requirements of a decentralized carbon emissions trading platform (CarboCoin). CarboCoin platform is based on the Bit coin, a peer-to-peer digital currency with no central authority. CarboCoin is focused on providing high privacy protection for participants in order to encourage more engagement in carbon emissions reduction process. CarboCoin requirements are elicited and specified based on the Bit coin design principles, algorithms, and platform specifications. CarboCoin platform should facilitate high-privacy carbon emissions trading, and increase private individuals engagement in the trading process.
Efficient Data Tagging for Managing Privacy in the Internet of Things	The Internet of Things creates an environment where software systems are influenced and controlled by phenomena in the physical world. The goal is invisible and natural interactions with technology. However, if such systems are to provide a high-quality personalised service to individuals, they must by necessity gather information about those individuals. This leads to potential privacy invasion. Using techniques from Information Flow Control, data representing phenomena can be tagged with their privacy properties, allowing a trusted computing base to control access based on sensitivity and the system to reason about the flows of private data. For this to work well, tags must be assigned as soon as possible after phenomena are detected. Tagging within resource-constrained sensors raises worries that computing the tags may be too expensive and that useful tags are too large in relation to the data's size and the data's sensitivity. This paper assuages these worries, giving code templates for two small micro controllers (PIC and AVR) that effect meaningful tagging.
Privacy preservation and enhanced utility in search log publishing using improved zealous algorithm	Search log records can enhance the quality and delivery of internet information services to the end user. Analysing and exploring the search log can explore the user's behaviour. When these search logs are published it must ensure privacy of the users at the same time it should exhibit better utility. The existing ZEALOUS algorithm uses a two threshold framework to provide probabilistic differential privacy. In the course of providing this level of privacy the search log looses it's utility, as it publishes only frequent items. So an algorithm is proposed to enhance the utility of search log by qualifying the infrequent items while publishing at the same time preserving the stronger level of privacy.
A novel framework to prevent privacy breach in cloud data storage area service	The present paper focuses on user data privacy invasion and it is more important in cloud data storage. Numerous approaches and techniques have proposed so for, to preserve the cloud user privacy. This paper introduces a layered framework for preserving secrecy of cloud user and preventing digital data loss, using onion privacy layer, garlic privacy layer. This layered framework prevents the confidential information by multiple encryption of onion and garlic privacy preserving layered approach.
Hybrid authentication technique to preserve user privacy and protection as an end point lock for the cloud service digital information	This paper presents a new approach for privacy preserving of user data and publishing in cloud storage area. Hybrid authentication technique overcomes the limitations of attackers and general intruders and preserves better utilization of user's confidential data by providing access only to authorized persons. In this proposed technique it is illustrated how this technique used to prevent user secret data attributes kept in digital cloud storage environment. Moreover the proposed system shows a better data privacy preserving utility by users and handling sensitive data during vulnerable attempts and attacks to the cloud storage area.
Privacy preserving method based on GM(1,1) and its application to data clustering	Protecting the users' privacy while mining information from massive data has become a popular research topic in recent years. Perturbation and reconstruction are two common technologies in implementing privacy preserving data mining. In this paper, a novel perturbation method based on GM(1,1) model is proposed and applied to data clustering. The effectiveness and efficiency of the proposed method is demonstrated by the experiments on real-world datasets.
Privacy preserving collaborative forecasting based on dynamic exponential smoothing	The development and deployment of private forecasting technologies could allow supply chain collaborations to take place without revealing any participants' data to the others, reaping the benefits of collaboration while avoiding the drawbacks. Atallah (2004) [1,3] is a step towards this goal, as it gives protocols for forecasting that reveal to the participants the desired answers yet do not reveal to any participant any other participant's private data. But the smoothing coefficient OC used in Atallah (2004) [1,3] is assumed to be public and constant, but most of the time series, particularly in the complex economic system, many random observations of the sequence do not have a smoothing coefficient which does not change. Therefore, traditional exponential smoothing model for forecasting has a marked deviation, even serious distortion. So the assumption of constant is out of accordance with the practice. A novel part of this work is that the dynamic smoothing coefficient is established for exponential smoothing, and a corresponding privacy preserving collaborative forecasting algorithm is provided.
A privacy preserving clustering technique using hybrid data transformation method	Despite many successful stories of data mining in a wide range of applications, this technique has raised some issues related to privacy and security of individuals. Due to these issues, data owners are often unwilling to share their sensitive information with data miners. In this paper, we present a novel method for privacy preserving clustering over centralized data. The proposed method is built upon the application of double-reflecting data perturbation method (DRDP) and rotation based translation (RBT) in order to provide secrecy of confidential numerical attributes without losing accuracy in results. The experiments demonstrate that the proposed method is effective and provides a feasible approach to balancing privacy and accuracy.
Design of Privacy-Preserving Cloud Storage Framework	Privacy security is a key issue for cloud storage. To solve this problem, the paper proposes a privacy-preserving cloud storage framework, which includes the design of data organization structure, the generation and management of keys, the treatment of change of users' access right and dynamic operations of data, and the interaction between participants. We design an interactive protocol and an extirpation-based key derivation algorithm, which are combined with lazy revocation, multi-tree structure and symmetric encryption to form a privacy-preserving, efficient framework for cloud storage. A system is realized which is based on the framework. The paper analyzes the effectiveness of extirpation-based key derivation algorithm, the overhead of the system and the privacy security of the framework. Finally, we summarize our work and introduce our future research directions.
Privacy Preserving C4.5 Algorithm Over Horizontally Partitioned Data	Privacy preserving decision tree classification algorithm is to solve such a distributed computation problem that the participant parties jointly build a decision tree over the data set distributed among them, and they do not want their private sensitive data to be revealed to others during the tree-building process. The existing privacy preserving decision tree classification algorithms over the data set horizontally partitioned and distributed among different parties only can cope with the data with discrete attribute values. This paper propose a solution to privacy preserving C4.5 algorithm based on secure multi-party computation techniques, which can securely build a decision tree over the horizontally partitioned data with both discrete and continuous attribute values. Moreover, we propose a secure two-party bubble sort algorithm to solve the privacy preserving sort problem in our solution
The Impact of Privacy Concern on M-commerce User Acceptance	By means of mobile communication technology, enterprises can more easily track users and collect their personal information. This has aroused users' privacy concern. This paper explores the impact of privacy concern on m-commerce user acceptance behavior. Privacy concern as a second-order factor includes four dimensions: collection, improper access, information error and secondary usage. The results show that improper access and information error have relatively higher loadings on the second-order factor. Privacy concern significantly affected user risk perception and trust and through them indirectly affected behavioral intention. Thus, m-commerce enterprises should pay more attention to users' privacy concern and take effective measures to alleviate their privacy anxiety.
Privacy Research on Ubicomp Computing with Neural Cryptography	The paper presents a new security solution in ubiquitous computing, which is a new and hot research point for computer scientists. Ubiquitous computing environments with their interconnected devices and services promise seamless integration of digital infrastructure into our daily lives. While the focus of current research is on how to connect new devices and build useful applications to improve functionality, the security and privacy issues in such environments have not been deployed widely to justify the evidence of threats, risk and vulnerability in real situations. Existing policies and mechanisms may not provide adequate guarantees to deal with new exposures and vulnerabilities introduced by the ubiquitous computing paradigm. In this paper we explore the challenges for building security and privacy into ubiquitous computing, describe our prototype implementation based on neural cryptography, and propose some directions for future work in the end.
Security and Privacy for Sensor Networks	This chapter contains sections titled: <br> Introduction <br> Security and Privacy Challenges <br> Ensuring Integrity of Measurement Process <br> Availability Attacks against the Wireless Link <br> Ensuring Privacy of Routing Contexts <br> Conclusion <br> References
Location Privacy for Users of Wireless Devices through Cloaking	The continued growth in online services that provide users with content based on location presents a unique privacy concern for the user. Since the user cannot control the use of the data included in his network transactions once they leave the device, nor can he control the response from the location-based system (LBS), he must assume that information is available to an unknown observer who could use the information to estimate the user's location. This paper presents a cloaking system that preserves a user's location privacy by submitting multiple requests from disparate false locations to the LBS in rapid succession in order to confuse the observer and meet the user's pre-determined location privacy threshold.
Internet Privacy in E-Commerce: Framework, Review, and Opportunities for Future Research	Increased Internet traffic and the sophistication of companies in tracking that traffic have made privacy a critical issue in electronic commerce (e-commerce). This has spawned a number of research works addressing Internet privacy from the perspectives of three main stakeholders - customers, companies and governments, as well as the interactions among them. The purpose of this paper is to analyze the extant studies and develop an understanding of the relationships among them. Accordingly, we review the research on Internet privacy in e-commerce that has been conducted in the fields of information systems, business, and marketing. We develop a framework for classifying the studies, review key findings, and identify opportunities for future research.
Citizens' Concerns about the Privacy of Personal Information Held by Government: A Comparative Study, Japan and New Zealand	The paper reports an investigation of the concepts of information privacy and trust in government in Japan, and compares the findings with an earlier study in New Zealand which used a similar instrument. Cultural and other factors are sought which might explain differences in attitudes shown in the two studies. The responses of Japanese citizens interviewed indicated that they had major concerns about information privacy, knew little about any protection offered in law, and had considerably less trust in government than New Zealand respondents showed. Cultural factors that might contribute to these differences, such as the difference between a collectivist versus a more individualistic culture were reflected in some of the respondents' explanations of their views.
Privacy-Preserving 1-n-p Negotiation Protocol	In this paper, we have designed an electronic market where a buyer negotiates with n suppliers to procure p types of items within a given time frame. A privacy preserving 1-n-p negotiation protocol has been developed based on secure group communication and secure multiparty computation. The suppliers submit their bids. The objective is to label the bids as winning or losing so as to minimize the buyer's cost with the constraint that the buyer obtains all items in required quantity. The negotiation process has two distinct phases - pre-bid and final bid. During pre-bid phase, the suppliers singly or jointly bid for a combination of items. The privacy requirements considered are: a) pre-bid: forward and backward privacy and anonymity of the winner in each pre-bid cycle, b) final bid: anonymity of the losers and traceability of the winners.
Consumer-Centric and Privacy-Preserving Identity Management for Distributed E-Health Systems	A new framework of privacy-preserving identity management for distributed e-health systems is proposed. Utilizing a consumer-centric approach, the healthcare consumer maintains a pool of pseudonymous identifiers for use in different healthcare services. Without revealing the identity of consumers, health record data from different medical databases distributed in various clinic/hospitals can be collected and linked together on demand. While pseudo-anonymity preserves user privacy, the architectural design allows the anonymity to be revoked by a trusted authority under well-defined policies with legal-compliance. This framework inherits the advantages in centralized management for distributed medical databases Security of the interactions among different entities in the architecture is guaranteed by certification and cryptographic technologies.
Pseudonymization for improving the Privacy in E-Health Applications	Electronic health records (EHR) promise to improve communication between health care providers, thus leading to better quality of patients' treatment and reduced costs. As highly sensitive patient information provides a promising goal for attackers and is also demanded by insurance companies and employers, there is an increasing social and political pressure regarding the prevention of health data misuse. This paper presents a detailed description of the new system PIPE (pseudonymization of information for privacy in e-health) which differs from existing approaches in its ability to securely integrate primary and secondary usage of health data. Therefore, PIPE provides a solution to shortcomings of existing approaches. Our approach may be used as a basis for implementing secure EHR architectures or as an extension to existing systems.
SecUre Privacy-presERving Medical Image CompRessiOn (SUPERMICRO)	The privacy and security of biomedical data are important. Ideally, biomedical data should be kept in a secure manner (i.e. encrypted). With the increasing deployment of the electronic health records, it is critical to make protected health information (PHI) available securely to private and public healthcare providers through the National Health Information Network (NHIN). Efficient transmission and storage of these large encrypted biomedical data becomes an important concern. An intuitive way is to compress the encrypted biomedical data directly. Unfortunately, traditional compression algorithms (removing redundancy through exploiting the structure of data) fail to handle encrypted data. The reason is that encrypted data appear to be random and lack the structure in the original data. The "best" practice has been compressing the data before encryption, however, this is not appropriate for privacy related scenarios (e.g., biomedical application), where one wants to process data while keeping them encrypted and safe. In this paper, we develop a Secure Privacy-presERving Medical Image CompRessiOn (SUPERMICRO) framework based on distributed source coding (DSC), which makes the compression of the encrypted data possible without compromising security and compression efficiency. Our approach guarantees the data transmission and storage in a privacy-preserving manner. We tested our proposed framework on two CT image sequences and compared it with the state-of-the-art JPEG 2000 lossless compression. Experimental results demonstrated that the SUPERMICRO framework provides enhanced security and privacy protection, as well as high compression performance.
Privacy Protection in Sharing Personal Genome Sequencing Data	The past few years has witnessed rapid development in human genome research, in particular the genome-wide association studies (GWAS) and personalized medicine, which has been made possible by the advance in the Next Generation Sequencing (NGS) technologies that produces a large amount of sequencing data at an exceedingly low cost. New technologies for large-scale meta-analysis on genomic data continue to be developed, enabling the application of human genome research to clinical diagnosis and therapy, a trend dubbed ΓÇ£base pairs to bedsideΓÇ¥. However, further progress in this area has been increasingly impeded by the constraints in accessing sequencing data, due in part to privacy concerns involved in data sharing. The current approach to protecting human genomic data is mainly based upon data-use agreements, which involves a time-consuming application/review/agreement process. To enable more convenient data access, this paper proposes a data analysis model that allows biomedical researchers and healthcare practitioners to use the sensitive genomic data that cannot be directly released in an efficient fashion, through the computing service over the data (instead of direct access to the data) provided by a large data center.
A Randomized Response Model for Privacy-Preserving Data Dissemination	Public dissemination of medical data encourages meaningful research and quality improvement. However, there is a big concern that improper disclosure may put sensitive personal information at risk. To maintain the research benefits and customize the privacy protection, we propose a novel and practical randomized response model (k-shuffle) and a statistical information recovery procedure. The former mixes distribution of patient records with samples drawn from k-1 pre-determined distributions to ensure differential privacy. The latter allows data receivers to recover statistical properties (e.g., the mean and variance) of interested sub-populations with accuracy proportional to the size of the sub-population. That is, our algorithm provides stronger privacy protection to smaller groups, and offers high data usability to studies targeted at larger population. Most importantly, with differential privacy guarantee, data receiver cannot reconstruct the record-to-identity mapping for each individual. In summary, our approach offers a scalable privacy-preserving data dissemination mechanism that can be applied in both centralized and distributed fashion, which makes it possible for perturbed data to be outsourced (in the cloud) with mitigated privacy risks. Our experimental results demonstrated the performance of our model in terms of privacy protection, information loss, and classification accuracy using both synthetic and real-world datasets.
Privacy-Preserving Biometric System for Secure Fingerprint Authentication	Privacy is an important concern when biometrics are used in authentication systems for accessing Electronic Health Records (EHR) or other biomedical research data repositories involving human subjects. Biometrics of individuals deserve careful protection because they contain sensitive information closely related to personal privacy (e.g., personal health, ethnic group, etc.) and the leakage of such information can be used to re-identify individuals. More importantly, biometrics are unique and they are not easily revocable. Existing secure biometric systems prevent attackers from collecting unprotected biometrics in databases, however, they cannot guarantee confidentiality in probing and transmitting biometrics.
Privacy, Preservation and Performance: The 3 P's of Distributed Data Management	Privacy, preservation and performance ("3 P's") are central design objectives for distributed data management systems. However, these objectives tend to compete with one another. This paper presents a model for describing distributed data management systems, along with a framework for measuring the privacy, preservation and performance offered by such systems. The framework enables a system designer to quantitatively explore and optimize the tradeoffs between the 3 P's.
Protecting privacy of children in social networking sites with rule-based privacy tool	With the growing use of social networking sites (SNS) such as Facebook, MySpace and Twitter, privacy issues have become a major concern especially for children nowadays. There is no doubt that this new form of communication is gaining popularity nowadays. SNS offer many benefits such as reconnecting long lost friends and communicating with each other by just sitting in front of the screen. However, it raises many ethical and social issues and privacy is one of them. Users are often exposed to various threats and violations because they do not know how to protect their personal information from being revealed to strangers. Hence, a system is needed to assist children in managing and controlling their privacy settings. The privacy management system proposed in this study is based on a rule-based expert system which is used to emulate human intelligence by using rules and conditions. The rules, which are the main component in a rule-based system, are used to determine the suitable privacy settings for children. The privacy settings are based on the recommendation obtained from a questionnaire given to the parents who have a Facebook account and are aware of how to manage and protect their privacy.
VANET-based privacy preserving scheme for detecting traffic congestion	We propose a VA NET-based (Vehicular Ad hoc NETwork), privacy-preserving, distributed, collaborative traffic congestion detection and dissemination system that conserves bandwidth and provides drivers with real-time information on traffic congestions over long distances. The system uses vehicles equipped with simple inexpensive devices, as gatherers and distributors of information without the need for costly road infrastructure such as sensors, cameras or external communication equipment. Each vehicle is assumed to be equipped with a Global Positioning System (GPS) device that provides with vehicle's current location, a real-time clock and a wireless communication device such as a two-way radio that allows it to communicate with vehicles nearby. The vehicles broadcast their current location, speed and direction at fixed time intervals. Our simulation results show that our solution addresses location privacy concerns and uses aggregation in the form of congestion sections to reduce bandwidth consumption.
MedSN System for In-Home Patient Monitoring: Architecture, Privacy and Security	The application of sensor networking to real-time healthcare monitoring is an important and developing area of research. Key research issues include the design of an adaptable system for information flow from one subset of users of the system (the patients, families, neighbors, etc.) to another (healthcare professionals) and the development of a value-centered design approach that preserves the privacy rights accorded to these users. In any health monitoring system, a patient's privacy is always at risk. We propose MedSN, a continuous health monitoring system, which addresses thelimitations of existing projects. This is achieved through support for an extended set of users with competing interests, integrated with an end-to- end consideration of privacy and security.
A New Grid-Based Cloaking Algorithm for Privacy Protection in Location-Based Services	In Location-Based Services (LBSs), users send location-based queries to LBS servers along with their exact locations, but the location information of the users can be misused by adversaries. For this, a mechanism to deal with the userspsila privacy protection is required. In this paper, we propose a new cloaking algorithm for privacy protection in LBSs. Our cloaking algorithm can support both k-anonymity and l-diversity. That is, it first creates a minimum cloaking region by finding l buildings (l-diversity) and then finds k users (k-anonymity). To generate the minimum cloaking region efficiently, we make use of a grid structure for storing buildings and users as well as a pruning technique for reducing unnecessary computation. Finally, we show from our performance analysis that our cloaking algorithm outperforms the existing grid-based cloaking algorithm, in terms of the size of cloaking regions, their creation time and query processing time based on them.
Enhancing data privacy and integrity in the cloud	Cloud computing is a new computing paradigm in which dynamically scalable resources are provided as a service over the Internet. One central concern in cloud computing is the privacy and integrity of data processed at the cloud. In this paper, we propose blind processing service using trusted computing mechanisms to provide improved privacy and integrity to potential users. Utilizing blind communication and execution services, a user exchanges his/her sensitive information with a cloud system via isolated processes whose execution environment and data is shielded from the rest of the system after ensuring the system has correct hardware, trusted computing base, correct credentials, and trustworthy state.
Access control enforcement on outsourced data ensuring privacy of access control policies	Nowadays, data outsourcing has become a solution for many organizations especially large scale enterprises due to the high costs of in-house management of the rapidly growing data. Among all security requirements in this context, user access control and its following dynamic changes are of interest. In this paper, we propose an efficient and reliable mechanism to solve this problem in owner-write-users-read applications. A novel solution is introduced to enforce access control on outsourced data using the Chinese Remainder Theorem. The solution allows updating policy changes at a limited cost in terms of both computational power and the number of users' secret keys. Although the server, on which data is stored, is delegated for enforcing access control, access control policies are protected from being revealed to the server or the users. The solution is applicable to data outsourcing scenarios where users are anonymous but the server is still able to enforce the owner access control policies.
An Approach to Protect the Privacy of Cloud Data from Data Mining Based Attacks	Cloud computing has revolutionized the way computing and software services are delivered to the clients on demand. It offers users the ability to connect to computing resources and access IT managed services with a previously unknown level of ease. Due to this greater level of flexibility, the cloud has become the breeding ground of a new generation of products and services. However, the flexibility of cloud-based services comes with the risk of the security and privacy of users' data. Thus, security concerns among users of the cloud have become a major barrier to the widespread growth of cloud computing. One of the security concerns of cloud is data mining based privacy attacks that involve analyzing data over a long period to extract valuable information. In particular, in current cloud architecture a client entrusts a single cloud provider with his data. It gives the provider and outside attackers having unauthorized access to cloud, an opportunity of analyzing client data over a long period to extract sensitive information that causes privacy violation of clients. This is a big concern for many clients of cloud. In this paper, we first identify the data mining based privacy risks on cloud data and propose a distributed architecture to eliminate the risks.
Privacy-preserving data mining on data grids in the presence of malicious participants	Data privacy is a major threat to the widespread deployment of data grids in domains such as health care and finance. We propose a novel technique for obtaining knowledge - by way of a data mining model - from a data grid, while ensuring that the privacy is cryptographically secure. To the best of our knowledge, all previous approaches for solving this problem fail in the presence of malicious participants. In this paper we present an algorithm which, in addition to being secure against malicious members, is asynchronous, involves no global communication patterns, and dynamically adjusts to new data or newly added resources. As far as we know, this is the first privacy-presenting data mining algorithm to possess these features in the presence of malicious participants. Simulations of thousands of resources prove that our algorithm quickly converges to the correct result. The simulations also prove that the effect of the privacy parameter on the convergence time is logarithmic.
An efficient authentication protocol supporting privacy in mobile computing environments	The anticipated increase in mobility and popular use of mobile services will require more technologies for authenticating mobile hosts and protecting their privacy. However, issues such as privacy and confidentiality in mobile computing environments and the resource restriction of mobile hosts have not been given enough consideration. In this paper, we present an authentication protocol that provides mobile hosts with the functionalities of authentication and session key distribution for user privacy and secure communication. Considering mobile computing environments, our protocol has design principles such as reducing computation and communication overhead of mobile hosts, and uses random numbers, time-stamps, and authentication codes in order to protect systems from attacks by eavesdroppers. While our protocol supports authentication, secure communication, anonymity, and untraceability for mobile hosts, it can be an efficient authentication protocol for mobile computing environments.
Transforming Privacy Policies to Auditing Specifications	With more and more personal data being collected and stored by service providers, there is an increasing need to ensure that their usage is compliant with privacy regulations. We consider the specific scenario where policies are defined in metric temporal logic and audited against the database usage logs. Previous works have shown that this can indeed be achieved in an efficient manner for a very expressive set of policies. One of the main ingredients of such an auditing process is the availability of sufficient database logs. Currently, it is a manual process to first determine the logs needed, and then come up with the necessary auditing specifications to generate them. This is not only a time consuming process but can be erroneous as well, leading to either insufficient or redundant logging. Logging in general is costly as it is an overhead on the real-time database performance, and hence redundant logging is not an alternative either. Our contribution in this work is to streamline the log generation process by deriving the auditing specifications directly from the policies to be audited. We also show how the required logging can be minimized based on the temporal constraints specified in the policies. Given privacy policies as input, the output of the proposed tool is the corresponding auditing specifications that can be installed directly in the databases, to produce logs that are both minimal and sufficient to audit the given policies. The tool has been implemented and tested in a real-life scenario.
Audit based privacy preservation for the OpenID authentication protocol	This paper studies a privacy vulnerability within OpenID, a distributed single sign on protocol. An OpenID system consists of three components: User Agent (UA); Relying Party - A web application that a UA would like to authenticate with using their unique identifier; and Identity Provider - A web server that provides a globally unique identifier for the UA and validates the identity of UAs on behalf of Relying Parties. The privacy vulnerability has been identified in existing literatures. However, no effective solution has been proposed to date. In this paper, we present an effective scheme to mitigate this vulnerability. In order for OpenID to gain wider acceptance, this vulnerability must be addressed with a solution that is convenient to the users of single sign on. We propose a method for mitigating this vulnerability by creating vertical levels of trust between constituents of an OpenID network through expanding the role of OpenID Identity Providers to include auditing OpenID Relying Parties for privacy vulnerabilities. In addition, Identity Providers may keep records of audits that identify Relying Parties that do not protect the privacy of OpenID users. The primary issue with this privacy vulnerability is that it is completely transparent - it occurs without the user ever being aware that it is happening. We cannot force Relying Parties to guarantee the privacy of OpenID users, nor would we like to burden individual users with browser level solutions that are often overly technical and difficult to understand. We have designed an audit solution at the level of the Identity Provider, which can accurately inform users when Relying Parties may be sharing information with third parties, therefore giving OpenID users the ability to make a conscious choice to share that information. We have performed real network experiments to validate our scheme, and the experimental results show that our scheme is effective.
Secure and privacy-preserving querying of content in MANETs	Ensuring security and privacy of content in a mobile ad-hoc network (MANET) is a challenging problem, especially when that content is distributed over the network using some form of peer-to-peer dissemination scheme. Since cooperation among nodes is vital in MANETs, the capture or compromise of a single node not only exposes locally cached content, but also allows an adversary to interrogate the network with the authority of an insider, acquiring important information such as content access patterns, popularity and location. Previous work in MANETs has predominantly focused on providing solutions for security and anonymity of routing protocols, confidentiality, and key management. In this paper, we present protocols that provide the ability to securely and privately locate content for two common peer-to-peer dissemination operations: publish/subscribe (content PUSH), and direct query (content PULL).
Freedom of Expression, Access to Information, and Privacy Protection	International organizations, governments, academia, industry, and the media have all begun to grapple with the information society as a global policy issue. The first United Nations World Summit on the Information Society (WSIS), held in December 2003, recognized the connections between information technology and human rights with a Declaration of Principles--in effect, the first "constitution" for cyberspace--that called for the development of the information society to conform to recognized standards of human rights. Critical issues in the policy debates around WSIS have been the so-called digital divide, which reflects a knowledge divide, a social divide, and an economic divide; and the need for a nondiscriminatory information society to provide universal access to information technology in local languages throughout the developing world. Other crucial issues include the regulatory frameworks for information access and ownership and such basic freedoms as the right to privacy. The contributors to this timely volume examine the links between information technology and human rights from a range of disciplinary perspectives. Scholars, human rights activists, and practitioners discuss such topics as freedom of expression, access to information, privacy, discrimination, gender equality, intellectual property, political participation, and freedom of assembly in the context of the revolution in information and communication technology, exploring the ways in which the information society can either advance human rights around the world or threaten them. An afterword reports on the November 2005 WSIS, held in Tunis, and its reaffirmation of the fundamental role of human rights in the global information society.Contributors:David Banisar, William Drake, Ran Greenstein, Anriett e Esterhuysen, Robin Gross, Gus Hosein, Heike Jensen, Rikke Frank J├â┬»├é┬┐├é┬╜├â┬»├é┬┐├é┬╜rgensen, Hans Klein, Charley Lewis, Meryem Marzouki, Birgitte Kofod Olsen, Kay Raseroka, Adama Samass├â┬»├é┬┐├é┬╜├â┬»├é┬┐├é┬╜kou, Mandana Zarrehparvar
Privacy as Freedom	This chapter contains sections titled: Privacy and Freedom, Privacy as a Threat, Secondary to Other Rights, Privacy as Law and Regulation, Informational Privacy, Key Threats to Privacy in the Information Society, Surveillance of All Activity, Privacy as Freedom, Privacy in an Open Information Society, Notes
Providing privacy preserving in Cloud computing	People can only enjoy the full benefits of Cloud computing if we can address the very real privacy and security concerns that come along with storing sensitive personal information in databases and software scattered around the Internet. There are many service provider in the internet, we can call each service as a cloud, each cloud service will exchange data with other cloud, so when the data is exchanged between the clouds, there exist the problem of disclosure of privacy. So the privacy disclosure problem about individual or company is inevitably exposed when releasing or sharing data in the cloud service. Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. Our paper provides some privacy preserving technologies used in cloud computing services.
Understanding users! Perception of privacy in human-robot interaction	Previous research has shown that design features that support privacy are essential for new technologies looking to gain widespread adoption. As such, privacy-sensitive design will be important for the adoption of social robots, as they could introduce new types of privacy risks to users. In this paper, we report findings from our preliminary study on users' perceptions and attitudes toward privacy in human-robot interaction, based on interviews that we conducted about a workplace social robot.
The effect of monitoring by cameras and robots on the privacy enhancing behaviors of older adults	This paper describes the results of an experimental study in which older adult participants interacted with three monitoring technologies designed to support their ability to age in place in their own home - a camera, a stationary robot, and a mobile robot. The aim of our study was to evaluate users' perceptions of privacy and their tendencies to engage in privacy enhancing behaviors (PEBs) by comparing the three conditions. We found that privacy concerns lead older adults to change their behavior in a home environment while being monitored by cameras or embodied robots. We expected participants to engage in more PEBs when they interacted with a mobile robot, which provided embodied cues of ongoing monitoring; surprisingly, we found the opposite to be true - the camera was the condition in which participants performed more PEBs. We describe the results of quantitative and qualitative analyses of our survey, interview, and observational data and discuss the implications of our study for human-robot interaction, the study of privacy and technology, and the design of assistive robots for monitoring older adults.
RBAC-Based Access Control Framework for ensuring Privacy in Ubiquitous Computing	The ubiquitous computing environment is an environment that freely shares all data anytime, anywhere, and through any device without considering constraints. However, the personal or private information in ubiquitous computing could be disclosed, shared from anyone, or used maliciously without consent from the owner of the data. Thus, privacy is one of the major issues in such an environment. Of many security methods, which are able to protect the privacy, The role-based access control (RBAC) model, a typical access control model within the enterprise environment, has been widely studied, applied to various applications, and implemented. However, much existing research for access control has not solved the privacy concerns within ubiquitous computing. This paper proposes a method and framework of user-centric and efficient access control to handle personal privacy within ubiquitous computing environment by using both proposed model based on core component of RBAC model and privacy policies
Symmetric Encryption in RFID Authentication Protocol for Strong Location Privacy and Forward-Security	RFID tag carries vital information in their operation and thus concerns on privacy and security issues do arise. The problem of traceability is critical in open radio frequency environments. An adversary can trace and interact with tag and this is referred as tracking. Nevertheless, with a strong authentication mechanism, uprising security problems in RFID systems can be solved. We had demonstrated current vulnerabilities and proposed our authentication mechanism to overcome them. As long as the secret information stays secret, tag forgery is not possible. Targeting RFID tag with short tag ID, we employ a resource friendly symmetric encryption scheme, which is a stream cipher building block to enhance the security features in active type RFID tag.
Supporting Secure Authentication and Privacy in Wireless Computing	The IEEE 802.11 standard for wireless LAN communications introduced the Wired Equivalent Privacy(WEP) protocol in an attempt to bring the security level of wireless systems closer to that of wired ones. Unfortunately, WEP falls short of accomplishing its security goals. Despite employing the well-known and believed-secure RC4 cipher, WEP contains several major security flaws. The flaws give rise to a number of attacks, both passive and active, that allow eavesdropping on, and tampering with, wireless transmissions. The IEEE 802.1x framework, what was known to have improved the IEEE 802.11b??s weakness in user authentication, is a port-based authentication protocol. The IEEE 802.1x does not specify an authentication method, although the most common approach for WLANs is EAP, which is a framework for a variety of authentication methods. However, the IEEE 802.1x is also vulnerable to Denial of service and session high-jacking attacks due to the lack of AP authentication and encryption mechanism. In this paper, we propose a Wireless LAN secure system that offers secure encrypted communication and user authentications. The purpose of the WLAN secure system that this study suggests is to improve the weakness in security of IEEE 802.1x and to guarantee a secure encrypted communication. The proposed system does not allow any faking of the identity by performing a thorough mutual authentication to all associated objects. Furthermore, it provides an integrity service by encrypting EAP-SUCCESS messages with distributed a new shared-key through the key distribution mechanism when an authentication process is executed, and securing the encrypted communication by using the 128 bit-length key.
Multi-Policy Access control considering Privacy in Ubiquitous Environment	In ubiquitous environment, the connected devices can be aware the status of users and provide the information to users automatically in anytime, anywhere. However, it requires more security technologies to protect private information. In this paper, we propose it allows automatically a user be aware the information what he wants. The proposed mechanism defines extended context roles from current RBAC. It controls the accesses to privacy in ubiquitous environment. It employs multi-policy to constrain privacy and role-data objects. Hence, when there is an access to one of them, the mechanism refers to the current context and determines whether accept it or not. We also provide advanced security authorization and analysis of our model and show how we preserve safety properties in spite of dynamic changes to access control permissions
Privacy preserving techniques for storage privacy attacks: A survey	Data mining is a process of extracting knowledge from large amount of data. In recent year privacy preserving data mining has been developed by research community working on knowledge modification and security. The collected data sample may be leaked while residing in storage or stolen anytime during the storing process. Hence protections of such data samples become increasingly important. In this paper we provide a review of preventing such attacks on third parties for the whole lifetime of the samples. We discuss different techniques like randomization method, anonymization method for preserving the privacy of storage data.
Privacy preserving mining of Association Rules on horizontally and vertically partitioned data: A review paper	Data mining can extract important knowledge from large database - sometimes this database is split among various parties. Here, the main aim of privacy preserving data mining is to find the global mining results by preserving the individual sites private data/information. Many Privacy Preserving Association Rule Mining (PPARM) algorithms are proposed for different partitioning methods by satisfying privacy constraints. The various methods such as randomization, perturbation, heuristic and cryptography techniques are proposed by different authors to find privacy preserving association rule mining in horizontally and vertically partitioned databases. In this paper, the analysis of different methods for PPARM is performed and their results are compared. For satisfying the privacy constraints in vertically partitioned databases, algorithm based on cryptography techniques, Homomorphic encryption, Secure Scalar product and Shamir's secret sharing technique are used. For horizontal Partitioned databases, algorithm that combines advantage of both RSA public key cryptosystem and Homomorphic encryption scheme and algorithm that uses Paillier cryptosystem to compute global supports are used. This paper reviews the wide methods used for mining association rules over distributed dataset while preserving privacy.
A publication process model to enable privacy-aware data sharing	As the Internet continues to permeate and connect communities, businesses, and things, there is an increasing demand for new approaches and technologies to analyze and synthesize data generated from diverse and distributed sources. In addition, this data must be accessible to a set of users having different analytic objectives and viewpoints. We examine these topics in light of the growing number of data consortia in sectors such as finance and healthcare, whose role is to share data among a set of contributing members. We address the need for data consortia to apply data customization and context-alignment services to make heterogeneous data relevant for its subscribers. Such services include record linkage, record selection, and scaling and homogeneity analysis. In addition, the often personal or business-sensitive nature of such data requires that privacy-preservation methods be employed to avoid improper disclosures. We provide a publication process model for data consortia that allow users to extract the maximum amount of information from these heterogeneous databases in a privacy-aware manner. We describe the Operational Riskdata eXchange (ORX) as a successful case study to illustrate these concepts.
Data-centric security: Integrating data privacy and data security	Classifying data according to its permissible use, appropriate handling, and business value is critical for data privacy and security protection. This is essential for compliance with the constantly evolving regulatory landscape concerning protected data. Problems arise when users compromise data privacy and security by overlooking the critical need to manage data according to these requirements. This paper considers the creation and application of data classification systems for security and privacy purposes. It focuses primarily on classifying information in a meaningful way through the use of a partially automated methodology that normalizes and classifies structured data throughout an enterprise. We introduce the three pillars of the data-centric security model, which are based on the data-centric security classification offering by IBM Global Business Services (GBS) and the IBM Research Division. In particular, we describe the data classification pillar of the data-centric security architecture, which provides the framework and method for partially automated classification of data to meet the demands of compliance standards.
Analysis of privacy and security policies	The distributed nature of the environment in which privacy and security policies operate requires tools that help enforce consistency of policy rules across different domains. Furthermore, because changes to policy rules are required as policies evolve over time, such tools can be used by policy administrators to ensure the consistency of policy changes. In this paper, we describe a number of different policy analysis tools and techniques that we have developed over the years and present them in a unified framework in which both privacy and security policies are discussed. We cover dominance analyses of general policies, conflicts among authorizations and prohibitions, and other analyses of obligations, as well as policy similarity analysis and policy distribution.
Privacy is essential for secure mobile devices	This paper contradicts the commonly held view that privacy and security of data must sometimes be sacrificed for the sake of national security. We demonstrate that for specific examples of real mobile devices, such as mobile phones, Wi-Fit┬«, electronic passports, and electronic government-employee ID cards, lack of sufficient attention to privacy actually harms the intended national security applications. We then present as a case study the Caernarvon high-security smart-card operating system developed by IBM, to show the feasibility of harmonizing personal privacy and security requirements with national security needs.
A privacy-aware architecture for a Web rating system	Net Trust is a fraud-detection application that enhances security while protecting privacy. Net Trust identifies fraudulent Web sites by aggregating individual opinions, user-selected browsing histories, and third-party information. In this paper, we examine the security properties intrinsic to the implementation of the Net Trust ratings system. The ratings system protects against attacks by limiting diffusion of information to those with whom there is an off-line trust relationship. We also propose a rich-client/ thin-server implementation architecture and examine the privacy properties of this architecture. The privacy properties function not only to prevent the compromising of user confidentiality, but also to make the ratings system more robust. By utilizing trusted off-line social networks, Net Trust enhances the security and privacy of the ratings data. The implementation architecture maintains high data availability while empowering browser-history owners with final control over data access. The Net Trust analysis we present illustrates the mutual reinforcement of individual privacy (defined as user control over personal information) and security (defined as the resiliency of data confidentiality and the efficacy of the rating system).
Policy framework for security and privacy management	Policies that address security and privacy are pervasive parts of both technical and social systems, and technology that enables both organizations and individuals to create and manage such policies is a critical need in information technology (IT). This paper describes the notion of end-to-end policy management and advances a framework that can be useful in understanding the commonality in IT security and privacy policy management.
Harmonizing privacy with security principles and practices	During the development of a software system, the process of requirements elicitation gathers both functional requirements (i.e., what the system should do) and nonfunctional requirements (i.e., what the system should be). Computer science and software engineering education have traditionally addressed the former more than the latter, because it is easier to test that functional requirements have been properly implemented. Within the category of nonfunctional requirements, the privacy requirements engineering process is less mature than that of security engineering, and underlying engineering principles can give little attention to privacy requirements. In this paper, we discuss how security and privacy requirements engineering can be taught as necessary aspects of software development. We suggest that the best way to harmonize security and privacy requirements is to link information systems experts with computer scientists with the goal of addressing the key issues that prevent systems from implementing effective security and privacy.
Privacy-value-control harmonization for RFID adoption in retail	Privacy concerns have, at least in part, impeded the adoption of radio frequency identification (RFID) in retail. The adoption of other automatic identification (auto-ID) applications shows that consumers often are willing to trade their privacy or their control of personal information against some value afforded by the application. In this paper, the interplay between privacy, value, and control is examined through a literature survey of four auto-ID applications: mobile phone, electronic toll collection, e-passports, and loyalty programs. The consumer value proposition for the use of RFID in retail is investigated through an online survey exploring end-user perceptions. The results of the survey are: 1) the customer value proposition has not been communicated well to customers; 2) privacy concerns are higher than other previously adopted applications despite similar privacy issues; and 3) harmonization of privacy, value, and control is likely to be achieved only after adoption, when customers will be educated through experience with the application.
A technology perspective on worldwide privacy regulations	In this paper we provide an overview of the worldwide privacy regulatory landscape from a technology perspective. We focus on data-centric definitions of personal information and then examine how these differ across different regulatory frameworks, such as the ones issued by the Organization for Economic Cooperation and Development, the European Union, the Asia Pacific Economic Cooperation, and the U.S. state laws. We discuss some of the challenges facing privacy regulatory bodies and involving leading-edge technologies, such as event data recorders, social networking Web sites, radio frequency identification, and national identification cards. Finally, we connect the regulatory environment with common security technologies that may assist organizations in complying with privacy requirements.
The Commercial Data Masking Facility (CDMF) data privacy algorithm	The Commercial Data Masking Facility (CDMF) algorithm defines a scrambling technique for data confidentiality that uses the Data Encryption Algorithm (DEA) as the underlying cryptographic algorithm, but weakens the overall cryptographic operation by defining a key-generation method that produces an effective 40-bit DEA key instead of the 56 bits required by the full- strength DEA. In general, products implementing the CDMF algorithm in an appropriate manner may be freely exported from the USA. The algorithm is thus intended as a drop-in replacement for the DEA in cryptographic products. Discussed in this paper are the design requirements, rationale, strength, and applications of the CDMF algorithm.
Privacy and knowledge management: Challenges in the design of the Lotus Discovery Server	The Lotus Discovery ServerΓäó (LDS) is a knowledge management system that lets users browse and search for information and expertise, collaborate instantly with colleagues, share knowledge, and look for resources, in a time-efficient manner. Because a knowledge management system has the power to make visible what was previously obscure, privacy issues are of particular concern. This paper discusses what the LDS product team learned about privacy issues in an enterprise knowledge management product, how it learned these things, and what steps the team took to protect users' privacy, allay their concerns, and promote the value of the product.
Enhancing security and privacy in biometrics-based authentication systems	Because biometrics-based authentication offers several advantages over other authentication methods, there has been a significant surge in the use of biometrics for user authentication in recent years. It is important that such biometrics-based authentication systems be designed to withstand attacks when employed in security-critical applications, especially in unattended remote applications such as e-commerce. In this paper we outline the inherent strengths of biometrics-based authentication, identify the weak links in systems employing biometrics-based authentication, and present new solutions for eliminating some of these weak links. Although, for illustration purposes, fingerprint authentication is used throughout, our analysis extends to other biometrics-based methods.
Practical server privacy with secure coprocessors	What does it take to implement a server that provides access to records in a large database, in a way that ensures that this access is completely privateΓÇöeven to the operator of this server? In this paper, we examine the question: Using current commercially available technology, is it practical to build such a server, for real databases of realistic size, that offers reasonable performanceΓÇöscaling well, parallelizing well, working with the current client infrastructure, and enabling server operators of otherwise unknown credibility to prove their service has these privacy properties? We consider this problem in the light of commercially available secure coprocessorsΓÇöwhose internal memory is still much, much smaller than the typical database sizeΓÇöand construct an algorithm that both provides asymptotically optimal performance and also promises reasonable performance in real implementations. Preliminary prototypes support this analysis, but leave many areas for further work.
Privacy-preserving concordance-based recommendations on vertically distributed data	Recommender systems are attractive components of e-commerce. Customers apply such systems to get help for choosing the appropriate product to purchase. To provide accurate and dependable referrals, recommender systems require sufficient user data. On the other hand, since people purchase products from different online vendors, collected user data for recommendation purposes might be distributed among several e-companies. Consequently, due to distributed data, such companies having inadequate data cannot provide truthful predictions. To overcome this challenge, data holders might want to collaborate. However, due to privacy and financial fears, they might hesitate to partnership. In this paper, we propose a concordance measure-based solution that enables data holders to produce recommendations without jeopardizing their privacy. We perform real data set-based experiments and analyze the solution in terms of privacy and extra costs. The experimental results show that e-companies can produce more accurate recommendations by employing the provided scheme.
A review of mobile location privacy in the Internet of Things	The goal of Internet of Things (IoT) research is to extend computing and connectivity to anything, anyone, anywhere and anytime. While there are apparent benefits in using IoT systems, the convergence of technologies has begun to challenge the privacy of users. Powered by location based services, these systems have the potential to enable a systematic mass surveillance and to impinge on the personal privacy of users, especially their location privacy. This paper overviews some of the existing location privacy issues found on mobile devices. Particular attention is paid to the current access permission mechanism used on the Android, iPhone and Windows Mobile platforms. It is anticipated that the current privacy issues in mobile platforms are more likely to be inherited if not magnified in the IoT.
Development of privacy-preserving RFID authentication system using mobile devices	A mobile RFID system is a radio frequency identification technology that allows users to read the information on its tags. Systems that allow free reading of tags with mobile RFID reader devices represent a significant risk to individual privacy because unauthorized individuals may easily obtain personal information from the tags. In addition, the fixed ID values on tags can be used to track users in network segments. Although various solutions have previously been proposed to resolve this RFID privacy problem, most require numerous calculations to be performed on the tags. Therefore, these techniques require active tags with high-capacity embedded processors, which are expensive. In addition, it is not practical to apply these techniques to a mobile RFID system based on passive tags attached to devices because of not only the high price but also the bulkiness of the tags themselves. In this paper, we propose an efficient protocol for authentication, which allows transferring of the heavy calculations to the mobile reader devices, thus requiring only the resulting values to be stored on the tags. This study mainly focuses on improving the limitations of existing RFID authentication protocols, which usually assume active tags. The proposed protocol achieves the same security level and performance that can be obtained through active tags. To evaluate the performance of the proposed protocol, we implemented it using EPC Gen-2 tags, a smartphone, a UHF RF dongle, and a database. The proposed protocol meets various security requirements such as tag protection and location- and traffic-tracking prevention. The proposed protocol also meets other requirements such as lightweightness and the desired level of performance.
Privacy-preserving cross-user source-based data deduplication in cloud storage	Cloud storage services possibly store only a single copy of redundant data to save disk space and provide links to that copy rather storing other actual copies of data. This is called deduplication. If deduplication is performed across different accounts at each client side, this is classified into cross-user source-based deduplication. However, cross-user source-based deduplication can server as a side-channel of breaching user's privacy. To protect user's privacy, Harnik et al. proposed a randomized solution for cross-user source-based deduplication, user's privacy is, however, still at risk with a high probability. In this paper, we propose a new cross-user source-based deduplication providing dramatically enhanced security.
Managing your privacy in an on-line world	In our changing world, it's becoming harder and harder to keep secrets. Government agencies maintain profiles on each of us, credit card companies record every transaction we make, and mailing lists sell our addresses and telephone numbers to anyone who wants to buy them. This has caused much alarm, and at first glance it seems that the Internet and the World Wide Web are rapidly making things worse. Already, there are many sites that let anyone look up our addresses and telephone numbers. Nevertheless, in this article, I argue that the Web actually offers an opportunity to improve our lives by managing the invasions of our privacy
Some privacy issues in knowledge discovery: the OECD personal privacy guidelines	Several countries have generated principles to protect individuals from the potential invasion of privacy that data collection and retrieval poses. The Organization for Economic Cooperation and Development (OECD) has provided probably the best known set of guidelines. A number of countries have adopted these guidelines as statutory law, in whole or in part. The OECD has specific guidelines pertaining to data privacy that directly affect those performing knowledge discovery generally, and those who use so called ΓÇ£personal dataΓÇ¥ in particular. The article addresses such questions as: What are the implications of the existing privacy guidelines, especially those of the OECD, for knowledge discovery? What are the limitations of these guidelines? How do the restrictions on knowledge discovery about individuals affect knowledge discovery on groups? How do legal systems influence knowledge discovery?
A Secure and Privacy Friendly 2D+3D Face Authentication System Robust Under Pose and Illumation Variation	An end-to-end face authentication system integrating 2D color images and depth data is presented in this paper, based on a low-cost sensor capable of real-time acquisition of 3D images and associated color images. Depth data is used for robust face detection, localization and 3D pose estimation, as well as for compensating pose and illumination variations of facial images prior to classification. The performance of the proposed system is tested on an extended face database recorded in real-world conditions, while a complete security and privacy analysis is conducted in order to ensure that all necessary countermeasures are built into the system.
Privacy-preserving SVM of horizontally partitioned data for linear classification	When we use support vector machine (SVM) to solve the classical classification problem, we should know all data. However, the data sometimes can reveal private information which is protected by laws. So recently, there has been growing focus on finding solutions to get a SVM classifier without revealing any information of the privately-held data. In this paper, we propose a new method which is ameliorated from the usual SVM to solve this problem over horizontally partitioned data which can protect the private information of the data completely. And under some special conditions, the model provided in this paper can achieve same accuracy with the usual SVM constituted by the original data. The experiments on real datasets show that the classification accuracy of our proposed method on the protected data is approximate to the SVM classifier on the original data.
Security analysis for privacy preserving search of multimedia	With the increasing popularity of digital multimedia such as images and videos and the advent of the cloud computing paradigm, a fast growing amount of private and sensitive multimedia data are being stored and managed over the network cloud. To provide enhanced security and privacy protection beyond traditional access control techniques, privacy preserving multimedia retrieval techniques have been proposed recently to allow content-based multimedia retrieval directly over encrypted databases and achieve accurate retrieval comparable to conventional retrieval schemes. In this paper, we introduce a security definition for the privacy preserving retrieval scenario and show that the recently proposed schemes are secure under the proposed security definition.
Restricted H.264/AVC video coding for privacy region scrambling	Scrambling is widely used to protect privacy in surveillance video. However, as a critical issue in privacy protected video scrambling, drift error has not been adequately studied. In this paper, we focus on drift error prevention for different elements scrambling in privacy protected H.264/AVC video, which is the prevailing coding standard. A restricted coding scheme is proposed to prevent drift error in Transform Coefficient (TC), Intra Prediction Mode (IPM) and Motion Vector (MV) scrambling, respectively. Experiments show that the proposed scheme effectively prevents drift error with coding efficiency dramatically improved.
An attribute-based framework for privacy preserving image querying	We are specifically concerned with scenarios in which multimedia data is stored once on the server and the same data is queried by multiple parties. We propose a framework for privacy preserving querying, in which encryption is performed only once, and the ciphertexts are stored on a database server. Rather than using public-key homomorphic cryptosystems, the parties querying the database first derive an ΓÇ£attributeΓÇ¥ from their query signal. They can decrypt the server's ciphertext only if their attribute satisfies a specified mathematical condition. This query-specific decryption capability makes attribute-based cryptography a vital addition to the secure signal processor's toolkit. We give an example of a construction for privacy preserving querying, in which a client can privately retrieve an image from the server if attribute vectors extracted from the server's and client's images are close enough in Euclidean distance.
Privacy protected image denoising with secret shares	The proliferation of digital cameras, wireless networks and distributed computing make sharing of visual data easier than ever. Such casual exchange of data, however, has increasingly raised questions on how sensitive visual information can be protected. Encrypted-domain signal processing techniques based on homomorphic encryption and garbled circuits are increasingly applied for such applications. Their high computation and communication complexity, however, are not suitable for pixel-level processing. In this paper, we propose an alternative approach of using information-theoretically secure protocols over multiple non-colluding semi-honest computing agents. The proposed protocols are based on classical Shamir's secret sharing scheme which supports multiplication and addition in the random-share domain. We extend the sharing scheme to handle other fundamental signal processing operations and use them to develop a novel privacy-protected wavelet denoising scheme over three computing agents. Our experimental results demonstrate the viability of using information-theoretic secure protocols to safeguard privacy in distributed pixel-level processing.
Delivery method for viewer-specific privacy protected video using discrete wavelet transform	This paper presents a delivery method for viewer-specific privacy protected video, where ΓÇ£viewer-specificΓÇ¥ implies that the way of privacy protection (e.g., box, mosaic, transparency) varies according to viewer's authority. In this method, in order to reduce the load of a delivery server, viewer-specific privacy protected videos are not produced at the delivery server, but they are produced at each viewer's terminal. The delivery server extracts and decomposes the information of human objects, and then embeds the information into background images using information hiding technique. Each viewer extracts a part of the decomposed information of human objects according to his/her authority, and then produces privacy protected video by integrating the extracted information. In this method, the discrete wavelet transform (DWT) plays a key role. The proposed method is evaluated through experiments.
Hiding privacy information in video surveillance system	This paper proposes a detailed framework of storing privacy information in surveillance video as a watermark. Authorized personnel is not only removed from the surveillance video as in J. Wickramasuriya et al. (2004) but also embedded into the video itself, which can only be retrieved with a secrete key. A perceptual-model-based compressed domain video watermarking scheme is proposed to deal with the huge payload problem in the proposed surveillance system. A signature is also embedded into the header of the video as in M. Pramateftakis et al. (2004) for authentication. Simulation results have shown that the proposed algorithm can embed all the privacy information into the video without affecting its visual quality. As a result, the proposed video surveillance system can monitor the unauthorized persons in a restricted environment, protect the privacy of the authorized persons but, at the same time, allow the privacy information to be revealed in a secure and reliable way.
On privacy and security in distributed visual sensor networks	There is a critical need to provide privacy assurances for distributed vision-based sensor networking in applications such as building surveillance and healthcare monitoring. To effectively address protection and reliability issues, secure networking and processing must be considered from system inception. This paper presents attacks that affect the data privacy in visual sensor networks and proposes privacy-promoting security solutions based on opponent detection via game-theoretic analysis and keyless encryption.
Privacy protecting visual processing for secure video surveillance	Privacy protection is important in video surveillance. In this paper, we address privacy protection related issues. First, based on questionnaire-based experiments we analyze personal sense of privacy from the viewpoint of the relationship between a viewer and a subject. With the analysis results, we introduce a privacy protected video surveillance system named PriSurv, which can adaptively protect subjects' privacy according to their privacy policy against each viewer. Then, we propose two methods of protecting individuals' privacy by controlling the disclosure of subjects' visual information. One uses a set of visual abstraction operators such as silhouette and dot, which gradually control subjects' visual information. The other uses an active appearance model (AAM) based masks which encode privacy information in the original face region. The latter method can be used especially when a subject's expression can be seen in the video and is characterized by the recoverability of the encoded privacy information.
Coding and encryption of visual objects for privacy protected surveillance	This paper presents a scheme for secure coding of arbitrarily-shaped visual objects. Called SecST-SPIHT, it employs SPIHT based coding along with selective encryption for efficient, secure storage and transmission of visual object shape and texture. The selective encryption utilizes a novel bit classification scheme which ensures protection of the entire code by encrypting only a small number of bits (less than 5% for securing shape and texture, and less than 0.5% for just the texture). The encryption is performed in the compressed domain and does not affect the rate-distortion performance of the coder. A parameter allows control over the strength of the encryption versus required processing overhead. The scheme can be employed in a privacy protected surveillance system, whereby visual objects of human subjects are encrypted so that the content is only available to certain entities, such as persons of authority, possessing the correct decryption key.
Managing privacy data in pervasive camera networks	Privacy protection of visual information is increasingly important as pervasive camera networks becomes more prevalent. The proposed scheme addresses the problem of preserving and controlling of the privacy visual data through two innovations. First, unlike the existing centralized control of privacy data, the proposed system allows individual users to make the final decision on every access to their privacy data. As such, it offers a much stronger form of privacy protection as the user no longer needs to trust, adhere or register his/her privacy preferences with a server. The second innovation is the development of a secure reversible data hiding scheme for embedding all the ownership information and privacy data into the obfuscated video bitstream. Not only has it resulted in an efficient design of protocols, the reversible data hiding allows perfect reconstruction of original data and supports arbitrary types of video obfuscation techniques. Impact of data hiding on bitrate and distortion is minimized through a rate-distortion optimization procedure and experimental results are provided to demonstrate its efficiency.
A discrete wavelet transform based recoverable image processing for privacy protection	This paper presents a novel scheme of a recoverable image processing for privacy protection in real-time video surveillance system. The privacy information is embedded into the video using information hiding. Thus, the original privacy information can be recoverable with secrete key if necessary. In the proposed system, the privacy information is defined as information of objects that consist of detailed data to recover the original image of objects. The scheme is based on discrete wavelet transform (DWT) which is used for generating privacy-protected low resolution image, as well as the high resolution data including privacy information. An amplitude modulo modulation based information hiding scheme is used to hide the privacy information. Experimental results have shown that the proposed system can reduce the amount of the privacy information significantly, and allows the privacy information to be revealed after being embedded in real time.
Privacy enablement in a surveillance system	This paper presents mechanisms for privacy protection in a distributed, multicamera surveillance system. The design choices and alternatives for providing privacy protection while delivering meaningful surveillance data for security and retail environments are described, followed by performance metrics to evaluate the effectiveness of privacy protection measures and experiments to evaluate these in retail store video. The paper concludes with a discussion including five principles for data presentation of privacy protection systems.
H.264/AVC video scrambling for privacy protection	In this paper, we address the problem of privacy in video surveillance systems. More specifically, we consider the case of H.264/AVC which is the state-of-the-art in video coding. We assume that regions of interest (ROI), containing privacy-sensitive information, have been identified. The content of these regions are then concealed using scrambling. More specifically, we introduce two region-based scrambling techniques. The first one pseudo-randomly flips the sign of transform coefficients during encoding. The second one is performing a pseudo-random permutation of transform coefficients in a block. The flexible macroblock ordering (FMO) mechanism of H.264/AVC is exploited to discriminate between the ROI which are scrambled and the background which remains clear. Experimental results show that both techniques are able to effectively hide private information in ROI, while the scene remains comprehensible. Furthermore, the loss in coding efficiency stays small, whereas the required additional computational complexity is negligible.
Privacy Preserving Pattern Classification	We give efficient and practical protocols for privacy preserving pattern classification that allow a client to have his data classified by a server, without revealing information to either party, other than the classification result. We illustrate the advantages of such a framework on several real-world scenarios and give secure protocols for several classifiers.
Image Feature Extraction in Encrypted Domain With Privacy-Preserving SIFT	Privacy has received considerable attention but is still largely ignored in the multimedia community. Consider a cloud computing scenario where the server is resource-abundant, and is capable of finishing the designated tasks. It is envisioned that secure media applications with privacy preservation will be treated seriously. In view of the fact that scale-invariant feature transform (SIFT) has been widely adopted in various fields, this paper is the first to target the importance of privacy-preserving SIFT (PPSIFT) and to address the problem of secure SIFT feature extraction and representation in the encrypted domain. As all of the operations in SIFT must be moved to the encrypted domain, we propose a privacy-preserving realization of the SIFT method based on homomorphic encryption. We show through the security analysis based on the discrete logarithm problem and RSA that PPSIFT is secure against ciphertext only attack and known plaintext attack. Experimental results obtained from different case studies demonstrate that the proposed homomorphic encryption-based privacy-preserving SIFT performs comparably to the original SIFT and that our method is useful in SIFT-based privacy-preserving applications.
Improving Scalability for RFID Privacy Protection Using Parallelism	In the ubiquitous environment of the next generation, RFID is predicted to occupy an important technical location and also expected to apply to various fields. However, the properties of tags in itself which is the core of RFID have a dysfunction like an invasion of privacy for user. An existing cryptanalytic protection scheme of the information leakage has a difficult problem to apply to RFID tags for privacy protection. We applied Ohkubo scheme to the protection of the tag's information efficiently in the RFID system environment using low-cost tags. But, this method has all information of tags to identify tag's ID and then performs the process of identification in sequence in the back-end server. These processes have lots of computations so that it has problems about scalability. In this paper, we are based on Ohkubo scheme to solve problems, and then analyze the parallelism with the Hellman's tradeoff method and divide it into nodes in parallel. As a result, we can reduce the computing complexity. So, we show the results to be enhanced the scalability.
HPPC-Hierarchical Petri-Net based Privacy nominal model approach for Cloud	This paper focusing on the data collected ubiquitously and conserved by cloud providers are assured that, the clients and users can assess that information globally as per their versatility, where as the cloud providers should gave some limited transparency policy to maintain client's secrecy. Usually the private data collected by the service providers can be shared with in their other platforms. Highest risk of data exposure occurs for cloud providers due to the breach of client's secrecy. In cloud architecture privacy policies and its standards is one of the main issues of cloud computing. Many researchers have been vigorously working in these issues. We studied these researchers work, frontward us to propose HPBP (Hierarchical Petri-net based Privacy nominal model for Cloud) architecture. Our proposed model facilitates clients, to have an augment trust on cloud providers as a pledge to maintain their high secrecy. The privacy of the proposed technique is analyzed briefly.
Spontaneous privacy-friendly indoor positioning using enhanced WLAN beacons	Location based services pervade our lives more and more. Not only are outdoor movement of people and vehicles sensed via GPS, but with the use of wireless networks it is possible even indoors to locate people. On the one hand, this offers helpful and entertaining features, where GPS is not available; on the other hand, individual privacy is at risk with the unprotected release of highly sensitive location data. Many state of the art positioning methods require data exchange between the device and the network to enable positioning. Thus the users must implicitly reveal their current position to the network provider. In this paper, we address this problem and offer a new approach that allows users to ascertain their positions without exposing themselves to the network provider. Our approach embeds position data as information elements into IEEE 802.11 beacon frames, which are broadcasted periodically within each 802.11 basic service set. Based on this data, a mobile device can calculate its current position without revealing its presence to the network since beacons can be monitored passively. Finally we introduce a protocol that enables the transmission of necessary location data required by the positioning methods Fingerprinting and Proximity Sensing.
Securing location privacy in Augmented Reality	In Augmented Reality (AR), users main concern includes privacy and safety of data. Since location based services (LBS) are one of the major applications of the AR, it is important to have a privacy-aware management of location information, providing location privacy for clients against vulnerabilities or abuse. This paper discusses how to protect the location privacy from various privacy threats, which occurred because of the unlimited usage of LBS, by a scalable architecture. We have developed an efficient LBS privacy protection algorithm. In our model, k-anonymization and pseudo-anonymization methods are used hand in hand. The proposed location privacy frame work is implemented by an efficient trusted third party server. We have studied the efficiency of our algorithm under different conditions using realistic work loads. Our experiment shows that the k-anonymization and the pseudo-anonymization methods used together in our algorithm provide an efficient location privacy.
Privacy by information accountability for e-health systems	Privacy has become one of the main impediments for e-health in its advancement to provide better services to its consumers. Even though many security protocols are being developed to protect information from being compromised, privacy is still a major issue in healthcare where privacy protection is very important. When consumers are confident that their sensitive information is safe from being compromised, their trust in these services will be higher and would lead to better adoption of these systems. In this paper we propose a solution to the problem of patient privacy in e-health through an information accountability framework could enhance consumer trust in e-health services and would lead to the success of e-health services.
Privacy preserving association rule mining by introducing concept of impact factor	Association Rules discovered by association rule mining may contain some sensitive rules, which may cause potential threats towards privacy and security. Many of the researchers in this area have recently made efforts to preserve privacy for sensitive association rules in statistical database. In this paper, we propose a heuristic based association rule hiding using oracle real application clusters by introducing the concept of impact factor of transaction on the rule. The impact factor of a transaction is equal to number of itemsets that are present in those itemsets which represents sensitive association rule. Higher the impact factor of a transaction, higher is its sensitivity. Proposed algorithm exhibits the concept of impact factor to hide several rules by modifying fewer transactions. As modifications are fewer, data quality is very less affected. Use of clustering aids in increasing performance by running operations in parallel.
A conceptual framework for privacy preserving of association rule mining in e-commerce	This paper proposes a conceptual framework for privacy preserving of association rule mining in e-commerce and a novel heuristic approach for association rule hiding based on intersection lattice theory. Our approach relies on characteristics of intersection lattice and frequent itemsets to specify exactly victim items in such a way that modifying them leads to reduction of confidence of the sensitive association rules but less impact on remains association rules. The experimental results indicate effectiveness of the proposed algorithm in comparison with previous work.
A personalized retrieval system with preserving privacy	The collection of extensive knowledge about users' interests, behavior, and actions is necessary for most personalized retrieval systems. However, users' browsing information and interest model contain their personal privacy, thus disclosure of privacy is possible. This paper proposes a personalized retrieval system called APIRS to preserve privacy. Its personalized service runs on the client side; the retrieval service runs on the server side; and the user login to the server is anonymous. The server only knows the client is a valid user, but it cannot ascertain which user that is. Even if the server side information is revealed, users' privacy will not be disclosed, thus makes it suitable for personalized information retrieval in digital libraries.
Shield privacy Hippocratic security method for virtual community	Pearlman et al., (2002) defines a virtual community as a large, multiinstitutional group of individuals who use a set of rules, a policy, to specify how to share their resources. With such a large collection of data stores in these resources, each of which could be data mined to different degrees, the privacy of each of the individuals needs to be protected. Within a virtual community, especially one also used to facilitate knowledge discovery, there are a number of privacy issues that must be addressed and resolved in ways other than through privacy laws and policies alone. This is due to the fact that, as to date, these laws have proved mainly ineffective and there is an ever growing concern by individuals about their privacy. Web surveys Srikant R. (2002) have identified that 82% of users have said improved privacy policies and methods would matter in Web environments. Agarwal R. (2002) highlights the fact that a secure collaborative environment, such as a virtual community, needs to provide authentication, authorization, privacy and data integrity. In this paper, we identify the technology issues, followed by the presentation of our proposed solution. We provide a conceptual framework of the Hippocratic security method to provide information security for shield privacy in virtual communities and we describe the architecture and design of the proposed solution. We outline the implementation, testing and evaluation strategies of our solutions. The proposed solution shall monitor the use of personal information as it is passed around the virtual community and protected information paths, data at rest, database and information resources through the use of the Hippocratic database principle to enforce Hippocratic security policies and procedures together with privacy preserving data mining Evfimievski et al., (2003) method for excellent information security in a virtual community environment.
FastRIPP: RFID Privacy Preserving protocol with Forward Secrecy and Fast Resynchronisation	In the next future radio frequency identiflcation (RFID) systems will be so pervasive that everyone will wear (maybe unawares) a kit of personal tags. However, a major concern that prevents a wide diffusion of this emerging technology is privacy. Several proposed protocols try to solve the privacy issue, but are exposed to many others security flaws, such as denial of service or lack of forward secrecy. One recently proposed solution addressing all these problems is RIPP-FS: an RFID identification protocol that guarantees privacy, authentication and forward secrecy, allowing the reading of many tags at once. While efficient, RIPP-FS requires some extra computations on the tag side when a tag misses several consecutive queries from the reader. In this paper we propose FastRIPP, an efficient protocol that significantly reduces the exposed overhead. This improvement is inspired by an efficient hash traversal amortization technique that uses fractal hash sequence representation. We analyzed the performances of the proposed protocol compared with the original version of RIPP-FS. The results of extensive simulations confirm the gain of performance of the proposed protocol. Finally, note that the proposed solution could be adopted by other RFID identification protocols as well.
The exploration of instrument of users' privacy concerns of Social Network Service	With rapid spread of acceptance and usage of Social Network Service (SNS, e.g., Facebook, Renren, Myspace), concerns about online information privacy have arisen. This paper explores the instruments of users' privacy concerns in the context of SNS. First, based on the relevant literature review, comparisons among four scales are discussed and necessities of new items are proposed. Then a pilot test with an open question is carried out collecting 28 samples through interviews. Several reliable and specific new items are added through qualitative content coding. And this is followed by an integrated questionnaire survey. Analyses of 115 respondents' data indicate that SNS user's concerns about privacy are covering a wider range than previous scales. Quantitative result illustrates the new items are acceptable. Finally requirement for further factor analysis is suggested.
DETECTIVE: a decision tree based categorical value clustering and perturbation technique for preserving privacy in data mining	Data mining is a powerful tool for information discovery from huge datasets. Various sectors, including commercial, government, financial, medical, and scientific, are applying data mining techniques on their datasets that typically contain sensitive individual information. During this process the datasets get exposed to several parties, which can potentially lead to disclosure of sensitive information and thus to breaches of privacy. Several data mining privacy preserving techniques have been recently proposed. In this paper we focus on data perturbation techniques, i.e., those that add noise to the data in order to prevent exact disclosure of confidential values. Some of these techniques were designed for datasets having only numerical non-class attributes and a categorical class attribute. However, natural datasets are more likely to have both numerical and categorical non-class attributes, and occasionally they contain only categorical attributes. Noise addition techniques developed for numerical attributes are not suitable for such datasets, due to the absence of natural ordering among categorical values. In this paper we propose a new method for adding noise to categorical values, which makes use of the clusters that exist among these values. We first discuss several existing categorical clustering methods and point out the limitations they exhibit in our context. Then we present a novel approach towards clustering of categorical values and use it to perturb data while maintaining the patterns in the dataset. Our clustering approach partitions the values of a given categorical attribute rather than the records of the datasets; additionally, our approach operates on the horizontally partitioned dataset and it is possible for two values to belong to the same cluster in one horizontal partition of the dataset, and to two distinct clusters in another partition. Finally, we provide some experimental results in order to evaluate our perturbation technique and to compare our clustering approach with an existing method, the so-called CACTUS.
Dynamic user reconfigurable privacy and trust settings for collaborative industrial environments	There is no doubting that collaborative industrial environments have become increasingly more popular as enterprise solutions for knowledge sharing. They facilitate information and data processing capabilities beyond the natural borders set within an organization. However, with this increased information openness and communications comes serious threats to both individual and organisational privacy. Privacy is a serious consideration and often legal obligation for most organizations. Current approaches to protecting privacy in collaborative environments have proven inadequate. We propose a novel framework to address the issues of privacy and trust in collaborative industrial environments. Our framework provides users with control over their personal information through reconfigurable access and privacy control settings. We use a collaborative environment suggestion box application to analyse how the framework is implemented, along with the benefits it provides for protecting privacy.
SHARDIS: A Privacy-Enhanced Discovery Service for RFID-Based Product Information	The EPCglobal Network is an emerging global information architecture for supporting Radio-Frequency Identification (RFID) in supply chains. Discovery services for the EPCglobal Network are distributed services that serve the following pivotal lookup function: Given an identifier for a real-world object, e.g., an Electronic Product Code (EPC) stored on an RFID tag, they return a list of Internet addresses of services that offer additional information about the object. Since a client's information interests in the EPCglobal Network can be used to create inventory lists and profiles of his physical surroundings, as well as be used for business intelligence on the flow of goods in corporate applications, protecting client privacy becomes crucial. In particular, privacy mechanisms should by design be integrated into discovery services where the client's information interests could be analyzed by many potential adversaries. This paper introduces SHARDIS, a privacy-enhanced discovery service for RFID information based on the peer-to-peer paradigm. The idea is to enhance confidentiality of the client's query against profiling by cryptographically hashing the search EPC and by splitting and distributing the service addresses of interest. Furthermore, a probabilistic analysis of the privacy benefits of SHARDIS is presented. SHARDIS was implemented using the global research platform PlanetLab. Several performance experiments show its practical feasibility for many application areas.
Using Time-of-Flight Measurements for Privacy-Preserving Tracking in a Smart Room	We present a method for real-time person tracking and coarse pose recognition in a smart room using timeof- flight measurements. The time-of-flight images are severely downsampled to preserve the privacy of the occupants and simulate future applications that use single-pixel sensors in smart ceiling panels. The tracking algorithms use grayscale morphological image reconstruction to avoid false detections, and are designed not to mistakenly detect pieces of furniture as people. A maximum likelihood estimation method using a simple Markov model was implemented for robust pose classification.We show that the algorithms work effectively even when the sensors are spaced apart by 25cm, using both real-world experiments and environmental simulation.
Communication security and privacy in pervasive user-centric e-health systems using Digital Rights Management and side channel attacks defense mechanisms	In this work, communication security and privacy in pervasive user-centric e-health systems is studied. Our proposed security scheme is presented which uses a combination of mechanisms from Digital Rights Management and side channel attacks defense in order to ensure privacy and security for patients' data. In particular, communication between medical, limited-resource, embedded devices, carried by the patients, and devices in central health installations is both encrypted by means of elliptic curve cryptography and protected against traffic analysis. In addition, a DRM scheme is used in order to ensure authorized-only access to sensitive health data.
Achieving Data Privacy and Security Using Web Services	The Internet has proven to be a powerful enabler for anywhere/anytime access to data and software located through the world. The downside of this capability is that it exposes these resources to information leakage, malicious invasion by hackers, and damage due to software viruses. This risk can be mitigated by the intelligent use of a web services architecture than can enforce both data privacy and security. In this talk I will propose a security architecture that enforces information security by addressing the key issues of authentication, authorization, and federation. Authentication results in a security token that conveys both the identity of the requestor and the trust level of the identification technology. Authorization determines what objects are accessible by a user given his identity token, request, role, context, and privileges. Federation, using both direct and indirect trust, addresses the problem of how identity, once legitimately established in one trust domain, can be reliably exported to another cooperating trust domain. I will discuss our implementation of these ideas in an on-going research project to protect medical data, and will illustrate how the concepts generalize to protect arbitrary data resources.
Achieving Data Privacy and Security Using Web Services	
Use of Ontology Technology for Standardization of Medical Records and Dealing with Associated Privacy Issues	Our goal is to move towards efficient and secure use of medical records for the purpose of correct patient identification, diagnosis, appointments scheduling and the like in everyday life as well as in emergency situations. We place emphasis on standardized use of medical records within various regions, countries and even continents. Ontologies can be used for this purpose. Instantiation of the generic medical record ontology concepts result in specific medical record ontologies that act as personalized medical records. Ontology files are machine readable and are suitable to be used within the information system. Medical record databases contain personal medical records. Through use of ontologies for standardization of medical records from these different databases, one big virtual database is created that contains medical records of all people. Another advantage of use of ontologies within the system is that hierarchical structure of ontologies will result in better control over access and use of personalized medical information addressing privacy issues associated with this. The significance of this research lies in use of ontology technology for the purpose of establishing worldwide standardization of medical records and dealing with associated privacy issues.
Integration of Situational and Reward Elements for Fair Privacy Principles and Preferences (F3P)	It is widely acknowledged that information privacy is subjective in nature and contextually influenced. Individuals value their personal privacy differently with many willing to trade-off of privacy for some form of reward or personal gain. Many of the proposed privacy protection schemes do not give due consideration to the contextual, and more importantly situational influence on privacy. Rather privacy preferences for personal data are configurable for only a limited set of notions that include purpose, recipient, category, and condition. Current solutions offer no, or very limited, support for individual situational privacy preferences. This paper proposes a conceptual framework that allows entities to assign privacy preferences to their personal data items that incorporate situation and reward elements. The solution allows entities to assign trade-off values to their personal data based on the situation and context of the data request. In this manner the data owners set what they perceive as fair privacy practices and preferences for evaluating the worth of their personal data.
The use of communications networks to increase personal privacy	Communications networks can separate as well as join information. This ability can be used to increase personal privacy in an environment where advances in technology makes it possible to collect and correlate increasing amounts of information about individuals. The tools and principles necessary to increase personal privacy are demonstrated by creating an anonymous credit card, in which a person's identity and purchases are separated, and a national health insurance plan, in which treatment, payment and an individual's identity are separated. An analysis technique is developed to determine how well the information is separated
Session Privacy Enhancement by Traffic Dispersion	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04146808.png" border="0">
Who Said That? Privacy at Link Layer	Wireless LAN and other radio broadcast technologies are now in full swing. However, the widespread usage of these technologies comes at the price of location privacy, be it by observing the communication patterns or the interface identifiers. Although a number of network level solutions have been proposed , this paper describes a novel approach to location privacy at the link layer level. We present a generic mechanism and then map it to a real protocol, IEEE 802.11. The work also provides an analysis of the protocol in terms of privacy and performance considerations.
Protecting Receiver-Location Privacy in Wireless Sensor Networks	Due to the open nature of a sensor network, it is relatively easy for an adversary to eavesdrop and trace packet movement in the network in order to capture the receiver physically. After studying the adversary's behavior patterns, we present countermeasures to this problem. We propose a location-privacy routing protocol (LPR) that is easy to implement and provides path diversity. Combining with fake packet injection, LPR is able to minimize the traffic direction information that an adversary can retrieve from eavesdropping. By making the directions of both incoming and outgoing traffic at a sensor node uniformly distributed, the new defense system makes it very hard for an adversary to perform analysis on locally gathered information and infer the direction to which the receiver locates. We evaluate our defense system based on three criteria: delivery time, privacy protection strength, and energy cost. The simulation results show that LPR with fake packet injection is capable of providing strong protection for the receiver's location privacy. Under similar energy cost, the safe time of the receiver provided by LPR is much longer than other methods, including Phantom routing (Kamat et al., 2005) and DEFP (Deng et al., 2005). The performance of our system can be tuned through a couple of parameters that determine the tradeoff between energy cost and the strength of location-privacy protection.
pDCS: Security and Privacy Support for Data-Centric Sensor Networks	The demand for efficient data dissemination/access techniques to find the relevant data from within a sensor network has led to the development of data-centric sensor networks (DCS), where the sensor data as contrast to sensor nodes are named based on attributes such as event type or geographic location. However, saving data inside a network also creates security problems due to the lack of tamper-resistance of the sensor nodes and the unattended nature of the sensor network. For example, an attacker may simply locate and compromise the node storing the event of his interest. To address these security problems, we present pDCS, a privacy-enhanced DCS network which offers different levels of data privacy based on different cryptographic keys. In addition, we propose several query optimization techniques based on Euclidean Steiner Tree and Keyed Bloom Filter to minimize the query overhead while providing certain query privacy. Finally, detailed analysis and simulations show that the Keyed Bloom Filter scheme can significantly reduce the message overhead with the same level of query delay and maintain a very high level of query privacy.
PDA: Privacy-Preserving Data Aggregation in Wireless Sensor Networks	Providing efficient data aggregation while preserving data privacy is a challenging problem in wireless sensor networks research. In this paper, we present two privacy-preserving data aggregation schemes for additive aggregation functions. The first scheme -cluster-based private data aggregation (CPDA)-leverages clustering protocol and algebraic properties of polynomials. It has the advantage of incurring less communication overhead. The second scheme -Slice-Mix-AggRegaTe (SMART)-builds on slicing techniques and the associative property of addition. It has the advantage of incurring less computation overhead. The goal of our work is to bridge the gap between collaborative data collection by wireless sensor networks and data privacy. We assess the two schemes by privacy-preservation efficacy, communication overhead, and data aggregation accuracy. We present simulation results of our schemes and compare their performance to a typical data aggregation scheme -TAG, where no data privacy protection is provided. Results show the efficacy and efficiency of our schemes. To the best of our knowledge, this paper is among the first on privacy-preserving data aggregation in wireless sensor networks.
ALPACAS: A Large-Scale Privacy-Aware Collaborative Anti-Spam System	While the concept of collaboration provides a natural defense against massive spam emails directed at large numbers of recipients, designing effective collaborative anti-spam systems raises several important research challenges. First and foremost, since emails may contain confidential information, any collaborative anti-spam approach has to guarantee strong privacy protection to the participating entities. Second, the continuously evolving nature of spam demands the collaborative techniques to be resilient to various kinds of camouflage attacks. Third, the collaboration has to be lightweight, efficient, and scalable. Towards addressing these challenges, this paper presents ALPACAS - a privacy-aware framework for collaborative spam filtering. In designing the ALPACAS framework, we make two unique contributions. The first is a feature-preserving message transformation technique that is highly resilient against the latest kinds of spam attacks. The second is a privacy-preserving protocol that provides enhanced privacy guarantees to the participating entities. Our experimental results conducted on a real email dataset shows that the proposed framework provides a 10 fold improvement in the false negative rate over the Bayesian-based Bogofilter when faced with one of the recent kinds of spam attacks. Further, the privacy breaches are extremely rare. This demonstrates the strong privacy protection provided by the ALPACAS system.
ECPP: Efficient Conditional Privacy Preservation Protocol for Secure Vehicular Communications	In this paper, we introduce an efficient conditional privacy preservation (ECPP) protocol in vehicular ad hoc networks (VANETs) to address the issue on anonymous authentication for safety messages with authority traceability. The proposed protocol is characterized by the generation of on-the-fly short-time anonymous keys between on-board units (OBUs) and roadside units (RSUs), which can provide fast anonymous authentication and privacy tracking while minimizing the required storage for short-time anonymous keys. We demonstrate the merits gained by the proposed protocol through extensive analysis.
Verifiable Privacy-Preserving Range Query in Two-Tiered Sensor Networks	We consider a sensor network that is not fully trusted and ask the question how we preserve privacy for the collected data and how we verify the data reply from the network. We explore the problem in the context of a network augmented with storage nodes and target at range query. We use bucketing scheme to mix the data for a range, use message encryption for data integrity, and employ encoding numbers to prevent the storage nodes from dropping data.
Privacy in VoIP Networks: A k-Anonymity Approach	Peer-to-peer VoIP (voice over IP) networks, exemplified by Skype, are becoming increasingly popular due to their significant cost advantage and richer call forwarding features than traditional public switched telephone networks. One of the most important features of a VoIP network is privacy (for VoIP clients). Unfortunately, most peer-to-peer VoIP networks neither provide personalization nor guarantee a quantifiable privacy level. In this paper we propose novel flow analysis attacks that demonstrate the vulnerabilities of peer-to-peer VoIP networks to privacy attacks. We present detailed experimental evaluation that demonstrates these attacks quantifying performance and scalability degradation.
DP┬▓AC: Distributed Privacy-Preserving Access Control in Sensor Networks	The owner and users of a sensor network may be different, which necessitates privacy-preserving access control. On the one hand, the network owner need enforce strict access control so that the sensed data are only accessible to users willing to pay. On the other hand, users wish to protect their respective data access patterns whose disclosure may be used against their interests. This paper presents DP<sup>2</sup> AC, a Distributed Privacy- Preserving Access Control scheme for sensor networks, which is the first work of its kind. Users in DP<sup>2</sup> AC purchase tokens from the network owner whereby to query data from sensor nodes which will reply only after validating the tokens. The use of blind signatures in token generation ensures that tokens are publicly verifiable yet unlinkable to user identities, so privacy- preserving access control is achieved. A central component in DP<sup>2</sup> AC is to prevent malicious users from reusing tokens. We propose a suite of distributed techniques for token-reuse detection (TRD) and thoroughly compare their performance with regard to TRD capability, communication overhead, storage overhead, and attack resilience. The efficacy and efficiency of DP<sup>2</sup> AC are confirmed by detailed performance evaluations.
An Efficient Privacy-Preserving Scheme against Traffic Analysis Attacks in Network Coding	Privacy threat is one of the critical issues in network coding, where attacks such as traffic analysis can be easily launched by a malicious adversary once enough encoded packets are collected. Furthermore, the encoding/mixing nature of network coding precludes the feasibility of employing the existing privacy-preserving techniques, such as Onion routing, in network coding enabled networks. In this paper, we propose a novel privacy-preserving scheme against traffic analysis in network coding. With homomorphic encryption operation on global encoding vectors (GEVs), the proposed scheme offers two significant privacy-preserving features, packet flow untraceability and message content confidentiality, for efficiently thwarting the traffic analysis attacks. Moreover, the proposed scheme keeps the random coding feature, and each sink can recover the source packets by inverting the GEVs with a very high probability. Theoretical analysis and simulative evaluation demonstrate the validity and efficiency of the proposed scheme.
ElliPS: A Privacy Preserving Scheme for Sensor Data Storage and Query	With in-network sensor data storage and query, storage nodes are responsible for storing the data collected by sensor nodes and answering queries from users. Thus, without proper protection for data types and user queries, compromise of storage nodes and/or sensor nodes may reveal sensitive information about the sensed environment as well as users' private interests and query patterns. In this paper, we explore trade-offs between privacy, computation overhead, communication overhead, network flexibility and network complexity, and propose ElliPS (Elliptic curve based Privacy Scheme) to provide joint protection on data type privacy and query privacy in the presence of sensor node compromise, storage node compromise, or under collusive attacks by compromised sensor nodes and storage nodes together. Extensive analysis and simulation are conducted to verify the security properties and efficiency of the proposed scheme.
ACTION: Breaking the Privacy Barrier for RFID Systems	In order to protect privacy, radio frequency identification (RFID) systems employ privacy-preserving authentication (PPA) to allow valid readers to explicitly authenticate their dominated tags without leaking private information. Typically, an RF tag sends an encrypted message to the reader, then the reader searches for the key that can decrypt the cipher to identify the tag. Due to the large-scale deployment of today's RFID systems, the key search scheme for any PPA requires a short response time. Previous designs construct balance-tree based key management structures to accelerate the search speed to 0(logN), where N is the number of tags. Being efficient, such approaches are vulnerable to compromising attacks. By capturing a small number of tags, compromising attackers are able to identify other tags that have not been corrupted. To address this issue, we propose an Anti- Compromising authenticaTION protocol, ACTION, which employs a novel sparse tree architecture, such that the key of every tag is independent from one another. The advantages of this design include: 1) resilience to the compromising attack, 2) reduction of key storage for tags from 0(logN) to 0(1), which is significant for resource critical tag devices, and 3) high search efficiency, which is 0(logN), as good as the best in the previous designs.
A-WEOR: Communication Privacy Protection for Wireless Mesh Networks Using Encoded Opportunistic Routing	Recent research in the physical and MAC models of IEEE 802.11 has shown that wireless nodes expose traffic patterns at PHY/MAC layers. Adversaries can easily utilize these patterns to derive the end-to- end communication relations using statistical traffic analysis attack. IEEE 802.11 provides MAC layer broadcast capabilities which can be used to protect the flow from such traffic analysis. In this paper, we present a novel approach A-WEOR, utilizing network coding and opportunistic routing to protect the communication patterns for wireless mesh networks. Our evaluation proves that A-WEOR is an efficient solution which achieves exceedingly superior anonymity compared to existing methodologies.
Refresh: Weak Privacy Model for RFID Systems	Privacy-Preserving Authentication (PPA) is crucial for Radio Frequency Identifcation (RFID)-enabled applications. Without appropriate formal privacy models, it is difficult for existing PPA schemes to explicitly prove their privacy. Even worse, RFID systems cannot discover potential security flaws that are vulnerable to new attacking patterns. Recently, researchers propose a formal model, termed as Strong Privacy, which strictly requires tags randomly generate their output. Adopting the Strong Privacy model, PPA schemes have to employ brute-force search in tags' authentications, which incurs unacceptable overhead and delay to large-scale RFID systems. Instead of adopting Strong Privacy, most PPA schemes improve the authentication efficiency at the cost of the privacy degradation. Due to the lack of proper formal models, it cannot be theoretically proven that the degraded PPA schemes can achieve acceptable privacy in practical RFID systems. To address these issues, we propose a weak privacy model, Refresh, for designing PPA schemes with high efficiency as well as acceptable privacy. Based on Refresh, we show that many well-known PPA schemes do not provide satisfied privacy protection, even though they achieve relatively high authentication efficiency. We further propose a Light-weight privAcy-preServing authenTication scheme, LAST, which can guarantee the privacy based on the Refresh model and realize O(1) authentication efficiency, simultaneously.
Privacy-Preserving Public Auditing for Data Storage Security in Cloud Computing	Cloud Computing is the long dreamed vision of computing as a utility, where users can remotely store their data into the cloud so as to enjoy the on-demand high quality applications and services from a shared pool of configurable computing resources. By data outsourcing, users can be relieved from the burden of local data storage and maintenance. However, the fact that users no longer have physical possession of the possibly large size of outsourced data makes the data integrity protection in Cloud Computing a very challenging and potentially formidable task, especially for users with constrained computing resources and capabilities. Thus, enabling public auditability for cloud data storage security is of critical importance so that users can resort to an external audit party to check the integrity of outsourced data when needed. To securely introduce an effective third party auditor (TPA), the following two fundamental requirements have to be met: 1) TPA should be able to efficiently audit the cloud data storage without demanding the local copy of data, and introduce no additional on-line burden to the cloud user; 2) The third party auditing process should bring in no new vulnerabilities towards user data privacy. In this paper, we utilize and uniquely combine the public key based homomorphic authenticator with random masking to achieve the privacy-preserving public cloud data auditing system, which meets all above requirements. To support efficient handling of multiple auditing tasks, we further explore the technique of bilinear aggregate signature to extend our main result into a multi-user setting, where TPA can perform multiple auditing tasks simultaneously. Extensive security and performance analysis shows the proposed schemes are provably secure and highly efficient.
Source-Location Privacy through Dynamic Routing in Wireless Sensor Networks	Wireless sensor networks (WSNs) have the potential to be widely used in many areas for unattended event monitoring. Mainly due to lack of a protected physical boundary, wireless communications are vulnerable to unauthorized interception and detection. Privacy is becoming one of the major issues that jeopardize the successful deployment of wireless sensor networks. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address the source-location privacy. For WSNs, source-location privacy service is further complicated by the fact that the sensor nodes consist of low-cost and low-power radio devices, computationally intensive cryptographic algorithms and large scale broadcasting-based protocols are not suitable for WSNs. In this paper, we propose source-location privacy schemes through routing to randomly selected intermediate node(s) before the message is transmitted to the SINK node. We first describe routing through a single a single randomly selected intermediate node away from the source node. Our analysis shows that this scheme can provide great local source-location privacy. We also present routing through multiple randomly selected intermediate nodes based on angle and quadrant to further improve the global source location privacy. While providing source-location privacy for WSNs, our simulation results also demonstrate that the proposed schemes are very efficient in energy consumption, and have very low transmission latency and high message delivery ratio. Our protocols can be used for many practical applications.
A Privacy-Preserving Scheme for Online Social Networks with Efficient Revocation	Online social networks (OSNs) are attractive applications which enable a group of users to share data and stay connected. Facebook, Myspace, and Twitter are among the most popular applications of OSNs where personal information is shared among group contacts. Due to the private nature of the shared information, data privacy is an indispensable security requirement in OSN applications. In this paper, we propose a privacy-preserving scheme for data sharing in OSNs, with efficient revocation for deterring a contact's access right to the private data once the contact is removed from the social group. In addition, the proposed scheme offers advanced features such as efficient search over encrypted data files and dynamic changes to group membership. With slight modification, we extend the application of the proposed scheme to anonymous online social networks of different security and functional requirements. The proposed scheme is demonstrated to be secure, effective, and efficient.
PriSense: Privacy-Preserving Data Aggregation in People-Centric Urban Sensing Systems	People-centric urban sensing is a new paradigm gaining popularity. A main obstacle to its widespread deployment and adoption are the privacy concerns of participating individuals. To tackle this open challenge, this paper presents the design and evaluation of PriSense, a novel solution to privacy-preserving data aggregation in people-centric urban sensing systems. PriSense is based on the concept of data slicing and mixing and can support a wide range of statistical additive and non-additive aggregation functions such as Sum, Average, Variance, Count, Max/Min, Median, Histogram, and Percentile with accurate aggregation results. PriSense can support strong user privacy against a tunable threshold number of colluding users and aggregation servers. The efficacy and efficiency of PriSense are confirmed by thorough analytical and simulation results.
SPRING: A Social-based Privacy-preserving Packet Forwarding Protocol for Vehicular Delay Tolerant Networks	In this paper, we propose a social-based privacy- preserving packet forwarding protocol, called SPRING, for vehicular delay tolerant networks (DTNs). With SPRING, Roadside Units (RSUs) deployed along the roadside can assist in packet forwarding to achieve highly reliable transmissions. In specific, we first heuristically define how to evaluate each traffic intersection's social degree in a vehicular DTN. Based on the social degree information, we then strategically place RSUs at some high-social intersections. As a result, these RSUs can provide tremendous assistance in temporarily storing packets and helping packet forwarding to achieve high delivery ratio. Performance evaluations via extensive simulations demonstrate the SPRING's efficiency. In addition, detailed security analyses show that the proposed SPRING can achieve conditional privacy preservation and resist most attacks existing in vehicular DTNs.
Maintaining source privacy under eavesdropping and node compromise attacks	In a sensor network, an important problem is to provide privacy to the event detecting sensor node and integrity to the data gathered by the node. Compromised source privacy can inadvertently leak event location. Existing techniques use either random walk path or generate fake event packets to make it hard for the adversary to traceback to the source, since encryption alone may not help prevent a traffic analysis attack. In this work, without using the traditional overhead intensive methods, we present a scheme to hide source information using cryptographic techniques incurring lower overhead. The packet is modified and route by dynamically selected nodes to make it difficult for a malicious entity to traceback the packet to a source node and also prevent packet spoofing. This is important because the adversary model considers a super-local eavesdropper having the ability to compromise sensor nodes. We analyze the ability of our proposed scheme to withstand different attacks and demonstrate its efficiency in terms of overhead and functionality when compared to existing work.
APPLAUS: A Privacy-Preserving Location Proof Updating System for location-based services	Today's location-sensitive service relies on user's mobile device to determine its location and send the location to the application. This approach allows the user to cheat by having his device transmit a fake location, which might enable the user to access a restricted resource erroneously or provide bogus alibis. To address this issue, we propose A Privacy-Preserving LocAtion proof Updating System (APPLAUS) in which co-located Bluetooth enabled mobile devices mutually generate location proofs, and update to a location proof server. Periodically changed pseudonyms are used by the mobile devices to protect source location privacy from each other, and from the untrusted location proof server. We also develop user-centric location privacy model in which individual users evaluate their location privacy levels in real-time and decide whether and when to accept a location proof exchange request based on their location privacy levels. APPLAUS can be implemented with the existing network infrastructure and the current mobile devices, and can be easily deployed in Bluetooth enabled mobile devices with little computation or power cost. Extensive experimental results show that our scheme, besides providing location proofs effectively, can significantly preserve the source location privacy.
A distributed and privacy preserving algorithm for identifying information hubs in social networks	This paper addresses the problem of identifying the top-k information hubs in a social network. Identifying top-k information hubs is crucial for many applications such as advertising in social networks where advertisers are interested in identifying hubs to whom free samples can be given. Existing solutions are centralized and require time stamped information about pair-wise user interactions and can only be used by social network owners as only they have access to such data. Existing distributed and privacy preserving algorithms suffer from poor accuracy. In this paper, we propose a new algorithm to identify information hubs that preserves user privacy. The intuition is that highly connected users tend to have more interactions with their neighbors than less connected users. Our method can identify hubs without requiring a central entity to access the complete friendship graph. We achieve this by fully distributing the computation using the Kempe-McSherry algorithm to address user privacy concerns. To the best of our knowledge, the proposed algorithm represents an arguably first attempt that (1) uses friendship graphs (instead of interaction graphs), (2) employs a truly distributed method over friendship graphs, and (3) maintains user privacy by not requiring them to disclose their friend associations and interactions, for identifying information hubs in social networks. We evaluate the effectiveness of our proposed technique using a real-world Facebook data set containing about 3.1 million users and more than 23 million friendship links. The results of our experiments show that our algorithm is 50% more accurate than existing distributed algorithms. Results also show that the proposed algorithm can estimate the rank of the top-k information hubs users more accurately than existing approaches.
Privacy analysis of user association logs in a large-scale wireless LAN	User association logs play an important role in wireless network research. One concern of sharing such logs with other researchers, however, is that they pose potential privacy risks for the network users. Today, the common practice in sanitizing these logs before releasing them to the public is to anonymize users' sensitive information, such as their devices' MAC addresses and their exact association locations. In this work, we aim to study whether such sanitization measures are sufficient to protect user privacy. By simulating an adversary's role, we propose a novel type of correlation attack in which the adversary uses the anonymized association log to build signatures against each user, and when combined with auxiliary information, such signatures can help to identify users within the anonymized log. Using a user association log that contains more than four thousand users and millions of association records, we demonstrate that this attack technique, under certain circumstances, is able to pinpoint the victim's identity exactly with a probability as high as 70%, or narrow it down to a set of 20 candidates with a probability close to 100%.We further evaluate the effectiveness of standard anonymization techniques, including generalization and perturbation, in mitigating correlation attacks; our experimental results reveal only limited success of these methods, suggesting that more thorough treatment is needed when anonymizing wireless user association logs before public release.
A cross-domain privacy-preserving protocol for cooperative firewall optimization	Firewalls have been widely deployed on the Internet for securing private networks. A firewall checks each incoming or outgoing packet to decide whether to accept or discard the packet based on its policy. Optimizing firewall policies is crucial for improving network performance. Prior work on firewall optimization focuses on either intra-firewall or inter-firewall optimization within one administrative domain where the privacy of firewall policies is not a concern. This paper explores inter-firewall optimization across administrative domains for the first time. The key technical challenge is that firewall policies cannot be shared across domains because a firewall policy contains confidential information and even potential security holes, which can be exploited by attackers. In this paper, we propose the first cross-domain privacy-preserving cooperative firewall policy optimization protocol. Specifically, for any two adjacent firewalls belonging to two different administrative domains, our protocol can identify in each firewall the rules that can be removed because of the other firewall. The optimization process involves cooperative computation between the two firewalls without any party disclosing its policy to the other. We implemented our protocol and conducted extensive experiments. The results on real firewall policies show that our protocol can remove as many as 49% of the rules in a firewall whereas the average is 19.4%. The communication cost is less than a few hundred KBs. Our protocol incurs no extra online packet processing overhead and the offline processing time is less than a few hundred seconds.
Location privacy protection from RSS localization system using antenna pattern synthesis	This paper studies the problem of location privacy protection in wireless LAN (WLAN) environment, where received signal strength (RSS) at access points (AP) can potentially be obtained by adversaries to obtain the location of a legitimate mobile station. We propose a two-step location privacy protection scheme using a linear smart antenna array on the mobile station. In the first step, the mobile station observes the arrangement of surrounding APs by moving around and estimating the path losses from itself to the APs. Based on the path loss information, in the second step, the mobile station optimizes the radiation pattern of its smart antenna so that its location privacy is protected while its communication quality is not affected. Two strategies are used in the radiation pattern optimization. The first strategy is to limit the number of APs in range of the mobile station to a safe level so that there are not enough measurements from the APs to make an estimation of the mobile station's location. If the first strategy is not possible, the mobile station falls to the second strategy, where its radiation pattern introduces maximum bias to any location estimation attempt so that the mobile station's true location is not revealed. Simulation results show that compared with traditional transmit power control (TPC) scheme, the first strategy significantly increases the probability of inadequate measurements for location computation. Simulation also demonstrates that the second strategy can significantly degenerate the precision of the positioning system. In many cases, the degenerated location precision is as low as the coverage range of the AP that the mobile station is associated with for communications. This essentially means that the second strategy can invalidate the use of RSS measurement for precise localization.
Protection of query privacy for continuous location based services	Location-based services (LBS) have become an immensely valuable source of real-time information and guidance. Nonetheless, the potential abuse of users' sensitive personal data by an LBS server is evolving into a serious concern. Privacy concerns in LBS exist on two fronts: location privacy and query privacy. In this paper we investigate issues related to query privacy. In particular, we aim to prevent the LBS server from correlating the service attribute, e.g., bar/tavern, in the query to the user's real-world identity. Location obfuscation using spatial generalization aided by anonymization of LBS queries is a conventional means to this end. However, effectiveness of this technique would abate in continuous LBS scenarios, i.e., where users are moving and recurrently requesting for LBS. In this paper, we present a novel query-perturbation-based scheme that protects query privacy in continuous LBS even when user-identities are revealed. Unlike most exiting works, our scheme does not require the presence of a trusted third party.
KIPDA: k-indistinguishable privacy-preserving data aggregation in wireless sensor networks	When wireless sensor networks accumulate sensitive or confidential data, privacy becomes an important concern. Sensors are often resource-limited and power-constrained, and data aggregation is commonly used to address these issues. However, providing privacy without disrupting in-network data aggregation is challenging. Although privacy-preserving data aggregation for additive and multiplicative aggregation functions has been studied, nonlinear aggregation functions such as maximum and minimum have not been well addressed. We present KIPDA, a privacy-preserving aggregation method, which we specialize for maximum and minimum aggregation functions. KIPDA obfuscates sensitive measurements by hiding them among a set of camouflage values, enabling k-indistinguishability for data aggregation. In principle, KIPDA can be used to hide a wide range of aggregation functions, although this paper considers only maximum and minimum. Because the sensitive data are not encrypted, it is easily and efficiently aggregated with minimal in-network processing delay. We quantify the efficiency of KIPDA in terms of power consumption and time delay, studying tradeoffs between the protocol's effectiveness and its resilience against collusion.
STAP: A social-tier-assisted packet forwarding protocol for achieving receiver-location privacy preservation in VANETs	Receiver-location privacy is an important security requirement in privacy-preserving Vehicular Ad hoc Networks (VANETs), yet the unavailable receiver's location information makes many existing packet forwarding protocols inefficient in VANETs. To tackle this challenging issue, in this paper, we propose an efficient social-tier-assisted packet forwarding protocol, called STAP, for achieving receiver-location privacy preservation in VANETs. Specifically, by observing the phenomena that vehicles often visit some social spots, such as well-traversed shopping malls and busy intersections in a city environment, we deploy storage-rich Roadside Units (RSUs) at social spots and form a virtual social tier with them. Then, without knowing the receiver's exact location information, a packet can be first forwarded and disseminated in the social tier. Later, once the receiver visits one of social spots, it can successfully receive the packet. Detailed security analysis shows that the proposed STAP protocol can protect the receiver's location privacy against an active global adversary, and achieve vehicle's conditional privacy preservation as well. In addition, performance evaluation via extensive simulations demonstrates its efficiency in terms of high delivery ratio and low average delay.
Reconciling privacy preservation and intrusion detection in sensory data aggregation	When wireless sensors are deployed to monitor the working or life conditions of people, the data collected and processed by these sensors may reveal privacy of people. The actual content of sensory data should be concealed to preserve the privacy, but the data concealment feature may be abused by compromised sensors to modify or ill-process data without being caught. Hence, reconciling privacy preservation and intrusion detection, which apparently conflict with each other, is important. This paper studies this problem in the context of sensory data aggregation, a fundamental primitive for efficient operation of sensor networks. A scheme is proposed that can detect ill-performed aggregation without knowing the actual content of sensory data, and therefore allow sensory data to be kept concealed. The results show that, the actual content of raw and aggregated sensory data can be well concealed. Meanwhile, most of ill-performed aggregations can be detected; the ill-performed aggregations that can escape from being detected have only negligible impact on the final aggregation results.
FindU: Privacy-preserving personal profile matching in mobile social networks	Making new connections according to personal preferences is a crucial service in mobile social networking, where the initiating user can find matching users within physical proximity of him/her. In existing systems for such services, usually all the users directly publish their complete profiles for others to search. However, in many applications, the users' personal profiles may contain sensitive information that they do not want to make public. In this paper, we propose FindU, the first privacy-preserving personal profile matching schemes for mobile social networks. In FindU, an initiating user can find from a group of users the one whose profile best matches with his/her; to limit the risk of privacy exposure, only necessary and minimal information about the private attributes of the participating users is exchanged. Several increasing levels of user privacy are defined, with decreasing amounts of exchanged profile information. Leveraging secure multi-party computation (SMC) techniques, we propose novel protocols that realize two of the user privacy levels, which can also be personalized by the users. We provide thorough security analysis and performance evaluation on our schemes, and show their advantages in both security and efficiency over state-of-the-art schemes.
Distributed privacy-preserving access control in a single-owner multi-user sensor network	A distributed access control module in wireless sensor networks (WSNs) allows the network to authorize and grant user access privileges for in-network data access. Prior research mainly focuses on designing such access control modules for WSNs, but little attention has been paid to protect user's identity privacy when a user is verified by the network for data accesses. Often, a user does not want the WSN to associate his identity to the data he requests, particularly in a single-owner multi-user WSN. In this paper, we present the design, implementation, and evaluation of a novel approach, Priccess, to ensure privacy-preserving access control. In addition to the theoretical analysis that demonstrates the security properties of Priccess, this paper also reports the experimental results of Priccess in a network of Imote2 motes, which show the efficiency of Priccess in practice.
Privacy-preserving multi-keyword ranked search over encrypted cloud data	With the advent of cloud computing, data owners are motivated to outsource their complex data management systems from local sites to the commercial public cloud for great flexibility and economic savings. But for protecting data privacy, sensitive data has to be encrypted before outsourcing, which obsoletes traditional data utilization based on plaintext keyword search. Thus, enabling an encrypted cloud data search service is of paramount importance. Considering the large number of data users and documents in the cloud, it is necessary to allow multiple keywords in the search request and return documents in the order of their relevance to these keywords. Related works on searchable encryption focus on single keyword search or Boolean keyword search, and rarely sort the search results. In this paper, for the first time, we define and solve the challenging problem of privacy-preserving multi-keyword ranked search over encrypted cloud data (MRSE). We establish a set of strict privacy requirements for such a secure cloud data utilization system. Among various multi-keyword semantics, we choose the efficient similarity measure of ΓÇ£coordinate matchingΓÇ¥, i.e., as many matches as possible, to capture the relevance of data documents to the search query. We further use ΓÇ£inner product similarityΓÇ¥ to quantitatively evaluate such similarity measure. We first propose a basic idea for the MRSE based on secure inner product computation, and then give two significantly improved MRSE schemes to achieve various stringent privacy requirements in two different threat models. Thorough analysis investigating privacy and efficiency guarantees of proposed schemes is given. Experiments on the real-world dataset further show proposed schemes indeed introduce low overhead on computation and communication.
Phantom: Physical layer cooperation for location privacy protection	Localization techniques that allow inferring the location of wireless devices directly from received signals have exposed mobile users to new threats. Adversaries can easily collect required information (such as signal strength) from target users, however, techniques securing location information at the physical layer of the wireless communication systems have not received much attention. In this paper, we propose Phantom, a novel approach to allow mobile devices thwart unauthorized adversary's location tracking by creating forged locations. In particular, Phantom leverages cooperation among multiple mobile devices in close vicinity and utilizes synchronized transmissions among those nodes to obfuscate localization efforts of adversary systems. Through an implementation on software-defined radios (GNU Radios) and extensive simulation with real location traces, we see that Phantom can improve location privacy.
Location privacy preservation in collaborative spectrum sensing	Collaborative spectrum sensing has been regarded as a promising approach to enable secondary users to detect primary users by exploiting spatial diversity. In this paper, we consider a converse question: could space diversity be exploited by a malicious entity, e.g., an external attacker or an untrusted Fusion Center (FC), to achieve involuntary geolocation of a secondary user by linking his location-dependent sensing report to his physical position. We answer this question by identifying a new security threat in collaborative sensing from testbed implementation, and it is shown that the attackers could geo-locate a secondary user from its sensing report with a successful rate of above 90% even in the presence of data aggregation. We then introduce a novel location privacy definition to quantify the location privacy leaking in collaborative sensing. We propose a Privacy Preserving collaborative Spectrum Sensing (PPSS) scheme, which includes two primitive protocols: Privacy Preserving Sensing Report Aggregation protocol (PPSRA) and Distributed Dummy Report Injection Protocol (DDRI). Specifically, PPSRA scheme utilizes applied cryptographic techniques to allow the FC to obtain the aggregated result from various secondary users without learning each individual's values while DDRI algorithm can provide differential location privacy for secondary users by introducing a novel sensing data randomization technique. We implement and evaluate the PPSS scheme in a real-world testbed. The evaluation results show that PPSS can significantly improve the secondary user's location privacy with a reasonable security overhead in collaborative sensing.
Traffic-aware multiple mix zone placement for protecting location privacy	Privacy protection is of critical concern to Location-Based Service (LBS) users in mobile networks. Long-term pseudonyms, although appear to be anonymous, in fact empower third-party service providers to continuously track users' movements. Researchers have proposed the mix zone model to allow pseudonym changes in protected areas. In this paper, we investigate a new form of privacy attack to the LBS system that an adversary reveals a user's true identity and complete moving trajectory with the aid of side information. We propose a new metric to quantify the system's resilience to such attacks, and suggest using multiple mix zones to tackle this problem. A mathematical model is presented that treats the deployment of multiple mix zones as a cost constrained optimization problem. Furthermore, the influence of traffic density is also taken into account to enhance the protection effectiveness. The placement optimization problem is NP-hard. We therefore design two heuristic algorithms as practical and effective means to strategically select mix zone locations, and consequently reduce the privacy risks of mobile users trajectories. The effectiveness of our proposed solutions is demonstrated through extensive simulations on real-world mobile user data traces.
Achieving usable and privacy-assured similarity search over outsourced cloud data	As the data produced by individuals and enterprises that need to be stored and utilized are rapidly increasing, data owners are motivated to outsource their local complex data management systems into the cloud for its great flexibility and economic savings. However, as sensitive cloud data may have to be encrypted before outsourcing, which obsoletes the traditional data utilization service based on plaintext keyword search, how to enable privacy-assured utilization mechanisms for outsourced cloud data is thus of paramount importance. Considering the large number of on-demand data users and huge amount of outsourced data files in cloud, the problem is particularly challenging, as it is extremely difficult to meet also the practical requirements of performance, system usability, and high-level user searching experiences. In this paper, we investigate the problem of secure and efficient similarity search over outsourced cloud data. Similarity search is a fundamental and powerful tool widely used in plaintext information retrieval, but has not been quite explored in the encrypted data domain. Our mechanism design first exploits a suppressing technique to build storage-efficient similarity keyword set from a given document collection, with edit distance as the similarity metric. Based on that, we then build a private trie-traverse searching index, and show it correctly achieves the defined similarity search functionality with constant search time complexity. We formally prove the privacy-preserving guarantee of the proposed mechanism under rigorous security treatment. To demonstrate the generality of our mechanism and further enrich the application spectrum, we also show our new construction naturally supports fuzzy search, a previously studied notion aiming only to tolerate typos and representation inconsistencies in the user searching input. The extensive experiments on Amazon cloud platform with real data set further demonstrate the validity and practicality of the p- oposed mechanism.
Priv-Code: Preserving privacy against traffic analysis through network coding for multihop wireless networks	Traffic analysis presents a serious threat to wireless network privacy due to the open nature of wireless medium. Traditional solutions are mainly based on the mix mechanism proposed by David Chaum, but the main drawback is its low network performance due to mixing and cryptographic operations. We propose a novel privacy preserving scheme based on network coding called Priv-Code to counter against traffic analysis attacks for wireless communications. Priv-Code is able to provide strong privacy protection for wireless networks as the mix system because of its intrinsic mixing feature, and moreover, it can achieve better network performance owing to the advantage of network coding. We first construct a hypergraph-based network coding model for wireless networks, under which we formalize an optimization problem whose objective function is to make each node have identical transmission rate. Then we provide a decentralized algorithm for this optimization problem. After that we develop an information theoretic metric for privacy measurement using entropy, and based on this metric we demonstrate that Priv-Code achieves stronger privacy protection than the mix system while achieving better network performance.
Estimating age privacy leakage in online social networks	We perform a large-scale study to quantify just how severe the privacy leakage problem is in Facebook. As a case study, we focus on estimating birth year, which is a fundamental human attribute and, for many people, a private one. Specifically, we attempt to estimate the birth year of over 1 million Facebook users in New York City. We examine the accuracy of estimation procedures for several classes of users: (i) highly private users, who do not make their friend lists public; (ii) users who hide their birth years but make their friend lists public. To estimate Facebook users' ages, we exploit the underlying social network structure to design an iterative algorithm, which derives age estimates based on friends' ages, friends of friends' ages, and so on. We find that for most users, including highly private users who hide their friend lists, it is possible to estimate ages with an error of only a few years. We also make a specific suggestion to Facebook which, if implemented, would greatly reduce privacy leakages in its service.
Privacy-preserving RFID authentication based on cryptographical encoding	Radio Frequency IDentification (RFID) technology has been adopted in many applications, such as inventory control, object tracking, theft prevention, and supply chain management. Privacy-preserving authentication in RFID systems is a very important problem. Existing protocols employ tree structures to achieve fast authentication. We observe that these protocols require a tag to transmit a large amount of data in each authentication, which costs significant bandwidth and energy overhead. Current protocols also impose heavy computational demand on the RFID reader. To address these issues, we design two privacy-preserving protocols based on a new technique called cryptographical encoding, which significantly reduces both authentication data transmitted by each tag and computation overhead incurred at the reader. Our analysis shows that the new protocols are able to reduce authentication data by more than an order of magnitude and reduce computational demand by about an order of magnitude, when comparing with the best existing protocol.
L2P2: Location-aware location privacy protection for location-based services	Location privacy has been a serious concern for mobile users who use location-based services provided by the third-party provider via mobile networks. Recently, there have been tremendous efforts on developing new anonymity or obfuscation techniques to protect location privacy of mobile users. Though effective in certain scenarios, these existing techniques usually assume that a user has a constant privacy requirement along spatial and/or temporal dimensions, which may not be true in real-life scenarios. In this paper, we introduce a new location privacy problem: Location-aware Location Privacy Protection (L2P2) problem, where users can define dynamic and diverse privacy requirements for different locations. The goal of the L2P2 problem is to find the smallest cloaking area for each location request so that diverse privacy requirements over spatial and/or temporal dimensions are satisfied for each user. In this paper, we formalize two versions of the L2P2 problem, and propose several efficient heuristics to provide such location-aware location privacy protection for mobile users. Through multiple simulations on a large data set of trajectories for one thousand mobile users, we confirm the effectiveness and efficiency of the proposed L2P2 algorithms.
PReFilter: An efficient privacy-preserving Relay Filtering scheme for delay tolerant networks	Without direct path, information delivery in sparse delay tolerant networks (DTNs) typically relies on intermittent relays, making the transmission not only unreliable but also time consuming. To make the matter even worse, the source nodes may transmit some encrypted ΓÇ£junkΓÇ¥ information, similar as the spam emails in current mail systems, to the destinations; without effective control, the delivery of encrypted junk information would significantly consume the precious resource of DTN and accordingly throttle the network efficiency. To address this challenging issue, we propose PReFilter, an efficient privacy-preserving relay filter scheme to prevent the relay of encrypted junk information early in DTNs. In PReFilter, each node maintains a specific filtering policy based on its interests, and distributes this policy to a group of ΓÇ£friendsΓÇ¥ in the network in advance. By applying the filtering policy, the friends can filter the junk packets which are heading to the node during the relay. Note that the keywords in the filtering policy may disclose the node's interest/preference to some extent, harming the privacy of nodes, a privacy-preserving filtering policy distribution technique is introduced, which will keep the sensitive keywords secret in the filtering policy. Through detailed security analysis, we demonstrate that PReFilter can prevent strong privacy-curious adversaries from learning the filtering keywords, and discourage a weak privacy-curious friend to guess the filtering keywords from the filtering policy. In addition, with extensive simulations, we show that PReFilter is not only effective in the filtering of junk packets but also significantly improve the network performance with the dramatically reduced delivery cost due to the junk packets.
Providing hop-by-hop authentication and source privacy in wireless sensor networks	Message authentication is one of the most effective ways to thwart unauthorized and corrupted traffic from being forwarded in wireless sensor networks (WSNs). To provide this service, a polynomial-based scheme was recently introduced. However, this scheme and its extensions all have the weakness of a built-in threshold determined by the degree of the polynomial: when the number of messages transmitted is larger than this threshold, the adversary can fully recover the polynomial. In this paper, we propose a scalable authentication scheme based on elliptic curve cryptography (ECC). While enabling intermediate node authentication, our proposed scheme allows any node to transmit an unlimited number of messages without suffering the threshold problem. In addition, our scheme can also provide message source privacy. Both theoretical analysis and simulation results demonstrate that our proposed scheme is more efficient than the polynomial-based approach in terms of communication and computational overhead under comparable security levels while providing message source privacy.
MobiShare: Flexible privacy-preserving location sharing in mobile online social networks	Location sharing is a fundamental component of mobile online social networks (mOSNs), which also raises significant privacy concerns. The mOSNs collect a large amount of location information over time, and the users' location privacy is compromised if their location information is abused by adversaries controlling the mOSNs. In this paper, we present MobiShare, a system that provides flexible privacy-preserving location sharing in mOSNs. MobiShare is flexible to support a variety of location-based applications, in that it enables location sharing between both trusted social relations and untrusted strangers, and it supports range query and user-defined access control. In MobiShare, neither the social network server nor the location server has a complete knowledge of the users' identities and locations. The users' location privacy is protected even if either of the entities colludes with malicious users.
Efficient algorithms for K-anonymous location privacy in participatory sensing	Location privacy is an important concern in participatory sensing applications, where users can both contribute valuable information (data reporting) as well as retrieve (location-dependent) information (query) regarding their surroundings. K-anonymity is an important measure for privacy to prevent the disclosure of personal data. In this paper, we propose a mechanism based on locality-sensitive hashing (LSH) to partition user locations into groups each containing at least K users (called spatial cloaks). The mechanism is shown to preserve both locality and K-anonymity. We then devise an efficient algorithm to answer kNN queries for any point in the spatial cloaks of arbitrary polygonal shape. Extensive simulation study shows that both algorithms have superior performance with moderate computation complexity.
Surveying Privacy Leaks Through Online Social Network	This paper presents a survey on social networks' privacy leaks and the potential hazards for users, especially teenagers. In particular, the profiles of two teenagers, one male and one female, with fake names were created. Using a suitable software tool, friend requests were sent massively. As a result, two networks of friends were created and access was granted to a significant amount of users' personal information. Both profiles received requests for friendship and personal chat by adults aged up to 53 years old. In general the survey leads to results that reveal several hazards for children and critical issues about privacy of social network users.
Semantic Information Model for Privacy-Aware Access Control	As privacy is becoming a salient issue for both organizations that provide digital services, as well as their users, access control shifts from traditional role-based models to more sophisticated paradigms that include additional provisions with respect to privacy. Complementing and particularizing our previous research work on the development of frameworks for the enforcement of privacy-aware access control, this paper targets the protection of personal data that are collected in the context of passive monitoring of communication networks. Specifically, this paper's focus is on the description of a semantic access control model conceived on the basis of the privacy legislation, which is enforced by an innovative two-tier monitoring architecture.
PROACT: An Ontology-Based Model of Privacy Policies in Ambient Intelligence Environments	Future computing environments involve integrating everyday objects equipped with tiny processors, sensors and wireless network cards. These smart objects (artifacts) may explore their environment and communicate with each other. Interactivity with humans may provide the ability of dealing with tasks in an intuitive way. In order to model the way everyday activities are carried out within such an environment, we introduce the notion of ΓÇ£activity sphereΓÇ¥. Activity spheres are/include such smart artifacts in order to provide functionality of various applications. The privacy of the users is considered as a major issue due to the invisibility of all computations which leads to the users being unaware of them. This paper describes how the privacy of the resources within each activity sphere owned by a user can be protected, by applying a privacy policy ontology, called PROACT.
Teenagers' Use of Social Network Websites and Privacy Concerns: A Survey	In the last few years students use the internet services and social network websites daily either at school or at home. Students create profiles, find friends and share with them personal information, thoughts and photos. In this work we have conducted a research, where we studied the relationship of Greek high school students with social networking sites as long as the information they publish and the privacy settings they make. Particular focus was given on gender differences concerning the use of social networking sites as well as their privacy settings.
Using Strand Space Model to Verify the Privacy Properties of a Fair Anonymous Authentication Scheme	The strand space model has been proposed as a formal method for verifying the security goals of cryptographic protocols. Many cryptographic protocols aim not only to provide security, but also privacy properties of the communication such as anonymity. In this paper, we apply the strand space model in order to verify the security and privacy goals of a recently proposed anonymous authentication scheme. We show that the strand space model can be used to formalize privacy properties such as transaction untraceability and unlink ability, user non-frame ability and anonymous credential non-transferability.
Towards Privacy-Aware Target Advertising	Online advertising tends to be one of the best ways for promotion and advertising in our days. The more targeted an advertisement is, the more efficient and attractive could also be to the end user. On the other hand, Internet targeted advertising is mostly based on user's personal information such as profiling, Internet habits, history, etc, even if part of such information could be characterized as private. Thus, gathering and analyzing users' information might raise serious privacy concerns. This paper presents a privacy-aware, ontology-based middleware architecture enabling information collection and analysis coming from real-time communication (i.e. chat applications) and triggering third party advertising servers, in order to achieve targeted advertising relevant to the real-time content.
Privacy and Traceability in Social Networking Sites	Over the last few years the use of social networking sites has been dramatically increased. However, this extensive growth is not without consequences, identity theft, cyber bullying and child exploitation are only some of the problems that have arisen and are directly connected to privacy violation and trace ability problems that are present in such platforms. This paper proposes an architecture for easing the aforementioned problems and demonstrates it through its implementation in facebook. Furthermore, the main advantages of the proposed approach are discussed in terms of future implementations in other social networking sites.
An Analysis of Privacy-Related Strategic Choices of Buyers and Sellers in E-commerce Transactions	E-commerce transactions, in addition to the exchange of goods and services for payment, often entail an indirect transaction, where personal data are exchanged for better services or lower prices. This paper analyses buyer's and seller's privacy-related strategic choices in e-commerce transactions through game theory. We demonstrate how game theory can explain why buyers mistrust internet privacy policies and relevant technologies (e.g. P3P) and sellers hesitate to invest in data protection.
Protect privacy of medical informatics using k-anonymization model	While there is an increasing need to share medical information for public health research, such data sharing must preserve patient privacy without disclosing any information that can be used to identify a patient. A considerable amount of research in data privacy community has been devoted to formalizing the notion of identifiability and developing techniques for anonymization but are focused exclusively on structured data. On the other hand, efforts on de-identifying medical text documents in medical informatics community rely on simple identifier removal or grouping techniques without taking advantage of the research developments in the data privacy community. This paper attempts to fill the above gaps and presents a framework and prototype system for de-identifying health information including both structured and unstructured data. We empirically study a simple Bayesian classifier, a Bayesian classifier with a sampling based technique, and a conditional random field based classifier for extracting identifying attributes from unstructured data. We deploy a k-anonymization based technique for de-identifying the extracted data to preserve maximum data utility. We present a set of preliminary evaluations showing the effectiveness of our approach.
An improved forward secure RFID privacy protection scheme	Lightweight authentication protocols are necessary in the RFID system because tags are lack of computational resources and communication ability. Many researchers have proposed some authentication protocols which only use lightweight operations, such as XOR, hash operation and so on. In this paper, we analyze some authentication protocols. Especially, we analyze a forward secure RFID privacy protection scheme proposed by Ohkubo et al and find its weakness. Afterwards, we propose an improved forward secure RFID privacy protection scheme and analyze it. It is low-cost and suitable for inexpensive tags. Moreover, it not only provides one-way authentication and forward security but also resists replay attack.
Towards Privacy in Personal Data Management	We present a personal data management framework called Polis, which abides by the following principle: Every individual has absolute control over her personal data, which reside only at her own side. Preliminary results indicate that beyond the apparent advantages of such an environment for userspsila privacy, everyday transactions remain both feasible and straightforward.
Privacy Preserving in eLearning Environment (Case of Modeling Hippocratic Database Structure)	The number and size of different kinds of electronic files (text, pictures and videos) incorporated into eLearning environments were dramatically increased during the last ten years and this triggered a development of new web based systems for that specific environment. These systems were developed to satisfy current and specific users' needs which lead to appearance of very heterogeneous environments without interoperability of their services. eLearning system security management, privacy and access control are currently attracting very much attention due to the latest trends in education systems development and attempts to create an electronic file of a student in order to enable the mobility of studying. Access control should prevent unauthorized access to shared resources. Meeting such a requirement in eLearning systems is very complex since it is necessary to protect the content, services and personal data not only from the external users of a system, but also from the development and administrative internal users of a system. Solution for the above mentioned problems can be found in application of the "Hippocratic Databases - HDB concept". The idea is inspired by the basic principles of Hippocratic Oath to be applied on the databases in order to provide data privacy and confidentiality to be one of the most important elements in information system design. Implementation and advantages of this concept have been researched for the needs of business intelligence systems and health information systems, but not of eLearning systems.This paper considers possibilities for development and implementation of HDB in eLearning systems and its sections (LMS- Learning Management System and CMS-Content Management System) by applying W3C (The World Wide Web Consortium) requirements and standards. HDB model structure and specific features for the needs of a specific eLearning environment are presented in the paper.
Privacy Preserving Record Linkage Using Phonetic Codes	Phonetic codes such as Soundex and Metaphone have been used in the past to address the Record Linkage Problem. However, to the best of our knowledge, no particular effort has been made within this context towards privacy assurance during the matching process. Phonetic codes have an interesting feature which can be cornerstone to providing privacy. They are mappings of strings which do not exhibit the one-to-one properly. In this paper, we present a novel protocol for achieving privacy preserving record linkage using phonetics, we provide proof of correctness for our approach and finally we illustrate experimental results concerning performance and matching accuracy. The proposed protocol can be equally well applied to codes different than the phonetic ones, which do not exhibit the one-to-one property, such as hash tables with comparable results.
Methods for Designing Privacy Aware Information Systems: A Review	A major challenge in the field of software engineering is to make users trust the software that they use in their everyday professional or recreational activities. Trusting software depends on various elements, one of which is the protection of user privacy. Protecting privacy is about complying with user's desires when it comes to handling personal information. It can also be defined as the right to determine when, how and to what extend information about them is communicated to others. The aim of this paper is to bring forward the modern practices for ensuring privacy during the design of information systems. To this end, it provides an overview of recent requirements engineering approaches which focus on the elicitation and management of privacy requirements. Comparative analysis of these approaches based on a systematic framework reflects on current research trends as well as open issues that provide a foundation for further research.
Privacy-Aware Passive Network Monitoring	Among the several threats to personal privacy caused by the emerging Information and Communication Technologies, activities related to passive network monitoring hold an outstanding position. This paper describes a privacy-aware passive network monitoring system, focusing on the specification and performance evaluation of its access control and authorization aspects.
Privacy Preserving Sequential Pattern Mining Based on Secure Multi-party Computation	Privacy-preserving data mining in distributed or grid environment is an important hot research topic in recent years. We focus on the privacy-preserving sequential pattern mining in the following situation: multiple parties, each having a private data set, wish to collaboratively discover sequential patterns on the union of the their private data sets respectively without disclosing their private data to any other party. Therefore, we put forward a novel approach to discover privacy-preserving sequential patterns based on secure multi-party computation using homomorphic encryption technology
Privacy Preserving Clustering by Cluster Bulging for Information Sustenance	Cluster analysis is a data mining approach for unsupervised learning. However, the use of clustering as a data mining tool has been a cause of growing concern as the use of this technology is violating individual privacy. This paper presents a method for privacy preserving clustering through cluster bulging. In this method, the objects of the database are first aligned into clusters based on a similarity measure. The data in these clusters is perturbed in a controlled manner by modifying the values of various objects, so that, in the perturbed data set, the clusters are bulged in comparison to those in the original data set. In order to perform this perturbation, every cluster is displaced along the line joining its centroid to the centroid of the whole data set. And, then, every object in each cluster is shifted along the line joining that object to the centroid of the cluster. The word bulging used here refers to both positive and negative bulging. The method in essence manipulates the similarity measures and recomputes the new perturbed objects of the respective clusters. Thus, every object in the bulged cluster represents its corresponding object from the original cluster. After the application of this method, the objects get perturbed, while the number of member objects and shape of each cluster remain the same as those of the original clusters, thereby the information in the two instances of the data sets is sustained, while, the privacy of sensitive data is preserved.
Privacy-preserving data publication: A review on ΓÇ£updatesΓÇ¥ in continuous data publication	Preserving the privacy of individuals while publishing their relevant data has been an important problem. Most of previous works in privacy preserving data publication focus on one time, static release of datasets. In multiple publications however, where data is published multiple times, these techniques are unable to ensure privacy of the concerned individuals as just joining either of the releases could result in identity disclosure. In this work, we tried to investigate the major findings in the scenario of continuous data publication, in which the data is not only published multiple times but also modified with INSERTS, UPDATES and DELETE operations.
A new method for preserving privacy in quantitative association rules using DSR approach with automated generation of membership function	Data mining is the process of extracting hidden patterns from data. With the explosion of data at a tremendous rate, data mining is essential to extract useful information. Association rule mining is a method of finding correlation relationships among large set of data items. A rule is characterized as sensitive if its disclosure risk is above a certain confidence value. Sensitive rules should not be disclosed to the public, as they can be used to infer sensitive data and provide an advantage for the business competitors. Techniques for hiding association rules are limited to binary items. But, real world data consists of quantitative values. In this paper, a method to hide fuzzy association rule is proposed, in which, the fuzzified data is mined using modified apriori algorithm in order to extract rules and identify sensitive rules. The sensitive rules are hidden by decreasing the support value of Right Hand Side (RHS) of the rule. A framework for automated generation of membership function is also proposed. Experimental results of the proposed approach demonstrate efficient information hiding with minimum side effects.
Employing bloom filters for privacy preserving distributed collaborative kNN classification	Increasingly, organizations are collecting users' personal data to mine rules that describe user behavior. In addition, different organizations may want to collaborate to derive rules based on collective data. However, due to the privacy-preserving requirements, organizations may not be able to share their data directly with others. In the current work, we employ Bloom filters to hide the sensitive data while still being able to perform collaborative data mining. In particular, we experiment with the kNN classifier. Using the Euclidean distance and Jaccard similarity measures, we evaluate the efficacy of the proposed representation. Using some real data, we show that Bloom filters effectively preserve data privacy while maintaining the accuracy of classifications.
A secure and efficient message authentication protocol for VANETs with privacy preservation	In this paper, a secure and efficient protocol for vehicular ad hoc networks has been proposed that ensures both message authentication and privacy preservation. As safety related message may contain life critical information, it is a necessity that the sender as well as the message are authentic. The proposed scheme is based on a secure elliptic curve digital signature algorithm approach. The proposed scheme supports conditional privacy, where the user's location can be revealed at the willingness of the user. Apart from this, the scheme is secure against attacks like DoS, Sybil and Grey/Black Hole attacks. From the comparison with previously proposed schemes, it is found that the proposed scheme as based on elliptic curve discrete logarithmic problem, outperforms existing algorithms based on integer factoring and discrete logarithmic problem.
Privacy preserving hierarchical content distribution in multiparty multilevel DRM	Digital rights management (DRM) system is widely used to restrict the illegal content consumption. However, to achieve security and accountability, the system loses privacy. In addition, multiparty multilevel (MPML) DRM system maintains single private key generator (PKG), which completely eliminates online lookup in a large network. In this paper, we present a hierarchical identity based encryption (HIBE) scheme for MPML DRM. In the proposed scheme, we use 2-level HIBE in which a trusted party act as a root PKG and each domain PKG act as a first level authorities, which are responsible to generate the private keys for the entities of their domains. Further, we address a commutative encryption based content key acquisition scheme to achieve privacy.
A novel methodology for security and privacy of cloud computing and its use in e-Governance	Cloud computing has opened a new door for both corporate and Government sectors. This new era of Information technology is similar to the invention of electrification in industrial age. Government sectors can also adopt this cutting edge technology as e-Governance to smoothen its working process. But this new technology needs to be matured in context of security, scalability, availability etc. In this regard, this manuscript has emphasized on security aspect of cloud computing and its subsequent impact on e-Governance as cloud-Governance. Here, an effective frame work for cloud-Governance has been proposed and then Hadamard matrix concept has been used for the development of encryption and decryption algorithms in order to enhance the security mechanism for cloud-Governance. Further, an experimental set up and results have been presented in order to lay bare the effectiveness of the proposed algorithms.
Application of Hippocratic principles for privacy preservation in social network	With the number of users of social network growing exponentially, the need of protecting the user privacy in network has gain the prime importance. While joining a social network, the user is requested to fill up a lot of unnecessary information like educational background, birth date, interests etc. This information may get leaked or mal-accessed if not protected with proper security measures. The data stored in social network may be attacked in different ways according to purpose of attack. In this paper we identify basic types of privacy breaches in social network. Secondly, we study the concept of Hippocratic principles. We propose a simple classification of the information requested from the user when he joins the social network. We also propose a privacy preserving model based on Hippocratic principles, specifically for Purpose, Limited Disclosure, Consent and compliance. Our proposed model work on privacy metadata, query analyzer is extended to check the define policy before giving the result out. This model can be used while mining on private data, which will help to enhance the privacy level of trustworthiness among internet users.
Holistic Estimation of Security, Privacy and Trust in Mobile Ad Hoc Networks	A holistic and semi-automatic framework for estimation of the overall security, privacy and trust (SPT) level could be used to answering to the challenges of the usage of mobile ad hoc networks in the Ubiquitous Computing Age. We propose our ideas for composing this framework, structured according to currently known security, privacy and trust challenges. We propose a measurement architecture is to monitor the SPT performance of mobile ad hoc networks at the node, network segment and entire network levels.
Does a Privacy Risk Impose a Real Threat in Collaborative Environments?	The designing and building of collaborative environments through inter-organizational information systems are faced by many challenges. One of these challenges is the privacy risk that might occur because of the lack of the protection while sharing sensitive data. In this paper, we present case study of building a collaborative environment among financial organizations who intend to improve their security capabilities by building collaborative intrusion detection system. However, the case study doesn't take into account the privacy problem and consequently, the damages that can be occurred because of the lack of the privacy protection. Our concentration is to show that the privacy risk should be considered as a real threat for the collaboration because, in some cases, a privacy breach might go beyond just being an annoying issue to cause more other serious damages and losses such as money or reputation for the collaborating organizations. In other words, we are going to provide the motivations for the need of the privacy protection for the collaborative environment which consequently ensures that the contributions from the organizations are useful and the expected results from the collaboration can be gained.
Design of internal information leakage detection system considering the privacy violation	Nowadays, companies are monitoring their employee's behavior using the DLP (Data Loss Prevention) solution to protect their information assets from internal attackers. During the monitoring the behaviors of employees, it is inevitable disclosing the private information to recognize the violation of internal regulation about handling of companies critical information. Actually there is trade-off relationship between privacy protection and data loss protection in company's information management. The trade-off relationship implies that there may be privacy violation if we are trying to prevent the internal information leakage strictly. In this paper, we are suggesting a data loss prevention method considering the privacy violation level. Especially, we are considering a method of quantifying the degree of privacy violation based on the data units which are exposed when the employee's data handling is monitored. At the same time, we are suggesting a method of quantifying the degree of importance of data units which are monitored.
Sensitivity to online privacy in social networking sites	Privacy has been a subject of discussion long before the advent of computer networks, however, the notion of privacy has taken a dramatic turn due to the proliferation of information technology tools and applications, which is further aggravated by the social networking sites which allow users to display their profile information to be viewed and shared by millions of online visitors. This gives the potential of negative use of their information. Previous works have concentrated largely on privacy in online transaction with just a few on the higher institution of learning, which is regarded as one of the earliest adopters of information technology and the most unsecured environments. This work examines the perception of online privacy among university students with the intention of examining the relationship between the demography, level of awareness and online privacy. The results show that despite there is no significant difference based on gender as well as whether the respondent is in IT related field or not, there is a contradiction between the level of awareness and expected attitude to online privacy.
Mitigating privacy issues on Facebook by implementing information security awareness with islamic perspectives	This paper highlights the broad range of information security awareness by providing an awareness guideline to address human vulnerabilities in social networking site. It explains the security challenges in social networking sites. These social networking sites pose great challenges on how to protect human privacy. Therefore, this paper will briefly discuss of the implementation of information security awareness in order to address privacy issues with social networking site i.e. Facebook. This paper will begin with the importance of information security to protect information assets by maintaining the confidentiality, integrity, and availability (CIA). It also focuses on the major privacy issues challenges on Facebook. The privacy issues can be mitigated with the information security awareness. This paper discusses privacy issues and security awareness from Islamic point of view to help minimize privacy issues on Facebook.
Privacy and trust in the Islamic perspective: Implication of the digital age	In the name of Allah, most Gracious and most Merciful. The digital age is slowly degrading the limitation and common understanding of privacy and trust through digital life, which has open world concept. It has become normal procedure when the user must submit their personal details for digital service such as social networking, electronic commerce, personal hosting, etc. Meanwhile, to be able to revealing their privacy willingly, user put their trust on organization to use their data based on agreement. In this sense, user expects their privacy right to be protected securely and actively. The dilemma occurred due to commercialization, consumerism and legislation as interaction issues, which shift the focus of user to identify the importance of their personal data and organization to analyze the process of data management. On the other hand, Islam gave the basic understanding in privacy and trust that emphasize important factor in human determination and intention. This paper will focus on how to define the standard and limitation of the concept privacy and trust based on Islamic perspective in aligning with the implication of digital age related to interest, classification and purpose.
System for privacy policy enforcement & access control for web applications	The paper aims at providing practical implementation details of a system for privacy policy enforcement and Role Based Access Control of data. The implementation is inspired by the lack of privacy policy enforcement in present application systems. Till now access control has been achieved by coding the required access policies in the application layer or by defining specific roles. This leaves less scope for scalability of the system when the need arises. We attempt to provide privacy aware access control framework that end developers can use for developing their applications. This system will be responsible for automatically implementing the policy enforcement. The developers can then freely utilize the functionality of our system to only focus upon writing their applications.
Secure Vault: A privacy preserving reliable architecture for Secure Social Networking	Social Networking Sites(SNS) are becoming the preferred medium for internet users to stay connected. Unfortunately, there are numerous threats to the privacy and security of users' personal data shared on these sites. Some third party privacy and security enhancing applications and solutions are available, but they only give a piece meal solution. The need of the hour is to design and develop a Secure Social Networking Site (SSNS) which addresses users concerns right from design stage. This paper proposes a novel architecture for a Secure Social Networking Site called "Secure Vault". Secure Vault addresses the privacy and security issues of a user by interleaving the concepts of data dislocation, fake information and encryption. In a unique solution to restrict unauthorized viewing by visitors we propose presenting to the unauthorized visitors "fake" information, rather than blocking out the visitor, an approach currently adopted by the existing SNSs. The architecture shields users' private data by using encryption and enhances reliability of storage of critical and sensitive data by dislocating it to user specified servers.
Enhanced sharing and privacy in distributed information sharing environments	With the advancement in distributed computing and collaborative software technologies, information sharing and privacy related issues are gaining interest of researchers related to digital information creation, management, and distribution. Collaborative information sharing environment requires enhanced information sharing among users while privacy laws demand for the protection of user's information from unauthorized access and usage. Keeping this trade-off in view, there is a need for a flexible and enhanced information sharing model that preserves the privacy of user's information. We extend the Role-Based Access Control (RBAC) model to incorporate sharing and privacy related requirements and present a Dynamic Sharing and Privacy-aware Role-Based Access Control (DySP-RBAC) model. It is a family of models including core, hierarchical, and constrained RBAC models. The RBAC model is extended using team and task data elements as well as new data elements related to sharing and privacy of information. Sharing and privacy-based permission assignments and their conflict-handling strategies are described for a distributed and dynamic information sharing scenario.
A novel system for fingerprint privacy protection<sup>1</sup>	This paper proposes a novel system for protecting the fingerprint privacy without using a token or key. In the enrollment, two fingerprints are captured from two of an user's fingers. We extract the minutiae positions from one fingerprint, the orientation from the other fingerprint and the primary cores from both fingerprints. Based on these extracted information, a combined minutiae template is generated and stored in a database. In the authentication, the user needs to provide two query fingerprints from the same two fingers which are used in the enrollment. By storing the combined minutiae template, the complete minutiae feature of a single fingerprint will not be compromised when the database is stolen. Furthermore, because of the similarity in topology, it is also difficult for the attacker to distinguish our template from the minutiae of an original fingerprint. We evaluate the performance of our system over the FVC2002 DB2_A database. The results show that the False Rejection Rate of our system is 3% when the False Acceptance Rate is 0.01%.
Protecting Privacy Credentials from Phishing and Spyware Attacks	Privacy credentials, such as user identification and passwords are vulnerable to phishing and spyware attacks. Through a combination of policy, monitoring, and enforcement these attacks can be mitigated.
Preserving User Location Privacy Based on Web Queries and LBS Responses	There is continued growth in online services that provide users with content based on location. These location based services (LBS) all require a location declaration by the user (or his electronic device). A typical example is a web query for services within an area in which the user is interested. Since the user cannot control the use of the data included in his query once it leaves the device or the response, he must assume that information is available to an unknown observer, thereby creating the potential for the user's location privacy to be compromised. This paper introduces the concept of a location privacy threshold which has two components: distance from the true location and probability that an observer would select the user's true location from a set of bogus locations. To preserve the user's location privacy, his location can be cloaked by adding additional web queries for the same information in areas near his designated location. A minimum spanning tree algorithm is used to identify clusters of potential user locations and determine whether the queries and replies provide enough uncertainty in the user's location to meet his predetermined privacy threshold.
An Exploration on Security and Privacy Issues of Biometric Smart ID Cards	Biometric and smart card technologies, which can be combined to create a digital identity for an individual, have recently received a great deal of attention. The biometric smart ID concept has been used by governments, financial institutions, and private companies worldwide to counter identity fraud in such applications as multi-purpose access cards, ATM cards, e-passports, and national ID cards. However, there are increasing concerns about both the technology's potential vulnerabilities and its relation to privacy issues (such as excessive profiling of users). In this paper, we analyze biometric smart card technology as it relates to security and privacy threats and investigate different biometric ID system configurations.
Privacy Preserving Reputation Inquiry in a Peer-to-Peer Communication Environment	This research presents a privacy preserving peer-to-peer communication mechanism that allows peers to obtain reputation information of each other through a trustworthy mediator proxy. A mediator proxy is considered trustworthy, if even when it is compromised, it can guarantee three conditions: (1) the anonymity of the identity of the responders and the target being inquired, (2) the privacy of the content in an inquiry and a response, and (3) the boundary limit of the reputation summary with no possibility of combining the response of multiple inquiries to reverse engineer the reputation rating of an individual responder.
Addressing privacy issues in CardSpace	CardSpace (formerly known as InfoCard) is a Digital Identity Management system that has recently been adopted by Microsoft. In this paper we identify two security flaws in CardSpace that may lead to a serious privacy violation. The first flaw is the reliance on Internet user judgements of the trustworthiness of service providers, and the second is the reliance of the system on a single layer of authentication. We also propose a solution designed to address both flaws. Our solution is compatible with the currently deployed CardSpace identity metasystem, and should enhance the privacy of the system with minor changes to the current CardSpace framework. We also provide a security and performance analysis of the proposed solution.
An Architecture for Privacy Preserving Collaborative Filtering on Web Portals	Popular E-commerce portals such as Amazon and eBay require user personal data to be stored on their servers for serving these users with personalized recommendations. These recommendations are derived by virtue of collaborative filtering. Collaborative filtering (CF) is a method to perform automated recommendations based upon the assumption that users who had similar interests in past, will have similar interests in future too. Storing user personal information at such servers has given rise to a number of privacy concerns [13] which are effecting business of these services [15]. In this paper, we present a novel architecture for privacy preserving collaborative filtering for these services. The proposed architecture attempts to restore user trust in these services by introducing the notion of 'distributed trust'. This essentially mean that instead of trusting a single server, a coalition of servers is trusted. Distributions of trust makes the proposed architecture fault resilient and robust against security attacks. Moreover, the architecture employs an efficient crossing minimization based biclustering algorithm for collaborative filtering. This algorithm is easily amenable to privacy preserving implementation. The privacy preserving implementation makes use of a threshold homomorphic cryptosystem. The proposed algorithm is fully implemented and evaluated with encouraging results.
Enforcing Privacy by Means of an Ontology Driven XACML Framework	Nowadays enforcing privacy in enterprises is recognized as an issue of impact. Actually, it is a big challenge to adapt normative laws and regulations in a software system. It is a challenging task to include the formalized laws and rules in enterprises since e.g. more than one regulation may affect the terms of privacy concerning one situation. Traditional access control provides a general mechanism for assigning rights to individual users or roles. In the context of privacy this is insufficient; it offers no means to fulfil certain aspects such as limitations to the duration for which private data may be stored. To enforce privacy in enterprises we further need a fine granular access control mechanism on the data entities to ensure that every aspect of privacy can be reflected. This paper provides a novel solution for this by means of ontologies. The usage of ontologies in our approach differs from the conventional form in focusing on generating access control policies which are adapted from our software framework to provide fine granular access on the diverse data sources.
A Model for the Study of Privacy Issues in Secure Shell Connections	The secure shell protocol strives to protect the privacy of its users in several ways. On one hand, the strong encryption and authentication algorithms that it adopts provide guarantees that the data exchanged between two SSH endpoints remain private to third parties. On the other hand, the type of traffic that each SSH channel transports, such as e-mail, remote shell activity, etc., is also supposed to be hidden from any observer that does not possess the necessary keys. This paper introduces a simple but accurate model of the SSH channel which can be used to study the level of privacy that SSH-protected traffic can achieve with respect to the users' activities. We think that the model can facilitate several types of projects. For example, network managers can detect traffic anomalies hidden by SSH connections more easily by relying on the output of our model. Another example, which we present in this paper, is the use of this model to derive accurate fingerprints of the type of applications run through an SSH channel by simply starting from the statistics of captured clear-text traffic. Such fingerprints can then be used to detect what type of activity, i.e., what type of traffic, is going on within an SSH channel, thereby breaking user privacy.
Network Level Privacy for Wireless Sensor Networks	Full network level privacy spectrum comprises of identity, route, location and data privacy. Existing privacy schemes of wireless sensor networks only provide partial network level privacy. Providing full network level privacy is a critical and challenging problem due to the constraints imposed by the sensor nodes, sensor networks and QoS issues. In this paper, we propose full network level privacy solution that addresses this problem. This solution comprises of Identity, Route and Location (IRL) privacy algorithm and data privacy mechanism, that collectively provides protection against privacy disclosure attacks such as eavesdropping and hop-by-hop trace back attacks.
Geolocation-Based Trust for Vanet's Privacy	Research in vehicular ad hoc networks (VANETs) has evolved considerably over the last years. Security and privacy in VANETs have recently appealed special interest in the research community. In this paper we overview the main privacy concepts and explain why this concept is fundamental for wide adoption of VANETs. A set of privacy requirements for VANETs are established and studied, towards proposing a novel mechanism beyond the use of pseudonyms. In particular, this research demonstrates that there are still several challenges concerning privacy which solution is feasible to be extrapolated from highly demanding environments like e-Health. This paper reports our work in progress mainly describing the basis of a privacy mechanism that uses an authorization paradigm based on a Mandatory Access Control model and a novel mechanism that propagates trust information based on a vehicle's geolocation.
Realistic Threats to Self-Enforcing Privacy	A recent privacy protocol for secure e-polls aims at ensuring the submitting individuals that the pollster will preserve the privacy of their submitted preferences. Otherwise the individuals can indict the pollster, provided that the pollster participates actively in this phase. The analysis of the protocol in a realistic threat model denounces that a malicious pollster that abuses the private preferences by disclosure will arguably not help out during its own indictment. Therefore, the protocol ensures insufficient fairness among their participants because it gives the pollster some advantage over the individuals. Two variant protocols are introduced and analysed in the same threat model - one is found to move the advantage over the individuals, the other is found to achieve a satisfactory level of fairness.
Systematic Website Verification for Privacy Protection	The Internet is now a prime vehicle for business, community, and personal interactions. The privacy of individuals sensitive information has become a major concern of consumers who use the Web to purchase goods or obtain services in Web-based computing environments. In this paper, we analyze the risks pertaining to various Web sites in Korea, and propose the dynamic Web site verification system (DWVS) for minimizing illegal sharing of sensitive information. We also demonstrate the feasibility of our framework through a proof-of concept implementation.
Privacy Protection for Speech Information	Ubiquitous network society will be achieved soon. In the society, all electronic equipments including "sensors" are connected to the network and communicate each other to share information. Sensor information is very important for the network, especially for virtual reality systems which give feeling of begin there. Since the sensor information, however, includes a lot of privacy information, it is not preferred to send raw privacy information through the network. In this paper, we describe about privacy protection for speech information. We think that the privacy information in speech is "voice characteristics" and "linguistic privacy information." We try to protect these privacy information by using "voice conversion" and "deletion of privacy linguistic information for speech recognition result." Since, however, speech recognition technology is not robust in real environment still now, "elimination of only speech in noisy speech" technique is also considered.
Common Friends Discovery with Privacy and Authenticity	In this paper, we propose a common friend discovery algorithm considering the privacy of users and the authenticity of friend relationships. The privacy means userspsila other friendspsila information does not be leaked except their common friends. The authenticity signifies anyone can not successfully claim he is a friend of someone unless he really is. It has many applications such as playing games by friends, finding talking-topics by strangers, finding introducer of job interview, finding matchmaker of someone you desire to know, etc. We consider its security and matching probability. We also implement the algorithm in two mobile phones to prove that it is workable.
Privacy Protection in On-line Shopping for Electronic Documents	Blind decoding schemes are proposed as tools for protecting customerspsila privacy in on-line shopping for electronic documents such that the company has no way of knowing which documents the customers have purchased. Most of the blind decoding schemes suffer from the oracle problem. Schemes utilizing the transformability of digital signatures were proposed to ensure the correctness of the requests from the customers. In this paper, a secure blind decoding scheme based on RSA scheme is proposed. It does not utilize the transformability of RSA digital signature.
A Low-cost RFID Authentication Protocol with Location Privacy Protection	RFID system is gaining popularity and attracting interest from both the enterprises and academic institutes. But now, we face several security problems and challenges in RFID systems. In human centric applications, location privacy problem is the most important issue that should be solved. In this paper, we propose a RFID authentication scheme that achieves the goal of location privacy. We also cite the threat model to analysis security threat of our protocol. Moreover, our scheme can be implemented with low-cost and high efficiency.
Researches on Integrating Database Access Control and Privacy Protection	The development of modern information technology and digitalization of our daily lives brings security database new challenges. It is necessary for a security database to provide access control and privacy protection mechanism to ensure the legal use of data and to prevent privacy breach. This paper introduces an integrated security model which can provide the functions of privacy protection and access control simultaneously by building the connection between the validity of query in parameterized authorization view model and the suspiciousness of a conjunctive select-project-join query in online query audit model, it also designs a polynomial time detecting algorithm and two incorporating frameworks for the integrated model. The integrated security model can provide higher performance and fine-grained access control in modern database systems.
A New Scheme to Privacy-Preserving Collaborative Data Mining	Protection of privacy has become an important problem in data mining. In this paper, we present a new scheme to privacy-preserving collaborative data mining based on the homomorphic encryption and ElGamal encryption system in distributed environment. This scheme can be used to compute the k-nearest neighbor search. Our scheme is provable secure and efficient and can prevent colluded attacker. Comparing with the previous work on this issue, our method can be used in multi-parties who want to cooperatively compute the answers without revealing to each other their identity and their private data.
A Novel Biometric-Based Authentication Scheme with Privacy Protection	Since biometric data are unique and permanent characteristics of individuals, the privacy protection of biometric authentication schemes has become a common concern of the public. Recently, Tang et al. proposed a biometric-based authentication scheme in an attempt to solve the privacy concerns. However, their scheme cannot resist the attack of tamper. Motivated by these concerns, in this paper, we proposed a new biometric-based authentication scheme, which achieves identity privacy and transaction untraceability. Its security is based on the semantic security of the ElGamal algorithm. Analysis results show that our scheme is higher in efficiency than Tang et al. scheme does, and meanwhile, it can resist the tamper attack. It is concluded that the proposed scheme is more secure and more practical than the existing ones.
P3ARM: Privacy-Preserving Protocol for Association Rule Mining	The ability to mine large volumes of distributed datasets enables more precise decision making. However, privacy concerns should be carefully addressed when mining datasets distributed over autonomous sites. We propose a new privacy-preserving protocol for association rule mining (P3ARM) over horizontally partitioned data. P3ARM is based on a distributed implementation of the Apriori algorithm. The key idea is to arbitrary assign polling sites to collect itemsets' supports in encrypted forms using homomorphic encryption techniques. A pair of polling sites is assigned for each itemset. Polling sites are different for consecutive rounds of the protocol to reduce the potential for collusion. Our performance analysis shows that P3ARM significantly outperforms a leading existing protocol. Moreover, P3ARM is scalable in the number of sites and the volume of data
Allowing Finer Control Over Privacy Using Trust as a Benchmark	Every time a user conducts an electronic transaction over the Internet a wealth of personal information is revealed, either voluntarily or involuntarily. This causes serious breach of privacy for the user, in particular, if the personally identifying information is misused by the other users present in the network. Ideally, therefore, the user would like to have a considerable degree of control over what personal information to reveal and to whom. Researchers have proposed models to allow a user to determine what personal information to reveal while doing a transaction over the Internet. However, these models do not help the user in determining who to trust, how much to trust and why to trust them with the personal information. The models fail to address loss of privacy through the misuse of information. In this paper we propose a privacy enhancing trust model to measure the degree of confidence that a user can have in the context of preservation of her privacy during a transaction. The model considers several factor while computing trust which include a user's own experience and knowledge about the target user and feedback obtained from groups of peer users called 'trusted neighbors' and 'friends'. The proposed scheme provides a flexible and powerful approach for the secure handling of private data and offers a user considerable control over how she wishes to disseminate her personal data
Terminating the spamming links and privacy guaranteed search logs	Search engine spamming is a practice of misleading the search engine and increasing the page rank of undeserving websites. The black hat search engine optimization (SEO) techniques leads to untrustworthy results for search engines. Some commonly used black hat techniques has been characterized and proposed a new way to counter those techniques using link based spam detection combined with the page rank algorithm. This technique enhances discovering of the target page and tracing down the entire graph responsible for spreading spam and it investigates the problem of protecting privacy for publishing search engine logs. With the exponential growth of the available information on the WWW, current search engines do not just store and index web pages, they also store and mine information about their users. Hence the attackers can actively influence the search log and therefore the privacy of the user is lost. A novel algorithm called ZEALOUS has been introduced to publish privacy guaranteed search logs. The result of this paper filter out the malicious sites from the search results and enables the search logs available without disclosing their user's sensitive information.
Cluster based Location privacy in Wireless Sensor Networks against a universal adversary	Even though a lot security is given in the wireless sensor networks yet the information is being exposed. Such information can then used by the adversary for the attack. The existing privacy techniques defend against a local adversary. There are two main categories of privacy preservation in Wireless Sensor Networks. They are data privacy and the context privacy. In this paper, we describe Location privacy. Location privacy is extremely important in Wireless Sensor Networks. Information on location of events or on location of base stations can be of a primary concern of adversary. Location privacy is very important in hostile environments. It is sufficient for the adversary to find out location of sensors currently monitoring the location of the source to successfully localize and capture the source. Similarly, the adversary only needs to find out location of the base station to be able to mount a physical or other DoS attack on the base station and thus inactivate the whole network. In this paper, they are two main categories of privacy preserving techniques for Wireless sensor network that have been presented, data-oriented and context-oriented. So different techniques against a universal adversary with respect to context privacy are discussed. The paper presents recurrent clustering mechanism.
Empowering privacy based multi-level trust using random perturbation techniques	An additive perturbation based PPDM is proposed to address the problem of developing accurate models about all data without knowing exact information of individual values. To preserve privacy, the approach introduces random perturbation to individual values, before the data are published to third parties for mining purposes. In Existing System, the PPDM approach assumes single level trust on data miners. Under the single level trust, a data owner generates only one perturbed copy of its data with affixed amount of uncertainty. In proposed system, the PPDM approach introduces multilevel trust on data miners. Here different perturbed copies of same data are available to data miner at different trust levels & may combine these copies to jointly add additional information about original data & release the data is called diversity attacks. To prevent these attacks using multilevel PPDM approach, where random Gaussian noise is added to the original data with arbitrary distribution. So, the data miners will have no diversity gain in their joint reconstruction of the original data. This allows data owners to generate perturbed copies of its data on demand at arbitrary trust levels. This property offers the data owners maximum flexibility.
An Improved Privacy Protocol in Location Based Service	Several protocols of secure processing of user's information in Location Based Service (LBS) have been raised up. Kohlweiss et al constructed a secure framework protecting for both the user's location information and user's usage profiles using oblivious transfer and homomorphic encryption. However, an intermediate proxy was introduced in the protocol to interact between the server and the user, which makes the privacy security partly depending on the proxy's honesty. Moreover, the usages of homomorphic encryptions and zero knowledge proves in the protocol make the efficiency not so satisfying. Based on Kohlweiss et al's protocol, we propose an improved one using two oblivious transfers. In our improved protocol, no trusted third party is needed and user's location information and usage information can be protected by using oblivious transfer twice. We show that this improved protocol is easily constructed and with higher privacy security and more satisfying efficiency.
Chaos-Based Renewable and Privacy Preserving Binary Palmprint Phase Templates for Cancellable Palmprint Recognition	This paper presents a chaos-based renewable and privacy preserving binary palmprint phase template for cancellable palmprint recognition. In the proposed approach, a novel 2D orthogonal Log-Gabor filter is firstly constructed by two 2D Log-Gabor filters with orthogonal orientations to extract binary palmprint biometric phase template. And then the binary palmprint phase templates are encrypted by chaotic stream ciphers encrypt run in integer domain to generate renewable and privacy preserving binary palmprint templates. During the matching stage, the Hamming distance between two encrypted palmprint templates is employed to measure the similarity of different palmprints. The experiments carried out on PolyU palmprint database confirm the effectiveness of the proposed approach.
Research on Privacy Preserving Data in Web Log Mining	Researches on preserving private data in the application of web data mining possess practical value. Through introducing basic concepts of web log mining and private data protection, this paper analyzes the status quo of privacy preservation in web log mining, and then it puts forward privacy preserving mining model based on evolutionary algorithm of cloud model, combining with evolutionary algorithm and cloud model theory. This model utilizes digital features of cloud and transformation between its qualitative concept and quantitative value expression. Thus, this model effectively conceals sensitive data, realizes web log mining based on privacy preservation. Results of the experiment reveal the feasibility and superiority of applying evolutionary algorithm of cloud model to privacy preservation in web log mining.
A User-Centric Privacy Access Control Model	Privacy is considered to be a critical issue for providing high quality ubiquitous network services to users over the Internet. User's privacy should be protected and access to privacy information must be controlled in accordance with user's privacy preferences. Existing privacy-aware access control strategies often store all the privacy access control policies on the server side and thus fail to consider the dynamic nature of privacy preferences. In this paper, we propose a user-centric privacy-enhanced access control model and show that our model takes the dynamic nature of user's privacy preferences into consideration and can thus fulfill any kind of privacy requirements. By separating access policies apart from privacy policies, which are now stored at user side and therefore fully under user's control, we demonstrate that our model can provide users with a flexible way of controlling privacy policies that are consistent with their preferences.
Privacy preserving evaluation of signal quality with application to ECG analysis	A problem often neglected in privacy-preserving protocols is the need to ensure that processed signals are of sufficient quality. This is a particularly pressing need in remote e-health services wherein measurements are performed by consumers, hence raising the need for solutions that assess the quality of the recorded signals to guarantee correct (medical) decisions. In this paper, we introduce the problem of assessing signal quality in the encrypted domain and propose a privacy-preserving protocol to solve it. We use the Signal-To-Noise Ratio (SNR) between the original signal and a filtered version of the signal itself as the quality measure. The proposed scheme relies on a hybrid multiparty computation protocol based on Homo-morphic Encryption and Yao's Garbled Circuits. A central point in the protocol is the application of the logarithm function to the linear SNR. We do so by introducing an efficient protocol for the computation of an integer version of the logarithm function that has linear complexity in the bitsize of the signal energy. We prove the validity of the proposed protocol, both in terms of accuracy and efficiency by applying it to the computation of the quality of ECG signals.
Privacy preserving string comparisons based on Levenshtein distance	Alice and Bob possess strings x and y of length m and n respectively and want to compute the Levenshtein distance L(x, y) between the strings under privacy and communication constraints. The Levenshtein distance, or edit distance, has a dynamic programming formulation that solves a series of minimum-finding problems. Based on this formulation, there are known symmetric privacy-preserving protocols for the computation of L(x, y), in which the two parties incur equal protocol overhead. In this work, we propose an asymmetric two-party protocol in which a lightweight client Bob with a string y interacts with a single powerful server Alice containing string x in its database. We present a privacy-preserving minimum-finding protocol based on semantically secure homomorphic functions and additive secret sharing. This protocol is executed repeatedly, to enable private computation of the edit distance. Our protocol supports arbitrary finite insertion/deletion costs and a variety of substitution costs. While Alice requires similar effort as in previous approaches, the advantage is that Bob incurs far fewer ciphertext operations and transmissions, making the protocol well-suited for client-server querying applications.
id-Privacy in large scale biometric systems	Balancing privacy and security concerns in biometric systems is an area of growing importance. While important work has gone on in template protection and revocable biometric tokens, these avenues of research address only one aspect of the problem. Such research does not address a critical issue: balancing the need government and anti-fraud programs to do deduplication (ensure one identity per person) against the potential for abuse using that data. Any existing system capable of deduplication, even if using a template protection scheme, would allow function creep or abuse by searching with latent prints. This paper introduces the concept of id-privacy, requiring at least i items (e.g. fingers) to be provided to resolve identity to better than d above random chance. We show how using cross-finger representation on unsegmented fingerprint slap data, we can address what may be the single most important ΓÇ£privacyΓÇ¥ issue in biometrics, privacy enhanced deduplication. We prove we can achieve (2,0)-id-privacy for fingerprint-based deduplication while preventing searching with a latent print. We introduce the Forest Finger algorithm - an approach for matching unsegmented slaps and cross-finger representations. Our results on the largest public slap database shows superior accuracy when compared with existing NIST Bozorth matcher when tested on unsegmented slaps, segmented prints or fused rolled prints.
Privacy amplification of content identification systems based on fingerprint bit reliability	In many problems such as biometrics, multimedia search, retrieval, recommendation systems requiring privacy-preserving similarity computations and identification, some binary features are stored in the public domain or outsourced to third parties that might raise certain privacy concerns about the original data. To avoid this privacy leak, privacy amplification is used. In the most cases, the privacy amplification is uniformly applied to all binary features resulting in the data degradation and corresponding loss of performance. To avoid this undesirable effect we propose a new privacy amplification technique that benefits from side information about bit reliability. In this paper, we investigate the identification rate-privacy leak trade-off. The analysis is performed for the case of perfect match between the side information shared between the encoder and decoder as well as for the case of imperfect side information.
Efficient privacy preserving K-means clustering in a three-party setting	User clustering is a common operation in online social networks, for example to recommend new friends. In previous work [5], Erkin et al. proposed a privacy-preserving K-means clustering algorithm for the semi-honest model, using homomorphic encryption and multi-party computation. This paper makes three contributions: 1) it addresses remaining privacy weaknesses in Erkin's protocol, 2) it minimizes user interaction and allows clustering of offline users (through a central party acting on users' behalf), and 3) it enables highly efficient non-linear operations, improving overall efficiency (by its three-party structure). Our complexity and security analyses underscore the advantages of the solution.
Secure binary embeddings for privacy preserving nearest neighbors	We present a novel method to securely determine whether two signals are similar to each other, and apply it to approximate nearest neighbor clustering. The proposed method relies on a locality sensitive hashing scheme based on a secure binary embedding, computed using quantized random projections. Hashes extracted from the signals preserve information about the distance between the signals, provided this distance is small enough. If the distance between the signals is larger than a threshold, then no information about the distance is revealed. Theoretical and experimental justification is provided for this property. Further, when the randomized embedding parameters are unknown, then the mutual information between the hashes of any two signals decays to zero exponentially fast as a function of the Γäô<sub>2</sub> distance between the signals. Taking advantage of this property, we suggest that these binary hashes can be used to perform privacy-preserving nearest neighbor search with significantly lower complexity compared to protocols which use the actual signals.
Privacy-preserving architecture for forensic image recognition	Forensic image recognition is an important tool in many areas of law enforcement where an agency wants to prosecute possessors of illegal images. The recognition of illegal images that might have undergone human imperceptible changes (e.g., a JPEG-recompression) is commonly done by computing a perceptual image hash function of a given image and then matching this hash with perceptual hash values in a database of previously collected illegal images. To prevent privacy violation, agencies should only learn about images that have been reliably detected as illegal and nothing else. In this work, we argue that the prevalent presence of separate departments in such agencies can be used to enforce the need-to-know principle by separating duties among them. This enables us to construct the first practically efficient architecture to perform forensic image recognition in a privacy-preserving manner. By deriving unique cryptographic keys directly from the images, we can encrypt all sensitive data and ensure that only illegal images can be recovered by the law enforcement agency while all other information remains protected.
A framework for privacy preserving statistical analysis on distributed databases	Alice and Bob are mutually untrusting curators who possess separate databases containing information about a set of respondents. This data is to be sanitized and published to enable accurate statistical analysis, while retaining the privacy of the individual respondents in the databases. Further, an adversary who looks at the published data must not even be able to compute statistical measures on it. Only an authorized researcher should be able to compute marginal and joint statistics. This work is an attempt toward providing a theoretical formulation of privacy and utility for problems of this type. Privacy of the individual respondents is formulated using ╧╡-differential privacy. Privacy of the marginal and joint statistics on the distributed databases is formulated using a new model called ╬┤-distributional ╧╡-differential privacy. Finally, a constructive scheme based on randomized response is presented as an example mechanism that satisfies the formulated privacy requirements.
Privacy-preserving user clustering in a social network	In a ubiquitously connected world, social networks are playing an important role on the Internet by allowing users to find groups of people with similar interests. The data needed to construct such networks may be considered sensitive personal information by the users, which raises privacy concerns. The problem of building social networks while user privacy is protected is hence crucial for further development of such networks. K-means clustering is widely used for clustering users in a social network. In this paper, we provide an efficient privacy-preserving variant of K-means clustering. The scenario we consider involves a server and multiple users where users need to be grouped into K clusters. In our protocol the server is not allowed to learn the individual user data and users are not allowed to learn the cluster centers. The experiments on the MovieLens dataset show that deployment of the system for real use is reasonable as its efficiency even on conventional hardware is promising.
Efficient privacy-preserving classification of ECG signals	We describe a privacy-preserving system where a server can classify an electrocardiogram (ECG) signal without learning any information about the ECG signal and the client is prevented from gaining knowledge about the classification algorithm used by the server. The system relies on the concept of linear branching programs (LBP) and a recently proposed cryptographic protocol for secure evaluation of private LBPs. We study the trade-off between signal representation accuracy and system complexity both from practical and theoretical perspective. As a result, the inputs to the system are represented with the minimum number of bits ensuring the same classification accuracy of a plain implementation. We show how the overall system complexity can be strongly reduced by modifying the original ECG classification algorithm. Two alternatives of the underlying cryptographic protocol are implemented and their corresponding complexities are analyzed to show suitability of our system in real-life applications for current and future security levels.
Privacy enhancement of common randomness based authentication: Key rate maximized case	In this paper, we consider security-privacy issues in authentication techniques based on the extraction of common randomness. We demonstrate that the key rate-privacy leak pairs can be enhanced using reliable components extraction from specially designed random projections. The decrease of bit error probability is estimated and its impact on the key rate and privacy leak is evaluated. Several authentication schemes with new helper data protocol are proposed.
Special issue on privacy and trust management in cloud and distributed systems	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Privacy-Preserving ECG Classification With Branching Programs and Neural Networks	Privacy protection is a crucial problem in many biomedical signal processing applications. For this reason, particular attention has been given to the use of secure multiparty computation techniques for processing biomedical signals, whereby nontrusted parties are able to manipulate the signals although they are encrypted. This paper focuses on the development of a privacy preserving automatic diagnosis system whereby a remote server classifies a biomedical signal provided by the client without getting any information about the signal itself and the final result of the classification. Specifically, we present and compare two methods for the secure classification of electrocardiogram (ECG) signals: the former based on linear branching programs (a particular kind of decision tree) and the latter relying on neural networks. The paper deals with all the requirements and difficulties related to working with data that must stay encrypted during all the computation steps, including the necessity of working with fixed point arithmetic with no truncation while guaranteeing the same performance of a floating point implementation in the plain domain. A highly efficient version of the underlying cryptographic primitives is used, ensuring a good efficiency of the two proposed methods, from both a communication and computational complexity perspectives. The proposed systems prove that carrying out complex tasks like ECG classification in the encrypted domain efficiently is indeed possible in the semihonest model, paving the way to interesting future applications wherein privacy of signal owners is protected by applying high security standards.
A Privacy-Preserving BuyerΓÇôSeller Watermarking Protocol Based on Priced Oblivious Transfer	Buyer-seller watermarking protocols allow copyright protection of digital goods. To protect privacy, some of those protocols provide buyers with anonymity. However, anonymous e-commerce protocols pose several disadvantages, like hindering customer management or requiring anonymous payment mechanisms. Additionally, no existing buyer-seller watermarking protocol provides fair exchange. We propose a novel approach for the design of privacy-preserving buyer-seller watermarking protocols. In our approach, the seller authenticates buyers but does not learn which items are purchased. Since buyers are not anonymous, customer management is eased and currently deployed methods of payment can be utilized. We define an ideal functionality for privacy-preserving copyright protection protocols. To realize our functionality, a protocol must ensure that buyers pay the right price without disclosing the purchased item, and that sellers are able to identify buyers that released pirated copies. We construct a protocol based on priced oblivious transfer and on existing techniques for asymmetric watermark embedding. Furthermore, we implement and evaluate the efficiency of our protocol, and we explain how to extend it in order to achieve optimistic fair exchange.
BIT-TRAPS: Building Information-Theoretic Traffic Privacy Into Packet Streams	Sniffing encrypted data packets traveling across networks can often be useful in inferring nontrivial information about their contents because of the manner in which the transmission of such packets is handled by lower layers in the communications protocol stack. In this paper, we formally study the side-channel formed by variable packet sizes, and explore obfuscation approaches to prevent information leakage while jointly considering the practical cost of obfuscation. We show that randomized algorithms for obfuscation perform best and can be studied as well-known information-theoretic constructs, such as discrete channels with and without memory. We envision a separate layer called a Bit - Trap, that employs buffering and bit-padding as orthogonal methods for obfuscating such side channels. For streams of packets, we introduce the use of mutual-information rate as an appropriate metric for the level of obfuscation that captures nonlinear relationships between original and modified streams. Using buffering-delay and average bit-padding as the respective costs, a Bit - Trap formulates a constrained optimization problem with bounds on the average costs, to implement the best possible obfuscation policy. We find that combining small amounts of delay and padding together can create much more obfuscation than either approach alone, and that a simple convex trade-off exists between buffering delay and padding for a given level of obfuscation.
Privacy Preserving Data Sharing With Anonymous ID Assignment	An algorithm for anonymous sharing of private data among <i>N</i> parties is developed. This technique is used iteratively to assign these nodes ID numbers ranging from 1 to <i>N</i>. This assignment is anonymous in that the identities received are unknown to the other members of the group. Resistance to collusion among other members is verified in an information theoretic sense when private communication channels are used. This assignment of serial numbers allows more complex data to be shared and has applications to other problems in privacy preserving data mining, collision avoidance in communications and distributed database access. The required computations are distributed without using a trusted central authority. Existing and new algorithms for assigning anonymous IDs are examined with respect to trade-offs between communication and computational requirements. The new algorithms are built on top of a secure sum data mining operation using Newton's identities and Sturm's theorem. An algorithm for distributed solution of certain polynomials over finite fields enhances the scalability of the algorithms. Markov chain representations are used to find statistics on the number of iterations required, and computer algebra gives closed form results for the completion rates.
Trail of Bytes: New Techniques for Supporting Data Provenance and Limiting Privacy Breaches	Forensic analysis of computer systems requires that one first identify suspicious objects or events, and then examine them in enough detail to form a hypothesis as to their cause and effect. Sadly, while our ability to gather vast amounts of data has improved significantly over the past two decades, it is all too often the case that we lack detailed information just when we need it the most. In this paper, we attempt to improve on the state of the art by providing a forensic platform that transparently monitors and records data access events within a virtualized environment using only the abstractions exposed by the hypervisor. Our approach monitors accesses to objects on disk and follows the causal chain of these accesses across processes, even after the objects are copied into memory. Our forensic layer records these transactions in a tamper evident version-based audit log that allows for faithful, and efficient, reconstruction of the recorded events and the changes they induced. To demonstrate the utility of our approach, we provide an extensive empirical evaluation, including a real-world case study demonstrating how our platform can be used to reconstruct valuable information about the what, when, and how, after a compromise has been detected. We also extend our earlier work by providing a tracking mechanism that can monitor data exfiltration attempts across multiple disks and also block attempts to copy data over the network.
Visual Cryptography for Biometric Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05658142.png" border="0">
Special issue on intelligent video surveillance for public security personal privacy	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Biometric Systems: Privacy and Secrecy Aspects	This paper addresses privacy leakage in biometric secrecy systems. Four settings are investigated. The first one is the standard Ahlswede-Csiszar secret-generation setting in which two terminals observe two correlated sequences. They form a common secret by interchanging a public message. This message should only contain a negligible amount of information about the secret, but here, in addition, we require it to leak as little information as possible about the biometric data. For this first case, the fundamental tradeoff between secret-key and privacy-leakage rates is determined. Also for the second setting, in which the secret is not generated but independently chosen, the fundamental secret-key versus privacy-leakage rate balance is found. Settings three and four focus on zero-leakage systems. Here the public message should only contain a negligible amount of information on both the secret and the biometric sequence. To achieve this, a private key is needed, which can only be observed by the terminals. For both the generated-secret and the chosen-secret model, the regions of achievable secret-key versus private-key rate pairs are determined. For all four settings, the fundamental balance is determined for both unconditional and conditional privacy leakage.
Special issue on privacy and trust management in cloud and distributed systems	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Utility-Privacy Tradeoffs in Databases: An Information-Theoretic Approach	Ensuring the usefulness of electronic data sources while providing necessary privacy guarantees is an important unsolved problem. This problem drives the need for an analytical framework that can quantify the privacy of personally identifiable information while still providing a quantifiable benefit (utility) to multiple legitimate information consumers. This paper presents an information-theoretic framework that promises an analytical model guaranteeing tight bounds of how much utility is possible for a given level of privacy and vice-versa. Specific contributions include: 1) stochastic data models for both categorical and numerical data; 2) utility-privacy tradeoff regions and the encoding (sanization) schemes achieving them for both classes and their practical relevance; and 3) modeling of prior knowledge at the user and/or data source and optimal encoding schemes for both cases.
A Decentralized Privacy Preserving Reputation Protocol for the Malicious Adversarial Model	Users hesitate to submit negative feedback in reputation systems due to the fear of retaliation from the recipient user. A privacy preserving reputation protocol protects users by hiding their individual feedback and revealing only the reputation score. We present a privacy preserving reputation protocol for the malicious adversarial model. The malicious users in this model actively attempt to learn the private feedback values of honest users as well as to disrupt the protocol. Our protocol does not require centralized entities, trusted third parties, or specialized platforms, such as anonymous networks and trusted hardware. Moreover, our protocol is efficient. It requires an exchange of messages, where and are the number of users in the protocol and the environment, respectively.
A Novel Privacy Preserving Location-Based Service Protocol With Secret Circular Shift for <formula formulatype="inline"> <img src="/images/tex/348.gif" alt="k"> </formula>-NN Search	Location-based service (LBS) is booming up in recent years with the rapid growth of mobile devices and the emerging of cloud computing paradigm. Among the challenges to establish LBS, the user privacy issue becomes the most important concern. A successful privacy-preserving LBS must be secure and provide accurate query [e.g., -nearest neighbor (NN)] results. In this work, we propose a private circular query protocol (PCQP) to deal with the privacy and the accuracy issues of privacy-preserving LBS. The protocol consists of a space filling curve and a public-key homomorphic cryptosystem. First, we connect the points of interest (POIs) on a map to form a circular structure with the aid of a Moore curve. And then the homomorphism of Paillier cryptosystem is used to perform secret circular shifts of POI-related information (POI-info), stored on the server side. Since the POI-info after shifting and the amount of shifts are encrypted, LBS providers (e.g., servers) have no knowledge about the user's location during the query process. The protocol can resist correlation attack and support a multiuser scenario as long as the predescribed secret circular shift is performed before each query; in other words, the robustness of the proposed protocol is the same as that of a one-time pad encryption scheme. As a result, the security level of the proposed protocol is close to perfect secrecy without the aid of a trusted third party and simulation results show that the k-NN query accuracy rate of the proposed protocol is higher than 90% even when is large.
A ROI Privacy Protection Scheme for H.264 Video Based on FMO and Chaos	With the increase of terrorist and criminal activities, closed circuit television (CCTV) is widely used in many occasions. However, abuse of surveillance video may result in the leakage of personal privacy. To protect the privacy in the video of CCTV, an encryption scheme for region of interest (ROI) of H.264 video based on flexible macroblock ordering (FMO) and chaos is proposed in this paper, where human face regions are selected as an example of ROI. First, the human face regions in the video are detected and extracted. Then, they are mapped into slice groups by using FMO technology in H.264. After that, these regions are encrypted using selective video encryption based on chaos. Experimental results and analysis show that the proposed scheme can effectively protect the private information of H.264 video and therefore, can strike a good balance among the security, encryption efficiency, and coding performance. It has a great potential to be used in the privacy protection of the video of CCTV.
Fingerprint Combination for Privacy Protection	We propose here a novel system for protecting fingerprint privacy by combining two different fingerprints into a new identity. In the enrollment, two fingerprints are captured from two different fingers. We extract the minutiae positions from one fingerprint, the orientation from the other fingerprint, and the reference points from both fingerprints. Based on this extracted information and our proposed coding strategies, a combined minutiae template is generated and stored in a database. In the authentication, the system requires two query fingerprints from the same two fingers which are used in the enrollment. A two-stage fingerprint matching process is proposed for matching the two query fingerprints against a combined minutiae template. By storing the combined minutiae template, the complete minutiae feature of a single fingerprint will not be compromised when the database is stolen. Furthermore, because of the similarity in topology, it is difficult for the attacker to distinguish a combined minutiae template from the original minutiae templates. With the help of an existing fingerprint reconstruction approach, we are able to convert the combined minutiae template into a real-look alike combined fingerprint. Thus, a new virtual identity is created for the two different fingerprints, which can be matched using minutiae-based fingerprint matching algorithms. The experimental results show that our system can achieve a very low error rate with FRR = 0.4% at FAR = 0.1%. Compared with the state-of-the-art technique, our work has the advantage in creating a better new virtual identity when the two different fingerprints are randomly chosen.
TrPF: A Trajectory Privacy-Preserving Framework for Participatory Sensing	The ubiquity of the various cheap embedded sensors on mobile devices, for example cameras, microphones, accelerometers, and so on, is enabling the emergence of participatory sensing applications. While participatory sensing can benefit the individuals and communities greatly, the collection and analysis of the participators' location and trajectory data may jeopardize their privacy. However, the existing proposals mostly focus on participators' location privacy, and few are done on participators' trajectory privacy. The effective analysis on trajectories that contain spatial-temporal history information will reveal participators' whereabouts and the relevant personal privacy. In this paper, we propose a trajectory privacy-preserving framework, named TrPF, for participatory sensing. Based on the framework, we improve the theoretical mix-zones model with considering the time factor from the perspective of graph theory. Finally, we analyze the threat models with different background knowledge and evaluate the effectiveness of our proposal on the basis of information entropy, and then compare the performance of our proposal with previous trajectory privacy protections. The analysis and simulation results prove that our proposal can protect participators' trajectories privacy effectively with lower information loss and costs than what is afforded by the other proposals.
Enforcing Secure and Privacy-Preserving Information Brokering in Distributed Information Sharing	Today's organizations raise an increasing need for information sharing via on-demand access. Information brokering systems (IBSs) have been proposed to connect large-scale loosely federated data sources via a brokering overlay, in which the brokers make routing decisions to direct client queries to the requested data servers. Many existing IBSs assume that brokers are trusted and thus only adopt server-side access control for data confidentiality. However, privacy of data location and data consumer can still be inferred from metadata (such as query and access control rules) exchanged within the IBS, but little attention has been put on its protection. In this paper, we propose a novel approach to preserve privacy of multiple stakeholders involved in the information brokering process. We are among the first to formally define two privacy attacks, namely attribute-correlation attack and inference attack, and propose two countermeasure schemes automaton segmentation and query segment encryption to securely share the routing decision-making responsibility among a selected set of brokering servers. With comprehensive security analysis and experimental results, we show that our approach seamlessly integrates security enforcement with query routing to provide system-wide security with insignificant overhead.
Guest Editorial: Special issue on privacy and trust management in cloud and distributed systems	The 13 papers in this special issue cover three major areas including privacy enhanced technology, trust and reputation, as well as applications in cloud computing environments.
Provably Secure Remote Truly Three-Factor Authentication Scheme With Privacy Protection on Biometrics	A three-factor authentication scheme combines biometrics with passwords and smart cards to provide high-security remote authentication. Most existing schemes, however, rely on smart cards to verify biometric characteristics. The advantage of this approach is that the user's biometric data is not shared with remote server. But the disadvantage is that the remote server must trust the smart card to perform proper authentication which leads to various vulnerabilities. To achieve truly secure three-factor authentication, a method must keep the user's biometrics secret while still allowing the server to perform its own authentication. Our method achieves this. The proposed scheme fully preserves the privacy of the biometric data of every user, that is, the scheme does not reveal the biometric data to anyone else, including the remote servers. We demonstrate the completeness of the proposed scheme through the GNY (Gong, Needham, and Yahalom) logic. Furthermore, the security of our proposed scheme is proven through Bellare and Rogaway's model. As a further benefit, we point out that our method reduces the computation cost for the smart card.
CAM: Cloud-Assisted Privacy Preserving Mobile Health Monitoring	Cloud-assisted mobile health (mHealth) monitoring, which applies the prevailing mobile communications and cloud computing technologies to provide feedback decision support, has been considered as a revolutionary approach to improving the quality of healthcare service while lowering the healthcare cost. Unfortunately, it also poses a serious risk on both clients' privacy and intellectual property of monitoring service providers, which could deter the wide adoption of mHealth technology. This paper is to address this important problem and design a cloud-assisted privacy preserving mobile health monitoring system to protect the privacy of the involved parties and their data. Moreover, the outsourcing decryption technique and a newly proposed key private proxy reencryption are adapted to shift the computational complexity of the involved parties to the cloud without compromising clients' privacy and service providers' intellectual property. Finally, our security and performance analysis demonstrates the effectiveness of our proposed design.
A Theoretical Analysis of Authentication, Privacy, and Reusability Across Secure Biometric Systems	We present a theoretical framework for the analysis of privacy and security trade-offs in secure biometric authentication systems. We use this framework to conduct a comparative information-theoretic analysis of two biometric systems that are based on linear error correction codes, namely fuzzy commitment and secure sketches. We derive upper bounds for the probability of false rejection (<i>P</i><sub>FR</sub>) and false acceptance (<i>P</i><sub>FA</sub>) for these systems. We use mutual information to quantify the information leaked about a user's biometric identity, in the scenario where one or multiple biometric enrollments of the user are fully or partially compromised. We also quantify the probability of successful attack (<i>P</i><sub>SA</sub>) based on the compromised information. Our analysis reveals that fuzzy commitment and secure sketch systems have identical <i>P</i><sub>FR</sub>, <i>P</i><sub>FA</sub>, <i>P</i><sub>SA</sub>, and information leakage, but secure sketch systems have lower storage requirements. We analyze both single-factor (keyless) and two-factor (key-based) variants of secure biometrics, and consider the most general scenarios in which a single user may provide noisy biometric enrollments at several access control devices, some of which may be subsequently compromised by an attacker. Our analysis highlights the revocability and reusability properties of key-based systems and exposes a subtle design trade-off between reducing information leakage from compromised systems and preventing successful attacks on systems whose data have not been compromised.
A Framework for Analyzing Template Security and Privacy in Biometric Authentication Systems	In this correspondence, we analyze the vulnerabilities of biometric authentication protocols with respect to user and data privacy. The goal of an adversary in such context is not to bypass the authentication but to learn information either on biometric data or on users that are in the system. We elaborate our analysis on a general system model involving four logical entities (sensor, server, database, and matcher), and we focus on internal adversaries to encompass the situation where one or a combination of these entities would be malicious. Our goal is to emphasize that when going beyond the usual honest-but-curious assumption much more complex attacks can affect the privacy of data and users. On the one hand, we introduce a new comprehensive framework that encompasses the various schemes we want to look at. It presents a system model in which each internal entity or combination of entities is a potential attacker. Different attack goals are considered and resulting requirements on data flows are discussed. On the other hand, we develop different generic attacks. We follow a blackbox approach in which we consider components that perform operations on biometric data but where only the input/output behavior is analyzed. These attack strategies are exhibited on recent schemes such as the distributed protocol of Bringer (ACISP 2007), which is based on the Goldwasser-Micali cryptosystem, the related protocol of Barbosa (ACISP 2008), which uses the Paillier cryptosystem, and the scheme of Stoianov (SPIE 2010), that features the Blum-Goldwasser cryptosystem. All these schemes have been developed in the honest-but-curious adversary model and show potential weaknesses when considered in our malicious insider attack model.
Voting With Unconditional Privacy by Merging <emphasis emphasistype="italic">Pr├èt ├Ç Voter</emphasis> and PunchScan	We present a detailed comparison of the Pret a Voter (PaV) and PunchScan (PS) protocols for booth voting. We also describe a simpler variation that keeps the ballot layout of PaV-Voter but borrows the cryptography from PS, which is based on any commitment scheme. By using unconditionally hiding commitments we obtain a conceptually very simple voting protocol with unconditional privacy.
Research on privacy preserving association rule mining a survey	Association rule mining is one of the hottest research areas that investigate the automatic extraction of previously unknown patterns or rules from large amounts of data. Recently, there has been growing concern over the privacy implications of association rule mining. This paper described the basic concepts related to association rule mining, and analyzed and summarized the general principles and methods of privacy preserving association rule mining, and pointed out the drawback of the these methods. It also introduced an effective metrics for measuring side-effects resulted from privacy preserving process. Finally the present problems and directions for future research are discussed.
The impact of privacy concern on users' usage intention of mobile payment	As mobile payment will get and use personal information of users to complete the payment process, which may generate the problems of users' privacy information stolen, leaked, improperly used, bringing about users' concern on personal information privacy. This paper uses structural equation model to analyze the impact of privacy concern on users' intention to use mobile payment. The results show that privacy concern has significant effects on perceived risk and trust, and indirectly affects the usage intention through the trust. Mobile payment service providers should take effective measures to alleviate users' privacy concern in order to reduce their risk perception and enhance their trust, and eventually improving users' usage intention and adoption behavior of mobile payment.
Enhance the User Data Privacy for SAAS by Separation of Data	To many users, the data security in Software-as-a-service (SAAS) is troubling, especially the sensitive data security. In this paper, further separation of user data is adopted, allowing users choose another unrelated third-party to provide database services. And the all operations to the data in the database, such as adding, deleting, encryption, are all still directly executed by the relevant software. The simple user interface in this design allows users update the component code of database access through easy operation. That can avoid service providers or software developers to easily get the user's privacy data.
An enhanced measurement transmission scheme for privacy protection in smart grid	Advanced metering infrastructure (AMI) as a core component of the smart grid integrates a two-way communications network which enables customers and utilities to actively monitor and manage their energy usage in real time. However, various privacy problems routinely arise. In this paper, an improved customer privacy-protection architecture called ΓÇ£Ring Communication Architecture (RCA),ΓÇ¥ and a novel mechanism is proposed in order to protect the privacy of customers. In our mechanism, the measurement of each smart meter is added together by means of orthogonal code (referred to herein as ΓÇ£ortho codeΓÇ¥) in the ring architecture of RCA, and transmitted the measurements to the utility through an aggregator. The utility can determine each of the measurements from the receiving summation information processed by aggregator without realizing the identification of each smart meter. By the quantitative and qualitative analysis of the performance and security, we show that the proposed mechanism can achieve low end-to-end delay, and prevent the system from threats by components compromise, as well as security in the form of confidentiality, integrity and privacy.
Research on privacy preserving classification data mining based on random perturbation	With the extending of the data mining application domain, the research of the privacy preserving data mining technique becomes more and more important. Privacy preserving classified data mining which is the main type of the privacy protection data mining has already become one of the hot spots in the field of data mining in recent years. How to transform the primitive real data and then structure decision tree based on the transformed data set is the key point of the privacy preserving classified data mining. This paper proposes a kind of privacy preserving classification mining method which is based on the random perturbation matrix. This method is suitable to the data of the character type, the boolean type, the classified type and the digital type. The experimental results show that our method protects privacy adequately and has high accuracy in the mining results.
Preserving Identity Privacy in Wireless Mesh Networks	Wireless mesh network (WMN) has emerged as a key technology for a numerous number of applications because of its ease of deployment, low cost and flexibility of use. WMN infrastructure is a multihop network where mostly the nodes are static in nature. Preserving identity privacy is an important issue in this type of multihop WMN which has been given a little attention in the research community. Compromising privacy may lead an attacker to reveal user's identity, his profiles and gain information about mobility. In this paper, we present an anonymous authentication scheme between mesh client and mesh router for preserving identity privacy and security in data communication in WMN. We have also shown the security and performance analysis of the proposed scheme.
Research on the Privacy Preserving Algorithm of Association Rule Mining in Centralized Database	The recent advance of data mining technology to analyze vast amount of data has played an important role in marketing business, despite its benefits in such areas, data mining also opens new threats to privacy and information security if not done or used properly. The main problem is that from non-sensitive data, one is able to infer sensitive information, including personal information, fact or even patterns that are not supposed to be disclosed. In order to focusing on privacy preserving association rule mining, the simplistic solution to address the problem of privacy is presented. The solution is to implement a filter after the mining phase to weed out or hide the restricted discovered association rules. Before implementing the algorithms, the data structure of database and sensitive association rule mining set have been analyzed to build the more effective model. This new algorithm can be used to balance privacy preserving and knowledge discovery in association rule mining.
SANATOMY: Privacy Preserving Publishing of Data Streams via Anatomy	Compared with generalization, anatomy preserves both the privacy and the correlation in data publication. On the other hand, data streams have gradually become a widely used data representation. Therefore, in this paper, we develop a novel algorithm of SANATOMY, to solve the problem of anatomized publishing of data streams. It creates l-diverse buckets according to the stream tuples' sensitive values, and controls the maximum release delay of each tuple. It also merges part of the buckets or re-partitions all the tuples into new buckets, while the bucket cannot be published straight. Experiments show that our algorithm allows significantly more effective data analysis than generalization in data streams, and has a better performance on data real-time processing and utilization.
Privacy policy preference (P3P) in e-commerce: Key for improvement	E-commerce is one of the mediums being used for online business via internet. Buying, selling and exchanging information are examples of activities conducted in e-commerce. In order to use e-commerce, some private information must be revealed by the customer. At this point, privacy policy plays the role in preventing unauthorized access to the user's private information. This study will investigate the concept of a privacy policy and the role of a platform for privacy policy preference (P3P) in e-commerce. This paper suggest some key improvements that should be included in privacy policy statements based on P3P and end with suggestions for future work.
A pioneering Cryptic Random Projection based approach for privacy preserving data mining	Privacy is the most important apprehension in many data mining applications. In this paper a new technique called Cryptic Random Projection, solves the re-identification quandary (which is found in the conventional random projections).Here this encryption based random projection assigns secret keys to the positions of random matrix elements and not to the random numbers. We have addressed two kinds of random sequences for generating the random sequences called determinist and indeterminist random sequences and encrypted it in a new way so that the original data cannot be re-identified. We have also optimized the privacy level which toughens the re-identification of original data without compromising the processing speed and data utility. We hope the projected solution will tarmac way for investigation track and toil well according to the evaluation metrics including hiding effects, data utility, and time performance.
Simulating the effect of privacy concerns in online social networks	While sharing information is the main purpose of online social networks (OSN), privacy is a major concern. It has been argued that the lack of privacy protection caused the massive departure of users from MySpace in 2008 - specially, due to mass media coverage on dangers of teenagers' public profiles and the appearance of Facebook, which provided a more private OSN. Besides mass media, we explore the impact of family and friends in instilling privacy concerns on teenagers. We develop an agent-based model to simulate propagation of privacy concerns through connection in a social network, and the effect of individual users' privacy decisions on the level of overall participation in an OSN. We report the results of simulating different privacy propagation factors. Our results are useful to understand and predict hidden patterns of user behavior that lead to changes in the number of active users in an OSN.
Preserving privacy of outsourced data: A cluster-based approach	With increasing opportunities for cheaper outsourcing of data, more and more organizations are seriously considering this option to reduce storage and processing costs. However, it has also given rise to the possibilities of security and privacy violations of data in outsourced environments. In this paper, we look at the privacy aspect, often referred to as data confidentiality. Our solution employs partitioning of the data into fragments (horizontal and vertical) so that only that group of fragments which do not violate the privacy are outsourced and the remaining are retained by the owner. The primary objective of the partitioning algorithm is to maximize the size of the outsourced fragment. Since obtaining optimal fragments that satisfy the privacy constraints is NP-hard, we suggest the use of clustering algorithms to provide near-optimal solutions. We provide proof of correctness for the proposed algorithm. We illustrate the proposed scheme using an example and show its efficacy.
In search of user privacy protection in ubiquitous computing	Participatory applications provide users with value-added and reusable information; however, collection of this information comes at the expense of the participants' privacy. Preserving the mobile participants' privacy is a key concern of mobile computing. This paper outlines current participatory application system model, privacy weaknesses, and existing privacy enhancing technologies. Next, it proposes a study to address mobile privacy protection by educating participants of exploitable privacy areas of their participatory applications. The contribution of the paper is two-fold: it provides a review of the existing privacy weaknesses of PS applications and demonstrates that participants' wanting to know more about these weaknesses warrants further study.
Privacy preserving delegated access control in the storage as a service model	Current approaches for enforcing fine-grained access control and confidentiality to sensitive data hosted in the cloud are based on selectively encrypting the data before uploading it to the cloud. In such an approach, organizations have to enforce authorization policies through encryption. They thus incur high communication and computation cost to manage keys and encryptions whenever user credentials or organizational authorization policies change. Ideally, organizations should use encryption only in order to hide the data from the cloud, whereas the cloud should be in charge of enforcing authorization policies on the hidden data in order to minimize the overhead at organizations. In this paper, we propose a novel approach for delegating privacy-preserving fine-grained access enforcement to the cloud. Our approach is based on a recent key management scheme that allows users whose attributes satisfy a certain policy to derive the data encryption keys only for the content they are allowed to access from the cloud. Our approach preserves the confidentiality of the data and the user privacy from the cloud, while delegating most of the access control enforcement to the cloud. Further, in order to reduce the cost of re-encryption required whenever the access control policies changes, our approach uses incremental encryption techniques.
Management of Users' Privacy Preferences in Context	There has been intensive research on user-controlled privacy from the perspective of agent automation of privacy related user tasks. The W3C's platform for privacy preferences (P3P) specifies standards that can be used by P3P agents to automatically retrieve a Web-site's privacy policy on how the users' data is collected, stored, and managed, and then to determine whether they are compatible with the user's privacy preferences. Current approaches to managing user's privacy do not capture context, are not user-friendly, and do cater well to the dynamic nature of privacy preferences very well. Clearly, the user's privacy preferences depend on the context of the user's online activity and the user's preferences evolve with user's experience and changing levels of trust in various organizations and domains. We propose a model for user's privacy preferences that incorporates the context for user activity and we apply it using a case-based reasoning (CBR) approach that relates the current activity to previous activities stored in the case-base and thus forms an intuitive and understandable process. We describe the context model for privacy preferences, how CBR is used to create a new contextual case from the Web-site's privacy policy and the user's current activity, and how the CBR retrieves matching cases to be applied to the retrieved privacy policy.
Privacy-Aware Role Based Access Control Model: Revisited for Multi-Policy Conflict Detection	Privacy-aware Role-based Access Control (P-RBAC) model is one of Role-Based Access Control (RBAC) model extensions that has been proposed to help the enforcement of privacy policies. Despite the enhanced privacy protection mechanism by P-RBAC, its pair-wise policy conflict detection algorithm has been pointed out as one of its limitations because conflicts within more than two policies are not detected. In this paper, we review and extend P-RBAC's existing conflict detection algorithm so that it can check conflicts in multiple policies. Our review includes the performance comparison on two conflict detection algorithms, triple-policy conflict detection vs. double-policy conflict detection. We find out that as the number of policies increases and the number of same condition variables in the policies increases, the running time complexity gets bigger. Especially for tripe-policy conflict, the probability of triple policy conflict also affects the complexity.
Location Privacy against Traffic Analysis Attacks in Wireless Sensor Networks	Traffic analysis attacks are passive attacks that try to deduce the traffic pattern based on the eavesdropped information. Through analyzing the packet traffic, it can deduce the location of strategic nodes, and then launch an active attack to those locations, such as DoS attack. Therefore, defending against a traffic analysis attack is to prevent the adversary from tracing the location of critical sensor nodes. Due to the open wireless communication media exposing the context information to adversaries, we cannot use traditional encryption and authentication to prevent the adversaries from eavesdropping on the wireless communication. In this paper, we propose three schemes to defend against the traffic analysis attacks. Firstly, a random routing scheme (RRS) is proposed to provide path diversity. Secondly, we combine RRS with a dummy packet injection scheme (DPIS) to confuse the adversary by tracing or tracing back the forwarded packet to reach the receiver or source. Finally, an anonymous communication scheme (ACS) is proposed to hide the identities of all nodes that participate in packets transmission. Through security analysis and simulation, we can see that our proposed schemes can efficiently defend against traffic analysis attacks, take less delivery time and achieve uniform energy consumption.
Scalable, Privacy-Preserving Remote Attestation in and through Federated Identity Management Frameworks	Creating trustworthy online computing is an important open issue in security research. Trusted Computing aims to address this problem through the use of remote attestation but comes with its own baggage in the form of privacy concerns. Federated Identity Management Systems (FIDMSs), on the other hand, provide another form of trust but lack the ability to measure the integrity of platforms that they vouch for. We note that these two security architectures have reciprocal strengths and weaknesses and can be combined to create an architecture that addresses the concerns of both. In this paper, we propose an extended FIDMS in which the identity provider not only vouches for the identity of a user but also for her platform's integrity. In this way, we (a) allow a service provider to establish trust on a client platform's integrity without sacrificing privacy; and (b) create a feasible and scalable architecture for remote attestation. We describe our proposed architecture in the context of Shibboleth FIDMS and provide the details of the implementation of this system.
Human Desire for Privacy: A Reason for Computer Supported Virtual Life	The present achievement of systems for fashioning virtuality, including avatars, multiplayer on-line games, virtual communities, and virtual reality is very remarkable. This paper presents a theoretical investigation to take account of human desire for privacy as a major momentum for computer supported virtual life. During the analysis process, I newly adopt the notion of the two games called the Virtuality/Reality game and the Privacy/Publicity game that humans play. By doing so, I reveal that humans are the beings who aspire for a virtual life, and privacy is an indispensible premise for virtual life. In particular, presenting Tuareg males' practice of face-veiling that explains social function of privacy, the paper helps to capture an understanding of the Privacy/Publicity game in more depth. Hopefully the analytic result of the paper provides researchers and system designers with the design rationale to build systems where privacy is concerned in the context of computer supported virtual life.
A NMF-Based Privacy-Preserving Recommendation Algorithm	The users pay more and more attention to personal information security with the recommender system applied widely. In this paper, a privacy-preserving collaborative filtering algorithm based on non-negative matrix factorization (NMF) is presented, which is combined with random perturbation techniques. The experimental results show that the algorithm cannot only protect users' privacy, but also generate recommendations with decent accuracy.
Query privacy in pervasive computing	With advance in wireless and location technology, Location-Based Services (LBSs) become the main applications in pervasive environment. Privacy of user query is becoming an increasingly important issue. In our proposed technique, user's point location has been expanded to region location. Because LBSs can't distinguish the true user from the other users in same region, user query privacy is protected. This paper has analyzed the problems that exist in the protecting of query privacy in pervasive computing. On this basis, a double threshold privacy model based on user distribution matrix is proposed for protecting user query privacy, include query location privacy and query content privacy. In this paper, we present a user cloaking algorithm to dynamic generation and modification user cloaking region. Experimental results validate the efficiency and effective of proposed technique.
Preference-Based Privacy Protection Mechanism for the Internet of Things	Based on the Internet privacy protection mechanism with the characteristics of Internet of things, preference-based privacy protection mechanism for the Internet of things is proposed. This mechanism introduces the third party organization to evaluate the individual user's privacy preference and feedback the result to the SP, which provide the Internet of things to the user, SP offers the appropriate level of the privacy protection according to the privacy preference, the third party organization will offer supervision for the SP. This mechanism gives user the right of speak of privacy protection at some levels.
Distributed Mining of Association Rules Based on Privacy-Preserved Method	With the rapid development of social information, the application of distributed database system is increasing. Distributed data mining will play an important role in data mining. As one of the well-known distributed association rules mining algorithm, the FDM algorithm is very fast and efficient, however, the cost of this algorithm is very great because it is designed under the condition of non-shared resource. Moreover, the important information at every site is exposed to other sites, which is not accord to the nowadays trend of attaching importance to privacy preserving increasingly. In this paper, we propose an improved algorithm based on the FDM algorithm. In the process, it computes the total support count with the privacy-preserved method, meanwhile ensures the source of every local large item-set and local support count is covered, so it reduces the time spent on communication and preserves the privacy of the data distributed at each site. The experimental evaluations show that the proposed algorithm is efficient and rather suitable for the practical application field.
Internet Privacy Database	Internet privacy has become an overlooked yet essential part our everyday lives. At any given moment, while browsing a web page, your identity could be stolen leaving you in thousands of dollars in debt. The purpose of this paper is to aid the general public to become more aware of these issues and the laws pertaining to them. We propose the creation of a database using machine learning and data mining techniques with the specific purpose of educating and informing the general public on these laws. In effect, we hope this will raise awareness on the subject as well as aiding any legal counsel needing quick but informative answers regarding internet invasion of privacy.
Designing privacy preserving router scheduling policies	We study the privacy compromise due to a queuing side channel which arises when a resource is shared between two users in the context of packet networks. The adversary tries to learn about the legitimate users activities by sending a small but frequent probe stream to the shared resource (e.g., a router). We show that for current frequently used scheduling policies, the waiting time of the adversary is highly correlated with traffic pattern of the legitimate user, thus compromising user privacy. Through precise modeling of the constituent flows and the scheduling policy of the shared resource, we develop a dynamic program to compute the optimal privacy preserving policy that minimizes the correlation between users traffic and adversarys waiting times. While the explosion of state-space for the problem prohibits us from characterizing the optimal policy, we derive a sub-optimal policy using a myopic approximation to the problem. Through simulation results, we show that indeed the sub-optimal policy does very well in the high traffic regime. Adapting the intuition from the myopic policy, we propose scheduling policies that demonstrate good tradeoff between privacy and delay in the low and medium traffic regime as well.
Privacy Preserving Collaborative Social Network	There are many kinds of social networks in existence. To our best knowledge, there is no effort on how to construct a social network jointly from different parties. Thus, there is a need for a proper protocol to both make a collaborative social network feasible between different parties and ensure privacy. We propose a series of protocols to create and interact with a privacy preserving collaborative social networks and evaluate their potential. The protocols are implemented, tested and evaluated.
The Economics of Privacy-Privacy: People, Policy and Technology	Privacy of personal information is an area of growing concern and importance in the digital age. Privacy as an issue rises when there is a conflict of interest between its commercial value and respect for an individual's right to privacy. This lends itself to the fact this trade off is of economic value and the issue of privacy is an economic problem and hence justifies the emergence of the economics of privacy as an important discipline which is a complex interplay of regulation, technology and people dynamics and the efficiency of doing business. In this survey paper we look into the work done by eminent people on the issue of privacy and its relationship with people, technology and regulation from an economic perspective and its increasing relevance today. Privacy affects each one of us in some way that we cannot afford to ignore it and it helps to be in cognizance of what is going on around us.
Collaborative Privacy Management System	In this paper, we consider a problem of monopolistic information management technologies. Most service providers have an access to any information. Even though the information is really a personal data, service providers can access with it merely with the user's first subscription. A collaborative privacy management system (Co- PMS) is suggested to satisfy the requirement. In this scheme, each user will provide ones own privacy policy by using a policy creation interface. The policy negotiation engine performs collaborative process with the certain service's data disclosure policy. This architecture provides more powerful right to each user to access ones own privacy policy and personal information. It also reinforces the security because of diverse privacy policy. It will develop the privacy policy based on security systems. We also expect the encrypted privacy policy to be used as an authentication certification.
Privacy Preserving SQL Queries	One of the most substantial ways to protect sensitive information is encryption of data. However, the cryptographic method brings in some problems such as inefficiency and malfunctioning, especially impossibility of arithmetic. The previous works in this area have been proved insecure or can provide only a few or several SQL queries. Actually, there is no scheme which can support secure all kinds of SQL queries and arithmetic. We propose a novel scheme to solve this problem. We do not encrypt every data itself but permute all the data within each attribute so that we can break the relation of the data and the owner. Accordingly, the proposed scheme guarantees intractability of re-identification for data-owners' privacy and at the same time enables the miner to get the information he wants.
Preserving Privacy in Joining Recommender Systems	In the E-commerce era, recommender system is introduced to share customer experience and comments. At the same time, there is a need for E-commerce entities to join their recommender system databases to enhance the reliability toward prospective customers and also to maximize the precision of target marketing. However, there will be a privacy disclosure hazard while joining recommender system databases. In order to preserve privacy in merging recommender system databases, we design a novel algorithm based on ElGamal scheme of homomorphic encryption.
Why MSN Lost to QQ in China Market? Different Privacy Protection Design	International software providers have entered China market in recent years. One typical example is MSN. As an indigenous IT products, QQ provides almost the same functions as MSN and competes with MSN for years. Market survey indicates that QQ dominates the local instance message market. Why QQ could win the battle with MSN in China market? In this paper, we investigate the detailed designs of MSN vs. QQ, focusing in particular on their privacy protection. We find that, in general, users' privacy concern level is low in China. Users show inclination to be connected with strangers in virtual community. They may trade off certain level of privacy protection to gain the chance of visiting by strangers. Moreover, in the position of control could mitigate users' privacy concern. Indigenous IT products, such as QQ, understand and leverage users' behavior. By lowering privacy protection and providing various control tools, QQ successfully caters to the need of young generation in China, which is main Internet users in China. Such results shed light on how to survive in China market for international IT product providers.
A Comparative Study of RFID Solutions for Security and Privacy: POP vs. Previous Solutions	In a true ubiquitous world, RFID tags will be available in everything, everywhere, and at all times. However, since those tags are bounded with constraints, with no foolproof method to manage the changing hands of the same-tagged item, there is no assurance of privacy and security in passive tags. Yet there are several vender specific solutions but none of them comprehensively solve the security risks and privacy threats arise in the domain of product lifecycle. Thus, there is a need to recognize a standard solution at least for a specific domain. Therefore we proposed the POP Method that comprehensively solves the problems arising in the domain of product lifecycle. In this paper, we compare and contrast the available major solutions against the POP method. We first provide evaluation criteria, and then we survey major proposed solutions, including ours. Next, we present the evaluation results addressing the security and privacy together with the functional aspects. Finally, we conclude the paper by realizing the best available solution for the product lifecycle with passive tags.
Privacy-preserving multimedia cloud computing via compressive sensing and sparse representation	Cloud computing is an emerging technology developed for providing various computing and storage services over the Internet. In this paper, we proposed a privacy-preserving cloud-aware scenario for compressive multimedia applications, including multimedia compression, adaptation, editing/manipulation, enhancement, retrieval, and recognition. In the proposed framework, we investigate the applicability of our/existing compressive sensing (CS)-based multimedia compression and securely compressive multimedia ΓÇ£trans-sensingΓÇ¥ techniques based on sparse coding for securely delivering compressively sensed multimedia data over a cloud-aware scenario. Moreover, we also investigate the applicability of our/existing sparse coding-based frameworks for several multimedia applications by leveraging the strong capability of a media cloud. More specifically, to consider several fundamental challenges for multimedia cloud computing, such as security and network/device heterogeneities, we investigate the applications of CS and sparse coding techniques in multimedia delivery and applications. As a result, we can build a unified cloud-aware framework for privacy-preserving multimedia applications via sparse coding.
Privacy: Aspects, definitions and a multi-faceted privacy preservation approach	There are many different definitions and understandings of the concept of privacy. Here we bring all the different aspects of privacy together and propose a comprehensive definition thereof. We also introduce the three different approaches to privacy preservation, and propose a comprehensive and multi-faceted approach in order to gain from the benefits of each and maximise privacy protection. We report on the evaluation of a prototype of such a privacy protective shopping environment.
On privacy calculus and underlying consumer concerns influencing mobile banking subscriptions	The advancement of technology in mobile devices places South African (SA) banking institutions in unique positions to leverage these advancements into innovative value added services. Mobile banking is one such innovation that has afforded banking clients the ability to, amongst other services, view bank statements, pay bills, and transfer money. Despite a growing trend in mobile banking service offerings by SA banks, privacy and security issues are still considered a concern. The paper conceptualizes the underlying concerns by bank clients regarding the adoption of mobile banking services. Privacy Calculus Theory (PCT) has been used as a theoretical lens to explain the cognitive process involved when a potential mobile banking subscriber is presented with mobile banking technology solutions. The paper extends PCT by abstracting the risk/benefit trade-off psyche held by SA bank clients. The paper attempts to explain, using PCT, the bank clients' cognitive process and willingness to subscribe to mobile banking services. Quantitative research method has been used for this purpose. Purposeful sampling that targeted SA bank-account holders was applied. Empirical results show that the South African banked consumers' psyche is largely influenced by the utility of a technology (mobile banking service) and interestingly, privacy and security play a lesser role in this trade-off.
Non-iterative privacy preservation for online lotteries	Unlike gambling, lottery games can exist in a lawful form to raise funds for charitable institutions. Owing to the expeditious development of network technology, lotteries over the Internet have become an inevitable trend. Since the Internet allows people to communicate with each other without direct contact, it is more difficult to guarantee the security and fairness of online lotteries than for conventional lottery games. However, electronic lottery methods can also provide something that conventional lottery mechanisms cannot: they allow players to purchase tickets at any time and in any place where they can access the Internet. The authors propose an online lottery mechanism that can confirm the propositions of general lottery games. Specifically, this novel method not only allows players to make <i>t</i>-out-of-<i>n</i> numbers in lotteries without iterative selection but also preserves the privacy of players' choices, making the system more similar to traditional lottery games.
Addressing security, privacy and confidentiality in a mobile teaching and learning assessment system for health and social care students	The ALPS programme and its Mobile Technologies Project has successfully implemented a large scale, 900 user, student assessment system using Windows Mobile PDAs for students across five universities involving 16 health and social care professions. The solution addresses the security needs within the context of the teaching and health and social care environment using a multi-layered approach including social and cultural change management, policy development and the application of several integrated security technologies such as device and data encryption, strong user authentication and physical signatures. A number of key conclusions and recommendations are drawn from the ALPS experience and are presented here which should inform future projects of this nature of best practice.
Building usable and privacy-preserving mobile collaborative applications for real-life communities: A case study based report	Distributed collaborative applications for supporting complex use cases in mobile environments have to provide contextual information (e.g. presence and group awareness) via their user interface. Social interaction and data sharing - being essential aspects of distributed collaborative applications - typically result in conflicting goals, primarily awareness vs. privacy. Preserving the end users' privacy especially in mobile collaborative settings is the most often-cited point of critique of mobile and ubiquitous computing. Since usability is a prerequisite for privacy and awareness mechanisms especially for mobile applications, we report in this paper on how to balance usability, privacy, and awareness trade-offs when building mobile collaborative applications. This is complemented by new approaches for preserving privacy tailored to the needs of respective communities in the domain of decentralized group-centric solutions. The requirements were gathered through an analysis of user's needs as well as first evaluations of prototypes. Those were built for different case studies focusing on privacy, trust, and identity management in real-life communities. We report on the outcomes of our work and show this exemplary with the help of a mobile prototype application to support an Angling Community with privacy and collaboration needs related to location-based services.
An extension of trust and privacy in the initial adoption of online shopping: An empirical study	While on-line shopping is considered as a special type of e-service, the adoption rate of this service in Taiwan has been paid attention recently. The initial adoption of on-line shopping is the important driving force to further influence the use and continued use of this service. The model of Trust and technology acceptance model (TAM) in Gefen et al. has been well studied in on-line shopping and showed that understanding both the Internet technology and trust issue is important in determining behavioral intention to use. The model of Trust and Privacy in Chiu et al. has been well discussed the consumer repurchase intention in on-lion shopping. An extension of Trust and Privacy would be in more comprehensive manner to understand behavioral intention to use on-line shopping. The finding also reveals that privacy effects on trust. Based on the results of this study, practical implications for online shopping and theoretical implications are recommended. Furthermore, a large sample survey is used to empirically examine this framework.
Will you be my friend? privacy implications of accepting friendships in online social networks	Online social networks (OSNs) have become extremely popular in recent years. Users actively interact in these networks and share large amounts of personal information. This has led to emergence of a treasure trove of data for many entities, from marketers and spammers to employers and intelligence agencies, which has become a serious privacy concern. Previous works have addressed many aspects about privacy in OSNs such as characterizing potential privacy leakage [14], possible ways for inferring sensitive private information [9], [18], and appropriateness of default privacy settings [11]. In contrast, we focus on the entity who plays the main role in guarding privacy: the user. By sending out friend requests to unknown users in one of the largest OSNs, we provide evidence that a considerable portion of OSN users are willing to let a stranger, possibly an adversary, into their social network, thus granting her access to the users' personal information and to some extent to those of their friends. We study several factors that might foster such behavior, and measure the amount of information that will consequently become accessible. We find that for more than 95% of the users who accept our friend requests, we gained access to personal information that would not otherwise be accessible. We also show that the majority of the users who accept the requests have indeed changed their default privacy settings to restrict access to some parts of their personal information to their friends while making them publicly inaccessible.
Online privacy and the universal service obligation: An alternative narrative	The argument in this research is that the Universal Services Obligation (USO) has endured for, and evolved over centuries, instead of reducing the USO in our digital world, it should be strengthened and redefined to ensure all members of society enjoy the full benefits of the new emerging digital world. This is particularly important at a time where research into new electronic services is in great demand and the submission of private information via electronic means is causing mounting privacy concerns among the public [1].
Personalized services in online shopping: Enjoyment and privacy	Enjoyment and privacy are essential ingredients for successful personalization. However, the current understanding of the influence of personalization is limited. This study extends personalization literature into the area of enjoyment and privacy issues related to intention to purchase and into the context of online shopping. Responses from 148 online customers were used to examine the effects of personalization on enjoyment, privacy issues and intention to purchase. Results show that personalization affects positively enjoyment and intention, but has no effect on privacy. Additionally, privacy affects negatively both enjoyment and purchase intentions, while enjoyment has a positive influence on purchase intentions. This study suggests future research directions including the relation of trust with privacy, as well as different types of emotions, hedonic and utilitarian dimensions that relate with personalized services.
Security and privacy analysis in social network services	The developers of social network services, due to pressure related with short development cycles, costs and usability, often disregard its security and privacy. Thus, they need documental support that provides a quick search concerning the best development habits of these two components. This article shows an updated analysis of security and privacy within these services and presents solutions for specific situations. In order to do that, we made a literature revision, complemented later with field work, being the result the identification of problems and security and privacy mechanisms, as well as their most common functionalities. Our field work consisted of an exploration of 18 social network services, based on a form developed to standardize the tests that were planned (n consegui melhor tradu├ºa╠âo. Espero que a ideia seja a mesma). Lastly, we analyzed the security and privacy mechanisms' identified functionalities in terms of quantity and quality. We also described the best practices related to security and privacy, for the development of functionalities that are safer and respect the final users' privacy. We found out that nowadays, privacy of information and contents of the profile and of the search results is constantly violated; that the best practices regarding the definition of the password are not demanded and that the information that is available in these services is often insufficient and dubious.
Research of Privacy Protection Mechanism of TPM	Introduced the credible computation's background and analyzed the TCG organization had Issued two authentication standard agreement: The trusted third party agreement and the direct anonymous authentication agreement, practice prove that the direct anonymous authentication agreement cannot be under the very good control in actual anonymous, this article proposed the improvement mentality in the original foundation, and provides the reference for the later research.
Privacy-preserving publication of diagnosis codes for effective biomedical analysis	Patient-specific records contained in Electronic Medical Record (EMR) systems are increasingly combined with genomic sequences and deposited into bio-repositories. This allows researchers to perform large-scale, low-cost biomedical studies, such as Genome-Wide Association Studies (GWAS) aimed at identifying associations between genetic factors and complex health-related phenomena, which are an integral facet of personalized medicine. Disseminating this data, however, raises serious privacy concerns because patients' genomic sequences can be linked to their identities through diagnosis codes. This work proposes an approach that guards against this type of data linkage by modifying diagnosis codes in a way that limits the probability of associating a patient's identity to their genomic sequence. Experiments using EMRs from the Vanderbilt University Medical Center verify that our approach generates data that can support up to 29:4% more GWAS than the best-so-far method, while permitting biomedical analysis tasks several orders of magnitude more accurately.
Security and privacy architectures for biomedical cloud computing	Biomedical research often relies on having access to vast amounts of sensitive information. Patient data in electronic form are held in medical databases and bio-repositories and have to be queried, data mined and operated on by doctors and researchers. Lately, all this information has been migrating to the cloud making access easier for all interested parties. While this helps with dissemination and access, it may have unintended consequences in terms of security and privacy. In this work we propose an architecture that combines distributed access control mechanisms with privacy preserving cryptographic protocols to enable secure sharing and computations on clouds holding sensitive biomedical data. The data shared are tagged with security policies that define who has access to it and how they should be used. Access rights may be delegated to other parties making collaborations easier. Finally, data can be operated on cryptographically to extract specific information without compromising the entire data set.
Privacy Protection in Mobile Agent Based Service Domain	In a mobile agent based environment personal data can be stolen, leaked or sent out to unauthorized persons by malicious mobile agents. In this paper we describe a new architecture and mechanism for user privacy protection in mobile agent based service domain. Agents meet at a protected and encapsulated agent computing environment from where they are not allowed to communicate with the outside world and also are not allowed to leave the platform. All the agents are killed at the host and the computation result is sent to respective parties by the trusted agent meeting and executing platform
Protecting Customer&#146;s Privacy in Querying Valuable Information Combined with E-Payment Scheme	In the online retrieving valuable information in special databases, it is important to protect the privacy of users preventing the server from knowing the information what the users retrieve. The problem was not solved until the privacy information retrieval (PIR) schemes were presented. A PIR scheme allows a user to retrieve a date item from online database while hiding the index of the data item from the database server. However, retrieving valuable information is another problem needs to be solved. Most transactions are completed by credit card through delivering its number and membership in the Internet to the server. Then the server knows the privacy of users. It becomes a challenge to private information retrieval (PIR) schemes considering the e-payment need. In this paper, we propose a new PIR scheme, which use a secure coprocessor (SC), with e-payment scheme for protecting the privacy of customers in querying valuable information. The scheme does not reveal personal information or buying information of customers in the Internet environment, it can really protect the customers' privacy. Comparing with previous PIR schemes, the scheme, combined with e-payment scheme in retrieving valuable information in special database, is more practical than previous PIR schemes in the Internet applications because of considering e-payment need
The (P, ╬▒, K) anonymity model for privacy protection of personal information in the social networks	The (P, ╬▒, K) anonymity model for privacy protection of personal information in the social networks is proposed in this paper. The hidden fields P and the hidden levels a are set according to the individual privacy needs of the users. Then make the released data to meet the privacy protection requirements through the Datafly algorithm and the clustering algorithm. The experimental data shows that the (P, ╬▒, K) model is better than the traditional K-anonymity model and L-Diversity modeling reducing the running time and reducing the loss of information.
eHealth record and personal privacy	This research paper aims to examine the conflict between the utilization of the technology in developing an online database system to keep an electronic health record of patients' and the need to protect an individual's personal data. A pretested questionnaire was used for data collection. A total of 301 individuals participated in this study from all walks of life and various professions, including medical practitioners, nurses, technical experts, patients and academics. The majority of the local population is in favor of the plan, many ask for more information and a lot of parameters must be studied before the initiation of the plan to avoid conflict with various groups of people opposing the plan mainly due to lack of information on its details.
Security, trust and privacy (STP) framework for federated single sign-on environment	Trust and privacy are hot and open concerns in Open Environment (OE). The Conventional Computing Platform (CCP) is deficient of platform trust that raises security concerns such as `phishing' attacks. The Trusted Computing Group (TCG) took an initiative to tackle security and trust anxieties in OE via Trusted Platform Module (TPM) and Remote Attestation (RA). However, the current RA technique has its own limitation i.e. missing of Mutual Attestation (MA) and platform privacy fears in OE. The Federated Single Sign-on (FSSO) scheme such as Shibboleth allows its users to access a resource across domains in a privacy preserving manner but what is still missing; it is the mutual platform trust establishment among client and Identity Provider (IdP) platforms in OE. In this paper, we embrace MA technique and integrated in Shibboleth with UserName (UN) to guarantee user is a legitimate owner of UN but also his/her and home domain IdP platform mutually authenticated. Hence, we achieves (a) strong security with two factor authentication i.e. UN and mutual attestation, (b) mutual platform trust establishment between the client and IdP machines, and (c) resource access in privacy protecting manner. We practicality demonstrate unified STP Framework notion for FSSO environment by Testbed prototype implementation that confirms productivity and scalability of our approach.
High performance computers and communications and telemedicine: from home care to privacy and security of health care data	The 21st Century will be the Information Age. Implementation and support of the strategic plan for a national/global information infrastructure will occur through the utilization of high-performance computing and communications (HPCC). HPCC technology provides a potentially huge payoff in health care. From teleconsultations to the availability of health-related databases, the effect of using HPCC will enhance patient care, improve drug design and broaden access to medical information. Geographic distance, time to accomplish tasks, separation of people from resources, and outdated organizational structures are impediments that inhibit the ultimate achievement of all these goals. Information technology has a pervasive and unprecedented ability to remove these barriers to progress. As part of the strategic planning process, three broad classes of user-driven applications have been identified: (1) high-performance applications; (2) high-confidence applications-improving the integration, privacy, security and reliability of information flows within and across enterprises; and (3) high-capability applications for the individual-empowering individuals with universal, easy-to-use access information, and providing customization and support of their information space
The global health network in the 21st Century: ΓÇ£Telehealth, homecare, genetics, counter-bioterrorism, security and privacy of information, do we need it and are we ready for it?ΓÇ¥	The Information Era we live in has created new challenges and opportunities. This age of information highways has an economic price which has not been properly evaluated. Detailed studies are needed to prove the cost and medical effectiveness of these technologies, as well as their effects on the quality of life. Our society's future may depend on it. People are living longer, while discoveries in genetics and in information technology are not only helping to produce newer drugs faster but are also providing the opportunity to exploit new areas such as disease prevention. These technologies provide a variety of opportunities to address public health challenges, such as universal access for the uneducated, counter-bioterrorism, telemedicine, distance education and home care. These opportunities present new challenges, such as surveillance and the privacy/confidentiality/security of personal information which will affect all of our lives. No strategy has been presented publicly yet, addressing the benefits or the pitfalls of such technologies
Enforcing Privacy through Security in Remote Patient Monitoring Ecosystems	We are a population that is getting progressively older. As we age, the need for better quality and efficient healthcare services at home and hospitals is becoming significantly more important. With the increasing cost of providing care-giver based monitoring services for patients and an ageing of the nurse and caregiver population itself, remote patient monitoring (RPM) has the potential to improve the quality of health services and lower the total cost of providing healthcare to chronic care patients by avoiding unnecessary hospitalizations, and ensuring urgent care is afforded to people who are in need of it. The commercial availability of monitoring units to measure vitals such as blood pressure, glucose and weight are assisting in the adoption of RHM. In this paper, the author discusses the enforcement of privacy and confidentiality through security measures and practices. The author end the discussion by outlining additional areas for research and suggestions for future work.
Privacy Preservation in SAT (Single Authentication Through)	In SAT (Single Authentication Through) scheme, each smart camera is capable of identifying, tracking identified objects, and delivering associate ID information to sibling subjects. So in this paper, we suggest a privacy preservation scheme for preventing privacy infringement during propagation of sensitive information.
Enabling Location Privacy and Medical Data Encryption in Patient Telemonitoring Systems	Patient telemonitoring systems (PTS) deal with the acquisition, processing, and secure transmission of a patient's physiological and physical parameters to a remote location, where expert medical knowledge is available. In emergency situations, when the patient's life is threatened, the trend in modern PTS is to transmit the current location of the patient. Although research in communications security has led to mechanisms that sufficiently protect medical data, research related to location privacy area is still in its early stages. This paper proposes an architecture that enhances PTS through location privacy and data encryption. We study the most popular PTS technologies in conjunction with location privacy architectures and propose an innovative scheme that exploits a point-to-point protocol called Mist. We describe a prototype implementation, developed for validating the proposed framework along with the corresponding evaluation results.
Enhancing Privacy and Authorization Control Scalability in the Grid Through Ontologies	The use of data Grids for sharing relevant data has proven to be successful in many research disciplines. However, the use of these environments when personal data are involved (such as in health) is reduced due to its lack of trust. There are many approaches that provide encrypted storages and key shares to prevent the access from unauthorized users. However, these approaches are additional layers that should be managed along with the authorization policies. We present in this paper a privacy-enhancing technique that uses encryption and relates to the structure of the data and their organizations, providing a natural way to propagate authorization and also a framework that fits with many use cases. The paper describes the architecture and processes, and also shows results obtained in a medical imaging platform.
Constructing Distributed Hippocratic Video Databases for Privacy-Preserving Online Patient Training and Counseling	Digital video now plays an important role in supporting more profitable online patient training and counseling, and integration of patient training videos from multiple competitive organizations in the health care network will result in better offerings for patients. However, privacy concerns often prevent multiple competitive organizations from sharing and integrating their patient training videos. In addition, patients with infectious or chronic diseases may not want the online patient training organizations to identify who they are or even which video clips they are interested in. Thus, there is an urgent need to develop more effective techniques to protect both <i>video content privacy</i> and <i>access privacy</i> . In this paper, we have developed a new approach to construct a distributed Hippocratic video database system for supporting more profitable online patient training and counseling. First, a new database modeling approach is developed to support concept-oriented video database organization and assign a <i>degree of privacy</i> of the video content for each database level automatically. Second, a new algorithm is developed to protect the video content privacy at the level of individual video clip by filtering out the privacy-sensitive human objects automatically. In order to integrate the patient training videos from multiple competitive organizations for constructing a centralized video database indexing structure, a privacy-preserving video sharing scheme is developed to support privacy-preserving distributed classifier training and prevent the statistical inferences from the videos that are shared for cross-validation of video classifiers. Our experiments on large-scale video databases have also provided very convincing results.
Data-Centric Privacy Protocol for Intensive Care Grids	Modern e-Health systems require advanced computing and storage capabilities, leading to the adoption of technologies like the grid and giving birth to novel health grid systems. In particular, intensive care medicine uses this paradigm when facing a high flow of data coming from intensive care unit's (ICU) inpatients just like demonstrated by the ICGrid system prototyped by the University of Cyprus. Unfortunately, moving an ICU patient's data from the traditionally isolated hospital's computing facilities to data grids via public networks (i.e., the Internet) makes it imperative to establish an integral and standardized security solution to avoid common attacks on the data and metadata being managed. Particular emphasis must be put on the patient's personal data, the protection of which is required by legislations in many countries of the European Union and the world in general. In this paper, we extend our previous research with the following contributions: 1) a mandatory access control model to protect patient's metadata; 2) a major security revision to our previously proposed privacy protocol by contributing with a ΓÇ£quality of securityΓÇ¥ quantitative metric to improve fragmented data's assurance; and finally, 3) a set of early results to demonstrate that our protocol not only improves a patient personal data's security and privacy but also achieves a performance comparable with existing approaches.
Technical guidelines for enhancing privacy and data protection in modern electronic medical environments	Raising awareness and providing guidance to on-line data protection is undoubtedly a crucial issue worldwide. Equally important is the issue of applying privacy-related legislation in a coherent and coordinated way. Both these topics gain extra attention when referring to medical environments and, thus, to the protection of patients' privacy and medical data. Electronic medical transactions require the transmission of personal and medical information over insecure communication channels like the Internet. It is, therefore, a rather straightforward task to capture the electronic medical behavior of a patient, thus constructing "patient profiles," or reveal sensitive information related to a patient's medical history. The consequence is clearly a potential violation of the patient's privacy. We performed a risk analysis study for a Greek shared care environment for the treatment of patients suffering from beta-thalassemia, an empirically embedded scenario that is representative of many other electronic medical environments; we capitalized on its results to provide an assessment of the associated risks, focusing on the description of countermeasures, in the form of technical guidelines that can be employed in such medical environments for protecting the privacy of personal and medical information.
A smart-card-enabled privacy preserving E-prescription system	Within the overall context of protection of health care information, privacy of prescription data needs special treatment. First, the involvement of diverse parties, especially nonmedical parties in the process of drug prescription complicates the protection of prescription data. Second, both patients and doctors have privacy stakes in prescription, and their privacy should be equally protected. Third, the following facts determine that prescription should not be processed in a truly anonymous manner: certain involved parties conduct useful research on the basis of aggregation of prescription data that are linkable with respect to either the patients or the doctors; prescription data has to be identifiable in some extreme circumstances, e.g., under the court order for inspection and assign liability. In this paper, we propose an e-prescription system to address issues pertaining to the privacy protection in the process of drug prescription. In our system, patients' smart cards play an important role. For one thing, the smart cards are implemented to be portable repositories carrying up-to-date personal medical records and insurance information, providing doctors instant data access crucial to the process of diagnosis and prescription. For the other, with the secret signing key being stored inside, the smart card enables the patient to sign electronically the prescription pad, declaring his acceptance of the prescription. To make the system more realistic, we identify the needs for a patient to delegate his signing capability to other people so as to protect the privacy of information housed on his card. A strong proxy signature scheme achieving technologically mutual agreements on the delegation is proposed to implement the delegation functionality.
Privacy-Preserving Telecardiology Sensor Networks: Toward a Low-Cost Portable Wireless Hardware/Software Codesign	Recently, a remote-sensing platform based on wireless interconnection of tiny ECG sensors called telecardiology sensor networks (TSN) provided a promising approach to perform low-cost real-time cardiac patient monitoring at any time in community areas (such as elder nursing homes or hospitals). The contribution of this research is the design of a practical TSN hardware/software platform for a typical U.S. healthcare community scenario (such as large nursing homes with many elder patients) to perform real-time healthcare data collections. On the other hand, due to the radio broadcasting nature of MANET, a TSN has the risk of losing the privacy of patients' data. Medical privacy has been highly emphasized by U.S. Department of Health and Human Services. This research also designs a medical security scheme with low communication overhead to achieve confidential electrocardiogram data transmission in wireless medium.
A purpose-based privacy-aware access control mechanism for distributed medical documents sharing	This paper presents the privacy-aware data access control and medical documents sharing mechanism based on purpose for distributed XML medical databases. A privacy access policy for XML is a tree-like model, and a group of distributed XML medical databases corresponding to a group of distributed policy trees, so we should mine the integrated patterns to control private data access in sharing environments. Firstly, we should sequence the policy trees and mine the integrated patterns. Secondly, we calculate the privacy information using entropy to identify the integrated patterns with larger information. At last, we query distributed medical documents using integrated patterns, which shares as many as possible private data on condition of privacy constraints. The experiments show that based on different privacy demands for different applications, entropy calculation can be the basis of the choice for integrated pattern and access data reasonably without privacy disclosure.
Factors that influence Internet users' privacy perception	Privacy concerns are identified as one of the main factors that have a negative impact on Internet users' online behaviour. Often, Internet users do not have confidence that a web site will ensure their privacy either in collection nor in future usage of their personal information. In this article we propose a categorization of factors that can influence users' privacy perception during their online activity. Furthermore, we report on a research model for Internet users' privacy perception, and a pilot study performed among online shopping/Internet banking users.
Internet users and online privacy: a study assessing whether Internet users' privacy is adequately protected	The paper examines the current state of Internet privacy. We assess the needs of UK Internet users in terms of online privacy protection, and determine the extent to which current privacy practices were satisfying those needs. Our work examines: (a) Internet users' attitudes towards online privacy; (b) 50 Web sites' privacy policies and practices and (c) existing privacy protection for users such as legislation and technological tools. The survey reveals a high level of concerns amongst Internet users related to their privacy in terms of: (i) personally identifying information that they provide to Web sites, (ii) the information that Web sites collect through the use of cookies and IP addresses and (iii) the information derived by tracking users' online activities.
Evaluation of security and privacy issues in integrated mobile telemedical system	Different modern information and communication technologies are emerging in all segments of our lives. The simplicity of using these high-tech and high-performance components enables us to build a wide range of enhanced and fast-in-reaction telemedical systems with the purpose of improving the quality of living. While building these systems it is easy to overlook or underestimate the need for data security and privacy protection. Telemedicine and e-health laws, regulations and standards, along with other telemedicine infrastructure components in the USA, Europe and Croatia are compared and discussed in this paper. After the common model for integrated mobile telemedical system is proposed with the example of heart-work monitoring system, all possible vulnerable and weak points in its architecture are identified and recommendations on design and implementation of similar systems are also discussed and given.
Computerisation, data privacy and scientific excellence; Where are we going?	Computerisation of most human activities that handle data is widely in function nowadays. General fears of Big Brother syndrome are ubiquitous. The paper attempts to challenge this common wisdom by demonstrating on some examples how computerisation in connection with proclaimed data privacy politics actually hinders the useful information, some of which was even formerly available, without computerisation or in older information system versions before the current rigid data privacy legislation. Examples are taken primarily from some personal author's experience and from information systems aimed for academic community in Croatia, developed at the author's Department. Data privacy prevents ordinary members of the academic community or society from proper investigation that could challenge the adequacy of existing policies. At the same time, the persons who institutionally have granted access to the collected information and who are the most influential to conduct policies have hardly time to do os.
Towards knowledge sharing and patient privacy in a clinical decision support system	Patient records and their disease and treatment history can be scattered among healthcare providers. Sharing the knowledge effectively and, at the same time, respecting patient privacy is crucial in providing safe and accurate clinical decision support systems (CDSSs). In this paper we reflect upon our experience in the HealthAgents project wherein a prototype system was developed and a novel approach employed that supports data transfer and decision making in human brain tumour diagnosis. Here we examine the capability of the lightweight coordination calculus (LCC), a process calculus-based language, in combining together distributed healthcare services and meeting security challenges in pervasive settings. The result is that various clinical specialisms, being captured in representational abstractions and making contribution to patient diagnosis and management, retain their autonomy. However, at the same time, the behaviour of specialists in sharing clinical knowledge about their patients and providing clinical support is constrained by policies and rules in respect of their own clinical duties and responsibilities. Being introduced into the programme of the HRB Centre for Primary Care Research, this novel approach has the potential to help the provision of optimal solutions in data linkage and sharing across the primary and cecondary care interface. As added value, its application also advances the process of integrating clinical prediction rules and implementing CDSSs in practice and, ultimately, the improvement of quality of care.
Association Rule Discovery of Privacy Information	An association rule expresses the dependence of a set of attributes on other attributes. An apriori algorithm is one of the known techniques that is used in the identification of association rules. In this paper, we report on our experiments using this technique for privacy data identification and extraction from printed documents
Diversity versus anonymity for privacy preservation	Although k-anonymity prevents disclosure individualspsila identity but it fails to prevent inferring sensitive information which is aimed by l-diversity. Most of the recent efforts that address diversity have focused on extending of k-anonymization methods to satisfy diversity as well. In this paper we show that diversity is lonely sufficient to protect private information of individuals and no need to apply k-anonymity first. Moreover l-diversity is stronger than k-anonymity and even some simple proposed techniques (like Anatomy) that consider only diversity are better than advanced k-anonymization techniques from privacy preservation point of view. We show all the cases by different scenarios and explain how diversity outperforms k-anonymity. Only in the case with some restricted assumptions about external data, some k-anonymization techniques give some protection in addition to l-diversity. We show even in this case the anonymity is related to number of tuples in external data instead of k, which is not so realistic.
Privacy-preserving in web services using hippocratic database	Nowadays, the growth of internet has been accompanied by the growth of web services (e.g e-government, e-health, e-commerce). Web services collect data, especially individuals, from users and use them for various purposes. Sometimes, web services need to release the data they own to third parties. Because privacy is an important concern in web services, there are several research efforts have been devoted to address issues related to the development of privacy-preserving data management techniques. In [3], Agrawal et. al. has introduced Hippocratic Database incorporating privacy protection in relational database systems. In this paper, weΓÇÖll proposed the use of Hippocratic Database to ensure the privacy in web services. We use a scenario for driving license renewal by Road Transport Department in order to illustrate this.
Protection of privacy in pervasive computing environments	In this paper, we present two techniques. The first technique called privacy sensitive information diluting mechanism (PSIUM) is able to prevent the misuse of data by a service provider by using a mixture of true and false sensor data. The second technique protects privacy sensitive information from being revealed to an attacker through traffic analysis by using a combination of frequently changing pseudonyms and dummy traffic.
Privacy and Information Security in Brazil? Yes, We Have It and We Do It!	This paper describes the implementation of a Management System of Information Security, presenting the procedures for privacy and information security, culminating in the achievement of an ISO 27001 Certification in a Data Center in a Public Sector in Brazil, The Data Center Prodesp, serving the government and 41 million citizens of the State of Sao Paulo. It discussed all aspects of legal, social and technical required for this implementation. We present a theoretical approach to the main concepts and methodologies used, like the concept PDCA (Plan-Do-Check-Act), to guarantee the privacy and information security to the topics discussed in this paper, that are: networks (wired and wireless), operating systems, hardware, use of encryption, treatment of threats, property rights and legal and criminal issues.
Non-interactive Secure and Privacy Preserving Protocol for Inter-vehicle Communication Networks	In this paper, we introduce a non-interactive secure protocol preserving privacy of the drivers for Inter-Vehicle Communication (IVC) networks. To protect the privacy among drivers, we propose to arrange vehicles into several groups. Vehicles in a group share the same public key, but each member can change his own set of public keys frequently, so the receiving vehicle cannot identify an individual driver in the group. In addition, each member has a private key provided by the Third Trusted Party (TTP) to enable the TTP, who is assumed to be fully trusted, to trace the driver who sends malicious information. Then, the TTP computes a fixed token of all members in the same group, but only participants in IVC networks can convince the receiving vehicle that the token is corresponding to their changed public keys set. So, we can achieve authentication.
Fuzzy-based Methods for Privacy-Preserving Data Mining	As more and more organizations are collecting and sharing data about their customers, there is a growing concern about violation of customer privacy. While some of the sharing is for the benefit of general public such as to understand disease behavior in medical research, individuals are concerned about violation of their privacy. The middle ground is found through privacy-preserving data mapping. Here, sensitive attributes of data are mapped to another domain so that original values are not revealed and yet the original associations are retained. In this paper, we compare a set of fuzzy-based mapping techniques in terms of their privacy-preserving property and their ability to retain the same relationship with other fields. In particular, our contribution is on four fronts: (i) modification of the fuzzy function definition, (ii) introducing seven ways to combine the different functional values for a data item into a single value, (iii) using several similarity metrics to compare the original data with the mapped data, (iv) measuring the effect of mapping on derived association rule. The paper presents preliminary results in this direction and proposes future work in this area.
A Privacy-Respecting Indoor Localization Approach for Identifying Shopper Paths by Using End-Users Mobile Devices	An established way to analyze shoppers' behavior at the point of sale consists of identifying their paths through the store as well as their approach behavior towards different shelves. Such proceeding allows e.g. for optimizing product placements or in-store advertising and guidance. Since there is a technological challenge in doing this inside the respective locations, there is a need for better localization methods than those using RFIDs or similar localization technologies (e.g. indoor GPS, CCTV, and different photo sensors) or by basing on human-based observations; at least due to privacy concerns. In this paper we introduce a multi-method approach for identifying shopper paths in the stores based on a combination of built-in sensors' capabilities of the end-users' mobile devices as well as a mobile product scanner application. Our approach allows for more privacy-preserving evaluation since the users could decide to provide accumulated paths data when paying at the point of sale. We also describe our prototypic implementation extending the Red pin system for iPhones, explain the architecture allowing also for anonymously sharing customers' paths in real-time, and address potential improvements for future work.
Location Privacy for Vehicle-to-Grid Interaction through Battery Management	Vehicle-to-grid research explores the possibility of centrally coordinating the charging behaviour of electric-drive vehicles and of employing such vehicles as a distributed grid resource. As such, they could be used both to improve the power grid's reliability and to store excess renewable energy. The information observable by the central coordination instance, however, can be a threat to the privacy of vehicle owners. In this work, we investigate when the observed information allows for vehicles to be distinguished and traced between stops and when not so that vehicles will mix with each other. Specifically, we analyse the role of battery information and reveal how it can influence vehicle mixing. Furthermore, we consider information minimisation, suppression, and generalisation and discuss their effects both on vehicle mixing and on service functionality. Lastly, we show that parking lots and garages naturally provide the conditions necessary for vehicle mixing and give an evaluation of mixing for this context.
Data Outsourcing in Cloud Environments: A Privacy Preserving Approach	With the increasing cost of maintaining IT centers, organizations are looking into outsourcing thier storage and computational needs to a cloud server. However, such outsourcing has also raised the more serious issue of data privacy. In this paper, we summarize our work in privacy-preserving data outsourcing. In particular, we discuss the issue of employing vertical fragmentation to a relation so that the fragment that is assigned to the cloud server contains maximum data without violating privacy. Here, privacy is expressed in terms of a set of confidentiality constraints. We represent the confidentiality constraints as a graph where the nodes are the attributes and links represent paired confidentiality. We then apply the graph coloring problem with two colors for the a cyclic portion of the graph. We use some heuristic to eliminate the cycles, and complete the coloring of all nodes. We are currently extending the work to multiple relations and constraints with multiple attributes in a constraint (i.e., triplet, quadruplet, etc.) instead of just pairs.
Perceived Privacy	To understand the notion of perceived privacy, this paper explores and proposes a model of the relationship between privacy and security. Security is measured in terms of the preparedness required to meet a certain level of threat. Privacy is measured in terms of level of exposure at a certain point of threat. With this understanding, perceived privacy is viewed as a proprietor (the person the information is about) perceiving the broker (handler of information) in his/her place with respect to valuing the sensitivity of the information, and taking care when handling this information. Transparency between proprietor and broker leads to trust.
A Study on the Security of Privacy Homomorphism	Informally, privacy homomorphism (PH) refers to encryption schemes with a homomorphic property allowing to obtain E<sub>k</sub>(a + b) or E <sub>k</sub>(a times b) from ciphertexts E<sub>k</sub>(a) and E<sub>k </sub>(b) without the knowledge of the decryption key. PH has a wide range of applications in information security due to its homomorphic property, but the best achievable security of them is yet unknown. In this paper, we discuss the security of PH in the black-box model and find that any PH is at most semantically secure under non-adaptive chosen-ciphertext attacks (i.e. IND-CCAI secure). We also show that the IND-CCAI security can be achieved with a small amount of hardware, namely, we offer a hardware-based solution to construct PH with provable security
Privacy Concerns of Semantic Web	In today's world, security is one of the most important quality attributes in Semantic Web. Semantic Web proposes new security requirements; therefore, previous security mechanisms provide insufficient support for an in-depth treatment of security in Semantic Web. This paper presents the mandatory role of privacy persevering method in access control model, inference and semantic data mining method and trust negotiation technique for applying in Semantic Web. We show the relation among them in order to secure Semantic Web. Privacy persevering method can prevent unauthorized access to confidential information and services further to being a hindrance for disclosure of private personal information.
Evaluation of Two Privacy-Preserving Protocols for the DNS	The rise of new Internet services, especially those related to the integration of people and physical objects to the net, makes visible the limitations of the DNS protocol. The exchange of data through DNS procedures flows today into hostile networks as clear text. Packets within this exchange can easily be captured by intermediary nodes in the resolution path and eventually disclosed. Privacy issues may thus arise if sensitive data is captured and sold with malicious purposes. We evaluate in this paper two DNS privacy-preserving approaches recently presented in the literature. We discuss some benefits and limitations of these proposals, and we point out the necessity of additional measures to enhance their security.
A Reinforced Authentication Protocol for Anti-Counterfeiting and Privacy Protection	In 2007, Chen et al. proposed a RFID authentication protocol for anti-counterfeiting and privacy protection. A feasible security mechanism for anti-counterfeiting and privacy protection was proposed using XOR and random number shifting operations to enhance RFID tags security providing a low cost. However, their authentication protocol has some drawbacks and security problems because they did not consider the surrounding environments. We conduct analysis on the protocol and identify problematic areas for improvement of the research. We also provide an enhanced authentication scheme based on the comment.
De-centralized location management: minimizing privacy concerns for location based services	For location-based services (LBS), security of location information (i.e. who has control) and user location privacy is a major concern. In this paper we investigate the risks associated with user's privacy- and location information-control, showing a peer-to-peer-based system framework as a possible approach. The focus is on peer-to-peer LBS relying on the IP multimedia subsystem (IMS), a future extension to GSM/UMTS core networks. A prototype peer-to-peer location-based instant messaging service has been implemented, demonstrating that such services can coexist with current cellular LBS system solutions. In addition to improving subscriber confidence about privacy and security issues in LBS, the proposed system has the potential of making location-service solutions more open and simple, thus leading to greater user acceptance hence prospective LBS market growth in the near future.
Utility and privacy of data sources: Can Shannon help conceal and reveal information?	The problem of private information ├é┬┐leakage├é┬┐ (inadvertently or by malicious design) from the myriad large centralized searchable data repositories drives the need for an analytical framework that quantifies unequivocally how safe private data can be (privacy) while still providing useful benefit (utility) to multiple legitimate information consumers. Rate distortion theory is shown to be a natural choice to develop such a framework which includes the following: modeling of data sources, developing application independent utility and privacy metrics, quantifying utility-privacy tradeoffs irrespective of the type of data sources or the methods of providing privacy, developing a side-information model for dealing with questions of external knowledge, and studying a successive disclosure problem for multiple query data sources.
Information theoretic privacy for smart meters	Smart meters (SMs) measure and report energy consumption of individual users to the utility provider at short intervals on the order of minutes. While SM data is used to increase the efficiency in electricity distribution, it also conveys sensitive private data on the energy consumption behaviour of individual customers. In this work, privacy in a smart metering system is studied from an information theoretic perspective in the presence of alternative energy sources and storage units. An alternative energy source provides increased privacy by diversifying the energy source, and the storage device filters the real energy consumption to reduce the leaked data. Connections between this problem and rate-distortion theory is established, and both theoretical and numerical results are presented.
A location privacy preserving algorithm based on linkage protection	The key of location privacy preserving is to protect the unlinkability between location and identity. Most of existing algorithms focus on location protection and identity protection separately. That will leads to decreased service quality, authentication, and auditability. In this paper, we propose a new algorithm which uses a variable-length anonymous communication path to protect the linkage between location and identity when users publish their location information. And give out detailed introduction and analysis of the algorithm. We evaluate the performance of the algorithm via simulation and show that it significantly increases anonymity, scalability and auditability at last.
Identity management with trust relationship and privacy preservation	Achieving trust relationship with privacy preservation is one of the key purposes of identity management. A novel identity management model is proposed to build trust relationship among different parties through identity validation and authentication. A two-way handshake process with two variants is introduced to implement strong mutual authentication between users and service providers without revealing real world identities of users. Security analysis and experiments show that confidentiality, integrity, usability and privacy protection ability for both users and service providers are enhanced effectively with good user experience and high performance.
Research on data streams publishing of privacy preserving	Data streams contain a lot of client information that need to be carefully managed to protect privacy of clients. Most of existing privacy preserving methods, such as k-anonymity, was designed for static data sets. However these methods can not be applied on data streams directly. Moreover, in dada streams applications, there is a need to offer strong guarantees on maximum allowed delay between incoming data and its anonymous output. This paper presents a novel weak clustering based data streams k-anonymity method for data publishing. Three advantages make its practical: first, little processing time for each tuple of data steam. Second, demand less memory. Last, both privacy preserving and utility of anonymous data are considered carefully. Theoretical analysis and experimental results show that the method is efficient and effective.
A practical customer privacy protection on shared servers	Customer privacy protection is very important in an e-commerce site. Without such protection, the customers may not be willing to provide personal information or conduct business at the site. Therefore, the merchant should protect its customer information in order to gain customer trust. In this paper, an approach for protecting customer information on shared servers is presented. The proposed method provides customer privacy by encrypting the customer information at the client machine and allows the key to be shared between the customer and the merchant. The encrypted customer information is sent and stored on the shared server. Therefore, attackers cannot access the customer information while the merchant can easily obtain such information. To make it practical, the technique is implemented in software and is transparent to the customer. Furthermore, this solution to protect customer privacy does not significantly increase the cost to develop and deploy the system.
Enabling user privacy in identity management systems	The issue of user privacy is constantly brought to the spotlight since an ever increasing number of online services collect and process personal information from users, in the context of personalized service provisioning. This issue is emphasized in the identity management systems where user identities and profiles are valuable assets. Existing privacy legislative laws have to be brought down to the electronic world reality to limit the disclosure of personal data and avoid their misuse. This paper defines a privacy module for user's devices to automatically enforce privacy protection in identity management environments.
Privacy-aware: Tracking and protecting sensitive information using automatic type inference	It is very hard to ensure that software is free of sensitive information leaks because current common software takes very little measures to control sensitive data propagation or limit data lifetime. We present Privacy-Aware, a sensitive data tracker and eraser based on type qualifier inference. We have adapted a simplified type qualifier inference to the LLVM framework, a low-level virtual machine infrastructure for a batch of languages. With type qualifier inference, Privacy-Aware can automatically reason about where the sensitive data has been propagated to and erase them before deallocation. We optimize Privacy-Aware with alias analysis and points-to analysis so that Privacy-Aware can be used as an effective annotation system for programmer to reduce the data lifetime in software development with minimal annotation effort. We have implemented Privacy-Aware by LLVM-based instrumentation. The preliminary evaluation suggests that Privacy-Aware can effectively clear sensitive data while only incurring a small amount of overhead, on average below 10%, in our benchmark. Our research provides evidence that requiring minimal programmer intervention, Privacy-Aware is an effective, efficient and autonomous strategy in privacy protection.
Scheme overcoming incompatibility of privacy and utilization of personal data	In the near future, continuing technical progress in computer science will allow the transformation of current visions of pervasive utilization on personal data into real world options. However, this perspective has raised deep concerns about the survival of privacy, as central building blocks of pervasive utilization on personal data which are in direct conflict with the fundamentals of privacy protection. Considerable efforts have been undertaken to cope with these concerns with limited conditions such as computational complexity and communication complexity. We highlight the principal incompatibility of privacy and pervasive utilization on personal data and propose a scheme under the existence of the trusted third party.
A theory of utility and privacy of data sources	The problem of frequent private information ΓÇ£leakageΓÇ¥ from the myriad large centralized searchable data repositories in use today drives the need for an analytical framework that quantifies unequivocally how safe private data can be (privacy) while still providing measurable benefit (utility) to multiple legitimate information consumers. Rate distortion theory is shown to be a natural choice to develop such a framework which includes modeling of data sources, developing application independent utility and privacy metrics, quantifying utility-privacy tradeoffs irrespective of the type of data sources or the methods of providing privacy, and developing a side-information model for dealing with questions of external knowledge.
How to achieve privacy in bidirectional relay networks	Recent research developments show that the concept of bidirectional relaying significantly improves the performance in wireless networks. This applies to three-node networks, where a half-duplex relay node establishes a bidirectional communication between two other nodes using a decode-and-forward protocol. In this work we consider the scenario when in the broadcast phase the relay transmits additional confidential information to one node, which should be kept as secret as possible from the other, non-intended node. This is the bidirectional broadcast channel with confidential messages for which we derive the capacity-equivocation region and the secrecy capacity region. The latter characterizes the communication scenario with perfect secrecy, where the confidential message is completely hidden from the non-legitimated node.
Multi-user privacy: The Gray-Wyner system and generalized common information	The problem of preserving privacy when a multi-variate source is required to be revealed partially to multiple users is modeled as a Gray-Wyner source coding problem with K correlated sources at the encoder and K decoders in which the k<sup>th</sup> decoder, k = 1, 2, ..., K, losslessly reconstructs the k<sup>th</sup> source via a common link of rate R<sub>0</sub> and a private link of rate R<sub>k</sub>. The privacy requirement of keeping each decoder oblivious of all sources other than the one intended for it is introduced via an equivocation constraint E<sub>k</sub> at decoder k such that the total equivocation summed over all decoders E ΓëÑ ╬ö. The set of achievable ({R<sub>k</sub>}<sup>K</sup><sub>k=1</sub>,R<sub>0</sub>,╬ö) rates-equivocation (K + 2)-tuples is completely characterized. Using this characterization, two different definitions of common information are presented and are shown to be equivalent.
Distributed computing with privacy	A set of terminals that observe correlated data seek to compute functions of the data using interactive public communication. At the same time it is required that this communication, observed by an eavesdropper, does not reveal the value of a private function of the data. In general, the private function and the functions computed by the terminals can be all different. We show that a class of functions are securely computable if and only if the conditional entropy of data given the value of private function is greater than the least rate of interactive communication required for an appropriately chosen multiterminal source coding task. A single-letter formula is provided for this rate in special cases.
Wireless network control with privacy using hybrid ARQ	We consider the problem of resource allocation in a wireless cellular network, in which nodes have both open and private information to be transmitted to the base station over block fading uplink channels. We develop a cross-layer solution, based on hybrid ARQ transmission with incremental redundancy. We provide a scheme that combines power control, flow control, and scheduling in order to maximize a global utility function, subject to the stability of the data queues, an average power constraint, and a constraint on the privacy outage probability. Our scheme is based on the assumption that each node has an estimate of its uplink channel gain at each block, while only the distribution of the cross channel gains is available. We prove that our scheme achieves a utility, arbitrarily close to the maximum achievable utility given the available channel state information.
Precise evaluation of leaked information with universal<inf>2</inf> privacy amplification in the presence of quantum attacker	We treat secret key extraction when the eavesdropper has correlated quantum states. We propose quantum privacy amplification theorems different from Renner's, which are based on quantum conditional Re╠ünyi entropy of order 1 + s. Using those theorems, we derive an exponential decreasing rate for leaked information and the asymptotic equivocation rate, which have not been derived hitherto in the quantum setting.
Privacy amplification theorem for bounded storage eavesdropper	In this paper, we consider a situation such that legitimate parties, Alice and Bob, share an identical source to generate a secret key, and an eavesdropper, Eve, can access a correlated data that is stored in a storage with bounded size. Then, Alice and Bob want to extract a secret as long as possible. We show a privacy amplification theorem for this problem, i.e., we clarify the rate of key generation for given rate of Eve's storage. The problem can be regarded as a dual randomness generation problem of the Wyner-Ahlswede-Ko╠êrner type source coding system, and the techniques used in the proof are exchanged, i.e., the so-called Markov lemma is used in the converse part, and the so-called image size characterization is used in the direct part.
Scheduling with privacy constraints	In multi-tasking systems where a finite resource is to be shared, a scheduler dictates how the resource is divided among competing processes. Examples of systems which have schedulers include, a computer where the CPU needs to be shared between the different threads running, a cloud computing infrastructure with shared computing resources, a network router serving packets from different streams etc. In such situations, when a processor is shared by multiple users, the delays experienced by jobs from one user are a function of the arrival pattern of jobs from other users, and the scheduling policy of the server. Consequently, a scheduling system creates a timing side channel in which information about arrival pattern from one user is inadvertently leaked to another. In this work, this information leakage is studied for a two user scheduling system. We first introduce a measure of privacy and then demonstrate that no scheduler can provide maximum privacy without idling/taking vacations, and consequently no policy can simultaneously be delay and privacy optimal.
Expurgation exponent of leaked information in privacy amplification for binary sources	We investigate the privacy amplification problem in which Eve can observe the uniform binary source through a binary erasure channel (BEC) or a binary symmetric channel (BSC). For this problem, we derive the so-called expurgation exponent of the information leaked to Eve. The exponent is derived by relating the leaked information to the error probability of the linear code that is generated by the linear hash function used in the privacy amplification, which is also interesting in its own right. The derived exponent is larger than state-of-the-art exponent recently derived by Hayashi at low rate.
Differential privacy as a protocol constraint	Differential privacy, introduced in 2006, has become a standard definition of privacy for statistical computations. Most of the research on differential privacy has explored questions arising in the client-server setting, where privacy guarantees are one-sided and cover data held by just one of the protocol participants. We observe that differential privacy complements the classic definition of secure multi-party computations by allowing one to quantify information leaked through the output of the computation. This view leads to a number of interesting questions, where differential privacy is treated as a constraint on the protocol. We survey the state-of-the-art of differential privacy in a multi-party setting and formulate several open problems.
Generalized privacy amplification	This paper provides a general treatment of privacy amplification by public discussion, a concept introduced by Bennett, Brassard and Robert (1988) for a special scenario. The results have applications to unconditionally-secure secret-key agreement protocols, quantum cryptography and to a non-asymptotic and constructive treatment of the secrecy capacity of wire-tap and broadcast channels, even for a considerably strengthened definition of secrecy capacity
Classical capacity of quantum channels, coherent quantum information and quantum privacy	We derive a relation between a quantum channel's capacity to convey classical information and its ability to convey quantum information. This relation is applied to the analysis of the privacy of a quantum channel
Privacy amplification over a non-authentic public channel	We show how to apply a proper authentication code to privacy amplification to detect Eve's active attacks, when independent partially secret keys are available.
Information-theoretic approach to privacy protection of biometric templates	This work presents a general secure biometric authentication algorithm that guarantees privacy protection of biometric templates. These are all based on the use of a one-way transform and helper data, which is used to achieve noise robustness at the input of the one-way transform. The biometrics templates obtained during enrollment are described by sequences of n i.i.d. random variables. A hashed form of the template is stored together with helper data in a database that is vulnerable to attacks from the inside.
Privacy amplification secure against an adversary with selectable knowledge	We introduce the concept of selectable knowledge, which models the information stored in an arbitrary (e.g., quantum mechanical) device. We then analyze a situation where an entity A holds selectable knowledge about some random variable X and quantify the information A has about the output H(X) of a randomly chosen function H applied to X. This generalizes the setting of privacy amplification by universal hashing. In particular, our result can be used to prove that privacy amplification remains secure even if the enemy possesses quantum instead of classical information.
Noise tolerance of the BB84 protocol with random privacy amplification	This paper shows that the BB84 protocol with random privacy amplification is secure with a higher key rate than Mayers' estimate with the same error rate. Consequently, the tolerable error rate of this protocol is increased from 7.5% to 11%. We also extend this method to the case of estimating error rates separately in each basis, which enables us to securely share a longer key
Strongly secure privacy amplification cannot be obtained by encoder of Slepian-Wolf code	The privacy amplification is a technique to distill a secret key from a random variable by a hash function so that the distilled key and an eavesdropper's random variable is statistically independent. There are two kinds of security criteria for the key distilled by the privacy amplification: the weak security criterion and the strong security criterion. As a technique to distill a secret key, it is known that the encoder of a Slepian-Wolf (the source coding with full side-information at the decoder) code can be used as a hash function for the privacy amplification if we employ the weak security criterion. In this paper, we show that the encoder of a Slepian-Wolf code cannot be used as a hash function for the privacy amplification if we employ the strong security criterion.
Differential privacy with compression	This work studies formal utility and privacy guarantees for a simple multiplicative database transformation, where the data are compressed by a random linear or affine transformation, reducing the number of data records substantially, while preserving the number of original input variables.We provide an analysis framework inspired by a recent concept known as differential privacy. Our goal is to show that, despite the general difficulty of achieving the differential privacy guarantee, it is possible to publish synthetic data that are useful for a number of common statistical learning applications. This includes high dimensional sparse regression, principal component analysis (PCA), and other statistical measures based on the covariance of the initial data.
Secret rate - Privacy leakage in biometric systems	Ahlswede and Csiszar [1993] introduced the concept of secret sharing. In their source model two terminals observe two correlated sequences. It is the objective of the terminals to form a common secret by interchanging a public message (helper data) in such a way that the secrecy leakage is negligible. In a biometric setting, where the sequences correspond to the enrollment and authentication data, respectively, it is crucial that the public message leaks as little information as possible about the biometric data, since compromised biometric data cannot be replaced. We investigated the fundamental trade-offs for four biometric settings. The first one is the standard (Ahlswede-Csiszar) secret generation setting, for which we determined the secret-key vs. privacy-leakage rate region. Here leakage corresponds to the mutual information between helper data and biometric enrollment sequence. In the second setting the secret is not generated by the terminals but independently chosen, and transmitted using a public message. Again we determined the region of achievable rate-leakage pairs. In setting three and four we consider zero-leakage, i.e. the public message contains only a negligible amount of information about the secret and about the biometric enrollment sequence. To achieve this a private key is needed, which can be observed only by the terminals. We considered again both secret generation and secret transmission and determined for both cases the region of achievable secret-key vs. private-key rate pairs.
Generalized privacy amplification	This paper, provides a general treatment of privacy amplification by public discussion, a concept introduced by Bennett, Brassard, and Robert for a special scenario. Privacy amplification is a process that allows two parties to distil a secret key from a common random variable about which an eavesdropper has partial information. The two parties generally know nothing about the eavesdropper's information except that it satisfies a certain constraint. The results have applications to unconditionally secure secret-key agreement protocols and quantum cryptography, and they yield results on wiretap and broadcast channels for a considerably strengthened definition of secrecy capacity
Discriminatory Lossy Source Coding: Side Information Privacy	A lossy source coding problem is studied in which a source encoder communicates with two decoders, one with and one without correlated side information with an additional constraint on the privacy of the side information at the uninformed decoder. Two cases of this problem arise depending on the availability of the side information at the encoder. The set of all feasible rate-distortion-equivocation tuples are characterized for both cases. The difference between the informed and uninformed cases and the advantages of encoder side information for enhancing privacy are highlighted for a binary symmetric source with erasure side information and Hamming distortion.
An Information-Theoretic Approach to Inference Attacks on Random Data Perturbation and a Related Privacy Measure	Random data perturbation (RDP) has been in use for several years in statistical databases and public surveys as a means of providing privacy to individuals while collecting information on groups, and has recently gained popularity as a privacy technique in data mining. This correspondence provides an information-theoretic framework for all inference attacks on RDP. The framework is used to demonstrate the existence of a tight asymptotic lower bound on the number of queries required per bit of entropy for all inference attacks with zero asymptotic error and bounded average power in the query sequence. A privacy measure based on security against inference attacks is proposed.
Exponential Decreasing Rate of Leaked Information in Universal Random Privacy Amplification	We derive a new upper bound for Eve's information in secret key generation from a common random number without communication. This bound improves on Bennett 's bound based on the Re╠ünyi entropy of order 2 because the bound obtained here uses the Re╠ünyi entropy of order 1+<i>s</i> for <i>s</i> Γêê [0,1]. This bound is applied to a wire-tap channel. Then, we derive an exponential upper bound for Eve's information. Our exponent is compared with Hayashi 's exponent. For the additive case, the bound obtained here is better. The result is applied to secret key agreement by public discussion.
Secret-key agreement over unauthenticated public channels .II. Privacy amplification	For pt. II see ibid., vol.49, no.4, p.832-38 (2003). Here, we consider the special case where the legitimate partners already share a mutual string which might, however, be partially known to the adversary. The problem of generating a secret key in this case has been well studied in the passive-adversary model - for instance, in the context of quantum key agreement - under the name of privacy amplification. We consider the same problem with respect to an active adversary and propose two protocols, one based on universal hashing and one based on extractors, allowing for privacy amplification secure against an adversary whose knowledge about the initial partially secret string is limited to one third of the length of this string. Our results are based on novel techniques for authentication secure even against adversaries knowing a substantial amount of the "secret" key.
Noisy Channel Coding via Privacy Amplification and Information Reconciliation	We show that optimal protocols for noisy channel coding of public or private information over either classical or quantum channels can be directly constructed from two more primitive information-theoretic protocols: privacy amplification and information reconciliation, also known as data compression with side information. We do this in the one-shot scenario of structureless resources, and formulate our results in terms of the smooth min- and max-entropy. In the context of classical information theory, this shows that essentially all two-terminal protocols can be reduced to these two primitives, which are in turn governed by the smooth min- and max-entropies, respectively. In the context of quantum information theory, the recently-established duality of these two protocols means essentially all two-terminal protocols can be constructed using just a single primitive. As an illustration, we show how optimal noisy channel coding protocols can be constructed solely from privacy amplification.
Privacy, additional information and communication	Two parties, each holding one input of a two-variable function, communicate in order to determine the value of the function. Each party wants to expose as little of its input as possible to the other party. The authors prove tight bounds on the minimum amount of information about the individual inputs that must be revealed in the computation of most functions and of some specific ones. They also show that a computation that reveals little information about the individual inputs may require many more message exchanges than a more revealing computation
Compressed and Privacy-Sensitive Sparse Regression	Recent research has studied the role of sparsity in high-dimensional regression and signal reconstruction, establishing theoretical limits for recovering sparse models. This line of work shows that lscr<sub>1</sub> -regularized least squares regression can accurately estimate a sparse linear model from noisy examples in high dimensions. We study a variant of this problem where the original <i>n</i> input variables are compressed by a random linear transformation to m Lt n examples in <i>p</i> dimensions, and establish conditions under which a sparse linear model can be successfully recovered from the compressed data. A primary motivation for this compression procedure is to anonymize the data and preserve privacy by revealing little information about the original data. We characterize the number of projections that are required for lscr<sub>1</sub> -regularized compressed regression to identify the nonzero coefficients in the true model with probability approaching one, a property called ldquosparsistence.rdquo We also show that lscr<sub>1</sub> -regularized compressed regression asymptotically predicts as well as an oracle linear model, a property called ldquopersistence.rdquo Finally, we characterize the privacy properties of the compression procedure, establishing upper bounds on the mutual information between the compressed and uncompressed data that decay to zero.
Privacy Preserving Sequential Pattern Mining in Progressive Databases Using Noisy Data	Research in the area of privacy preserving techniques in databases and subsequently in data mining concepts have witnessed an explosive growth-spurt in recent years. This work investigates the problem of privacy-preserving mining of frequent sequential patterns over progressive databases. We propose a procedure to protect the privacy of data by adding noisy items to each transaction. The experimental results indicate that this method can achieve a rather high level of accuracy. The method is applied on an existing algorithm PISA for frequent pattern mining. This algorithm works on both static and dynamically increasing databases, and thereby takes full advantage of their applicability of the module.
Development of a Privacy Conscious Video Communication System Using JPEG2000 Technology	This paper aims at extracting human region based on the multi-resolution expression of wavelet transform technique, and also creating transparent image of person based on bit-plane encoding technique, which both techniques are a constituent technology of JPEG2000. The purpose of using these techniques is to reduce the computational cost and data transfer bit rate. We developed the privacy conscious video communication system by using these techniques. In this system, the persons who stay far from the camera at the sending site are displayed as a high-transparent person at the receiving site, in order to protect their privacy
Privacy preserving and ownership authentication in ubiquitous computing devices using secure three way authentication	In todays world of technology and gadgets almost every person is having a portable device, be it a laptop or the smart phones. The user would like to have all the services at his fingertips and access them through the portable device he owns. Maybe he wants some data from the fellow user or from the service provider or maybe he wants to control his smart devices at home from wherever he is. In the present era of mobile environments, interactions between the user device and the service provider must be secure enough regardless of the type of device used to access or utilize the services. In this paper we propose a ΓÇ¥Secure Three Way Authentication (STWA)ΓÇ¥ technique intended to preserve the user privacy and to accomplish ownership authentication in order to securely deliver the services to the user devices. This technique will also help the users or the service providers to check if the device is compromised or not with the help of the encrypted pass-phrases that are being exchanged.
Author Privacy, Data Fabrication, and Knowledge Discovery in Databases	The problem of data fabrication, due to heightened consumer concerns about privacy, is on the rise. The unique characteristic of the Internet, anonymity, is a probable contributor to the intention of users to fabricate information. We propose a technological solution to this problem based on the deployment of knowledge discovery in database (KDD) systems to learn discrimination functions that discriminate between correct and fabricated data. These discrimination functions can then be used to form filters that remove falsified data from marketing data. That such discrimination functions are possible is due to the characteristic form falsified data takes. The greatest hurdle to implementing this approach is the availability of data labeled as "falsified" and "correct." However, the proposed technological solution offers potential to marketers and businesses alike
Efficiency, Privacy, and Security Analysis of Ubiquitous Systems in the Retail Industry	The radio frequency identification (RFID) tagging technology is being implemented by many businesses for production efficiency, logistics planning, supply-chain management, and other business related operations. However, there have been several implementation and control issues with the pervasiveness of this technology. This paper analyzes the security and privacy issues with the use of RFID in the commercial industry. It proceeds to assess the challenges with industry standardization among the RFID manufacturers at both the national and international borders. The Wal-Mart company is then used as a case study to assess its strategic use of RFID technology and its advantageously competitive positioning in light of its RFID technological renovation
ODYSSEY: Policy-Driven Anonymizer for Handheld Wireless Devices Privacy	In this paper we present ODYSSEY (pOlicy-Driven anonYmizer for handheld WireleSS dEvices privacY) as an efficient security architecture for assuring privacy through applying selective confidentiality and integrity on Web traffic between wireless handheld devices and the Internet. The anonymizer hides the identity of the user to surfed Web sites and the user's traffic to its ISP. This is done by acting as a proxy node to the client and by preserving confidentiality and integrity thru applying content-based encryption and hashing on the Web traffic between the gateway and the client. The system is a scalable, policy-based solution capable of evolving and adapting to suit the security requirements of a wide range of wireless devices. In addition, ODYSSEY is autonomous since it continuously updates the policy based on existing policy rules and user behaviors. All this give ODYSSEY considerable performance gains over existing standard anonymizers that use bulk encryption such as SSL
Enabling Access Control and Privacy through Ontology	The need for information security and privacy in today's connected systems is overwhelming. This paper focuses on the access control and privacy issues in a project based business environment to access project resources and to maintain privacy of members. In this regard, the SemID ontology is proposed which formalizes roles of the members, and controls access to project resources by means of formalized privacy policies and rules. The ontology is modeled from a corporate project scenario using the Protege ontology editor platform.
A Hierarchical Approach to the Specification of Privacy Preferences	In applications such as e-Health systems, a user's consent should usually be obtained before his/her private information can be disclosed. For this purpose, users need to specify their privacy preferences about what data are to be disclosed to which recipients for what purposes. However, this may become a daunting task in a complicated application that involves potentially a large number of combinations of data recipients, purposes, and granularities of data. This paper proposes a hierarchical approach to address this issue. More specifically, we first observe that hierarchies naturally exist in each dimension of a privacy preference. We then propose a series of methods for users to more conveniently specify their privacy preferences based on such hierarchies. We also define meta-policies to resolve potential conflicts between preferences specified over time. Finally, we discuss how to represent the preferences with a snow- flake schema in backend databases.
A privacy preserving clustering technique using Haar wavelet transform and scaling data perturbation	Despite the benefits of data mining in a wide range of applications, this technique has raised some issues related to privacy and security of individuals. Due to these issues, data owners may prevent to share their sensitive information with data miners. In this paper, we introduce a novel approach for privacy preserving clustering (PPC) over centralized data. The proposed technique uses Haar wavelet transform (HWT) and scaling data perturbation (SDP) to protect the underlying numerical attribute values subjected to clustering analysis. In addition, some experimental results are presented, which demonstrate that the proposed technique is effective and finds an optimum in the tradeoff between clustering utility and data privacy.
Trust-privacy tradeoffs in distributed systems	In distributed systems, it is often needed to establish trust before entities interact together. This trust establishment process involves making each entity ask for some credentials from the other entity, which implies some privacy loss for both parties. We propose a model for achieving the right privacy-trust tradeoff in distributed environments. Each entity aims to join a group in order to protect its privacy. Interaction between entities is then replaced by interaction between groups on behalf of their members. Data sent between groups is saved from dissemination by a self-destruction process. Simulations performed on the proposed model using the Aglets platform show that entities requesting a service need to give up more private information when their past experiences are not good, or when the server entity is of a paranoid nature. The privacy loss in all cases is quantified and controlled.
An extensible model for improving the privacy of web services	Today, most Internet users are worried about protecting their personal information, which may be gathered by Web services. This concern can have a profound influence on finding a way for applying privacy-aware policies on Web services. In this regard, there are just a few accessible Web services on the Web, which usually provide users with simple operation and are not able to apply the user preferences. In this paper we present a new method for applying the users' interests within the privacy-aware policies on the Web services. In this method, an extensible method for describing the users' preferences on the Web services is proposed, which along with general rules it can cover desired criteria according to privacy-aware policies.
Next generation networks: Human-aided and privacy-driven	New generation networks (NGNs) deployed in the next fire to ten years will integrate a myriad of underlying network technologies into a common internet protocol (IP) backbone. We put forward two theses on how NGNs will evolve based on recent trends in increasing ubiquity and the need for increased security. We assert that NGNs will be increasingly human- aided and privacy-driven. We discuss how these points are inter-related, and then we culminate this paper with a model that allows formal analysis of network privacy, including the tracing of entities.
The Users' Privacy Protecting Scheme Based on Knapsack Problem	In the e-commerce environment, the protection of users' privacy from a server was not considered feasible until the private information retrieval (PIR) problem was stated and solved. In this paper, we propose a one-server PIR scheme based on a knapsack problem, it is more suitable than other previous PIR schemes in the real e-commerce environment. In addition, a security proof to our scheme and comparisons to other PIR schemes are given.
Extraction of the Value Representing Human Feature for the Development of the Sensor with the Function of Privacy-Protection and the Construction of Discrimination-Circuit	In a rest room, the camera cannot be used from the viewpoint of privacy. In such a place, it is important to get the human's behavior and state without his discrimination. In this study, the sensor that converts the two-dimensional image into one-dimensional distribution is proposed. From one-dimensional distribution, the human's behavior and state can be extracted. As the algorithm, the learning vector quantization (LVQ) is adopted. This is because that the program size is not large, so it is possible to be put in a microcomputer. However, it takes much time to find the optimum parameters of LVQ. For improving it, the S-System was adopted to get the optimum parameters. As a result, the model using LVQ which is called "discrimination circuit" is constructed. By the use of S-System, the a priori knowledge is not needed to get the best parameters
Protecting the Privacy of Users in Retrieving Valuable Information by a PIR Scheme with Mutual Authentication by RSA Signature Algorithm	While the users retrieve valuable information on the internet, the protection of users' privacy from a database server was not considered feasible until the private information retrieval (PIR) problem was stated and solved. A PIR scheme allows a user to retrieve a data item from an online database while hiding the identity of the item from a database server. In this paper, a new PIR scheme combined with mutual authentication by RSA signature algorithm for protecting the privacy of users is proposed. Using only one server and including the mutual authentication process in the proposed scheme, it is more secure and more practical in the real application compared with previous PIR solutions.
A Privacy Preserving Model for Personal Information in Search Engine	In this modern-day society, people get information by using a search engine, and this is a very ordinary part of our lives. When users, however, begin to retrieve some information after their login on the portal sites, the data related to the user and the query information may be sent to the portal server to enhance the users' comfort. Here, the information that the user does not want to expose can be included. So, an invasion of privacy can occur and we have to protect this kind of incident. In this case, if the user hides all the information, the server can not show the customized result for the user, which can influence the advertising revenue. Moreover, there may be a general downward trend in the portal sites field. Thus, in this paper, we propose a user privacy preserving model in a search engine by using a homomorphic encryption algorithm on the user's policy to solve this problem. This can provide information on what the user wants to know with encrypted user information and targeted advertising service from the portal sites.
Privacy-Preserving Collaborative Filtering Using Randomized Response	This paper proposes a new privacy-preserving recommendation method classified into a randomized perturbation scheme in which a user adds random noise to the original rating value and a server provides a disguised data to allow users to predict rating value for unseen items. The proposed scheme performs perturbation in randomized response scheme, which preserves higher degree of privacy than that of additive perturbation. To address the accuracy reduction of the randomized response, the proposed scheme uses a posterior probability distribution function, derived from Bayes' estimation to reconstruction of the original distribution, to revise the similarity between items computed from the disguised matrix. A simple experiment shows the accuracy improvement of the proposed scheme.
Game theoretic analysis of privacy-aware Advanced Metering Infrastructure	Demand response systems seek to flatten the demand for electricity by providing real-time pricing to consumers to motivate avoidance of power-intensive tasks when rates are high. Advanced Metering Infrastructure (AMI) has been developed to facilitate this process, allowing for billing that applies fine-grained prices to fine-grained consumption data. But AMI also presents a unique privacy risk to consumers - fine-grained consumption data reveals a great deal about the behaviour, beliefs, and preferences of consumers. Such information is of interest to third parties, further exacerbating the privacy risk. This suggests a need for AMI to be developed from a privacy-aware perspective. Adopting a game-theoretic model, we consider utilities that offer both privacy-aware and non-privacy-aware AMI. A non-cooperative game is developed in which a representative consumer strategizes against the utility. The regulatory measures required for the desired privacy-facilitating Nash equilibrium of the game are discussed, and recommendations for policymakers are presented. In particular, it is found that a combination of regulation and consumer awareness must overcome the financial benefit arising from the sale of consumption information to third parties.
Virtual energy demand data: Estimating energy load and protecting consumers' privacy	To address global warming, the construction of energy-efficient houses that have low environmental impact is essential. Variations in energy load and energy efficiency can be estimated by numerical simulation using measured data on energy demand, for example, for a house newly equipped with solar panels and storage batteries. Data on energy demand is useful for estimating the variation in energy load, and this data can be acquired with a smart meter. However, high-resolution data on energy demand can expose consumers' behavior patterns through the identification of specific appliances and the times that they are used within the household. Although the introduction of smart grid technology has been applauded, its deployment has been slowed by serious security vulnerabilities that could compromise consumers' privacy. Furthermore, although cooperation among specialists from various fields is necessary for achieving environmental goals, data on energy demand is difficult to share between research institutes. We propose a method for generating data, which we call ΓÇ£virtual demand dataΓÇ¥, which will allow data to be shared while protecting consumers' privacy. Appliances used in consumers' houses are identified differently in virtual energy demand data and in measured demand data. Moreover, virtual energy demand data is useful for estimating the variation of energy load and energy efficiency instead of measured demand data, because the distribution of measured demand data for a single day taken from a measurement period is statistically consistent with the distribution of virtual energy demand data.
Economic analysis of privacy-aware Advanced Metering Infrastructure adoption	Demand response systems primarily seek to reduce demand levels during periods of high load and increase demand as necessary in the off-peak hours. The objective of this flattening of the demand curve is to curb the need for generators to frequently ramp up or down and to reduce peak load levels. This, in turn, would potentially decrease the aggregate production cost of electricity. One of the most effective known methods of accomplishing this is to use Advanced Metering Infrastructure (AMI), an intelligent metering technology that collects temporally precise consumer electricity usage data and relays it to the local utility. Because AMI modules collect fine granularity consumer data, a significant threat to consumer privacy exists, as this data can be shared or sold by the utility to interested third parties. A privacy-aware AMI module can be used to avoid this inherent danger by protecting an individual consumer's data using public key infrastructure. However, while privacy-aware AMI would be preferred by consumers, utilities would naturally prefer non-privacy-aware modules, as they could profit from the sale of consumer usage data. Therefore, it is not clear what regulatory structure should be implemented in determining what type of AMI to offer consumers and with what regulations. In this paper, we examine two possible regulatory regimes using consumer decision theory and determine the economic conditions required for privacy-aware AMI adoption at equilibrium under both regimes. Finally, we predict the privacy-aware AMI adoption rates for each regime and provide regulatory recommendations.
A secure and privacy-preserving communication scheme for Advanced Metering Infrastructure	Smart grid is the modernization of the existing nation-wide power grid. As a core component of the smart grid, Advanced Metering Infrastructure (AMI) integrates a two-way communications network which enables customers and utilities to actively monitor and manage their energy use. While the deployment of AMI brings enormous social and industrial benefits, some incurred security and privacy issues need to be properly addressed. In this paper, we propose a data communication scheme for AMI with particular considerations on these issues. In our approach, we require strong device authentication before a smart meter joins AMI network. Data confidentiality as well as customer privacy associated with sensitive data are protected by taking advantage of homomorphic encryption. Each in-network message is digitally signed for data integrity. Security analysis is provided to justify our scheme.
Wavelet-based load profile representation for smart meter privacy	A significant portion of (potential) end-users at this point in time are wary about possible disadvantages of smart grid technologies. A critical issue raised by end-users in various studies is the lack of trust in the level of privacy. Smart metering is the component in the end-user domain around which the most intense debate on privacy revolves, because load profiles are made available at high resolutions. Non-intrusive load monitoring (NILM) techniques allow the analysis of these load profiles to infer user behaviour, such as sleep-wake cycles. We investigate and compare the utility of different variants of the wavelet transform for creating a multi-resolution representation of load profiles. In combination with selective encryption, this multi-resolution representation allows end-users to grant or deny access to different resolutions on a ΓÇ£need-to-knowΓÇ¥ basis. Access to the different resolutions is thereby only granted to parties holding the needed keys. The whole datastream can be transmitted over the smart grid communications network. The lifting implementation of the wavelet transform has computationally low demands and can be run in embedded environments, e.g. on ARM-based architectures, in acceptable time. The proposed approach is evaluated based on the provided level of security, computational demands and feasibility in an economic sense.
Privacy enhanced data management for an electronic identity system	The electronic identity (eID) is being positioned to be a basic tool for identification, authentication and authorization in application domains ranging from eCommerce in private sector to eGovernance in public sector. A practical and flexible eID should be usable in both a network-connected online setting as well as in conventional offline situations. While improving security of communication and enhancing access control to resources, eID schemes also have the potential to become a serious negative factor on user privacy rights. This paper discusses the specific issue of privacy protection in eID systems and considers a range of solutions that could be implemented in a privacy-enhanced eID system featuring both data access and data management.
A parallel algorithm PMASK based on privacy-preserving data mining	Because of the increasing ability to trace and collect large amount of personal information, privacy preserving has become an important issue in the development progress of data mining techniques. Many methods have been brought out to solve this problem. In this paper, an algorithm on privacy preserving data mining named PMASK is introduced. PMASK not only can help preserve privacy but it can also be used to deal with mass data. PMASK proposed is effective according to the experimental results presented at the end of the paper book.
PrivOSN: Practical Privacy in Online Social Network	Today's online social networks (OSNs) do little to protect users' private information especially relationships between them. This paper presents PrivOSN, an online social network system designed to be more private than existing systems while keeping neutral performance, preserving existing services, and defending against kinds of attacks already known. In PrivOSN, users' relationships are kept locally and can't be seen by OSN providers. By subscribing, users can follow and set up relationship with others, and these are transparent to OSN providers, for better privacy.
VLSP: Enabling Location Privacy in Vehicular Location Based Services	In this paper, we present VLSP, a Vehicular Location based Service with Privacy grantees. In VLSP, we assume the service provider is untrusted and users do not have pre-established social relationships with each other, we use standard cryptographic primitives, Broadcast Encryption (BE) and Attribute-based Encryption (ABE) to provide privacy guarantees. By using VLSP, we are able to protect users' location privacy in vehicular location sharing social services. VLSP is mainly composed with three parts: OBUs, RSUs, and vehicular location sharing service provider. RSUs use RFID readers to communicate with users' OBUs to log users' locations, and uses standard cryptographic primitives and BE-based mechanism to establish trust and protect privacy for users who share their location information. We leverage ABE-based mechanism on service provider to control who can see users' location information. We evaluate VLSP using protocol, security and system implementation analysis, and find VLSP is both privacy-preserving and feasible.
Flight privacy in the NextGen: Challenges and opportunities	ΓÇó Flight privacy is an emerging problem in aviation ΓÇö ADS-B substantially increases privacy threat surface compared to Mode A/C/S ΓÇó No privacy solution in high-end GA aircraft ADS-B standard ΓÇó RTCA DO-260B ΓÇó Privacy weaknesses in DO-282B temporary, random ID solution ΓÇó Encryption based privacy solutions may be impractical for GA ΓÇó We can potentially enhance DO-282B and DO-260B standards to protect GA user privacy, without the need for key encryption ΓÇó We can potentially enhance DO-282B/260B to enable privacy preserving beneficial access to ATC services.
Private recommendation service for IPTV systems: Protecting user profile privacy	IPTV providers employ third party content recommendation service to help end users find personalized content, and at the same time increase content sales and gain competitive advantage over other IPTV providers. However current implementations of recommendation services are mostly centralized where all the information about the users' profiles is stored on a dedicated server. A common fear among users is that their user profile data being misused by recommendation provider. Also sharing profile data makes the end users vulnerable to attacks like insider attacks, where an employee of the recommendation service may compromise the confidentiality and integrity of their profiles. For these reasons, privacy aware users intentionally decline to use recommendation or even provide inaccurate or wrong information because they consider it as untrusted service. On the other hand, to build an accurate recommendation model the user must reveal information that is typically considered private such as watching history, previous buying behaviour, content ratings, etc. Further privacy concerns arise when the user data are stored in countries that have privacy laws different from the country where the service is consumed. This poses a severe privacy hazard, since the users profiles are fully under the control of recommendation provider and stored in locations that are not legally bound to ensure the privacy of its users. Due to different legal structures that relate to data privacy laws in different legal jurisdictions maintaining user profile privacy is not a trivial solution. Regardless of the official legal framework requirements, when outsourcing users' profiles the private data should be kept safe when it is in the possession of any third party service. In this paper we introduce a private recommendation method using collaborative filtering techniques. The method preserves the privacy of its users when using the system and allows sharing data among different users in the netwo- - rk. We also introduce two obfuscations algorithms that protect users profile privacy as well as preserve the aggregates in the dataset to maximize the utility of information to provide accurate recommendations. Using these algorithms provides the privacy of users personal profiles.
A Solution to Privacy Issues in RFID Item-level Applications	Radiofrequency identification (RFID) raises significant privacy concerns as it allows automated identification possibly without knowledge or permission of the tag bearer. Traditional cryptographic operations, such as authentication and encryption, to prevent unauthorized read are too costly for RFID tags to be deployed into cost-sensitive applications, e.g., into item-level applications in supply chains. This paper addresses the privacy issues and demonstrates a solution which achieves high security while maintains low manufacturing and management cost. The RFID tags carry only ID numbers which are disguised in response through randomization and a hash function to avoid clandestine tracking. The response of ID numbers is divided into segments to reduce database computational complexity. The database stores and maintains the inventory information to avoid clandestine inventorying. Also, the burden of cryptographic operations shifts from tags to database, tags will thus be cheap to manufacture and manage.
HPC - privacy model for collaborative skyline processing	In general, skyline query is defined as finding a set of interesting database objects, which are not dominated to one another objects. A typical example is to find the hotel that is cheap and close to the beach. Since the introduction of skyline operator by Borzsonyi et al into database community, there has been a number of research works evolving and related publications related in last decade. However, there is only a few of them working on distributed skyline processing in collaborative computing environments. None of them considered the issue of privacy enforcement. The problem is that server has to disclose the sub-skylines (the actual skyline points) without privacy protection. In this paper, we propose the Hierarchical Piecewise Curve (HPC) model to enforce privacy during collaborative skyline processing and the private information can be released in a hierarchically controllable manner. Firstly we develop the polynomial expressions of Piecewise Curve (PC) by Spline interpolation to approximate the actual sub-skyline points. Figure 1 graphically showed the approximation. With Spline function, PC in R knocks are defined as: equations where there is no intersection among all knocks and the corresponding Mean Square Error (MSE) is defined as: equations. Secondly, we define the operators for the PC. If we have two servers working on the skyline query, we may have two Curve, c1 and c2 with respective intervals as a Γëñ x Γëñ b and n Γëñ x Γëñ m. We observed that there are 3 categories of relationships. First, c1 totally dominates c2; Second, c1 and c2 are totally independent; Third, c1 partially dominates c2. In the experiments, we observe that increasing the order of the polynomial and/or the number of PC resulted in reduction of MSE. Moreover, we observed the performance dropped when number of object in database increased. Meanwhile, the performance of skyline processing by the HPC model with 10 servers and 20 servers were relatively stat- - ic when the database size increased. The poor performance of traditional approach was bottlenecked at constructing the global database for computing the global skyline. In the contrary, HPC model enabled distributed sub-skyline processing. Although there was computation overhead for merging curves (by equation 13), it could take advantage of distributing skyline computation among servers. Technically, we demonstrated Piecewise Curves (PC) as an answer approximation to response to the skyline query instead of actual skyline points. From the preliminary experimental results, we observed that the performance of HPC model for skyline processing out performance the traditional approach in distributed and cooperative computing environments.
Generalizing terrorist social networks with K-nearest neighbor and edge betweeness for social network integration and privacy preservation	Social network analysis has been shown to be effective in supporting intelligence and law enforcement force to identify suspects, terrorist or criminal subgroups, and their communication patterns. However, social network data owned by individual law enforcement units contain private information that must be preserved before sharing with other law enforcement units. Such privacy issue tremendously reduces the utility of the social network data since the integration of social networks from different law enforcement units cannot be fully integrated. Without integration of social network data, the effectiveness of terrorist or criminal social network analysis is diminished. In this paper, we introduce the KNN and EBB algorithm for constructing generalized subgraphs and a mechanism to integrate the generalized information to conduct the closeness centrality measures. The result shows that the proposed technique improves the accuracy of closeness centrality measures substantially while protecting the sensitive data.
Privacy preserving two-party k-means clustering over vertically partitioned dataset	We propose a secure approximate comparison protocol and develop a practical privacy-preserving two-party k-means clustering algorithm over vertically partitioned dataset. Experiments with to real datasets show that the accuracy of clustering achieved with our privacy preserving protocol is similar to the standard (non-secure) kmeans function in MATLAB.
Preserving privacy in social network integration with ╧ä-tolerance	Social network analysis and mining is very useful for law enforcement and intelligence to extract criminals or terrorists interaction patterns and identify their roles in the organizations. Due to the privacy concerns, social network data is usually captured within a law enforcement or intelligence unit without sharing with other units. As a result, the utility of social network analysis is diminished when the social network data within an individual unit is incomplete. In this project, the objectives are sharing the insensitive and generalized information to support social network analysis and mining but preserving the privacy at the same time. We ensure that a prescribed level of privacy leakage tolerance is satisfied. The measurement of the privacy leakage is independent to the privacy preserving techniques of integrating social network data.
Preserving privacy for moving objects data mining	The prevalence of mobile devices with geopositioning capability has resulted in the rapid growth in the amount of moving object trajectories. These data have been collected and analyzed for both commercial (e.g., recommendation system) and security (e.g. surveillance and monitoring system) purposes. One needs to ensure the privacy of these raw trajectory data and the derived knowledge by not disclosing or releasing them to adversary. In this paper, we propose a practical implementation of a (╬╡; ╬┤)-differentially private mechanism for moving objects data mining; in particular, we apply it to the frequent location pattern mining algorithm. Experimental results on the real-world GeoLife dataset are used to compare the performance of the (╬╡; ╬┤)-differential privacy mechanism with the standard ╬╡-differential privacy mechanism.
OSINT, the Internet and Privacy	In just 17 years the Internet has transformed practically every facet of modern life. The launch of Mosaic, the first web browser in 1993 was the catalyst for a communication revolution, whose implications are still unraveling. The Web was always intended to be a two-way multi-user publishing system undermining state controlled one way broadcasting. Unleashing a mass worldwide communication network to millions of people has brought huge benefits but also some dangers. Countering new threats from malicious, criminal and terrorist activity is a major topic of this conference. These security risks are difficult to control and monitor without affecting personal freedom. Securing networks, tracking attacks and countering extremism has driven the development of OSINT (Open Source Intelligence) tools and techniques. Governments and politicians have also found themselves vulnerable to the viral effect of instant communication as has been seen for instance during the Arab Spring. Counterbalancing all this and in reaction to this spread of mass communication has been a growing threat to individual privacy through electronic surveillance. Personal identity and privacy threats come from governments, criminals, and large commercial interests. The Internet genie is out of the bottle and can never be put back in. How far should governments and security services be allowed to monitor and track individual communication in a democratic society? How far can we trust the information we access on the Internet? Although we can never return to the naivety and excitement of that first Internet dream, are we instead slipping into a potential "big brother " world where all our personal details, opinions and actions are monitored electronically?
Technologies for Granting Balance between Security and Privacy in Video-Surveillance	Protecting citizens' privacy is a critical issue in the nowadays society. As data collection capabilities increase with the introduction of new technologies for automatic data capturing, new threats related to privacy protection need to be faced. In this field, video surveillance represents a critical technology: the existence of large amounts of stored personal data increases the probability of personal data misuse. In this paper, a technology that tackles the complex challenge of balancing security and privacy in video-surveillance is presented. The technology has potential for a greater social acceptance of video surveillance technology, due to the inclusion of the value of privacy alongside the enhanced security.
Fast Fourier Transform Based Data Perturbation Method for Privacy Protection	Privacy preservation is a major concern in the application of data mining techniques to counterterrorism and homeland security. Data distortion is a critical component to preserve privacy in security-related data mining applications. We propose a Fast Fourier Transform (FFT) based method for data distortion, and compare it with the Singular Value Decomposition (SVD) based method. The experimental results show that the FFT based method can obtain similar performance as SVD based method in preserving privacy as well as maintaining utility of the datasets, however, the computational time used by the FFT based method is much less than the SVD based method. We conclude that the FFT based method is a very promising data distortion method.
Addressing Accuracy Issues in Privacy Preserving Data Mining through Matrix Factorization	Maintaining data mining accuracy on distorted datasets is an important issue in privacy preserving data mining. Using matrix approximation, we propose several efficient and flexible techniques to address this issue, and utilize unique characteristics of matrix factorization to maintain data pattern. We use the support vector machine classification to compare accuracy maintenance after data distortion by different methods. With better performance than some classical data perturbation approaches, nonnegative matrix factorization and singular value decomposition are considered to be promising techniques for privacy preserving data mining. Experimental results demonstrate that mining accuracy on the distorted data used these methods is almost as good as that on the original data, with added property of privacy preservation. It indicates that the matrix factorization-based data distortion schemes perturb only confidential attributes to meet privacy requirements while preserving general data pattern for knowledge extraction.
On the Communication Complexity of Privacy-Preserving Information Sharing Protocols	We address issues related to privacy protection in distributed information sharing systems where multiple autonomous entities share data across their private databases. Most existing solutions place restrictions on adversarial behavior in order to enable communication-efficient privacy-preserving information sharing. These restrictions substantially underestimate the capabilities of adversaries in reality, and do not always suffice for real systems. We consider a threat space containing more powerful adversaries, including not only semi-honest but also malicious ones, and analyze the tradeoff between privacy protection and communication complexity in information sharing. In particular, we use Kolmogorov complexity to derive lower bounds on the communication complexity required to defend against various kinds of adversaries.
Protecting Location Privacy with Dynamic Mac Address Exchanging in Wireless Networks	In this paper, we propose a novel dynamic Mac address assignment and exchange strategy to reduce location disclosure risks. The use of dynamic Mac addresses in a local area network (LAN) is feasible since the address uniqueness needs only to be handled within the LAN. Though each node has a universal Mac address assigned by the manufacturer, a local unique Mac address is sufficient for the node to participate in communications. Our proposed strategy includes three major schemes. The first is to assign a Mac address to the client using the same idea as the IP address assignment. Next, a Mac addresses shuffle is conducted among the clients in the wide local area network (WLAN) without exposing any exchange relations or frequently disrupting current connections. Lastly, dummy messages are sent from the wireless client to cover others during idle. In current wireless networking, a client must communicate with an access point (AP) and authorization server in order to obtain authorization to access a local wireless network. In our scheme, we do not use a node's real physical Mac address when associating with an AP. Instead, there is a public special Mac address broadcast in the beacon messages which will be chosen as the source Mac address in the association request frame. As a result, the user will never expose its identifier when associated with the AP. The client also keeps a variant silent period as a defense against a correlation attack.
Using Homomorphic Encryption and Digital Envelope Techniques for Privacy Preserving Collaborative Sequential Pattern Mining	Nowadays, data mining is widely used in various applications. Privacy is an important issue in data mining systems. By privacy, we mean how to conduct data mining without compromising much data privacy. In particular, we consider the scenario where data sharing for data mining purpose is the main goal. However, we would like minimize the data disclosure during data mining process.
Privacy Preserving Collaborative Data Mining	Data mining and knowledge discovery in databases are important research areas that investigate the automatic extraction of previously unknown patterns from large amounts of data. The field connects the three worlds of databases, artificial intelligence and statistics. However, the usefulness of this data is negligible if meaningful information or knowledge cannot be extracted from it. Data mining and knowledge discovery attempts to answer this need. Aiming at developing practical solutions to privacy-preserving data mining problems, we have applied the random perturbation technique and the randomized response technique. The idea is to add random noise to the original data so that it is hidden. In another field, the success of homeland security aiming to counter terrorism depends on a combination of strength across different mission areas, effective international collaboration and information sharing to support a coalition in which different organizations and nations must share some, but not all, information. Information privacy thus becomes extremely important and our technique can be applied. In the Internet era, collaborative data mining is becoming a popular way to extract useful knowledge from large databases.
Information sharing and privacy protection of terrorist or criminal social networks	Terrorist or criminal social network analysis is helpful for intelligence and law enforcement force in investigation. However, individual agency usually has part of the complete terrorist or criminal social network and therefore some crucial knowledge is not able to be extracted. Sharing information between different agencies will make such social network analysis more effective; unfortunately, it may violate the privacy of some sensitive information. There is always a tradeoff between the degree of privacy and the degree of utility in information sharing. Several approaches have been proposed to resolve such dilemma in sharing data from different relational tables. There is not any work on sharing social networks from different sources and yet try to minimize the reduction on the degree of privacy. In this paper, we propose a subgraph generalization approach for information sharing and privacy protection of terrorist or criminal social networks. Our experiment shows that such approach is promising.
Probabilistic frameworks for privacy-aware data mining	Often several cooperating parties would like to have a global view of their joint data for various data mining objectives, but cannot reveal the contents of individual records due to privacy, ownership or competitive considerations. In this talk, we present a probabilistic framework for resolving such seemingly contradictory goals. Rather than sharing parts of the original or perturbed data, the framework shares the parameters of suitable probabilistic models built at each local data site. We mathematically show that the best representative of all the data is a certain ldquomeanrdquo model, and empirically show that this model can be approximated quite well by generating artificial samples from the underlying distributions using Markov chain Monte Carlo techniques, and then fitting a combined global model with a chosen parametric form to these samples. We also propose a new measure that quantifies privacy in such situations based on information theoretic concepts, and show that decreasing privacy leads to a higher quality of the combined model and vice versa. The method can also be applied to situations where different local datasets may not have identical features by using certain maximum likelihood and maximum entropy principles. We provide empirical results on different data types with continuous vector, categorical and directional attributes to highlight the generality of our framework. The results show that high quality distributed clustering or classification can be achieved with little privacy loss and low communication cost.
A framework for privacy-preserving cluster analysis	Releasing person-specific data could potentially reveal sensitive information of individuals. k-anonymization is a promising privacy protection mechanism in data publishing. Though substantial research has been conducted on k-anonymization and its extensions in recent years, few of them consider releasing data for a specific purpose of data analysis. This paper presents a practical data publishing framework for determining a generalized version of data that preserves both individual privacy and information usefulness for cluster analysis. Experiments on real-life data suggest that, by focusing on preserving cluster structure in the generalization process, the cluster quality is significantly better than the cluster quality on the generalized data without such focus. The major challenge of generalizing data for cluster analysis is the lack of class labels that could be used to guide the generalization process. Our approach converts the problem into the counterpart problem for classification analysis where class labels encode the cluster structure in the data, and presents a framework to evaluate the cluster quality on the generalized data.
BBN-based privacy management sytem for facebook	Online social networking sites (SNSs) has changed our lifestyle and become a main medium of communication among young adults to stay in touch with their friends, to organize events, to make friends, to promote themselves, to date, etc. To create content rich environment, SNSs make their platform available for third-party developers. The developers can build their applications based on users' social graph containing their personal and social information. Unfortunately, any information users posted on their profile can be harvested and used for unethical purposes due to Facebook's lack of application privacy configuration. In this paper we propose a privacy-management system for Facebook applications. The system can take advantage of the correlation between some profile features and network privacy settings, in this way it can automatically configure a users privacy settings. Our preliminary result show promising result.
Practical privacy-preserving protocols for criminal investigations	Social Network Analysis (SNA) is now a commonly used tool in criminal investigations, but evidence gathering and analysis is often restricted by data privacy laws. We consider the case where multiple investigators want to collaborate but do not yet have sufficient evidence that justifies a plaintext data exchange. We propose a practical solution that allows an investigator to expand his current view without actually exchanging sensitive private information. The investigator gets a partially anonymized view of the entire social network, while preserving his known view.
Privacy leaks in mobile phone internet access	Accessing the Internet and specifically the World Wide Web from a mobile phone is common today. Especially since the usage fees for packet-data access dropped to a point where anybody who can can afford a mobile phone can afford mobile Internet access. Almost every mobile phone today comes with an integrated web browser that can display HTML web pages and execute JavaScript. Almost all major web sites such as news sites, social networks, and shopping sites run websites that are optimized for small displays of mobile phones. Due to the broad use of mobile web access we investigated possible privacy problems of mobile phone web access. We conducted a study where we monitor all HTTP headers sent from mobile phones to our web server. We analyzed the logged data for privacy problems. Through this study we determined that a world wide privacy problem exists when accessing the world wide web from a mobile phone. We show what kind of data is leaked and who leaks it.
Business model considerations for privacy protection in a mobile location based context	In this paper we discuss the main privacy issues around mobile business models and we envision new solutions having privacy protection as a main value proposition. We construct a framework to help analyze the situation and assume that a third party is necessary to warrant transactions between mobile users and m-commerce providers. We then use the business model canvas to describe a generic business model pattern for privacy third party services. This pattern is then illustrated in two different variations of a privacy business model, which we call privacy broker and privacy management software. We conclude by giving examples for each business model and by suggesting further directions of investigation.
From ΓÇ£security for privacyΓÇ¥ to ΓÇ£privacy for securityΓÇ¥	This article envisions the use of context-awareness to improve single sign-on solutions (SSO) for mobile users. The attribute-based SSO is expected to increase users' perceived ease of use of the system and service providers' authentication security of the application. From these two features we derive two value propositions for a new business model for mobile platforms. The business model can be considered as an instantiation of the privacy-friendly business model pattern presented in our previous work, reinforcing our claim that privacy-friendly value propositions are possible and can be used to obtain a competitive advantage.
Privacy-preserving data mining demonstrator	We present a system for demonstrating anonymized data mining on user profiles, which also evaluates the remaining utility of the generalized information through comparison of the classification results. The use case for this scenario builds around profiles containing personally identifiable information, which should be analyzed and classified by a third party. Our goal is to preserve the privacy of the users while maintaining a certain level of utility to allow data mining over the anonymized information.
Things with the Privacy Protection Technology	Things are information technology development to a certain stage of the product, the concepts of things also entered the people's attention. Things are all the articles and other sensing devices through radio frequency identification information connected to the Internet, intelligent identification and management, is the second computer, Internet and mobile communication network again after the wave of the information industry. This paper analyzes the face of things several security issues, and proposed security mechanisms related things.
Distributed constraint satisfaction and optimization with privacy enforcement	Several naturally distributed negotiation/cooperation problems with privacy requirements can be modeled within the distributed constraint satisfaction framework, where the constraints are secrets of the participants. Most of the existing techniques aim at various tradeoffs between complexity and privacy guarantees, while others aim to maximize privacy first, according to Yokoo et al. (2002), Silaghi (2003), Faltings (2003), Liu et al. (2002) and Wallace and Silaghi (2004). In Silaghi (2003) we introduced a first technique allowing agents to solve distributed constraint problems (DisCSPs), without revealing anything and without trusting each other or some server. The technique we propose now is a dm times improvement for m variables of domain size d. On the negative side, the fastest versions of the technique require storing of O(d<sup>m</sup>) big integers. From a practical point of view, we improve the privacy with which these problems can be solved, and improve the efficiency with which <span style="font-family:Arial" class=MsoNormal>Γöö</span>n-1/2<span style="font-family:Arial" class=MsoNormal>Γöÿ</span>-privacy can be achieved, while it remains inapplicable for larger problems. The technique of Silaghi (2003) has a simple extension to optimization for distributed weighted CSPs. However, that obvious extension leaks to everybody sensitive information concerning the quality of the computed solution. We found a way to avoid this leak, which constitutes another contribution of This work.
Privacy Loss in Classical Multiagent Planning	Privacy is often cited as the main reason to adopt a multiagent approach for a certain problem. This also holds true for multiagent planning. Still, papers on multiagent planning hardly ever make explicit in what ways their systems protect their users' privacy, nor do they give a quantitative analysis. The reason for this is that a theory of privacy loss in multiagent planning is virtually non-existent so far. This paper proposes a measure for privacy loss based on Shannon's theory of information. To illustrate our approach, we apply this metric to an existing multiagent planning system to assess its merits when it comes to privacy on two domains. For this, we compare its plans to centrally generated solutions (by a trusted third party) for the same problems. The results clearly establish the need for such an analysis: even though the multiagent planner seemingly exchanges little information, its overall performance with respect to privacy is less than that of the centralised system (not taking into account the privacy loss with respect to the central planner, of course).
Multimodality to improve security and privacy in fingerprint authentication system	With the pace of increasing online transactions and communication, the demand for security and privacy increases. To protect confidential information and to authenticate people electronically, several solutions already introduced. Traditional biometric systems that are based on single biometric usually suffer from problems like impostorspsila attack or hacking, unacceptable error rates. To improve security and privacy and systempsilas reliability two or more biometrics of the same identity could be combined in a method that enhances the efficiency of the system. The biometric information, however, is irreplaceable information, when it is compromised. Thereby, one must give a special attention to protection of such information. We propose a novel protection technique for the biometric information, especially the feature information and the templates. The point of our proposal is securely embeds and extracts an iris template in a fingerprint image using a combined DWT and LSB based biometric watermarking algorithm in each authentication. The embedded data travel through insecure communication line like the Internet, and they are used in matching process. This technique causes security against eavesdropping and replay attacks on the Internet, because the watermark embedded transmitted data are used in the authentication session after watermark extraction.
Privacy, freedom and control in intelligent environment	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01515310.png" border="0">
Research on Privacy-Preserving Technology of Data Mining	It has been a significant research subject that how to extract valuable knowledge in data and to preserve private or sensitive information in data mining process from leaking. By comparing and analyzing privacy-preserving data mining algorithm, the paper has established the classification frame of privacy-preserving algorithm, found the opening of present privacy-preserving technology study and meanwhile prospected privacy-preserving research orientation.
Keynote lecture anonymity and privacy in communicating critical systems	Summary form only given. It is well known that despite all of its advantages the digital revolution also leads to large variety of new risks. One principal issue in this context is the growing dependence of our modern information society from the availability and correct (proved) function of modern communication services. First, I'll give a short overview on threats in communication networks (grids, clouds, etc), protocols and secure personal devices. Then I'll discuss current network security approaches based on anonymous message exchanges within communicating systems. Cryptography was first used to ensure data confidentiality, it has been ΓÇ£democratizedΓÇ¥ by ensuring the safety of telecommunications services, thereby extending its scope to authentication of a person or device, or a message, non-repudiation, integrity but also the anonymity of transactions. The anonymity is sometimes quite important in the new telecommunication and mobile networks services, much more than just message confidentiality. The talk will focus on some examples and new approaches developed in our research laboratory to deal with anonymity in routing protocols for mobile communicating systems.
Preserving privacy in social networks against subgraph attacks	With the rapid development of internet, explosive growth of social network creates large-scale social network data. In order to discover the potential value of the social network data, many analysis methods have been developed. However, using prior knowledge about the subgraph structure of a given network, it is possible to identify a target node or infer some useful information. In this paper, we mainly consider how to prevent such subgraph attack, and propose a practical method to battle it. We use iterative hash to detect the isomorphic subgraph structures and try to greedily match the anonymous subgraphs. Empirical queries on anonymized social network shows both the security and utility advantage of our algorithm.
Privacy quantitative model with multiple decision factors	In various computing environments and their applications, before any useful service offered, some user information which may contain privacy must be submitted. So how much privacy can the user afford to lose in order to get some service? It should be important to study effective privacy quantitative method in network environments. In this paper, we propose a novel privacy quantitative model with multiple decision factors. Our motivation is supply a privacy quantitative model, according to the result of quantification user can get the decision for their privacy disclosure. Our main contributions include following. (1) With multiple decision factors considered, our model satisfy privacy demand well, and support privacy disclosure decision more trustfully; (2) Allow the users set their privacy preference in the privacy quantitative model, and the users can change their privacy preference conveniently; (3) Our model can be used in various computing applications to protect privacy flexibly.
Privacy-preserving path-inclusion protocol through oblivious automata	This paper focuses on path-inclusion secure two-party computation problem, and an efficient protocol for securely computing the path-inclusion problem is proposed. This problem is defined in the two parties setting, where Alice and Bob both have a path. The goal of Bob is to learn whether his path is included by the path Alice holds, without revealing it to Alice or learning anything else about Alice's path. Our construction is based on an automata evaluation sub-protocol. In our protocol, each path is coded into a string which reserves all information about the original path. Then both parties are involved in the automata evaluation sub-protocol. Finally one of them can learn whether one path includes the other one.
Privacy Preserving Detection of Patterns in Event Sequences	We propose to use pattern matching on data streams from sensors in order to monitor and detect events of interest. We consider a privacy preserving pattern matching problem where patterns are given as sequences of constraints on input elements. We describe a new privacy preserving pattern matching algorithm over an infinite alphabet A where a pattern P is given as a sequence {p<sub>i</sub> <sub>1</sub>, p<sub>i</sub> <sub>2</sub>,..., p<sub>i</sub> <sub>m</sub>} of predicates pi<sub>j</sub> defined on A. The algorithm address the following problem: given a pattern P and an input sequence t, find privately all positions in t where P matches t. The privacy preserving in the context of this paper means that sensor measurements will be evaluated as predicates p<sub>i</sub>(e<sub>j</sub>) privately, that is, sensors will not need to disclose the measurements x<sub>i</sub> <sup>(j)</sup>, x<sub>2</sub> <sup>(j)</sup>,..., x<sub>n</sub> <sup>(j)</sup> to the evaluator.
Privacy Preserving Pattern Matching on Remote Encrypted Data	In this paper we propose a solution to matching bitstrings in the bitstring encrypted by stream cipher. We consider the following problem setting. There is a bitstring encrypted with owner's secret key and allocated on the remote untrusted site. The owner of these data wants to find all occurrences of some pattern presented as a bit string in the string on the remote site without revealing either pattern string or the data string on the remote site. The owner knows the secret key but he/she is not allowed to reveal either data or the pattern to the remote site. We propose an efficient algorithm that solves the problem efficiently in amortized time.
Two tiered privacy enhanced intrusion detection system architecture	The paper describes an architecture for privacy-enhanced intrusion detection systems, that separates privacy-invasive and privacy-preserving operations. This can be useful in cases where less sensitive network monitoring is outsourced to a third party and more sensitive network monitoring operations and data forensics are performed in-house or by law enforcement agencies.
Detecting privacy in attention aware system	Privacy and security are important issues for acceptation of ambient technology. For this reason, we propose a detector of relations between users and objects based on attention aware system. This detector is inspired by social sciences and completes the representation-driven model mainly used in ontology-based approaches. We discuss the role of context in these approaches and managing privacy. An attention model is derived from the gravitation model and cognitive psychology approaches. This model exploits contextual elements such as position, speed and saliency of objects in a scene to estimate shared attention. An application has been developed to demonstrate the efficiency of this system when managing windows applications, while guaranteeing the security and privacy of users
The ambient intelligence paradigm A review of security and privacy strategies in leading economies	In this paper, we comparatively review the AmI paradigm, as it emerges in three of the world's leading economies, namely: European Union, United States and Japan. We identify agonies, trends, and strategies of the national governments and private industries, we discuss the way these new concepts are perceived in each national context, and we examine the perspective they adopt to deal with the rising security and privacy risks. Furthermore, we examine the social disruption issues introduced and we conclude by presenting some general observations regarding the emerging paradigm
SPIROS - A system for privacy-enhanced information representation in smart home environments	This paper presents a novel concept for personalized privacy support on large public displays in intelligent home environments. In order to validate the conceptual approach a system called SPIROS was developed. The SPIROS system automatically adapts the information visible on public displays according to the current social situation and the individual privacy preferences of the user working at the display
Towards privacy protection in pervasive healthcare	Proliferation of small handheld devices and wireless technologies has kindled the phenomenon of pervasive computing. Healthcare, being a prime concern for every society, has been considered as an ideal setting for deployment of this technology. Pervasive healthcare aims to improve patient independent living and quality of life and pay special attention to issues of security, privacy, transparency and ease of use. From its very nature of being open and dynamic, the pervasive environment has been challenged with security and privacy related issues with regards to collaborative information sharing. In this paper, we present some of the privacy challenges that arise when designing pervasive healthcare environments and discuss addressing some of these issues in a home based patient monitoring system. Specifically, we cover privacy violation through individual healthcare information availability and information leakage through context-aware services.
A scheme for quantizing privacy in context-aware ubiquitous computing	Privacy is one of the areas of security with tradeoffs in ubiquitous computing and tends to a difficult, yet necessary, design issue in such dynamic environments. Context and social nuances contribute to creating privacy for the user, making it a meta-property. Developers currently incorporate little support in designing frameworks that help end- users manage their privacy in an undaunted way. In this paper, we present a scheme for introducing granularity of user privacy in context-aware systems deployed in ubiquitous computing environments. Our scheme aims to configure the privacy of the overall system (1) based on the overall privacy set by the user and (2) dynamically, based on the context rulesets and policies. We strive to make perception of privacy intuitive for the user, yet allowing the scheme to be adept in resolving context. We consider two real life situations and present results demonstrating the implementation of our scheme.
An Improved Authentication Approach to Enhance Security and Privacy in RFID System	Radio Frequency Identification (RFID) systems is increasingly rife in a variety of applications during recent years, such as inventory management, automobile immobilizers, animal tracking, supply chain management (SCM) and payment system. However, due to its wireless communication and demand for invisibility, security and privacy in RFID system becomes a serious challenge. In this paper, our main attention is constructing an efficient privacy preserving proposal. After reviewing the past work, we propose an improved method to enhance the security and privacy in RFID system. Based on random hash lock approach, we use random list stored in tag instead random value generator, and this novel method can achieve both mutual authentication with lower tag design cost. Meanwhile, the proposed solution satisfies security requirements, for instance, no information leaking, forward security and is resistant to replay attacks. In addition, it is suitable for distribute environment. Analysis of this approach shows it effective and efficiency. Compared with some existing schemes, this solution is superior.
Privacy Preserving Identification: Order Statistics List Decoding Perspective	In this paper, the performance of privacy preserving Biometric/Physical Unclonable Function identification based on the order statistic list decoding is analyzed by evaluating the corresponding probabilities of correct identification and false acceptance. We demonstrate the impact of candidate list size on the identification system performance and compare it with the unique identification setup. Finally, the influence of privacy amplification on the system performance is analyzed.
Privacy by Data Provenance with Digital Watermarking - A Proof-of-Concept Implementation for Medical Services with Electronic Health Records	Security is one of the biggest concerns about Cloud Computing. Most issues are related to security problems faced by cloud providers, who have to ensure that their infrastructure is properly secure and client data are protected, and by the customers, who must ensure proper security measures have been taken by the provider in order to protect their personal data. When you move your information into the cloud, you lose control of it. The cloud gives you access to your data, but you have no way of ensuring no one else has access to these data. In this article, we propose an evaluation of a proof-of-concept implementation of a usage control system for an ex post enforcement of privacy rules regarding the disclosure of personal data to third parties. The system is based on cryptographic protocols and digital watermarking in medical services and electronic health records.
Unified Metric for Measuring Anonymity and Privacy with Application to Online Social Network	Online social networks are used by more and more people. While they enable rich communication, posting information on such networks can degrade one's privacy and anonymity. A metric based on probability and entropy has been developed for measuring the degree of information revelation caused by posting to social networks. It can be used to measure the loss of privacy as well as the loss of anonymity.
A Survey of the Security and Privacy Measures for Anonymous Biometric Authentication Systems	The challenge in applying the known information theoretical measures for biometric authentication systems is that on one hand these measures are defined in a specific context and on the other hand there are several constructions known for the protection of biometric information. The goal of this work is to organize and conceptualize the existing knowledge in the area of security of biometrics and build a bridge between the formal model of cryptography and the practical view of the signal processing area. It is the scope of this paper to build and present the framework where results from both cryptography and signal processing can be integrated.
Based on Private Matching and Min-attribute Generalization for Privacy Preserving in Cloud Computing	When our private data are out-sourced in cloud computing, we should guarantee the confidentiality and search ability of the private data. However, nowadays privacy preserving issues in the cloud have not been carefully explored at current stage. To relieve individuals' concerns of their data privacy, this paper explores a new approach based on private matching and min-attribute generalization to solve the problem of privacy preserving in the cloud. This paper also states the new problem of privacy indexing in the internet and proves that our proposed approach can avoid privacy indexing issue in the cloud.
Privacy Preserving Confidential Forensic Investigation for Shared or Remote Servers	It is getting popular that customers make use of third party data service providers to store their data and emails. It is common to have a large server shared by many different users. This creates a big problem for forensic investigation. It may not be easy to clone a copy of data from the storage device(s) due to the huge volume of data. Even if it is possible to make a clone, there are many irrelevant information/data stored in the same device for which the investigators have no right to access. The other alternative is to let the service provider search the relevant information and retrieve the data for the investigator provided a warrant can be provided. However, sometimes, due to the confidentiality of the crime, the investigator may not want the service provider to know what information they are looking for or the service provider herself may be one of the suspects. The problem becomes even more obvious in terms of cloud computing technology. In this paper, we address this problem and using homomorphic encryption and commutative encryption, we provide two forensically sound schemes to solve the problem so that the investigators can obtain the necessary evidence while the privacy of other users can be protected and at the same time, the service provider cannot know what information the investigators are interested in.
Multimedia Privacy Protection System for Mobil Environments	In recent years, mobile phones have become very popular due to technology advances. However, unprotected personal photos and videos can easily be leaked when the phone falls into the hands of a malicious user. In this paper, we propose a multimedia privacy-preserving system for mobile phones. The system can protect information of the faces on the images or encrypt the whole image. Since most of the mobile phones are equipped with low computational power, low complexity and high accuracy are the two chief considerations for our system. Experimental results show the feasibility of the proposed method.
Privacy Implications of Identity References in Biometrics Databases	We analyze the privacy implications of identity references in biometric databases in which either raw biometric samples or templates are stored. The analysis was inspired by the privacy requirement imposed by the Norwegian National DPA (Data Protection Act Privacy Advisor) on the fingerprint data collection for one of our research projects. The respective DPA approved maintenance of a fingerprint database but required deletion of personal information, e.g., name, gender, age, and email address which were collected and stored in a 'namelist' (XLS-file) as identity references and maintained on a separate hard-disk from the biometric references. We discuss in this paper whether deletion of identity references, as the simplest anonymization way, is appropriate for privacy protection. We take a closer look at the identity attributes and assess to which degree they achieve privacy for an entity based on the proposed criteria. We analyze different biometric database models against the given criteria to give privacy protection guidelines for the identity reference construction and maintenance in a biometric database. In addition, the possibility of joint protection of identity references and biometric references is also investigated in some proposed models suitable for the identity authentication scenario.
An Effective Privacy-Preserving RFID Scheme against Desynchronization	Radio-frequency identification (RFID) is regarded as a fundamental technology for ubiquitous services and thus a growing security and privacy concern goes along with its applications integrated into everyday life, often in an invisible way. The possible abuse of RFID's tracking capability raises threats to user privacy. It has inspired lot of research interest, but many measures bring about a very challenging risk, that is, synchronization. Failure to keep changes of the shared secret in step between the tag and the back-end server will cause RFID system out of action. This paper presents an effective privacy-preserving protocol by means of commutative cipher to obviate the possibility of the mistake. In the proposed scheme, the tag output associated to the fixed secret identifier is not fixed at every session to conduct mutual authentication with reader-to-tag and tag-to-reader in turn. Therefore, our work is robust against desynchronization attacks and other security attacks, such as cloned use and man-in-the-middle attack, as well.
Feature Correlation Attack on Biometric Privacy Protection Schemes	Privacy protection techniques are an important supplementary of biometric systems. Their main purpose is to prevent security leakages in common biometric systems and to preserve the user's privacy. However, when cryptographic functions are used in the algorithms, randomness of biometric features is strictly required from the security point of view. This randomness is hard to achieve in many feature extraction algorithms, especially for those using the local information of biometric modality. In this paper we discuss privacy protection based on a fuzzy extractor. We show that the security of the algorithm is strongly reduced when statistical properties of biometric features as well as the details of the algorithm are known. An attack exploiting feature correlation is demonstrated.
Why Vein Recognition Needs Privacy Protection	This paper describes the emerging biometric modality of vein recognition and privacy concerns that arise with its widespread use. Current sensors are able to capture vein patterns inside the human body, this is considered as a private biometric characteristic. In fact two medical disease patterns are presented that can be extracted from the vein patterns. In order to be compliant with data privacy protection laws privacy enhancing mechanisms have to be applied in vein recognition systems. Experiments of applying the helper data scheme to a back-hand vein database were conducted with remarkable results. A privacy-enhanced verification system can be realized, which shows good biometric performance under laboratory conditions.
On Privacy-aware Delegation of Personal Data using Digital Watermarking	Privacy in business processes for providing personalized services is currently a matter of trust. Business processes require the disclosure of personal data to third parties and users are not able to control their usage and so their further disclosure. Existing privacy-enhancing technologies consider access control but not usage control of personal data. The current work on usage control mainly considers formalization of usage rules, i.e. obligations, and their enforcement by using the mechanisms of digital rights management, secure logging of access requests for ex post enforcement, and non-linkable delegation of access rights to personal data. However, either these enforcement mechanisms do not consider a disclosure of personal data to third parties or they assume trustworthy data consumers or data providers. We investigated digital watermarking as a way of enforcing obligations for further disclosure of personal data without mandatory trust in service providers.
A Novel Secure RFID System to Ensure Privacy	In this paper, we propose a novel Radio Frequency Identification (RFID) system to preserve privacy and enhance security by using the public key cryptography method. In the proposed architecture, the access rights of the tags are controlled by a backend server. These improve security of the system and remedy privacy problems. We analyse security of the proposed system and demonstrate its robustness against impersonation, replay, cryptanalytic and tracking attacks. Furthermore, we show the performance of the proposed system under collusion which is very common problem in many practical applications.
Study of Privacy Preserving Data Mining	There has been an important research area that how to protect private information or sensitive knowledge from leaking in the mining process, meanwhile obtain more accurate results of data mining. This paper describes data distortion, data encryption and reconstruction techniques in detail. Following a comprehensive comparison and analysis of existing technologies, the future work is showed.
The Research of Privacy-Preserving Clustering Algorithm	This paper proposes HDPPDK-Means clustering algorithm for privacy-preserving over horizontal partitioned database, using secure multi-party computation protocol to realize privacy-preserving of clustering algorithm. Theoretical analysis and examples illustrate that the proposed algorithm can effectively solve privacy-preserving problem of clustering mining over horizontal distribution and achieve the privacy-preserving aim.
A Quantifying Metric for Privacy Protection Based on Information Theory	In open and dynamic computing environments, the entities that make connections and interactions may know little about each other or without prior knowledge. So, certain level of trust must be established. This may require that an entity request some information from other entities that probably involves privacy. Therefore, quantifying privacy loss and trust gain is a meaningful and important subject. Although some work has already been done in this area, it has failed to consider the relationship between privacy information and dynamic trust variation during quantifying process. In this paper, we propose a novel quantifying metric for privacy protection based-on information theory in which we investigate dynamic trust variation to lower privacy loss while achieving more trust gain when exchange information. Simulation results show that our metric can achieve the goal well.
Research on Privacy Preserving Distributed C4. 5 Algorithm	This paper studied how two parties collaboratively built a decision tree on the union of their dataset without revealing privacy when dataset is vertically and horizontally distributed. We gave an algorithm of privacy preserving C4.5 which is applicable to vertically and horizontally partitioned dataset, and also gave the detailed computation method of the information gain ratio in the case of without revealing privacy. The secure scalar product protocol, the xln(x) protocol and the secure sum protocol are used in collaborative computing, which can protect privacy effectively.
Knowledge Reserving in Privacy Preserving Data Mining	We present in this paper a novel method to protect data privacy in data mining. Nowadays, privacy is becoming an increasingly important issue in many data mining applications. Among the current privacy preserving techniques, data anonymization provides a simple and effective way to protect the sensitive data. However, in most of the related algorithms, data details are lost and the result dataset is far less informative than the original one. In our method, we adopt a statistical way to anonymize the dataset and we are able to preserve not only the data details but also the useful data knowledge. We also analyze in detail the accuracy and the privacy levels of our method. Experimental results further demonstrate the effectiveness of our method by comparing it to the existing methods.
Distributed Privacy-Preserving Secure Aggregation in Vehicular Communication	Vehicular ad hoc networks (VANETs), formed by computers embedded in vehicles and the traffic infrastructure, are expected to develop in the near future to improve traffic safety and efficiency. To this end, VANETs should be designed to be resistant against various abuses and attacks. In this paper, we first review the existing proposals to provide security, privacy, and data aggregation in vehicle-to-vehicle communication. We then address the fundamental issue of achieving these conflicting properties in a unified solution, having observed that separate efforts cannot fulfill the VANET design objectives. A set of new mechanisms are suggested for efficiently managing identities and securely compressing cryptographic witnesses, which are among the major obstacles to the deployment of strong security mechanisms in VANETs.
Privacy-Preserving Affinity Propagation Clustering over Vertically Partitioned Data	Data mining has been well-studied in academia and widely applied to many fields. As a significant mining means, clustering algorithm has been successfully used in facility location, image categorization and bioinformatics. K-means and affinity propagation (AP) are two effective clustering algorithms, in which the former has involved in privacy preserving data mining, but the latter does not. Considering the unparalleled advantages of AP over k-means, we firstly propose a secure scheme for AP clustering in this paper. Our scheme runs over a partitioned database that different parties contain different attributes for a common set of entities. This scheme guarantees no disclosure of parties' private information by means of the cryptographic tools which have been successfully applied in privacy preserving k-means clustering. The final result for each party is the assignment of each entity, but gives nothing about the attributes held by other parties. In the end, we make a brief security discussion under the semi-honest model and analyze the communication cost to show that our scheme does have good performance.
Harnessing Pseudonyms with Implicit Attributes for Privacy-Respecting Mission Log Analysis	Many applications in the area of collaborative work can be enhanced by tracking users regularly. Consider a future emergency management application, in which mobile first responders are continuously tracked in order to support a better coordination of the rescue missions and to create a mission log. However, continuous tracking of individuals and storing the data for later use is often in conflict with individual privacy preferences. Therefore, it is a challenge to deal with conflicting traceability and privacy protection requirements. A common way to implement some kind of privacy protection is to use pseudonyms instead of fixed IDs for each user. However, in order to build a multilateral secure and acceptable solution, a more complex system design w.r.t. to pseudonym linkability is required, that also allows third parties to analyze the logs for organizational and legal reasons. In this paper, we present our approach to deal with this issue: we propose to encode additional information into pseudonyms that are used in location tracking systems and stored in data logs. Our concept comprises both access rights for the user herself and implicit attributes that may be verified by third parties in a privacy-respecting manner. We introduce the cryptographic constructions, which employ cryptographically secure pseudorandom number generators, threshold cryptography and techniques for securely evaluating encrypted data. Moreover, in this paper, we sketch a practical application example in the area of emergency mission log analysis and discuss the main security properties of our concepts.
Two-Servers PIR Based DNS Query Scheme with Privacy-Preserving	In a society preoccupied with gradual erosion of electronic privacy, loss of privacy in current DNS queries is an important issue worth considering. From the definition, the privacy problem is to prove that none of the private data can be inferred from the information which is made public. The privacy disclosure problem in DNS Query was well analyzed by Zhao et al. from MUE 2007. In this paper, we first analyze the "Range Query " from that paper, then by results of that scheme and another well-known client- to-server privacy-preserving query scheme: Two- DBServer Private Information Retrieval theory, we propose a new privacy-preserving DNS Query scheme, which was proved to achieve higher efficiency and theoretic privacy.
Respectful cameras: detecting visual markers in real-time to address privacy concerns	To address privacy concerns with digital video surveillance cameras, we propose a practical, real-time approach that preserves the ability to observe actions while obscuring individual identities. In our proposed respectful cameras system, people who wish to remain anonymous agree to wear colored markers such as a hat or vest. The system automatically tracks these markers using statistical learning and classification to infer the location and size of each face and then inserts elliptical overlays. Our objective is to obscure the face of each individual wearing a marker, while minimizing the overlay area in order to maximize the remaining observable region of the scene. Our approach incorporates a visual color-tracker based on a 9 dimensional color-space by using a probabilistic AdaBoost classifier with axis-aligned hyperplanes as weak-learners. We then use particle filtering to incorporate interframe temporal information. We present experiments illustrating the performance of our system in both indoor and outdoor settings, where occlusions, multiple crossing targets, and lighting changes occur. Results suggest that the respectful camera system can reduce false negative rates to acceptable levels (under 2%).
Security and privacy solutions for low-cost RFID systems	Low cost radio frequency identification (RFID) systems are increasingly being deployed in industry and commerce. These contactless devices have raised public concern regarding violation of privacy and information security. There is a growing need in the RFID community to discover and develop techniques and methods to overcome several problems posed by the abovementioned concerns. This paper presents proposals on feasible security mechanisms for low cost RFID systems and analyses them from both security and privacy points of view.
Privacy-preserving data aggregation in Participatory Sensing Networks	Participatory sensing using mobile devices is emerging as a promising method for large-scale data sampling. A critical challenge for participatory sensing is how to preserve the privacy of individual contributors' data. In addition, the integrity of the data aggregation is vital to ensure the acceptance of the participating sensing model by the participants. Existing approaches to these issues suffer from excessive communication cost, long delays or rely on a trusted third party. The objective of our research is to design a data-aggregation scheme for participatory sensing systems that addresses user privacy and data integrity while keeping communication overhead as low as possible. We propose four techniques to address these challenges and validate them through analytical models and simulations.
Relative and cardinal directions for privacy-aware personal navigation services: A comparison towards navigation efficiency	Traditionally, individual location has been difficult to utilize, due to a lack of precise positioning technologies. Now, with location-aware technologies integrated into lightweight mobile devices such as sensor nodes, location-based services are becoming a phenomenon in mobile services. These nodes, however, can potentially reveal sensitive and private information about individuals. In most location-aware applications such as personal navigations, location privacy is an issue. In this paper, new finding about generating efficient navigation instruction for imprecise location known as imprecise navigation is discussed. An algorithm called privacy-aware personal navigation algorithm is introduced and two types of navigational directions (relative and cardinal direction) are used for comparison. The efficiency of the algorithms has been analyzed based on its navigational performance and privacy protection. Hence, this research has the potential to support both protecting location privacy and generating better navigational instruction for imprecise navigation.
Protection of privacy in JPEG files using reversible information hiding	The privacy of unknown person may be included in the digital images unintentionally. The action of the file upload of it would constitute an invasion of his/her privacy. The JPEG files may include an exif information which is regarded as personal privacy. For these two privacy problems, we propose a privacy protection technique for JPEG files using reversible information hiding. We adopt the reversible information hiding for the region included privacy in the image. We are also able to protect personal privacy if we embed an exif information into the region. We use Coltuc's method, which changes the pixel value to carry the additional information directly, as a reversible information hiding. Although Coltuc's method modifies the pixel value of cover image directly, we apply this to quantized DCT coefficients of it. In the experiments, we investigate our method and show an example of privacy protection image.
Privacy Preservation in a Two-Tiered Sensor Network through Correlation Tracking	The architecture of two tiered sensor networks, where storage nodes serve as an intermediate tier between sensors and a sink for storing and processing data, has aroused researchers' attention because of the benefits of power and storage saving. In a sensor network, multiple sensor data streams are correlated. Correlation tracking can describe the key trends and reduce the complexity of further data processing. However, the importance of storage nodes also makes them attractive to attackers. In this paper we propose a method to guarantee both the utility and privacy of data on storage nodes through correlation tracking. To preserve privacy, we add random noise on original data. To preserve utility, the additive noise is distributed along the direction of sensor data. We provide both a mathematical and experimental evaluation on real dataset to validate the effectiveness of our algorithm.
A Many-Sorted Logic Model for Privacy Control Policy in Ubiquitous Computing	Ubiquitous computing applications lead to increasing capture, storage and utilization of user data, and raise privacy issue. Controllable customization mechanism for specify privacy policy can regulate how systems use user personal data. Thus, how to express privacy policy should be settled first and foremost. In this paper, we first introduce an access control mechanism that is suitable for privacy protecting, and then present a many-sorted predicate logic model to express and reason about user privacy policy, in which three sorts are defined, including Object, Requester and Action. Because we use many-sorted logic, our privacy policy model can be extended to meet various applications by adding sorts to it. We also give a brief overview of a proposed application framework based on this privacy policy model.
Privacy preserving in data mining - Experimental research on SMEs data	Analysis of data on individuals and business sensitive data as well as revealing the results of such analysis without disclosing confidential and sensitive information is a very important issue. Many techniques for preserving privacy of data are currently being used. This paper is addressing some of the basic techniques: randomization, k-anonymity, distributed privacy preserving and application effectiveness downgrading. Most of the techniques should be applied in the phase of data collection or their preprocessing, which can lead to different results (better or worse) of data mining than would be obtained on original data. For this reason, data analysts should be encouraged to quantify the ratio between privacy preserved in data with application of each technique and the loss of data or quality of outputs. This paper illustrates the application of certain techniques for preserving privacy on experimental dataset, and reveals the effects that their use has on the results.
Privacy preserving attribute reduction for horizontally partitioned data	There has been concern over the apparent conflict between privacy and data mining. Attribute reduction is one of the most important contributions of rough set theory to data mining. In this paper, we address the issue of privacy preserving attribute reduction. Specifically, we consider a scenario in which two parties owning private data, wish to run a attribute reduction algorithm on the union of their databases, without revealing information about individuals. Our work is motivated by the need both to protect private information and to enable its use for research or other purposes. The above problem is a specific example of secure multi-party computation. We focus on the problem with the attribute reduction algorithm based on relative granularity, address an efficient protocol for securely computing the relative granularity, and present a privacy preserving attribute reduction algorithm for horizontally partitioned data.
Enabling trust and privacy for RFID system	Future generation of RFID technology is moving towards integration with other systems. This new technology integration trend creates more benefits to user because potentially many problems could be solved in one integrated system. The integration of RFID with other systems is advantageous to users because it could use its unique contactless communication ability for numerous sectors of the community. Unfortunately, this special ability of RFID system is vulnerable because the tag can be tracked by adversary who then exploits and abuse data and location privacy. Past works on privacy-preserving RFID protocols have dealt with lots of issues regarding trust and availability. In this paper, we stress the importance of trust and privacy. We believe that data anonymity must be strengthened with integrity verification in every platform (machine or device) to avoid any untrusted platform from becoming threat to others. One such threat could be in the form of adversary making use of the privacy technique to hide its real identity. We believe that integrity verification which forms trust establishment for the system is crucial. Trust and privacy are usually contradictory in their mechanism, so we need to harmonize them to effectively protect user data. Therefore, we propose a hybrid technique for establishment of trust and privacy in RFID system. We also do trust and privacy analysis on our proposed model.
A Customer Privacy Protection Protocol on Agent-Based Electronic Commerce Transaction	Mobile agent technology is going to play an important role in the future electronic commerce due to the characteristics of mobility and autonomy of the agents. Therefore, security issues should be solved before we use this new technology. However, privacy protection of customers is seldom considered. In this paper, we focus on the privacy protection of customers. Moreover, we improve our scheme more feasible to the modern world.
Novel Algorithms for Privacy Preserving Utility Mining	Privacy preserving data mining (PPDM) has become a popular topic in the research community. How to strike a balance between privacy protection and knowledge discovery in the sharing process is an important issue. This study focuses on privacy preserving utility mining (PPUM) and presents two novel algorithms, HHUIF and MSICF, to achieve the goal of hiding sensitive itemsets so that the adversaries can not mine them from the modified database. In addition, we minimize the impact on the sanitized database in the process of hiding sensitive itemsets. The experimental results show that HHUIF achieves the lower miss costs than MSICF does on two synthetic datasets. On the other hand, MSICF generally has the lower difference between the original and sanitized databases than HHUIF does.
Privacy-preserving protocols for perceptron learning algorithm in neural networks	Neural networks have become increasingly important in areas such as medical diagnosis, bio-informatics, intrusion detection, and homeland security. In most of these applications, one major issue is preserving privacy of individualpsilas private information and sensitive data. In this paper, we propose two secure protocols for perceptron learning algorithm when input data is horizontally and vertically partitioned among the parties. These protocols can be applied in both linearly separable and non-separable datasets, while not only data belonging to each party remains private, but the final learning model is also securely shared among those parties. Parties then can jointly and securely apply the constructed model to predict the output corresponding to their target data. Also, these protocols can be used incrementally, i.e. they process new coming data, adjusting the previously constructed network.
Privacy-Aware Autonomous Agents for Pervasive Healthcare	Hospitals are convenient settings for deploying pervasive computing technology, but they also raise important privacy concerns. Hospital work imposes significant demands on staff, including high availability, careful attention to patients, confidentiality, rapid response to emergencies, and constant coordination with colleagues. These demands shape the way hospital workers experience and understand privacy. In addition, healthcare professionals experience a high level of mobility because they must collaborate with colleagues and access information and artifacts distributed throughout the premises. Autonomous agents can help developers design privacy-aware systems that handle the threats raised by pervasive technology
Authorization and privacy for semantic Web services	Web services will soon handle users' private information. They'll need to provide privacy guarantees to prevent this delicate information from ending up in the wrong hands. More generally, Web services will need to reason about their users' policies that specify who can access private information and under what conditions. These requirements are even more stringent for semantic Web services that exploit the semantic Web to automate their discovery and interaction because they must autonomously decide what information to exchange and how. In our previous work, we proposed ontologies for modeling the high-level security requirements and capabilities of Web services and clients.1 This modeling helps to match a client's request with appropriate services-those based on security criteria as well as functional descriptions.
Securing EPCglobal Object Name Service - Privacy Enhancements for Anti-counterfeiting	In RFID-aided supply chains captured location-based event data is stored in distributed repositories. Performing anti-counterfeiting involves checks on the good's path in the supply chain. The path is reconstructed by querying corresponding event data from distributed repositories. The object name service performs lookups of relevant event repositories in EPCglobal networks. Attacking the lookup process can be used to break privacy of inquirers, e.g. to derive product and user profiles. We share details about our security enhancement prototypes to protect the privacy of querying parties. Our developed enhancements are designed for easy integration into existing network infrastructures without major efforts.
Tutorial: Privacy Preservation in MANET: Issues and Challenges	Summary form only given. Sometimes the physically distributed computing devices in a network may be interested in computing some function of their private inputs without disclosing these inputs to one another. This type of computation falls under the category of Secure Multiparty Computation (SMC). The solution to SMC problems in Mobile Ad hoc Networks (MANET) can be found with the modification of the data inputs or with some anonymization technique. MANETs are the wireless networks of the mobile computing devices with no support of any fixed infrastructure. The mobile nodes use any of the radio technology like Bluetooth, IEEE 802.11 or Hiperlan for directly communicating with each other. The nodes behave as hosts as well as routers. The security challenges in the MANET arise due to its dynamic topology, vulnerable wireless link and nomadic environment. An identification mechanism is needed between the nodes using identification and the credentials. This security architecture simultaneously leads to privacy problems. Some mechanism is needed which prevents a node to learn the identity or the credentials of other nodes. To provide location privacy in MANET is a nontrivial task. Current routing protocols do not focus much on the security and the privacy issues. These aspects are postponed till further development. An authentication protocol is needed between nodes using some cryptographic technique. In service-oriented MANET the denial of the service must be taken care of so that the availability of the service is maintained. The security requirement of the ad hoc network depends on its application. For example, for a simple business meeting the requirement is mitigated and for the military battlefield it is severe. Thus no general security architecture can be developed for MANET. Specific security architecture is needed for specific application. Much security related work is still pending and will add to the standards as the physical deployment of the MANET will gro- . In this talk, an emphasis is made on how SMC solutions can be used for privacy preservation during computation.
SeVeCom ΓÇö Security and privacy in Car2Car ad hoc networks	In order to reduce the amount of traffic accidents on the roads, new safety systems based on vehicular communication - which allows vehicles to exchange information with nearby vehicles - are being developed. Similar to wireless communication in other domains, this type of information exchange is threatened by various kinds of attacks that could outweigh the advantages of safety applications and cause additional risks for traffic participants. Therefore, it is necessary for applications to recognize attacks and stop eavesdroppers from gaining sensitive information about the vehicles' occupants. The SeVeCom project dealt with those challenges and developed solutions that can be applied in realistic scenarios.
A secure anonymous key mechanism for privacy protection in VANET	In vehicular ad hoc networks (VANETs), the malicious messages and tampered messages threat other drivers' life or confuse the traffic order possibly. The anonymity has to be traceable when the law enforcement authority wants to figure out the accountabilities about the anonymity. We describe the problem that characterizes the privacy of VANETs and proposes a new anonymous key mechanism with a system architecture based on bilinear paring and elliptic curve cryptography which adapts to VANETs. The anonymous key pair generated by proposed anonymous key mechanism can realize basic security requirements, and protect identity privacy and location privacy in VANETs communication. The data storage cost can also be decreased when the numbers of node grows quickly.
Privacy implications of the Traffic Probe Message Service	The Traffic Probe Message Service will enable traffic managers to gather roadway state data via wireless communication with vehicles. Despite privacy protections specified for the service, it remains vulnerable to inference attacks aimed at reconstructing the path of a vehicle through the roadway. This paper presented a model for evaluating the location privacy in the Traffic Probe Message Service. This model identifies three key areas for improvement in the privacy protection of participating vehicles, including guidelines for the changing of pseudonymous identifiers, for data attributes included in the probe service, and for the placement of roadside equipment.
Evaluation of privacy preserving algorithms using traffic knowledge based adversary models	By providing location traces of individual vehicles, mobile traffic sensors have quickly emerged as an important data source for traffic applications. In dealing with the privacy issues associated with this, researchers have been proposing different privacy protection algorithms. In this paper, we propose traffic-knowledge-based adversary models to attack privacy algorithms. By doing so, we can compare and evaluate different privacy algorithms in terms of both privacy protection and the convenience for traffic modeling. Results show that by having a relatively good privacy performance, the released datasets of both the 3.3 level of confusion entropy and the 0.1 individual likelihood can still be applied for a fine level of traffic applications.
Congestion Pricing That Preserves Driver Privacy	In 2003, the city of London implemented a congestion pricing policy in order to reduce traffic and raise revenues for transit improvements. The dramatic success of this system has led to widespread consideration of the adoption of such variable tolling, including road pricing, in dense urban cores around the world. While from many perspectives the broad implementation of such congestion pricing systems would be socially beneficial, the likely consequences for the privacy of motorists are extremely negative. A sophisticated congestion pricing strategy assigns a cost to a specific space-time path of a vehicle through the pricing zone. Straightforward implementations of monitoring systems to assess congestion tolls thus require detailed tracking technology to monitor the paths of each individual vehicle. In this paper, we introduce a novel protocol for computing congestion pricing tolls in a fashion that preserves driver privacy. Our scheme uses cryptographic algorithms to guarantee that the state can collect arbitrarily nuanced congestion pricing tolls without being able to track the movements of individual drivers. That is, the system provides simultaneous guarantees that the state can correctly compute the tolls for a particular driver from the information it collects but that the state cannot reconstruct the path of the driver no matter what it does with this information. Our system is built using a variant of the protocol we described in a previous paper to handle automated traffic enforcement (i.e. stop-light violation detection) in a way that preserves driver privacy and eliminates camera use. The protocol is relatively easy to implement with existing technology, and such implementation can be done in a fashion which is sufficiently robust to handle realistic operational requirements. In particular, we discuss methods for ensuring resistance to attempts to cheat and modifications to handle sporadic users (tourists)
Automated traffic enforcement which respects "driver privacy"	At many intersections in downtown Los Angeles, cameras take pictures of the license plates of vehicles which run red lights. This information is used to automatically mail tickets to offenders. It seems likely that such systems becomes increasingly widespread in the near future, as they are perceived to be effective in cutting down on traffic infractions, boosting governmental revenues, and freeing law enforcement officials for other tasks. However, a network of cameras poses dramatic threats to the privacy of motorists - if kept continuously running, such a network could be used to track detailed driving habits of specific individuals. Speculative proposals involving state-monitored GPS transmitters in every registered vehicles pose even greater threats to "driver privacy". This situation is an example of the standard tension between citizen privacy and law enforcement. In this paper, we discuss the design of a novel camera-free protocol for traffic monitoring involving EZ-pass-like transponders. Our system uses cryptographic algorithms to guarantee that the state is able to detect and identify violators of a wide variety of traffic laws (light violations, speeding, illegal turns, and so forth) without having the ability to track the movements of motorists. That is, we design a traffic monitoring system with the property that no matter how it is misused, it is impossible to reconstruct the driving paths of specific cars. On the other hand, the system also guarantees that specific information about motorists who commit traffic infractions can be recovered. In addition, this protocol can be easily adapted for sophisticated and nuanced anonymous toll-collection. The system is fairly easy to implement and is immune to a variety of attacks and cheats.
PACP: An Efficient Pseudonymous Authentication-Based Conditional Privacy Protocol for VANETs	In this paper, we propose a new privacy preservation scheme, named pseudonymous authentication-based conditional privacy (PACP), which allows vehicles in a vehicular ad hoc network (VANET) to use pseudonyms instead of their true identity to obtain provably good privacy. In our scheme, vehicles interact with roadside units to help them generate pseudonyms for anonymous communication. In our setup, the pseudonyms are only known to the vehicles but have no other entities in the network. In addition, our scheme provides an efficient revocation mechanism that allows vehicles to be identified and revoked from the network if needed. Thus, we provide conditional privacy to the vehicles in the system, that is, the vehicles will be anonymous in the network until they are revoked, at which point, they cease to be anonymous.
A Physical-Layer Location Privacy-Preserving Scheme for Mobile Public Hotspots in NEMO-Based VANETs	A network mobility (NEMO)-based vehicular ad hoc network (VANET) is a new approach to integrate the NEMO protocol with VANETs. This integration supports communications between roadside units (RSUs) and vehicles and provides Internet access through public hotspots located inside public transportation systems, such as buses, trains, and shuttles. Passengers inside these public transportation systems enjoy full Internet access by using different mobile network nodes (MNNs), such as cell phones and personal digital assistants. However, due to the open nature of wireless network environments, physical-layer attackers can easily localize the MNNs by measuring their received signal strength (RSS) through positioning schemes such as the triangulation scheme. In this paper, we modify obfuscation, i.e., concealment, and power variability ideas and propose a new physical-layer location privacy scheme, i.e., the fake pointΓÇôcluster-based scheme, to prevent attackers from localizing users inside NEMO-based VANET hotspots. The proposed scheme involves fake-point- and cluster-based subschemes, and its goal is to confuse the attackers by increasing the estimation errors of their RSSs measurements and, hence, preserving MNNs' location privacy. Using correctness, accuracy, and certainty metrics, we show that the fake pointΓÇôcluster-based scheme achieves higher MNN's location privacy when the number of network grid points in the hotspot decreases. In addition, our extensive simulations show that the fake pointΓÇôcluster-based scheme achieves 23% and 37% decreases in the average sender's power and the MNN-AP route path length, respectively, compared with the fake-point subscheme.
A Dynamic Privacy-Preserving Key Management Scheme for Location-Based Services in VANETs	In this paper, to achieve a vehicle user's privacy preservation while improving the key update efficiency of location-based services (LBSs) in vehicular ad hoc networks (VANETs), we propose a dynamic privacy-preserving key management scheme called DIKE. Specifically, in the proposed DIKE scheme, we first introduce a privacy-preserving authentication technique that not only provides the vehicle user's anonymous authentication but enables double-registration detection as well. We then present efficient LBS session key update procedures: 1) We divide the session of an LBS into several time slots so that each time slot holds a different session key; when no vehicle user departs from the service session, each joined user can use a one-way hash function to autonomously update the new session key for achieving forward secrecy. 2) We also integrate a novel dynamic threshold technique in traditional vehicle-to-vehicle (V-2-V) and vehicle-to-infrastructure (V-2-I) communications to achieve the session key's backward secrecy, i.e., when a vehicle user departs from the service session, more than a threshold number of joined users can cooperatively update the new session key. Performance evaluations via extensive simulations demonstrate the efficiency and effectiveness of the proposed DIKE scheme in terms of low key update delay and fast key update ratio.
Privacy-Aware Traffic Monitoring	Traffic-monitoring systems (TMSs) are vital for safety and traffic optimization. However, these systems may compromise the privacy of drivers once they track the position of each driver with a high degree of temporal precision. In this paper, we argue that aggregated data can protect location privacy while providing accurate information for traffic monitoring. We identify a range of aggregate query types. Our proposed <i>privacy-aware monitoring system (PAMS)</i> works as an aggregate query processor that protects the location privacy of drivers as it anonymizes the IDs of cars. Our experiments show that PAMS answers queries with high accuracy and efficiency.
A Secure and privacy protecting protocol for VANET	Before the deployment of any vehicular communication system, security and privacy issues have to be resolved. In this paper, for achieving secure and privacy preserving communications, an easily implementable PKI-based protocol is proposed. Security requirements for vehicular communications are defined and a detailed definition of the scheme, which uses shared asymmetric keys and PKI techniques to provide anonymous and secure communications, is given. Furthermore, the proposed protocol is evaluated against the defined security requirements. Providing privacy and security, the proposed scheme does not introduce any complexity and computational overheads.
Digital Risk Management: Protecting Your Privacy, Improving Security, and Preparing for Emergencies	As our information systems grow more complex and we rely more on the electronic storage and transfer of information, the risk of damage, loss, and fraud increases dramatically. What information needs to be protected, and how do we go about doing that? This paper defines a variety of data vulnerabilities, and presents some simple steps that you can take to protect yourself, your company, and your information
Privacy, security and storage issues in medical data management	Health care industries are adopting Electronic Medical Record (EMR) system from paper based records. With EMR, health services can be provided at accelerated rate but privacy, security and storage of information will be of concern. There are different regulations for the use and disclosure of health information. In this research study, we focus on Health Insurance Portability and Accountability Act (HIPAA) and discuss how it protects health information of an individual while allowing the flow of information to carry out necessary health care functions. The web based EMR system is proposed based on security and privacy features defined by HIPAA.
Privacy and Confidentiality in E-Learning Systems	Security demands for e-learning systems are only marginally examined up to now. Major problem within such research is the connection of abstract criteria and requirements of educational science with technical realisation possibilities like provided by informatics. The presented research project starts with this interdisciplinary situation and investigates e-learning with respect to both affiliated disciplines aiming at a proposition for a security concept with sufficient strength while still taking care of requirements given by the learning process. Exemplary conceptual problems for confidentiality of personal data in learning management systems will be presented and discussed.
UPP: User Privacy Policy for Social Networking Sites	Since their introduction, SNS (Social Networking Sites) such as MySpace, Facebook and LinkedIn have attracted millions of users and have become established places for keeping contact with old acquaintances and meeting new ones. Nonetheless, due to lack of user awareness and proper privacy protection tools, huge quantities of user data, including personal information, pictures and videos are quickly falling into the hands of authorities, strangers, recruiters and even the public at large. By using SNSs and accepting their privacy policy, users have volunteered to relinquish their ownership on their own data, which explains why the proposed privacy solutions based on current SNSs cannot solve all user privacy issues. As such, we start by setting the foundations for privacy and introduce a privacy framework for SNSs. Then, based on this framework, we present a user privacy policy (UPP) which provides users with an easy and flexible way to specify and communicate their privacy concerns to other users, third parties and to the SNS provider.
Stochastic voting protocol to protect voters privacy	The paper proposes a voting scheme that protects voters' privacy, even when the Central Tabulating Facility reveals individual responses. The basic idea is to add random noise to the true opinion by randomizing in a way such that the true vote is chosen with higher probability than the other alternatives. A major part of the paper is to outline the statistical properties of our proposed protocol. A commitment protocol is also proposed to cope with dishonest voters who do not randomize their votes. The primary result is that the accuracy of the voting result improves as the number of voters increases
The problem with privacy	We survey issues of privacy, particularly in light of increased concerns for national security. We discuss privacy in two contexts: large distributed information systems and sensor webs. Both of these lead to direct Internet applications.
Privacy preservation for personalised services in smart spaces	Context-awareness in pervasive smart spaces exposes intuitively useful services. These services implicitly annotate users' personal information with contextual cues to individualise experiences. Mobile terminals have positioned most domestic and business users as potential consumers of these services. To alleviate the inconveniences of small screens, compact keyboards and users' limited attention span, personalised services tend towards transparency. As the services become more transparent requiring less user intervention, the more personal and context information they solicit. Richer contextual and deeper personal information facilitates better automation and adaptation. Unfortunately, transparent soliciting, acquiring and handling of personalisation constructs raises privacy concerns. We argue that, privacy policies enforced through reputable authority preserves and safeguards compromises regarding personal information. To this we propose a Privacy Policy Enforcement Authority to monitor and regulate service adherence to policy stipulations. Addressed concerns are; disclosures, retention, use and repurpose of personalisation attributes.
Privacy-Preserving Data Mining Based on Sample Selection and Singular Value Decomposition	For improving the PPDM (privacy-preserving data mining) methods based on matrix decomposition, this paper proposed a new PPDM method both using sample selection and matrix decomposition. The original matrix decomposition-based methods perform attribute extraction by matrix decomposition to analyze data, find the important information for data mining and remove the unimportant information to perturb data. In addition to attribute extraction, sample selection also can analyze data. If both sample selection and matrix decompositions are used, the important information for data mining should be found more accurately, which is the basic idea of this proposed new method. The experiments showed that this new method can perform better in privacy preserving than the methods using matrix decompositions alone, while keeping data utility.
Privacy Preserving Clustering by Random Response Method of Geometric Transformation	With the large influx of the data mining technology and mining tools, the confidentiality requirements of the personal privacy are becoming more and more urgent. Therefore, how to ensure personal privacy and get the correct mining results becomes a severe issue to be resolved. In this paper, we propose a kind of random response method of geometric transformation- the combination of the random response technology and the geometric transform algorithm. The algorithm is designed to solve the shortage of low privacy protection of the geometric transform algorithm. The algorithm first gives four parameters, corresponding to the probability of four different types of geometric transformations. According to the various random number generated, different geometric transformation method is selected, which serves the dual effect of privacy protection. Our experiment proves that this method has a high degree of privacy protection and can get correct mining results.
Privacy Preserving Association Rules Mining Based on Data Disturbance and Inquiry Limitation	Privacy is an important issue in data mining and knowledge discovery. In this paper, we use the randomized response technology to conduct association rule mining. We propose a privacy preserving association rule mining algorithm which is called DDIL based on data disturbance and inquiry limitation. Applying DDIL on the data set, the original data can be disturbed and hidden and the degree of privacy-preserving is improved effectively. Specially, a high effective method of generating frequent items from transformed data sets is proposed. Our experiments demonstrate that when the random parameters are chosen suitably, our methods are effective and provide acceptable values in practice for balancing privacy and accuracy.
Centralized Web Proxy Services: Security and Privacy Considerations	The widespread use of centrally controlled, externally run Web proxy services has several potential security issues related to privacy and deception, intranet information disclosure, and the creation of a single point of failure for widespread attacks. The author evaluates the security implications of such a Web proxy service from the viewpoints of users, organizations, and content providers. The discussion is illustrated with an analysis of Google's Web Accelerator, a free Web proxy service.
Preserving security and privacy	At the "Computers, Freedom, and Privacy (CFP) Conference held in Berkeley, California, the spotlight was on the twin weights of national security and personal liberty - with technology the fulcrum on which all turns. It highlights included sessions devoted to the new international cybercrime treaty, a global crusade to spread technology to underdeveloped nations, laws meant to block illegal sites at the IP-address level, and wiretapping voice-over-IP (VoIP) communications.
Privacy for Telecom Services	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00978364.png" border="0">
The Tussle around Online Privacy	The predominant business model for most online entities is to offer a free service that attracts users and then monetize those users' personal information via advertisements and marketing. Owing to these strong economic incentives, online services are becoming increasingly more adept at using new ways to collect personal information, while users lose more of their privacy. Here, the author investigates this "tussle" between online stakeholders.
Security and Privacy in Social Networks	Over the past several years, social networking sites have arisen to facilitate social interactions on the Internet while revolutionizing how online users interact with others. Most social networking sites offer the basic features of online interaction, communication, and interest sharing, letting individuals create online profiles that other users can view. Unfortunately, current trends in social networks indirectly require users to become system and policy administrators to protect their online contents. Social networks' security and privacy requirements still aren't well understood or fully defined. Nevertheless, it's clear that they'll be quite different from classic security and privacy requirements because social networks involve user-centric concerns and allow multiple users to specify security policies on shared data. So, we must bring a depth of security experience from multiple security domains and technologies to this field, as well as a breadth of knowledge about social networks.
Privacy Problems in the Online World	Modern technology's benefits have accelerated our migration to social networking and other online activities. However, the confluence of the online world and life offline is imperfect, immature, and incomplete. People's habits, customs, and relationships are going through profound changes that will have as-yet-unknown effects on them and society as a whole. Here, the author looks at how literature can help identify and characterize the human nature of privacy problems in the online world. Multidisciplinary approaches that align knowledge from social sciences and humanities with computer science are needed to tackle the problem of privacy in the digital world.
Privacy risks in recommender systems	Recommender system users who rate items across disjoint domains face a privacy risk analogous to the one that occurs with statistical database queries
Privacy Gets a New Round of Prominence	A recent round of publicized privacy vulnerabilities on prominent websites has led technologists, regulators, and end users all to begin asking more detailed questions about how best to achieve privacy: What data leaves a user's computer, what another party can observe about that user via that data, and then, vitally, what that party does with it? Several privacy advocates have cautioned that HTML 5 might enable advertisers and malware creators to embed more persistent tracking opportunities. The most publicized example thus far is Samy Kamkar's Evercookie, which can burrow into at least 10 places on a computer, far more than usually found. It combines traditional tracking tools with new features that come with the new Web language.
ORGs for Scalable, Robust, Privacy-Friendly Client Cloud Computing	The advent of multicore architecture stands to transform cloud computing in terms of scalability, robustness, and privacy. Social systems offer promising metaphors to address these issues. This column presents an approach based on organizations of restricted generality (ORGs), which are analogous to human organizations.
Did You Want Privacy With That?: Personal Data Protection in Mobile Devices	Smartphones and mobile devices make desktops and laptops seem clunky in comparison, but do they protect privacy? Here, the author examines the mechanisms for mobile device privacy, from operating system approaches to what users should know about risks.
Privacy Is Dead: Long Live Surveillance Symmetry	Increasingly, despite the protests and concerns of consumers and consumer advocates, privacy is becoming encroached upon and whittled away. Here, the author offers an unconventional approach on how to handle this loss of privacy and empower the average person.
Personalization and privacy	Personalization has been a hot topic or nearly a decade now, and many new products and advanced algorithms have emerged in that time. Several companies now sell tools such as recommender systems, which take input about users and products and generate recommendations about which products the users will like best. At their best, recommenders can be wonderful tools for users, helping them sort through myriad items they could read, buy, or watch to select those few that are most valuable to them. The algorithms that power these systems have evolved dramatically, and the best can produce rapid recommendations over data sets of millions of users and hundreds of thousands of products. The other edge of the sword is that recommender systems provide perfect tools for marketers and others to invade users' privacy. After all, recommenders; seek to learn everything about our preferences, including what we like to read, what we like to buy, how much money we spend, and what influences us to spend it. How a recommender deals with privacy decides whether its-users view it,as a boon or a bane. If the recommender only uses this information to help us find items to purchase on a Web site, we will probably value the feature - it might even bring us back to shop there again. On the other hand, if the Web site sells our information to other companies, so they can more effectively bother us. with phone calls at dinner time, we'll probably feel our privacy has been invaded. Privacy is a critical issue for recommender systems. In the end, personalization is an important factor in developing effective Web sites because it creates a user experience that is both compelling and sticky. The experience is compelling because it helps users find exactly the information, products, and services they need. It is sticky because a personalized Web site trains itself over time to serve its users better, which makes those users less likely to go to a new site that they would have to train all over again
Beyond Secrecy: New Privacy Protection Strategies for Open Information Spaces	When the US government erected export-control barriers against the cryptographic technology used to ensure data confidentiality, a coalition of privacy advocates joined IT companies to get those barriers removed and enable widespread adoption of encryption for privacy protection. The most fundamental challenge to 20th century privacy laws is more social than technical - adding to the stream of personal data is a new wave of user-generated content in the form of blogs. Access control and security techniques will remain vital to privacy protection - access control is important for protecting sensitive information and, above all, preserving anonymity.
Preserving Relation Privacy in Online Social Network Data	Online social networks routinely publish data of interest to third parties, but in so doing often reveal relationships, such as a friendship or contractual association, that an attacker can exploit. This systematic look at existing privacy-preservation techniques highlights the vulnerabilities of users even in networks that completely anonymize identities. Through a taxonomy that categorizes techniques according to the degree of user identity exposure, the authors examine the ways that existing approaches compromise relation privacy and offer more secure alternatives.
Google, Profiling, and Privacy	Antitrust questions put a useful spotlight on the privacy issues of online profiling by those who sell advertising on the Web. These questions apply not just to Google but to any site that uses personal information and behavior data to develop and use individual users' profiles. But simply assuring advertisers a fair marketplace won't be sufficient to guarantee user privacy. We know that many users are willing to give up some privacy protection for short-term convenience, but we shouldn't conclude from these chokes that privacy means the sum total of whatever people end up choosing.
From Home to Home Page: New Challenges to Basic Notions of Privacy and Property	The notion of "home" is a critical organizing principle for how we understand the relationship between individuals and society at large. A wide range of cultural and legal practices enshrine the home with various protections that ensure us a degree of privacy, security, solitude, and control over our lives there. As our private papers migrate to the Web, activities that we could previously conduct in "private" have seemingly been thrown open to unfettered public view. Additionally, as increasingly powerful communication technologies reach into our homes, places that were once private become more connected to public life
Who Are You? The Trade-Off between Information Utility and Privacy	There's no doubt that personal information can be valuable to companies. People are willing to give up information about themselves not because they're stupid or because they're being tricked by evil corporations, but because it can sometimes be in their best interests to do so. From this perspective, the important questions are how users can provide or limit access to that information, what benefits they might receive in exchange for a bit of information, and how they perceive the value of those benefits.
The National Strategy for Trusted Identities in Cyberspace: Enhancing Online Choice, Efficiency, Security, and Privacy through Standards	Password-centric attacks are increasingly common, and reliance on weak password technology has been a growing attack vector that threatens to erode confidence in the online world. Alternative technologies are needed to replace passwords as the primary method of online authentication. The US government's National Strategy for Trusted Identities in Cyberspace (NSTIC) focuses on working in partnership with the private sector to remove the barriers that have precluded most of the country from easily adopting online identification technologies that are secure and trusted and looks to technologies such as the Common Access Card to securely manage identities.
Privacy Ontology Support for E-Commerce	Privacy is becoming increasingly important due to the advent of e-commerce. E-commerce applications frequently require customers to divulge many personal details about themselves that must be protected carefully in accordance with privacy principles and regulations. Here, the authors define a privacy ontology to support the provision of privacy and help derive the level of privacy associated with e-commerce transactions and applications. The privacy ontology provides a framework against which e-commerce sites can benchmark their privacy policies and implementations.
Authentication and its privacy effects	As communications and computer technologies ingrain themselves further into our lives, we're asked to authenticate ourselves in a variety of ways, using increasingly sophisticated authentication systems. Most of this authentication requires personal information, which raises many privacy concerns. The US National Academies' Committee on Authentication Technologies and Their Privacy Implications recently issued its second report, who goes there? Authentication through the lens of privacy, to address the set of issues that personal authentication elicits. We summarize some of the highlights and key insights from that report.
Location-Related Privacy in Geo-Social Networks	Geo-social networks (GeoSNs) provide context-aware services that help associate location with users and content. The proliferation of GeoSNs indicates that they're rapidly attracting users. GeoSNs currently offer different types of services, including photo sharing, friend tracking, and "check-ins." However, this ability to reveal users' locations causes new privacy threats, which in turn call for new privacy-protection methods. The authors study four privacy aspects central to these social networks - location, absence, co-location, and identity privacy - and describe possible means of protecting privacy in these circumstances.
Are We Getting Privacy the Wrong Way Round?	Individualists, communitarians, and technological determinists agree that privacy's benefits accrue to individuals, and that its costs (in terms of less security or efficiency) fall on society. As such, it is the individual's choice to give privacy away. However, privacy does benefit wider society in important respects, and so this consensus is flawed.
Who Are You, Part II: More on the Trade-Off between Information Utility and Privacy	The ways in which people handle information about themselves on the Internet is changing from one where people are simply asked for information about themselves to one where the personal information is a fundamental part of the application or service they're using. This shift has led to changes in how privacy is viewed, one in which people are willing to give up information about themselves because they're getting something of value in return. This changes the nature of how people make use of these sites, and how they think about information privacy on the Internet.
Implementing Privacy with Erlang Active Objects	Functional active objects are a new paradigm for the implementation of services. They offer safe distributed evaluation with futures and immutable objects guaranteeing efficient implementation of privacy while offering verified quality assurance based on the functional paradigm and a development in an interactive theorem prover. In this paper, we present a novel and highly performant implementation of functional active objects in Erlang. Besides outlining the guiding principles of the interpreter, we show by concrete examples how secure services can be realized.
Enhancing Privacy Implementations of Database Enquiries	Privacy is an issue of increasing concern to the Internet user. To ensure the continued success of distributed information systems, a reliable information flow must be established in certified but immediately evident ways. We begin with basic consideration of the privacy problem in the general setting of database enquiries. From there, we develop a simple solution, which we illustrate with a simple implementation in the programming language Erlang, and conclude by providing an informal security analysis.
Privity: Scalable infrastructure for enforcing privacy and security of personal information	Today, privacy and security concerns are being perceived as major roadblocks to creating vibrant marketplaces for context-aware personalized information services. Marketplace members would benefit if a trusted third-party could manage the complex privacy and security requirements associated with such services accessing end-user's personal and confidential information. This paper describes a clearinghouse approach that can foster information services marketplaces for end-users, personal and confidential information database owners, and value-added Application Service Providers (ASPs). The paper focuses on a credential-delegation crypto-system for scaling the clearinghouse by obviating the need for ASPs to proxy every request to the clearinghouse for approval.
A secure and efficient message authentication protocol for vehicular Ad hoc Networks with privacy preservation(MAPWPP)	Reliability, efficient bandwidth utilisation, consistency and authenticity are some of the required applications that are required for proper implementation of vehicular ad-hoc networks (VANETs). As vehicular Ad hoc Networks are expected to greatly influence and improve road safety as well as driving conditions, they are attracting much attention these days. But along with all the benefits that it offers, there is more chance of giving way to frequent and severe malicious attacks. Due to this reason much attention is being given to the security and privacy issues in VANETs. A lot of research work is being performed to improve the standards of this network. In this paper we present a security protocol for VANET for message authentication which also promises privacy for its users. Privacy is a big issue in today's information age. Information is abundant but getting the authentic information at appropriate time and place is very crucial.
System architecture for collaborative security and privacy monitoring in multi-domain networks	The System architecture presented in this paper is developed in DEMONS project of the European FP7 framework project to realize the trustworthy multi-domain network with collaborative and decentralized security and privacy monitoring system. The system architecture so developed comprises of five sub-systems: (i) programmable monitoring nodes called BlockMon nodes providing the monitoring infrastructure data plane, ii) BlockMon Controller, iii) Mitigation Control Point, in charge of providing a unique interface towards mitigation equipments, iv) an Inter-domain Exchange Point devised to provide gateway functionalities (at both control and data plane) from/to external administrative domains, and v) a Workflow Planner and Orchestrator Controller for authorization, brokerage, and run-time control service towards the deployed monitoring and mitigation primitives on the basis of the application needs, operational requirements, and regulatory provisions. The DEMONS system architecture further comprises two external interfaces to the end users, namely i) a Programming and Administrative Interface through which the system and its components are programmed, administered and maintained, and ii) an Application User Interface through which the system is used for monitoring by users in a given domain, plus a number of dedicated interfaces among the internal DEMONS' sub-systems / components.
Location Privacy in Mobile Telephony Networks -- Conflict of Interest between Safety, Security and Privacy	Mobile telephony (e.g. GSM) is today's most common communication solution. Due to the specific characteristics of mobile communication infrastructure it can provide further real added value to different third parties. Using location information and mobility patterns, it not only contributes to emergency planning as well as safety and security, but also is a driving force behind new commercial services. However, by exploiting the subscriber's location information and mobility patterns, an individual's privacy is threatened. We discuss this problem based on an opponent model and show how users may regain control over their mobile handset using a software GSM network stack. While such behavior is rational for an individual subscriber and may not impair the technical functionality of the mobile infrastructure, the additional safety and security provided by the networks will decrease and/or be prevented.
RFID as an Enabler of the Internet of Things: Issues of Security and Privacy	RFID is one of the enabling technologies of the Internet of Things. RFID has the potential to enable machines to identify objects, understand their status, and communicate and take action if necessary, to create "real time awareness." The pervasiveness of RFID technology has given rise to a number of serious issues including security and privacy concerns. This paper will discuss current RFID usage issues and conduct a threat analysis of the RFID system components then identify issues/risks and elucidate how these issues can be resolved or risks can be mitigated.
Security, privacy and efficiency of Internet banking transactions	The last decade has witnessed the emergence of a plethora of approaches for securing financial transactions over the Internet. During the same period, attacks have matured from isolated exploits to an organized e-criminal industry. In the midst of this evolution stood the End User, whose instances have often been neglected under the assumption that refunding financial losses is all that mattered. This paper analyzes the existing deployments of Internet banking services from the perspective of the End User, whose main goal is completing the online transaction. The sole use on the client side of so-called ΓÇ£trustedΓÇ¥ hardware devices will be discussed and shown to fall short of the requirements for truly secure Internet banking. Evidence will be provided in support of the need to protect the client components using connected devices and applying software hardening techniques to lower the hacking ROI and help rebalance forces in the fight against cyber criminals. A new metric for gauging the effectiveness of security software will be described and applied to measure the practical security of existing Internet banking systems. Finally, a number of guidelines will be provided for assuring that reasonable care is exercised in the design and deployment of Internet banking systems.
Session 11: Security, trust and privacy	Start of the above-titled section of the conference proceedings record.
Session 3: Security, trust and privacy	Start of the above-titled section of the conference proceedings record.
A case study in open source software security and privacy: Android adware	The goal of this paper is to analyze the behavior and intent of recent types of privacy-invasive Android adware. This paper starts with a review of Android mobile operating system security. This paper also addresses the broader issue as to the pros and cons of an open source operating system in terms of security and privacy. Static analysis of malware can provide higher quality results and lead to a better understanding. This approach is used in this paper. As Android's market share is rapidly growing around the world, Android security will be a crucial area of research for IT security professionals and their academic counterparts. The upside of the current situation is that malware is being quickly exposed, thanks to open-source software development tools.
Enforcing location privacy policies through an AOP-based reference monitor	Location based services have become more and more popular over the last years and allow the tracking of persons and goods. User of these services often have little control over their private data as it is accessed, processed and stored. This paper presents a privacy enforcement concept that combines a sticky-policy approach with an aspect-oriented programming based reference monitor. We demonstrate the feasibility and ease-of-use of our concept with the example of a theme-park location service.
Research on Genetic Algorithms-Based in Privacy Automated Negotiation	With the development of the web, online privacy abuse issues has become more and more serious; personal privacy information security has become a major focus. The P3P (Platform for Privacy Preferences) proposed by W3C is a method for protecting user privacy, however, it is not flexible enough to meet the needs of the interaction between users and sites, this technology has not received wide spread support. In order to overcome the shortcomings of P3P and achieve flexibility in accommodating the privacy interaction between users and sites, this paper proposes an auto privacy negotiation mechanism, and researches the privacy negotiation model and algorithm. The mechanism uses the Pareto-based genetic algorithms to implement auto privacy negotiation and uses the MATLAB 2009A to carry out the experiments. The results of the experiments showed the algorithm supported bilateral multi-issue automated negotiation, and the negotiation time was very short, thus confirming the feasibility of applying the genetic algorithms to privacy negotiation.
Privacy-Preserving Trust Management for Social-Based P2P Networks	Being a new Internet application, social-based P2P network, which merges P2P file sharing technology and social network, is drawn more and more attention. However, it also brings in new challenges when facing the problems of trust management and personal privacy protection. In this paper, we aim at social-based P2P, and design a set of trust management mechanisms with peer uncertain risk evaluation and personal privacy preserving, which is able to encourage peers cooperation and defend Bad-Mouth attack from malicious peers. Another advantage of our solution is that it is very flexible for users to define fine-grit access control policy.
Preserving Privacy in Social Networks against Homogeneity Attack	Social networks have gained growing popularity in various application domains. World Wide Web has facilitated the application of information collection, dissemination and analyses to a great extent. Privacy protection is therefore especially challenged in publishing network data, because an individual's network contents can be used for identifying themselves even if other identified information is removed. However, up to now, most of the work is paying close attention to structural attacks and to the best of our knowledge, there is no effort on how to resist homogeneity attack simultaneously. In this paper, we propose a model (called k-1 generalized graph) to protect against structural and homogeneity attacks and to develop an algorithm that produces k-1 generalized graph.
Privacy Domain-Specific Ontology Building and Consistency Analysis	With the rapid development of the Internet, people increasingly pay attention to the users' online privacy issues. And so , building privacy domain-specific ontology is a necessary method for using and protecting privacy data among computer systems. Ontology is an explicit conceptualization for specific domain and is used in natural language processing, information retrieval, knowledge sharing and other fields widely. This paper introduces the principles and steps of building a privacy ontology, and studies a basic concept of privacy ontology and describes the ontology with OWL, and then gives the methods system of the privacy ontology establishment. At the same time, this paper makes a preliminary analysis of the consistency of privacy ontology. The privacy ontology building realizes knowledge sharing and the reuse of privacy domain and helps to protect and manage the online privacy of Internet users.
Security for Video Surveillance with Privacy	In this paper, a video surveillance system is designed to provide means for ensuring privacy information security and offer the capability of proving authenticity. First, a real-time scrambling approach to conceal video information is presented. The sign of transform coefficients for intra macro- block is pseudo-randomly flipped, and so only the authorized persons are allowed to correctly decode the code-stream. At the same time, a method for embedding digital watermark into videos is proposed. The relationship among the DC components in several successive frames is used for hiding data. Simulation results based on MPEG-4 show that a good level of security is provided by the end-to-end security scheme. Furthermore, this is achieved with a small impact on coding performance and computation complexity.
Privacy metrics in ubiquitous computing applications	The move to ubiquitous computing is underway fueled by both the advancements in technology and the need to free users from managing system operations. To achieve this, devices have to acquire sufficient and relevant information to provide the required services. This information is acquired without human assistance thus it poses a threat to personal and organisational privacy.
Defending privacy: The development and deployment of a darknet	New measures imposed by governments, Internet service providers and other third parties which threaten the state of privacy are also opening new avenues to protecting it. The unwarranted scrutiny of legitimate services such as file hosters and the BitTorrent protocol, once relatively unknown to the casual Internet user, is becoming more obvious. The darknet is a rising contender against these new measures and will preserve the default right to privacy of Internet users. A darknet is defined in the context of file sharing as a network which operates on top of another network such as the Internet for the purpose of secure and private distribution of digital material. While there are other darknet applications in existence, such as Freenet, WASTE again, and Relakks, they harbour some caveats. Whether they be proprietary solutions, depend on other services, are prone to feature creep or have security shortcomings, there is room for improvement. The aim of this paper is to address and improve on some of the problems of these alternative darknet clients with the development of a lightweight darknet application suite Umbra. It is then demonstrated how its deployment can circumvent or defeat the draconian measures currently threatening privacy in the public domain.
Strictly alphanumeric data: Improving privacy in smart environments	Among the challenges for acceptance and adoption of Smart environments is users' privacy concern. Since almost every operations in Smart environments are seamlessly conducted with close monitoring, human users feel are not in control of their life. To address this challenge, this article proposes to limit the use of sensors to only Bluetooth, RFID and any other sensors that capture alphanumeric data. In this approach, human activities are explicitly represented and users' identities, through their devices, are used to trigger appropriate support. This approach reduces the amount of personal identifiable information (PII) to be collected, and therefore increase the chances of maintaining users' privacy. Additionally, since there will be no physical monitoring, users may feel comfortable to work in such environments and hence increase their acceptability. Although this is not a new approach to users' identification in Smart environments, there is no work that has associated this approach to privacy concerns.
Session 4: Trust, privacy, and data security	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/05678099.png" border="0">
Quaternary privacy-levels preservation in computer forensics investigation process	Privacy preservation and computer forensics investigation are two contradictory information security directions. The privacy preservation principle stress on utmost protection of users privacy as privacy is a right, whereas computer forensics investigation attempts to unearth user data for possible digital evidences hidden within them. Although, a number of research efforts have been directed towards privacy preservation during forensics investigation process and consequently, forensics tools are in existence, most of them employ binary privacy levels, i.e., user privacy is either fully protected or not at all. In this paper, we introduce the concept of quaternary privacy levels and their protection mechanism in computer forensics investigation process. The privacy levels are identified on the basis of different entities and their participation roles during a computer forensics investigation process and represent different granule of privacy that can be enforced by the court of law depending on the nature of crime to be investigated. We also re-define the forensics investigation steps to regard different privacy levels for an investigation process.
Privacy enabled web service access control using SAML and XACML for home automation gateways	A recent trend in home automation are gateways that offer a Web service based Application Programming Interface (API) to access an underlying home automation system. Due to the ease of use and the interoperability of Web services numerous use cases can be found for third party applications using such APIs. Smart homes allow to control nearly every aspect of living within a building, which also imposes great security and privacy concerns. Therefore this paper contributes a generic access control concept for Web service based APIs using the Security Assertion Markup Language and the Extensible Access Control Markup Language. This concept allows a user to securely authorize the access of third party applications to the home automation system in order to protect privacy and to ensure security. The access control concept is generic since no API change is required leaving the service provider and service consumer untouched.
Privacy requirements specification for digital identity management systems implementation: Towards a digital society of privacy	Knowing more details about people's identities is in the same time becoming one of the digital society's growing needs and compromising security. Privacy protection is perceived as medium that would secure people's identities, reduce identity theft and increase trust. In many digital identity management system implementation initiatives, privacy needs are only dealt from technical perspective and they are not considered as being part of the core software requirements from the beginning of projects. In this article, we explain that privacy is to be dealt from the start with an integrated and multidisciplinary approach. Therefore, we provide a specification of privacy requirements that are drawn from global, domestic, and business-specific privacy policies. The requirements are to be considered in the design phase of digital identity management systems.
On the privacy of two tag ownership transfer protocols for RFIDs	In this paper, the privacy of two recent RFID tag ownership transfer protocols are investigated against the tag owners as adversaries. The first protocol called ROTIV is a scheme which provides a privacy-preserving ownership transfer by using an HMAC-based authentication with public key encryption. However, our passive attack on this protocol shows that any legitimate owner which has been the owner of a specific tag is able to trace it either in the past or in the future. Tracing the tag is also possible via an active attack for any adversary who is able to tamper the tag and extract its information. The second protocol called, Chen et al.'s protocol, is an ownership transfer protocol for passive RFID tags which conforms EPC Class l Generation2 standard. Our attack on this protocol shows that the previous owners of a particular tag are able to trace it in future. Furthermore, they are able even to obtain the tag's secret information at any time in the future which makes them capable of impersonating the tag.
Automated healthcare information privacy and security: UAE case	Information Privacy and Security issues are serious matters that organizations from all industries have to deal with. Healthcare industry is no exception. Personally identifiable healthcare information automated by the healthcare industry can be stolen, intercepted, altered, and misused. Acceptable safeguards, therefore, have to be in place in order to ensure the privacy and protection of this information. Without governmental intervention however, it seems unlikely that the healthcare industry will voluntarily implement such safeguards. Specific laws and ePHI security rules does not exist at this point of time in the UAE. The qualitative investigation in this paper was aimed at finding out if healthcare authorities are in the process of formulating and imposing healthcare privacy and security rules and standards. If healthcare institutions adhere to these privacy and security rules. Also, if lack of specific laws open the door to none compliance and adherence to healthcare privacy and security rules and standards imposed by regulatory bodies. This research study revealed that while Health Authorities are doing their best to improve healthcare standards through data standards, implementation of EHR and ePHI protection, data collected revealed mixed results. While some healthcare institutions are striving to meet some recommendations, others are less responsive. Therefore, a detailed privacy and security rule and enforcing mechanisms are required.
Intelligent strategies and techniques for effective cyber security, infrastructure protection and privacy	There has been increasing challenges in the effective design of critical information infrastructures for effective security, privacy and data protection. The increase in transmission of highly sensitive data and challenges of data protection and of privacy, data loss prevention has major significant implications for systems engineering, systems integration, and systems analysis, design and validation. Furthermore, the design and development of complex integrated systems engineering and network systems lack effective transparency, auditability, validation and implementation of adequate security measures for transfers of highly sensitive metadata across global networks using third party and outsourced networks and the Internet and global privacy regulatory requirements for such data transfer across international borders. The major problem with current state of art approaches of controls for global critical infrastructures of Virtual Private Networks (VPN) depend on inadequate third-party systems. Thus current approaches lack transparency, auditability and validation of the implementation of adequate privacy and security controls for data transfers of highly sensitive metadata across global networks. The paper examines the effectiveness strategies for effective critical information infrastructures protection, privacy and cyber security for complex large data transfers across multiple network zones.
Privacy and trust policies within SOA	Privacy for Service-Oriented Architecture (SOA) is required to gain the trust of those who would use the technology. Through the use of an independent privacy service (PS), the privacy policies of a service consumer and provider can be compared to create an agreed upon privacy contract. In this paper we further define a metamodel for privacy policy creation and comparison. A trust element is developed as an additional criterion for a privacy policy. We define the PS and what operations it must perform to accomplish its goals. We believe this PS combined with the presented metamodel provide a strong solution to providing privacy for SOA.
On securing privacy in composite web service transactions	Today's numerous online transactions are implemented as composite web services in various domains including business, healthcare, government and education. One important aspect of secured online transactions is privacy protection. This paper addresses privacy issues in composite web service transactions by providing an intelligent semi-automated privacy-aware approach to efficiently building an appropriate composite web service that (1) satisfies service functional requirements with (near) minimum number of services and information leakage, and (2) complies, as much as possible, with a customer's privacy preferences and trust (in service providers when available). Furthermore, we describe details of the proposed approach and illustrates its use that exploits generic knowledge about types and sensitivity levels of information, together with specific knowledge about customer privacy preferences and trusts on certain providers.
Towards development of a trust grid to balance between organization's interests and employee's privacy	To avoid financial and other losses that occur because of insider threat an agent based profiling model was developed. When profile of the trusted user becomes mature it is analyzed and verified against organization's policy. The users are marked as suspicious if their activities are against the policies of the organizations. This paper discusses the privacy and ethical issues of the proposed model, ACENET, when it is deployed in the organization to monitor an employee's activities. The paper also addresses misconception regarding security and privacy. The conventions regarding privacy policy of some standard bodies have also been referred. The tentative issues and the conflict between employer and employee that rises because of their interests have also been addressed and solution in form of Trust - Grid has been proposed. Finally, it has been concluded that in the light of provided guidelines, policy-making is the foundation to resolve all kind of probable conflicts.
An access control approach for privacy-preserving passive network monitoring	Passive network monitoring is very useful for the operation, maintenance, control and protection of communication networks, while in certain cases it provides the authorities with the means for law enforcement. Nevertheless, the flip side of passive network monitoring activities is that they are natively surrounded by serious privacy implications. In this paper, an innovative approach for privacy-preserving access control to data originating from passive network monitoring is described. The proposed framework relies on an ontological model for the specification of the access control policies, which are evaluated and enforced on a two-phase and two-stage basis by a system that intercedes between the network link and the monitoring applications. The two stages refer to controlled access regarding both the data that are disclosed to the monitoring application from the mediating system and the raw data that the mediator retrieves from the network link. On the other hand, the two phases concern respectively the execution of ├é┬┐static├é┬┐ and ├é┬┐dynamic├é┬┐ control; the former enforces the rules that are a priori applicable, grounded on the data, role and purpose semantics, while the latter evaluates the real-time ├é┬┐privacy context├é┬┐ for the adaptation of the access control procedures to the particular conditions underlying a request.
Anonymisation vs. Pseudonymisation: Which one is most useful for both privacy protection and usefulness of e-healthcare data	Due to sensitivity nature of the data in e-healthcare and the need of these data to different ├é┬┐healthcare team├é┬┐, privacy is one of the important issues to consider for its use. Without highly consideration of privacy issues, available data will not be useful. This results in introduction of different techniques that insist privacy protection. Anonymisation and Pseudonymisation are the main methods in privacy protection. Even though they both protect privacy, their usefulness may vary depending on the usage of the data, therefore users must be able to choose a technique to use. This paper compares characteristics of anonymisation and pseudonymisation techniques in e-healthcare. Depending on characteristics of e-healthcare data, authors proposes the use of pseudonymisation (the use of false names (pseudonym)), technique rather than anonymisation (without name) technique in e-healthcare as it will allow usage of the data to different ├é┬┐healthcare team├é┬┐ while protecting privacy of an individual. Also the use of different techniques to ├é┬┐healthcare team├é┬┐ has been proposed.
User interactive Internet of things privacy preserved access control	The Internet of Things (IoT) is a network of objects; it is enabled by the Internet technologies. The IoT always collects sensitive data, but inadequate protection may lead to serious user privacy leakage. Thus, privacy protection functions are important to the IoT. Our research aims to provide better privacy protections to IoTs. Firstly, user controlled privacy preserved access control protocol is proposed. Secondly, context aware k-anonymity privacy policy and filter are designed. Thirdly, privacy protection mechanisms are investigated, and the privacy protection mechanisms are improved based on the investigation results. Therefore, users can control which of their personal data is being collected and accessed, who is collecting and accessing such data, and when these are happening.
Evaluating security and privacy in cloud computing services: A Stakeholder's perspective	The cloud computing paradigm is now adopted in many organizations in various fields because of its low cost, high availability and scalability features. Healthcare, education, business, and many other domains look at cloud computing as an endeavor to solve the continuous shortage in volume, infrastructure, accessibility, and monitoring potency. However, moving data to the cloud implies shifting control of the customer's data to the cloud service provider indefinitely. Hence, the security and privacy of the customer's information becomes an important issue. Being an emerging field, there is a lack of experience in cloud security and lack of consensus on security and privacy. Assessing and comparing among potential cloud computing services, poses an issue for novice customers interested to move their work to the cloud to choose security options that are sufficient and robust at the same time. This paper attempts to identify and categorize a list of attributes which reflect the various aspects of cloud security and privacy. These attributes can be used to assess and compare cloud computing services so that consumers can make well educated choices. Cloud service providers can use them to build and/or offer better cloud solutions.
Perturbation for privacy-preserving participatory sensing on mobile	Summary form only given. Participatory sensing applications collect data from participants to construct statistical information of environment or phenomenon, using their mobile phone. Mobile phone is closely related to participant's daily life, therefore the invasion of privacy in participatory sensing would have dire consequences. In this research, we study privacy-preserving participatory sensing technique which is the perturbation using negative surveys and limited negative surveys on mobile to promote use of participatory sensing in healthcare, investigation, and other useful applications. When participants report the data in negative surveys, their mobile phones automatically select a value from the set complement of the sensed data value at random. In other words, we can construct public statistics without knowing the personal information of citizens. Additionally, our research extends negative surveys to limited negative surveys, which have the capable of change, according to the feature of data, especially the number of categories. We combine negative survey and limited negative survey, because it is difficult to construct valuable databases when the categories of perturbed is large size on mobile phone. We also present the evaluation of these schemes on the view point of privacy and utility of data sets in central collection server.
Systematic analysis and evaluation of web privacy policies and implementations	In this research work, we introduce the first metric for systematic analysis and evaluation of a website's entire approach to online privacy. Since the user is the ultimate judge of whether privacy was acceptably maintained, our metric views all aspects of the privacy implementation from the perspective of usability. By examining the privacy policy, technical implementation and customizable features and interface from the perspective of usability, our metric identifies modifications to privacy policies and implementations which would improve user privacy outcomes in practice. Our work is motivated by the potential of improved privacy metrics to help organizations systematically identify and implement improvements in their privacy practices and interfaces. We evaluated ten websites using our metric and reveal potential for improvement in all websites as well as contrasts between websites with similar functions, such as social networking, online shopping and information retrieval.
The mobileak project: Forensics methodology for mobile application privacy assessment	When talking about privacy, we talk about information, about data. There are several aspects that have to be considered when aiming to assess the privacy level of an application. These aspects are the states in which data can exist: data at rest, data in use and data in transit. Each of these require different methodologies and technologies in order to be properly addressed. This paper focuses on the state where data are at rest. It will be shown how common mobile forensics methodologies and tools can be used to assess the privacy level of mobile applications, and therefore how mobile applications store and manage personal information.
Enhancing privacy in social applications with the notion of group context	Nowadays, a large user community uses the Internet as a platform for manifold interactions. While sharing content, communicating or collaborating, users share a common context which can be exploited by services to adapt to users needs or to support collaborations. In this paper, we introduce group context as a means for clearly separating individual context knowledge from context information shared among the members of a group in a social interaction. Group context is established by a negotiation process among all group members keeping all participants under control of their individual context knowledge. We introduce a modeling approach for group context and define a process to establish group context based on the individual context of all group members. The feasibility of our approach is illustrated based on a social networking scenario.
ERASE- entropy-based sanitization of sensitive data for privacy preservation	Effective and efficient sanitization of digital storage media is essential from both an information security as well as a digital forensics standpoint. The method proposed in this paper, ERASE, unlike brute force methods, computes the entropy of each data block in the target area, and if the entropy is within the specified sensitivity range, then that block is wiped with a user specified number of passes and pattern. ERASERS, an enhancement to ERASE that employs random sampling, is also proposed. ERASERS divides the given population into numerous subpopulations and uses random sampling to sample blocks from each subpopulation. Then, it computes the entropy of each sampled block, and if the entropy of any sampled block in the subpopulation is within the sensitive entropy range, which is a tunable parameter, then the entire subpopulation is wiped. The random sampling component of ERASERS gives organizations an alternative for a faster wipe as compared to regular brute force methods of overwriting. Our research resulted in different levels of sanitization for different time windows, a factor most organizations will consider when wiping large disks. According to Seagate, in 2011, the average size of hard drives they shipped that year was 590 GB [1]. Overwriting a 590 GB hard drive with one pass of random data, takes approximately 14.6 hours using dd. However, ERASE optimizes the data overwriting process allowing it to sanitize a 590GB hard drive in 9.5 hours, assuming 50% of the data on the drive is within the sensitive entropy range, thereby achieving a performance improvement of approximately 34.8%. If a wipe pattern of 1 pass using /dev/zero as the source is used, dd takes approximately 1.584 hours and ERASERS takes 0.85 hours in its best case performance and 1.580 hours in its worst case performance, assuming 50% of the data is within the sensitive entropy range. Thus, achieving a performance improvement in the range of 0.2% - 46.6%.
Data privacy in mobile agent communication	Communicating with confidential data requires special attention in a mobile agents environment, especially when the other hosts must be prevented from eavesdropping the communication. We propose two methods for secured communication between the agent and a host (or other agent). The first approach for an untrusted environment uses on the fly encryption-decryption sequence to directly convert the message or plaintext into one that is encrypted directly with the public key of receiver thus reducing the overhead of retrieving the public key of sender. The technique uses AIGamal encryption/decryption. Theoretically it is proved that this scheme indeed gives the desired result. The second approach uses a trusted central authority for supply of public keys. It uses time stamps, identity of agents and RSA algorithm to provide a secured communication. Our minimal implementation of this technique suggests that it is possible to embed the entire functionality for communication security within an agent. Finally, we also state and explain how the second approach is useful in context of mobile agents with itinerary.
SMC protocol for privacy preserving in banking computations along with security analysis	The expansion of internet escalated banking to a new level and has raised tremendous opportunities of joint transactions in which multiple banks cooperatively conduct some computation. Such computations use confidential data of the involved banks to compute the result. As the concerned data is private for the owning organization, its security is prime concern. Privacy preservation concern rises as no party can be trusted enough to know all the inputs of computation. In this paper we have proposed a scalable and efficient protocol to perform secure multi-party computations on encrypted data. The process involves encrypting data in a manner that it does not affect the result of the computation. Virtual parties are created by all organizations and encrypted data is distributed among them. Modifier tokens are generated along encryption which are assigned to virtual parties, and finally used in the computation. The computation function uses the acquired data and modifier tokens to compute result. As the data involved in computation was encrypted, without revealing the data right result can be computed and privacy of the parties is maintained. The protocol is highly efficient in conducting banking computations. We have analyzed the security and complexity of protocol and shown how zero hacking security can be achieved. Also we have analyzed the performance through various tests.
Federated EHR: How to improve data quality maintaining privacy	Designing information integration solutions for healthcare in development countries is particularly complex due both to technical and organizational constraints. Classical data integration solutions based on a central database or data warehouse are not easily adaptable to this sparse environment with high number of autonomous data sources and no central controller. In such a distributed and loosely connected environment, privacy and data quality become particularly challenging as it is neither possible to control how data is used nor to measure its level of quality. In this paper we provide a lightweight solution to share healthcare data in a distributed and poorly connected environment to better coordinate healthcare services, minimize human errors, accelerate operative procedures and improve visibility of distributed healthcare processes to the governing bodies. This paper presents the architectural and theoretical framework to deal with privacy and data quality in an EHR (Electronic Health Records). The proposed solution derives from the lessons learned from e-health projects developed in Mozambique and in Italy.
Privacy and data protection in eHealth: A comparative approach between South African and French legal systems	Telemedicine has become an important tool for health professionals as well as for patients. It offers major possibilities for diagnosis, surgery and medical follow-up. Health data concerning patients are circulated via web applications, telephone, videoconferences... and general practitioners may ask for second opinion regarding a medical exam. However, eHealth and mobile Health (mHealth), which are based on information and communication technologies, raise legal concerns on both professional and patient sides. The very specific nature of these data and their use in the context of eHealth are key elements to evaluate its implications in terms of liability. Through a comparative study of South African and French law, this article aims at highlighting: on the one hand, how privacy impacts eHealth, for patients and professional practices; and, on the other hand, whether patients control the use of their medical data by health professionals.
Balancing security and privacy in eGovernment services	Advances in digital technology are increasing the volume of computer data and accelerating the massive integration of software into our daily lives. The widespread interconnection of networks and digital convergence accentuates this computerization process, making computing, telecommunications and audiovisual information increasingly compatible and interoperable. eGovernment services to citizens and businesses can take advantage of these developments. However, security and privacy concerns must be properly addressed if eGovernment services are to be both fully functional and enjoy significant take-up by end-users. These are not straightforward issues, though, and the resolution of the interplay between security and privacy cannot be achieved by a purely technical means. Instead, there is a balance required between the technological and societal elements; of which there has been significant exploration and reflection recently in the EU Trust and Security communities [1]. In the on-line world, the conflict between privacy and security often manifests itself in a debate between anonymity and accountability. This paper expounds on this apparent dispute by describing the properties of anonymity and accountability; presenting an instructive use case; and, extracting some conclusions with regard to the consequences for relevant stakeholders, should either of these two properties triumph over the other. Steps towards quantifying and measuring the various components that comprise security and privacy are also outlined.
Users' privacy in the Second Life Library	The second life library (SLL) is a virtual environment which providing library services in the context of second life. This article discusses the kinds of users' privacy issues stemming from the SLL. Various privacy-enhancing measures can be adopted for privacy protection: the SLL's privacy policy, privacy-enhancing technologies, protection for the avatar privacy, users' moral self-discipline, instuction from librarians, and an appropriate between privacy and trust.
Privacy preservation for attribute order sensitive workload in medical data publishing	Privacy becomes a more serious concern in applications involving microdata such as medical data publishing or medical data mining. Anonymization methods based on global recording or local recording or clustering provide privacy protection by guaranteeing that each released record will be indistinguishable to some other individual. However, such methods may not always achieve effective anonymization in terms of analysis workload using the anonymized data. The utility of attributes has not been well considered in the previous methods. In this paper, we study the problem of utility-based anonymization to concentrate on attributes order sensitive workload, where the order of the attributes is important to the analysis workload. Based on the multidimensional anonymization concept, a method is discussed for attributes order sensitive utility-based anonymization. The performance study using public data sets shows that the efficiency is not affected by the attributes order processing.
How to solve the security and privacy problems within e-learning	The knowledge and information based society requires a revolution in education system. These do directly result in the e-learning boom times. E-learning provides convenience for the learner, which makes anyone can study in anytime, anywhere. But the security and privacy problems could derail e-learning development plan in future. The learner's privacy may be violated while the personal information is collected, used, delivered, stored because of security mechanism. This paper provides perspective and prescription of security and privacy problems within e-learning. At first, we classify the motivation of privacy invasion within e-learning. Furthermore, we analyze information security mechanism and propose security solutions of privacy invasion problems. We focus on the methods how to constructing an e-learning system in that the learner ensure secure access to education resources and service.
A modified strong proxy signature with proxy signer privacy protection	In 1996, Mambo et al. first introduced the concept of a proxy signature scheme. In 2001, Lee et al. constructed a strong non-designated proxy signature scheme. In 2002, Shum and Wei presented an enhancement to the Lee et al.psilas scheme to hide the identity of the proxy signer. No one can determine the identity of the proxy signer only from the proxy signature. Moreover, a trusted authority can reveal the proxy signerpsilas identity if needed. However, In 2005, Narn-Yih Lee *, Ming-Feng Lee showed that the Shum-Wei scheme cannot keep the property of the strong unforgeability. That is, not only the proxy signer but also the original signer can generate valid proxy signatures. On the base of it, So we present a modified strong proxy signature scheme with proxy signer privacy protection which is efficient and secure.
Privacy-preserving DBSCAN on horizontally partitioned data	Privacy preserving data mining of distributed data is an important direction for data mining, and privacy preserving clustering is one of the main researches. At present, most privacy preserving clustering algorithms are concentrated on k-means and based on two parties and a trusted third party, clustering results are uncertain and hard to find complex shape clusters, and the protocols are inefficient because of using encryption, so we propose a algorithm called HPPDBSCAN based on semi-honest models for horizontally partitioned databases using some secure protocols such as secure sum computation, scalar product computation, standardization, and comparison by means of a semi-honest third party. The algorithm resolves the problem of privacy preserving under semi-honest circumstance for multi-party. Theoretic argument and example analysis demonstrate that the scheme is secure and complete with good efficiency.
Medical Record Privacy and Security in a Digital Environment	Quality healthcare increasingly means addressing the security, privacy, and confidentiality of medical records in both wire-line and wireless environments. This article attempts to address these concerns by presenting a comparison of data-flow patterns in an electronic healthcare setting to those in traditional medical offices and demonstrating cost-effective ways that IT consultants can help healthcare providers working in EHRs maintain and administer their own privacy and security policies.
IEEE Security and Privacy Subscription Information	
Maintaining privacy in a online world	As long as the government does not regulate online privacy policies, market forces will largely dictate the practices of most businesses. If the market values data collection highly, then data collection will be here to stay. Businesses that do not monitor their data collection practices or violate privacy policies risk serious repercussions from an unforgiving public. Companies continue to face criticism from the media and on Wall Street for egregious breaches of trust. Given this climate, businesses will seek solutions that show them to be good corporate citizens while delivering maximum value to their customers. For businesses, privacy and profit must go hand-in-hand.
IEEE Security and Privacy subscription information	IEEE Security & Privacy subscription information
Addressing Security and Privacy Risks in Mobile Applications	Applications for mobile platforms are being developed at a tremendous rate, but often without proper security implementation. Insecure mobile applications can cause serious information security and data privacy issues and can have severe repercussions on users and organizations alike.
BYOD: Security and Privacy Considerations	Clearly, there are several important advantages for employees and employers when employees bring their own devices to work. But there are also significant concerns about security privacy. Companies and individuals involved, or thinking about getting involved with BYOD should think carefully about the risks as well as the rewards.
IEEE Security & Privacy House Advertisement	
Security and Privacy Subscription Information	
Dirty laundry: privacy issues for IT professionals	Individual online privacy, already a hot button in the political landscape, is no less important for IT professionals. In 1999, the authors distributed a survey to 500 data workers in the healthcare and financial fields. The results of the study suggest that privacy concerns are not confined to consumers, but the employees who access and collect the data are concerned as well. The survey posed 15 questions regarding the responders' attitudes about the organizational practices at their organization. The data collected from the survey reveals that healthcare workers are concerned about organizational practices causing errors in patient information, as well as unsanctioned use of patient information. Similarly, the survey research indicates that employees of financial institutions are concerned with organizational practices that allow improper access to customer information. Given the results in these two fields, IT workers and managers in all fields must be prepared to deal with this issue, for it is likely to confront them soon
Privacy Guaranteed Mutual Authentication on EPCglobal Class 1 Gen 2 Scheme	Concerning the security weakness of EPC scheme especially on privacy concerned applications, an anonymous mutual authentication protocol is proposed for light-weight security inauguration on Class 1 Gen 2 UHF RFID (EPC C1G2) scheme. By utilizing the existing functions and memory bank of tag, we amend the processing sequence based on current EPC architecture. And an auto-updating index number IDS is enrolled to provide privacy protection to EPC code. A light weight encryption algorithm utilizing tagpsilas existing PRNG and keys are introduced for mutual authentication. Several attacks to the RFID solutions can be effectively resolved through our improvement.
Privacy Preserving Spatial Outlier Detection	Spatial outlier detection can be applied in the finding of terrorist activities and the forecast of abnormal climate activity etc. For protecting privacy information and mining spatial outliers, we presented privacy preserving spatial outlier mining algorithm. By the definition and application of secure multiparty computation protocols based on semi-honest model, we realized the preserving of the privacy information. We utilized data mining algorithm based on privacy-preserving spatial local outlier factor (PPSLOF) to solve the mining of the spatial outlier, and used the resident linear list in memory and improved R*-tree index to decrease the communication amount, reduce the number of the input/output (I/O), and improve the retrieval velocity, so the algorithm efficiency is improved. The theory analysis shows that privacy preserving spatial outlier mining algorithm can efficiently preserve the privacy data, and efficiently mine spatial outliers.
Privacy-Preserving Query based on Virtual Organization in Grid Database	As the development of the grid technology, it becomes more and more important in commerce application to preserve privacy and prevent information from being leaked when querying in a dynamic and heterogeneous grid database. This paper proposes a privacy-preserving query middleware PVOM (privacy-preserving visual organizations mediator) based on the security requirement of heterogeneous grid nodes, and present query algorithm based on privacy-preserving rule processed by PVOM, which can effectively preserve private information via detecting query and improve security in commercial environment application.
IEEE workshop on security, privacy and authentication in wireless networks (WoWMoM 2008)	
IEEE workshop on security, privacy and authentication in wireless networks (WoWMoM 2008)	
Camouflaging mobility for itinerary privacy in mobile ad-hoc networks	The privacy of wireless communications is becoming an important issue due to the open nature of wireless medium. Much research work has been proposed to address the anonymity of communicating parties, the location privacy of the message source and destination, and the privacy of the network routing paths. However, with the advent of new radio identification and localization techniques, more advanced privacy attacks are possible. We describe a new privacy attack in which the adversary tries to infer the itineraries of the nodes in the network. To protect itinerary privacy, we design an algorithm, called the Delta-mobility camouflaging algorithm, which can be applied upon any mobility model by changing the original motion segments into Delta-shaped camouflaging paths. Our analysis results show that the Delta-mobility camouflaging algorithm is cost-effective, which in most cases decreases the itinerary exposure probability more than 80% at a cost of less than 3% extra travel distance.
A Secure and Privacy-Protecting Aggregation Scheme for Sensor Networks	Wireless sensor networks are emerging as a practical and powerful solution to monitoring problems. However, their use in real world scenarios faces several issues. In fact, sensor nodes are tiny devices with very limited resources, and thus it is important to optimize the battery consumption. For instance, aggregation operations are widely used to minimize transmission operations, that are the most power-consuming operations for the devices. In addition, since sensor nodes operate in open and often hostile environments, security issues must be taken into account. In this paper, we propose a novel aggregation scheme which provides data integrity and privacy-protection and guarantees efficiency with respect to data transmissions, congestion, and memory overhead. To test performance of the scheme, we implemented it within a simulation software environment. We tested its performance to verify its feasibility and we evaluated the computation and power required to ensure security. Simulation results confirmed that our scheme is to be considered efficient enough to being used in real world scenarios.
Privacy preserving trust authorization framework using XACML	Nowadays many organizations share sensitive services through open network systems and this raises the need for an authorization framework that can interoperate even when the parties have no pre-existing relationships. Trust negotiation is the process used to establish these first relationships, through the transfer of attributes, embedded in digital credentials, between the two parties. However, these attributes may themselves be considered sensitive and so may need protection from disclosure. In some environments, the policies that govern the protected services may also be considered sensitive and their release to arbitrary strangers may leak confidential business information. This paper describes a way to unify the protection of services, sensitive credentials and policies in a synchronized trustworthy manner. We propose a trust authorization framework (TAF) that builds on the capabilities of XACML to support the bilateral exchange of policies and credentials through trust negotiation
Preserving traffic privacy in wireless mesh networks	In this paper, the traffic confidentiality and study of the traffic pattern concealment problem via routing control is focused. First, the number of nodes in a WMN is limited. Second, traffic forwarding relationship among nodes is strongly dependent on their locations and the network topology, which is static and known a priori in WMN. To better utilize the wireless channel resource and enhance the data delivery performance, a short path is usually selected. In light of these problems, it is aimed to design a light weight traffic privacy preserving mechanism for WMN. The penalty-based routing algorithm is proposed to achieve the goal of hiding traffic pattern by exploiting the richness of available paths between two nodes in WMN. The algorithm operates in three phases, path pool generation, candidate path selection and individual packet routing. These results show that with this algorithm, the destination node is able to consistently limit the proportion of mutual information it shares with the observing nodes
PRICE: Privacy preserving incentives for cooperation enforcement	Many incentive mechanisms have been proposed to foster cooperation among nodes in Peer-to-Peer (P2P) networks. Unfortunately, most of existing solutions rely on the existence of an online centralized authority that is in charge of a fair distribution and transaction of credits (incentives) between peers. Such centralized mechanisms mainly suffer from privacy leakage and single point of failure problems. To cope with these problems, we propose to take advantage of the distributed nature of P2P networks in order for the peers to take care of credit-based operations. Cheating and other DoS attacks are prevented thanks to a threshold security mechanism where the operation should be approved by a predefined certain number of peers. The main novelty of the proposed mechanism is the fact that a ΓÇ£creditΓÇ¥ is assigned to some peers using distributed hash tables, hence, peers can follow and control the history of operations with respect to this credit, only. Thanks to this new approach, a malicious node cannot easily keep track of all operations originating from a single node and the impact of cheating or similar attacks would be strongly reduced.
PPS: Privacy-preserving statistics using RFID tags	As RFID applications are entering our daily life, many new security and privacy challenges arise. However, current research in RFID security focuses mainly on simple authentication and privacy-preserving identification. In this paper, we discuss the possibility of widening the scope of RFID security and privacy by introducing a new application scenario. The suggested application consists of computing statistics on private properties of individuals stored in RFID tags. The main requirement is to compute global statistics while preserving the privacy of individual readings. PPS assures the privacy of properties stored in each tag through the combination of homomorphic encryption and aggregation at the readers. Re-encryption is used to prevent tracking of users. The readers scan tags and forward the aggregate of their encrypted readings to the back-end server. The back-end server then decrypts the aggregates it receives and updates the global statistics accordingly. PPS is provably privacy-preserving. Moreover, tags can be very simple as they are not required to perform any computation, but only to store data.
Adaptive and context-aware privacy preservation schemes exploiting user interactions in pervasive environments	In a pervasive system, users have very dynamic and rich interactions with the environment and its elements, including other users. To efficiently support users in such environments, a high-level representation of the system (namely, context) is usually exploited. However, since pervasive environments are inherently people-centric, context might consist of sensitive information. As a consequence, privacy concerns arise, especially in terms of how to control information disclosure to third parties (e.g., other users). In this paper we propose context-aware approaches to privacy preservation in wireless and mobile pervasive environments. Specifically, we design two schemes: (i) to reduce the interactions between the user and the system, and (ii) to exploit the interactions between different users. Both of our solutions are adaptive, thus suitable for dynamic scenarios. In addition, our schemes require limited computational and storage resources, so that they can be implemented on resource-constrained personal and sensing devices. We apply our solutions to a smart healthcare scenario, and show that our schemes not only effectively protect the user privacy, but also significantly reduce the interactions with the system, thus improving the user experience.
The impact of location privacy on opportunistic networks	Opportunistic networking involves forwarding messages between proximate users, who may or may not know one another. This assumes that users are willing to forward messages to each other. This assumption may not hold if users are concerned about using the opportunistic network service. One such concern may be due to privacy; for instance, users' locations may be leaked. A privacy-concerned user may therefore disable their mobile device's opportunistic-networking features at various times, to preserve their privacy. This paper studies the impact of location privacy concerns on the performance of an opportunistic network. Using data from a real-world location-aware user study to develop a privacy model, we conduct trace-based simulations of various opportunistic routing protocols with two real-world traces. We find that users' location privacy preferences may potentially reduce the delivery performance of an opportunistic network to zero.
Safebook: A distributed privacy preserving Online Social Network	Online Social Network (OSN) applications and services such as picture sharing, wall posting, and the like, nowadays have a strong impact on the way users interact with each other. Catering for a broad range of users of all ages, and a vast difference in social, educational, and national background, these applications and services allow even users with limited technical skills to share a wide range of personal information with a theoretically unlimited number of partners. This advantage comes at the cost of increased security and privacy exposures for users for two main reasons: first of all, users tend to disclose private personal information with little guard, and secondly, existing OSN applications severely suffer from vulnerabilities in their privacy protection or the lack thereof. The exploitation of these vulnerabilities can lead a malicious user to launch many different types of attacks such as Id theft, profile cloning or secondary data collection. Furthermore, even assuming a perfect protection from such malicious users, legitimate users are still exposed to a major orthogonal privacy threat, since in all existing OSN applications, the service provider has access to all the data including some private information stored and managed by the application itself and can misuse such information easily. Since the access to users' private data is the underpinning of a promising business model, current OSN services are not likely to address this problem in the near future. Researchers recently proposed to design the OSN application based on a peer-to-peer architecture in order to avoid centralized control over users' data. While in one hand a peer-to-peer model seems to be a good candidate to build a privacy preserving solution that avoids centralized control, on the other hand it lacks any a priori trust relationships among parties.
Privacy-triggered communications in pervasive social networks	Pervasive social networks extend traditional social networking by enabling users to share information in a peer-to-peer fashion using their wireless mobile devices. Contrary to traditional online social networks, privacy protection in such networks depends heavily on users' context (time, location, activity, etc.) and their sensitivity to the shared data and context. Existing privacy-preserving mechanisms do not adapt well to different data, context and user sensitivities. In this work, we follow a fresh approach for privacy preservation, called privacy-triggered communications; it allows users in such pervasive networks to dynamically regulate their communications based on their context and on the evolution of their privacy in that context. Our initial results show that this is a feasible strategy for privacy management in pervasive social networking scenarios.
A privacy mechanism for mobile commerce	In mobile commerce, a company provides location based services to a set of mobile users. The users report to the company their location with a level of granularity to maintain a degree of anonymity, depending on their perceived risk, and receive in return monetary benefits or better services from the company. This paper formulates a quantitative model in which information theoretic metrics such as entropy, quantify the anonymity level of the users. The individual perceived risks of users and the benefits they obtain are considered to be linear functions of their chosen location information granularity. The interaction between the mobile commerce company and its users are investigated using mechanism design techniques as a privacy game. The user best responses and optimal strategies for the company are derived under budgetary constraints on incentives, which are provided to users in order to convince them to share their private information at the desired level of granularity.
Events privacy in WSNs: A new model and its application	A novel issue resource constrained Wireless Sensor Networks (WSNs) are affected by is context privacy. Indeed, while a few solutions do exist to provide data privacy to WSNs (i.e. to protect message confidentiality), providing context privacy (e.g. preventing an adversary to locate the source of a message) is still an open research problem. This paper attacks the issue providing several contributions. First, a formal model to reason about event privacy in WSNs is introduced. This model also captures dynamic events. Second, we introduce a new realistic class of mobile events a WSN can experience. These events become the target of our privacy preserving efforts. Third, we propose a privacy enforcing solution for the above class of events: the Unobservable Handoff Trajectory (UHT) Protocol. UHT is scalable and distributed. The analysis shows that it is both effective and efficient in terms of the induced overhead. It also minimizes the delay to notify the event sources location to the base station, while preserving the intended degree of privacy. Finally, extensive simulations confirm our findings.
Privacy-by-design in ITS applications	This paper analyses how ITS applications may embrace a privacy-by-design approach. We take a holistic viewpoint based on three founding principles: data minimization, enforcement and transparency. The impact on architecture and technology is presented. Three challenges for ITS deployment are further discussed: the intrinsic instability of the resulting engineering process; the impact on future ITS platforms; the difficulty to reach consensus. Finally, tangible steps are identified on how to go forward in terms of further research work as well as building further industry consensus.
Safebook: Feasibility of transitive cooperation for privacy on a decentralized social network	Social networking services (SNS), which provide the application with the most probably highest growth rates in the Internet today, raise serious security concerns, especially with respect to the privacy of their users. Multiple studies have shown the vulnerability of these services to breaches of privacy and to impersonation attacks mounted by third parties, however the centralized storage at the providers of SNS represents an additional quite significant weakness that so far has not satisfyingly been addressed. In this paper we show the feasibility of ldquoSafebookrdquo, our proposal for the provision of a competitive social networking service, which solves these vulnerabilities by its decentralized design, leveraging on the real life relationships of its users and means of cryptography.
Privacy in context-based and epidemic forwarding	Autonomic and opportunistic communications require specific routing algorithms, like replication-based algorithms or context-based forwarding. Privacy is a major concern for protocols which disseminate the context of their destination. In this paper, we focus on the privacy issue inherent to context-based protocols, in the framework of an original epidemic forwarding scheme, which uses context as a heuristic to limit the replication of messages. We define the achievable privacy level with respect to the trusted communities assumption, and the security implications. Indeed, privacy in such an environment raises challenging problems, which lead us to a solution based on two refinements of identity-based encryption, namely searchable encryption and policy-based encryption. This new solution enables forwarding while preserving privacy by allowing secure partial matches in the header and by enforcing confidentiality of the payload.
Location privacy through secret sharing techniques	We present a novel architecture to protect the location and the identification of a mobile user. This architecture, called "share the secret - STS", simply divides the secret, i.e., the location of a user, and uses totally untrusted entities to distribute portions of this anonymous location information. STS avoids cryptography methods. As a lightweight scheme it can be applied to a network of nodes demonstrating low processing and computational power, such as the nodes of an ad-hoc network and sensors.
A statistical matching approach to detect privacy violation for trust-based collaborations	Distributed trust and reputation management mechanisms are often proposed as a means of providing assurance in dynamic and open environments by enabling principals to building up knowledge of the entities with which they interact. However, there is a tension between the preservation of privacy (which would suggest a refusal to release information) and the controlled release of information that is necessary both in order to accomplish tasks and to provide a foundation for the assessment of trustworthiness. However, if reputation-based systems are to be used in assessing the risks of privacy violation, it is necessary both to discover when sensitive information has been released, and then to be able to evaluate the likelihood that each of the set of principals that knew that information was involved in its release. We argue that statistical traceability can act as a basis for reaching a proper balance between privacy and trust. To enable this, we assume that interacting principals negotiate service level agreements that are intended to constrain the ways in which personal information may be used, and then monitor violations, ascribing likelihoods of involvement in release using an approach based on statistical disclosure control. Even though our approach cannot guarantee perfect privacy protection for personal information, it provides a framework using which detected privacy violation can be mapped onto a measure of accountability, which is useful in deterring such violation.
First International IEEE WoWMoM Workshop on Trust, Security and Privacy for Ubiquitous Computing	Presents the table of contents of the proceedings.
How trusted computers can enhance privacy preserving mobile applications	Trusted computing is designed to be a cheap, exportable and ubiquitous way of improving the security of personal, corporate and government data. The paper gives an introduction to how trusted computing can be relevant to mobile and pervasive computing and provides some examples of what can be done to enhance privacy and trust using (extensions of) this technology.
Security and privacy for mobile electronic health monitoring and recording systems	In this paper we detail the security and privacy architecture and implementation of the HealthNet mobile electronic health monitoring and data collection system. HealthNet consists of a body sensor network embedded in clothing that communicates wirelessly to the wearer's mobile phone. The mobile phone is used to manage, store and transfer the data in a secure way. Data may be transferred to other parties, such as medical experts, emergency care and private parties trusted by the wearer himself, e.g. his family. The patient controls who may access his data. Only emergency physicians nearby the patient may access vital data without the patient's individual consent. We describe the unique security and privacy features of our architecture which may also be used to improve other telemonitoring solutions.
A distributed privacy-preserving scheme for location-based queries	In this paper we deal with security and historical privacy in Location Based Service (LBS) applications where users submit accurate location samples to an LBS provider. Specifically we propose a distributed scheme that establishes access control while protecting the privacy of a user in both sporadic and continuous LBS queries. Our solution employs a hybrid network architecture where LBS users: (a) are able to communicate with an LBS provider through a network (e.g., cellular) operator, and (b) they are also able to create wireless ad-hoc networks with other peers in order to obtain privacy against an adversary that performs traffic analysis. Our threat model considers the network operator, the LBS provider and other peers, as potential privacy adversaries. For historical privacy we adopt the generic approach of using multiple pseudonyms that are changed frequently. In order to establish untraceability against traffic analysis attacks, a message is not sent directly to the cellular operator, but it is distributed among mobile neighbors who act like mixes and re-encrypt a message before sending it to the LBS provider via the cellular operator. As an extension, we also discuss how to aggregate independent data from different mobile peers before sending them to the LBS provider. This approach may be suitable in applications where aggregate location data are useful (e.g., traffic monitoring and control)
Evolutionary privacy-preserving data mining	Data mining technology can help extract useful knowledge from large data sets. The process of data collection and data dissemination may, however, result in an inherent risk of privacy threats. Some sensitive or private information about individuals, businesses and organizations has to be suppressed before it is shared or published. The privacy-preserving data mining (PPDM) has thus become an important issue in recent years. In this paper, we propose an evolutionary privacy-preserving data mining method to find appropriate transactions to be hidden from a database. The proposed approach designs a flexible evaluation function with three factors, and different weights may be assigned to them depending on users' preference. Besides, the concept of prelarge itemsets is used to reduce the cost of rescanning a database and speed up the evaluation process of chromosomes. The proposed approach can thus easily make a good trade-off between privacy preserving and execution time.
Studies of EPC encoding and privacy of RFID tag in traceability systems	RFID is a non-contact, multi-objective automatic identification technology, widely used in traceability from farm to supermarket. But standardization and privacy are the main problems to solve urgently for recent RFID traceability systems. In this paper, a standard format for the content of the RFID tags compliant with the EPCglobal standard is introduced, and the conversion between EAN-128 bar code and EPC code is presented. For privacy protection, EPC code is encrypted before written into the RFID tags, and then re-encrypted periodically. Encryption and re-encryption use the ElGamal cryptosystem. Finally, EPC encoding and re-encryption are implemented on Tag-it HF-I Transponder and ARM based on RFID readers, Montgomery's method and optimization are discussed for accelerating the computation of ElGamal, and the simulation results show that our plan is very effective.
A privacy-respecting context-aware architecture	This paper targets personal privacy protection concerns in context-aware ubiquitous computing environments. It proposes a generic context-aware architecture that is specially designed with privacy protection in mind. The proposed context-aware architecture provides functional support for context collecting, storage, processing and dissemination. It also provisions access control mechanisms to protect context information against unauthorized access, and develops a privacy agent technology to enable individuals to manage their privacy requirements towards dynamic context-aware environments with relative ease.
Privacy - The forgotten challenge in sensor and distributed systems	Privacy is a right that is granted by law and decree to all citizens of Europe and to the registered organisations they work, play or congregate through. The role of sensor networks in general, and wireless sensor networks in particular, in maintaining the privacy of users is considerable, but unfortunately very largely not addressed or not understood. The paper introduces on-going work in FP7 project i-Tour and in the world of standards at ETSI on the means to exchange privacy assertions across distributed networks such that the original consent is maintained even when new actors are introduced to the system.
A controllable privacy protection framework in position-based routing for suspicious MANETs	The privacy protection is an important issue for suspicious MANETs, a kind of Mobile Ad-hoc Networks (MANETs) that the nodes do not trust each other. One vital problem of the privacy protection in suspicious MANETs is that the malicious nodes may abuse the privacy protection to initiate some attacks that can not be tracked. As a solution to this problem, this paper proposes a universal controllable privacy protection framework in position-based routing for suspicious MANETs. We integrate a Perturbation-based Privacy Preservation (PPP) mechanism and a Malicious Node Revocation (MNR) mechanism with the common position-based routing protocols, and achieve the controllable privacy protection to nodes and the controllable security of networks. The analyses show that our framework can achieve the node-control location privacy of the nodes, and can defend the malicious insider nodes and impersonation attacks with acceptable overheads in suspicious MANETs.
Reed-Solomon codes and multi-path strategies to improve privacy performance over ad hoc networks	This paper presents a privacy protection scheme, suitable for devices limited in CPU and/or in memory capabilities, which not only ensures anonymity and confidentiality but has also a limited impact on end-to-end network performance. Such an approach for anonymous communications, inspired by network coding techniques, benefits from recent improvements in list decoding algorithms for Reed-Solomon codes, and takes advantage of multi-path routing capabilities. The combination of these techniques is adapted for constrained and pervasive environments, such as wireless ad hoc networks, as it decreases the processing complexity of the cryptographic/decoding operations and as it ensures better tolerance to packet losses (due to mobility or to bad quality of the radio channel).
Privacy protection for secure mobile RFID service	Widespread deployment of radio frequency identification (RFID) tags may create new threats to user privacy due to the automated tracking capability. Recently, RFID technology shows a convergence tendency. RFID reader is contained in a mobile phone. User privacy problem is a prior consideration for mobile RFID service deployment, since most mobile RFID service scenario is based on end-user service. In this paper, we propose a new solution for user privacy protection, which is a modification of EPC Class-1 Generation-2 protocol. Furthermore, we introduce a privacy protection scenario for mobile RFID service using this proposed scheme.
Privacy preserving social networking through decentralization	The recent surge in popularity of on-line social network applications raises serious concerns about the security and privacy of their users. Beyond usual vulnerabilities that threaten any distributed application over Internet, on-line social networks raise specific privacy concerns due their inherent handling of personal data. In this paper we point to the centralized architecture of existing on-line social networks as the key privacy issue and suggest a solution that aims at avoiding any centralized control. Our solution is an on-line social network based on a peer-to-peer architecture. Thanks to its fully distributed nature, the peer-to-peer architecture inherently avoids centralized control by any potentially malicious service provider. In order to cope with the lack of trust and lack of cooperation that are akin to peer-to-peer systems and to assure basic privacy among the users of the social network, our solution leverages the trust relationships that are part of the social network application itself. Privacy in basic data access and exchange operations within the social network is achieved thanks to a simple anonymization technique based on multi-hop routing among nodes that trust each other in the social network. Similarly cooperation among peer nodes is enforced based on hop-by-hop trust relationships derived from the social network.
Privacy in the pervasive era: A distributed firewall approach	Pervasive computing and communications are (slowly) enabling local ad-hoc services. Preserving privacy in a pervasive environment is one of the key challenges ahead: How can users define their ΓÇ£communication boundariesΓÇ¥? how can the network avoid wasting resources and eventually collapse under the burden of undesired traffic that will be discarded at the receiver machine? In this paper we propose the adoption of distributed filtering techniques implementing a network-wide firewall whose goal is defining precisely, and under the user control, the boundaries in space, time, information content, and logical addressing of a user communication scope. Initial results based on an implementation integrated with OLSR are presented.
Territorial privacy in ubiquitous computing	Smartphones define a trend towards increasing combination and integration of sensing capabilities with almost ubiquitous inter-connectivity. Resulting location-based services and context-aware applications will benefit users by adapting better to the user application needs. However, there is a lack of effective means for controlling privacy in such systems which will likely increase further with future ubiquitous computing systems. Territorial privacy is a concept that moves away from the information-centric view in traditional systems to a context-centric approach. In this paper, we define and model territorial privacy in the context of ubiquitous computing. We further discuss potential observers and disturbers in our model and provide an overview on how territorial privacy can be controlled in different environments, ranging from personal to public.
Privacy implications of in-network aggregation mechanisms for VANETs	Research on vehicular ad hoc networks (VANETs) is active and ongoing. Proposed applications range from safety applications, and traffic efficiency applications to entertainment applications. Common to many applications is the need to disseminate possibly privacy-sensitive information, such as location and speed information, over larger distances. In-network aggregation is a promising technology that can help to make such privacy-sensitive information only available in the direct vicinity of vehicles instead of communicating it over larger areas. Further away, only aggregated information that is not privacy-relevant anymore will be known. At the same time, aggregation mechanisms help to cope with the limited available wireless bandwidth. However, the exact privacy properties of aggregation mechanisms have still not been thoroughly researched. In this paper, we propose a metric to measure privacy enhancements provided by in-network aggregation and use it to compare existing schemes.
Privacy in inter-vehicular networks: Why simple pseudonym change is not enough	Inter-vehicle communication (IVC) systems disclose rich location information about vehicles. State-of-the-art security architectures are aware of the problem and provide privacy enhancing mechanisms, notably pseudonymous authentication. However, the granularity and the amount of location information IVC protocols divulge, enable an adversary that eavesdrops all traffic throughout an area, to reconstruct long traces of the whereabouts of the majority of vehicles within the same area. Our analysis in this paper confirms the existence of this kind of threat. As a result, it is questionable if strong location privacy is achievable in IVC systems against a powerful adversary.
A New Scheme of LBS Privacy Protection	LBS provide users with highly personalised information accessible by means of a variety of mobile devices that are able to locate themselves. Nevertheless, the wide deployment of LBS can jeopardise the privacy of their users, so ensuring user privacy is paramount to the success of those services. This article focuses on finding a new safe and efficient scheme to prevent LBS server or other users in group from receive real user's personal info. In this scheme, we adopt ASGKA protocol to build safe group and design a cycle-like structure to make group member have safe status.
Analysis of Privacy-Preserving Mechanisms for Outsourcing Data Mining Tasks	Many organizations have to outsource some of their data mining tasks due to inadequate in-house IT expertise. During this process, the organizations lose full security control of their source data which may lead to the exposure of their business privacy. In this paper, we first present different application scenarios of outsourcing computing tasks of data mining, then identify the elements that may expose privacy with a focus on why, how and when these element may expose privacy. We also discuss the properties of promising solutions that can protect these elements thereby preserving privacy in outsourcing scenarios.
Concern for Information Privacy and Intention to Transact Online	There are several factors restricting the development of online-shopping in China, the imperfect privacy protection law and consumers' distrust are the main barriers. By using a sample of 759 Chinese students, our study examined the IUIPC instrument and analyzed the relationship between Internet users' information privacy concerns and their intention to transact online. Consistent with prior findings, the results suggest that IUIPC as a second-order factor structure instrument shows acceptable reliability and validity. The results also indicate that Internet users' trust in online companies' information practices fully moderate the relationship between their information privacy concerns and intentions to transact online. Our findings implicate that the key ways to improve the Chinese B-C commerce development are to reduce the Internet users' information privacy concern and promote their trust in Internet-management through privacy notices.
Protecting Classification Privacy Data Aggregation in Wireless Sensor Networks	As broad deployed of wireless sensor networks, privacy concerns have emerged as the main obstacle to success. When wireless sensor networks are used in everyday life, the privacy about monitored object' sensitive data becomes an important issue. Consequently, providing efficient data aggregation privacy protection is desirable. However, the existing technique is always energy exhausting, and does not consider different privacy levels of data aggregation. In this paper, DADPP (Data Aggregation Different Privacy-Levels Protection) is proposed to deal with data aggregation privacy protection. DADPP offers different levels of data aggregation privacy based on different node-numbers for pretreating data. According to desired privacy level, all nodes within the same cluster are partitioned into many groups, any group including node- numbers belong to the same privacy level. Data are pretreated only in the same group. Compared with the existing technique, DADPP has lower energy costs while ensuring expected privacy level.
A Study of Privacy Preserving Joint-Ordering Policy	The development and deployment of privacy preserving joint-ordering policy could allow supply chain collaborations to take place without revealing any participant's data to the others, reaping the benefits of collaboration while avoiding the drawbacks. In this paper, we develop and apply secure multi-party computation protocols to the joint-ordering policy between a single supplier and a single retailer.
An Anonymous Authentication Protocol for Privacy Protection in Location Based Services	Privacy protection is particularly challenging in location based services (LBS). On one hand, service providers want to authenticate legitimate users. On the other hand, mobile users would prefer not to expose any information which enables anyone, including service providers, to get some clue regarding their whereabouts. To resolve this dilemma, we propose an anonymous authentication protocol to protect mobile users' privacy during the interactions between users and service providers in LBS. In this protocol, the service providers use blind signature to generate an authorized anonymous ID for the user, and then the user uses ring signature to mix the anonymous ID into a group of authorized IDs. We formally verify the correctness of the authentication and key establishment procedure in the protocol. In some practical situations, our protocol provides an efficient mechanism for balancing users' need for high-quality information services against their need for privacy protection.
Privacy-Preserving Cooperative Linear System of Equations Protocol and its Application	Privacy-preserving cooperative linear system of equations problem is an important scientific computation and widely used in many areas such as banking, manufacturing, and telecommunications. In this paper, we present a new privacy- preserving cooperative linear system of equations protocol under the semi-honest mode, which is more efficient as compared with existing schemes. The security of the newly devised protocol is also examined. Privacy-preserving cooperative linear system of equations protocol can be used to solve many privacy preserving scientific computation problems. As an example, a secure privacy-preserving polynomial interpolation protocol is developed based on the newly devised privacy-preserving cooperative linear system of equations protocol.
Privacy-Preserving Association Rules Mining Using the Grouping Unrelated-Question Model	Privacy preserving data mining algorithms have been intensively investigated since 2000. But almost all these approaches don't consider different privacy attitudes of different people. Some people are willing to provide their privacy data to investigators under almost any condition. Thus the privacy- preserving algorithm grouping informants will lead to higher accuracy of results. The Warner model, an important algorithm on collecting privacy data, limits the probability of randomized response and two questions in the model are closely related, which decreases informants' cooperation. Hence we propose the grouping unrelated-question model (GUQM) for the first time to solve the limits of the Warner model and to collect privacy data of people with different attitudes about privacy. Furthermore, we combine association rules mining with GUQM to solve the high time complexity in association rules mining. The paper analyzes the algorithm's validity, privacy protection and time complexity in theory. The experimental results show the effect of every parameter in our algorithm on the results of mining association rules.
A New Method to Protect Privacy in RFID based on Object Deputy model	Recently RFID has been applied in many different areas such as supplying chain management and inventory control. While the RFID system has many advantages, however, it may create new problems to the user's privacy. In this paper, we propose a new architecture of RFID system which designs a special data privacy protection module in traditional RFID system for protecting users' privacy. And the new privacy protection module is based on Object Deputy Model .Simulation and Performance analysis indicates that: the new method is safer and has higher throughput compared to the Randomized Hash-lock protocol.
A Modified Strong Proxy Signature Scheme For Privacy Protection	Now most of the proxy signature scheme can't protect original signer's privacy efficiently. Based on the current situation, as we cryptanalyzes the existing digital proxy signature scheme for privacy protection in this paper, we find a lack of security in the former ones and put forward a new modified scheme, which resolves security problem in original scheme. The improvement is much more perfect and adaptable. The modified scheme can completely prevent the forgery attack by original signer in the process of proxy signature and resist all known attack.
An improved approach to security and privacy of RFID application system	Radio frequency identification (RFID) has been considered as a time- and money-saving solution for a wide variety of applications, such as manufacturing, supply chain management, and inventory control. However, there is a growing need in the RFID community to research and find out the approach to overcome the problems posed by the privacy and information security of RFID system. This paper briefly presents the current solutions to security and privacy of RFID application system. After that an improved approach is proposed which is based on random number assisting and symmetric encryption. Then, the paper analyzes it from both security and privacy points of view. Finally, it gets the conclusion that this scheme prevents tracking, spoofing and attacking by adversaries effectively.
A Scalable Privacy-Preserving Protocol for RFID-Based Supply Chain	Scalability and privacy are crucial for the RFID-based supply chain systems. But few existing protocols consider the scalability requirement and they have security and privacy issues more or less. In this paper, aiming at the special needs of the supply chain, we propose a Lightweight Scalable Privacy-preserving protocol, LSP, which only needs to XOR and hash operations. By introducing the reverse hash chain, LSP greatly reduces the burden on the database comparing with the existing constant-time protocols. Based on our analysis, the protocol can guarantee confidentiality, untraceability, forward security and reader authentication as well as high efficiency. Meanwhile, LSP can prevent desynchronization attack. We also use the MICAz sensor nodes to simulate our protocol and the result shows it spends less time.
An Attack Tree Based Risk Assessment for Location Privacy in Wireless Sensor Networks	The challenging nature of insecure wireless channels and constrained resources make protection for wireless sensor networks (WSNs) an especially essential problem. The existing work has focused on preventive techniques to achieve location privacy protection, while the location privacy risk assessment receives less attention. In this paper, we propose a novel risk assessment approach to evaluate the risk of WSNs privacy based on attack tree. Using the attack tree model, we can estimate the degree that a certain threat might bring to the WSNs and identify possible attack sequences that an attacker may launch towards the privacy preserving system in WSNs. Then we adopted the multi-attribute utility theory to calculate the system's total risk value as well as the probabilities of each attack sequence. The analysis results can provide support for decision makers to make corresponding protection measures of location privacy∩╝Ä
TPOT: A Two-Party Privacy-Preserving Ownership Transfer Protocol for RFID Tags	When embedded in consumer goods, RFID (Radio-Frequency IDentification) tags often suffer from risking customer privacy, especially after the transactions being completed, which makes designing excellent RFID tag ownership transfer protocols more urgent than ever. We propose a hash-based method, TPOT, to transfer RFID tag ownership to customers. For tag owners' privacy protection, our scheme lets readers do ownership trans-fer instead of back-end servers. Our final result, 4H (four hash calculations) efficiency of ownership transfer on the reader side, outperforms most of previously reported solutions based on hash. TPOT is also suitable for large-scale RFID systems.
PA-SIP: A Privacy-Aware SIP for VoIP over WMNs	Voice over Internet Protocol (VoIP) over wireless mesh networks (WMNs) is becoming more and more popular due to its significant cost advantage, higher flexibility and wide coverage. One of the most basic requirements of VoIP is that it must provide privacy and security protection for VoIP clients. Unfortunately, little effort is spent on this area. In this paper, we focus on the privacy security of session initiation protocol (SIP) and propose a privacy-aware SIP called PA-SIP to enhance the VoIP privacy security. PA-SIP extends the SIP and applies a subjective logic based reputation mechanism to detect and isolate the insider malicious nodes. Finally, we analyze the PA-SIP in terms of security and performance.
On the privacy protection in publish/subscribe systems	In a publish/subscribe (pub/sub) system, information (referred to as events) published by publishers and interests submitted by subscribers are sent to the network, which conducts matching between events and interests, and only delivers those events satisfying the interests. When the pub/sub infrastructure is untrusted, it is often desirable to keep both events and interests secret from the pub/sub network. In this paper, we formulate this goal as the private subscription problem. We then describe cryptographic schemes to solve this problem in some types of publish/subscribe systems. The algorithms we present are efficient in that they are based on symmetric encryptions requiring O(n) cipher operations for a message of length n.
Distributed Access Control with Privacy Support in Wireless Sensor Networks	A distributed access control module in wireless sensor networks (WSNs) allows the network to authorize and grant user access privileges for in-network data access. Prior research mainly focuses on designing such access control modules for WSNs, but little attention has been paid to protect user's identity privacy when a user is verified by the network for data accesses. Often, a user does not want the WSN to associate his identity to the data he requests. In this paper, we present the design, implementation, and evaluation of a novel approach, Priccess, to ensure distributed privacy-preserving access control. In Priccess, users who have similar access privileges are organized into the same group by the network owner. A network user signs a query command on behalf of his group and then sends the signed query to the sensor nodes of his interest. The signature can be verified by its recipient as coming from someone authorized without exposing the actual signer. In addition to the theoretical analysis that demonstrates the security properties of Priccess, this paper also reports the experimental results of Priccess in a network of Imote2 motes, which show the efficiency of Priccess in practice.
An Efficient Threshold Anonymous Authentication Scheme for Privacy-Preserving Communications	Anonymous authentication enables any user to be authenticated without being identified. (t,n)-threshold ring signatures, introduced by Bresson et. al., are ring signature schemes that allow a group of t members to jointly sign a message anonymously in a ring of n members. Threshold ring signature schemes provide a nice tradeoff between anonymity and creditability since it allows multiple ring members to sign a message jointly. The complexity in both signature generation and signature verification of the threshold ring signature scheme proposed by Bresson et. al. is mathcal{O}(n^2). They also proposed an efficient threshold ring signature scheme based on an (n,t)-complete fair partition, with complexity mathcal{O}(n log n). In this paper, a new efficient (t,n)-threshold ring signature scheme is proposed. This scheme is constructed through a system of t linear equations and n variables, where t is generally a fixed number that is much smaller than n. The proposed threshold ring signature scheme can provide unconditional signer ambiguity, threshold unforgeability and provable security in the random oracle model. The complexity of signature generation and signature verification of the proposed threshold ring signature scheme are mathcal{O}(t log^2_2t) and mathcal{O}(n), respectively. Furthermore, the length of the threshold ring signature is the same as the regular ring signature introduced by Rivest et. al., which is 2n+2, while the length of the threshold ring signature scheme proposed by Bresson et. al. is 3n-t+3.
Network Coding Based Privacy Preservation against Traffic Analysis in Multi-Hop Wireless Networks	Privacy threat is one of the critical issues in multi-hop wireless networks, where attacks such as traffic analysis and flow tracing can be easily launched by a malicious adversary due to the open wireless medium. Network coding has the potential to thwart these attacks since the coding/mixing operation is encouraged at intermediate nodes. However, the simple deployment of network coding cannot achieve the goal once enough packets are collected by the adversaries. On the other hand, the coding/mixing nature precludes the feasibility of employing the existing privacy-preserving techniques, such as Onion Routing. In this paper, we propose a novel network coding based privacy-preserving scheme against traffic analysis in multi-hop wireless networks. With homomorphic encryption on Global Encoding Vectors (GEVs), the proposed scheme offers two significant privacy-preserving features, packet flow untraceability and message content confidentiality, for efficiently thwarting the traffic analysis attacks. Moreover, the proposed scheme keeps the random coding feature, and each sink can recover the source packets by inverting the GEVs with a very high probability. Theoretical analysis and simulative evaluation demonstrate the validity and efficiency of the proposed scheme.
A novel scheme for protecting receiver's location privacy in wireless sensor networks	Due to the open nature of a sensor network, it is relatively easy for an adversary to eavesdrop and trace packet movement in the network in order to capture the receiver physically. After studying the adversary's behavior patterns, we present countermeasures to this problem. We propose a locationprivacy routing protocol (LPR) that is easy to implement and provides path diversity. Combining with fake packet injection, LPR is able to minimize the traffic direction information that an adversary can retrieve from eavesdropping. By making the directions of both incoming and outgoing traffic at a sensor node uniformly distributed, the new defense system makes it very hard for an adversary to perform analysis on locally gathered information and infer the direction to which the receiver locates. We evaluate our defense system based on three criteria: delivery time, privacy protection strength, and energy cost. The simulation results show that LPR with fake packet injection is capable of providing strong protection for the receiveriquests location privacy. Under similar energy cost, the safe time of the receiver provided by LPR is much longer than other methods, including Phantom routing [1] and DEFP [2]. The performance of our system can be tuned through a few system parameters that determine the tradeoff between energy cost and the strength of location-privacy protection.
Privacy-Preserving Distributed Profile Matching in Proximity-Based Mobile Social Networks	Making new connections according to personal preferences is a crucial service in mobile social networking, where an initiating user can find matching users within physical proximity of him/her. In existing systems for such services, usually all the users directly publish their complete profiles for others to search. However, in many applications, the users' personal profiles may contain sensitive information that they do not want to make public. In this paper, we propose FindU, a set of privacy-preserving profile matching schemes for proximity-based mobile social networks. In FindU, an initiating user can find from a group of users the one whose profile best matches with his/her; to limit the risk of privacy exposure, only necessary and minimal information about the private attributes of the participating users is exchanged. Two increasing levels of user privacy are defined, with decreasing amounts of revealed profile information. Leveraging secure multi-party computation (SMC) techniques, we propose novel protocols that realize each of the user privacy levels, which can also be personalized by the users. We provide formal security proofs and performance evaluation on our schemes, and show their advantages in both security and efficiency over state-of-the-art schemes.
TSVC: timed efficient and secure vehicular communications with privacy preserving	In this paper, we propose a timed efficient and secure vehicular communication (TSVC) scheme with privacy preservation, which aims at minimizing the packet overhead in terms of signature overhead and signature verification latency without compromising the security and privacy requirements. Compared with currently existing public key based packet authentication schemes for security and privacy, the communication and computation overhead of TSVC can be significantly reduced due to the short message authentication code (MAC) tag attached in each packet for the packet authentication, by which only a fast hash operation is required to verify each packet. Simulation results demonstrate that TSVC maintains acceptable packet latency with much less packet overhead, while significantly reducing the packet loss ratio compared with that of the existing public key infrastructure (PKI) based schemes, especially when the road traffic is heavy.
Mobile Privacy in Wireless Networks-Revisited	With the widespread use of mobile devices, the privacy of mobile location information becomes an important issue. In this paper, we present the requirements on protecting mobile privacy in wireless networks, and identify the privacy weakness of the third generation partnership project - authentication and key agreement (3GPP-AKA) by showing a practical attack to it. We then propose a scheme that meets these requirements, and this scheme does not introduce security vulnerability to the underlying authentication scheme. Another feature of the proposed scheme is that on each use of wireless channel, it uses a one-time alias to conceal the real identity of the mobile station with respect to both eavesdroppers and visited (honest or false) location registers. Moreover, the proposed scheme achieves this goal of identity concealment without sacrificing authentication efficiency.
Privacy-Preserving Universal Authentication Protocol for Wireless Communications	Seamless roaming over wireless networks is highly desirable to mobile users, and security such as authentication of mobile users is challenging. In this paper, we propose a privacy-preserving universal authentication protocol, called Priauth, which provides strong user anonymity against both eavesdroppers and foreign servers, session key establishment, and achieves efficiency. Most importantly, Priauth provides an efficient approach to tackle the problem of user revocation while supporting strong user untraceability.
Location sensing and privacy in a context-aware computing environment	This article presents and evaluates the performance of a location sensing algorithm developed and demonstrated at Carnegie Mellon University. We compare our model with various others based on different architectures and software paradigms. We show comparative results in accuracy, the complexity of training, total power consumption, and suitability to users. Our method reduces training complexity by a factor of eight over previous algorithms, and yields noticeably better accuracy. The algorithm uses less power than previous models, and offers a more secure privacy model.
Data security and privacy in wireless body area networks	The wireless body area network has emerged as a new technology for e-healthcare that allows the data of a patient's vital body parameters and movements to be collected by small wearable or implantable sensors and communicated using short-range wireless communication techniques. WBAN has shown great potential in improving healthcare quality, and thus has found a wide range of applications from ubiquitous health monitoring and computer assisted rehabilitation to emergency medical response systems. The security and privacy protection of the data collected from a WBAN, either while stored inside the WBAN or during their transmission outside of the WBAN, is a major unsolved concern, with challenges coming from stringent resource constraints of WBAN devices, and the high demand for both security/privacy and practicality/usability. In this article we look into two important data security issues: secure and dependable distributed data storage, and fine-grained distributed data access control for sensitive and private patient medical data. We discuss various practical issues that need to be taken into account while fulfilling the security and privacy requirements. Relevant solutions in sensor networks and WBANs are surveyed, and their applicability is analyzed.
Privacy protection for users of location-based services	With the proliferation of mobile devices such as smartphones and tablets, location-based services are becoming increasingly popular. LBSs, albeit useful and convenient, pose a serious threat to users' privacy as they are enticed to reveal their locations to LBS providers via their queries for location-based information. How to protect users' privacy against potentially compromised LBS providers is of vital importance to the well being of the LBS ecosystem, given that the LBS market can expand and prosper only if users feel comfortable about using LBSs. This article presents a comprehensive overview of the existing schemes for protecting LBS users' privacy. We first introduce potential privacy threats to LBS users, followed by a discussion on privacy metrics. We then classify the protection schemes according to their architectural properties (i.e., server-based or mobile-device-based) and privacy metrics (e.g., k-anonymity or location entropy). Finally, we discuss several promising directions for future research into LBS users privacy protection.
Security and privacy in emerging wireless networks [Guest Editorial]	Rapid advances in wireless ad hoc networking have extended its application from mobile ad hoc networks and wireless sensor networks to emerging wireless networks including wireless mesh networks, delay-tolerant networks, vehicular networks, and urban sensing networks. While facilitating ubiquitous network access as well as social interactions, these emerging networks are particularly vulnerable to numerous privacy and security threats. For example, attackers may jeopardize the privacy of users in vehicular and urban sensing networks; the adversary may also compromise selected nodes in a tactical delay-tolerant network and thus fail the critical mission of the network. There is clearly an urgent need to protect emerging wireless networks from various security and privacy threats, thereby eliminating a major impediment to their widespread adoption.
Complementing public key infrastructure to secure vehicular ad hoc networks [Security and Privacy in Emerging Wireless Networks]	Vehicular ad hoc networks are emerging as an effective technology for providing a wide range of safety applications to by-vehicle passengers. Ensuring secure operation is one of the prerequisites for deploying reliable VANETs. In this article we argue that public key infrastructure is the most viable mechanism for securing VANETs as it can meet most VANET security requirements. However, PKI cannot provide certain security requirements such as location privacy, efficient authentication, and distributed and fair revocation. To complement the security services provided by PKI, we introduce complementary security mechanisms that can meet the aforementioned security requirements. Since denial of service attacks have severe consequences on network availability, which is one of the VANET security requirements, we propose a mechanism for mitigating the effect of DoS attacks in VANETs. Simulation results show that the complementary mechanisms together with PKI can efficiently secure VANETs.
Location privacy in urban sensing networks: research challenges and directions [Security and Privacy in Emerging Wireless Networks]	During the last few years there has been an increasing number of people-centric sensing projects. These combine location information with sensors available on mobile phones, giving birth to a different dimension in sensing our environment and providing us with new opportunities to create collective intelligence systems to address urban-scale problems such as air pollution, noise, and traffic. However, as people are directly involved in the collection process, they often inadvertently reveal information about themselves, raising new and important privacy concerns. While standard privacy enhancing technologies exist, they do not fully cover the many peculiarities of these new pervasive applications. The ubiquitous nature of the communication and the storage of location traces compose a complex set of threats on privacy, which we overview in this article. Then we go through the latest advances in security and privacy protection strategies, and discuss how they fit with this new paradigm of people-centric sensing applications. We hope this work will better highlight the need for privacy in urban sensing applications and spawn further research in this area.
Exploiting the physical layer for enhanced security [Security and Privacy in Emerging Wireless Networks]	While conventional cryptographic security mechanisms are essential to the overall problem of securing wireless networks, they do not directly leverage the unique properties of the wireless domain to address security threats. The wireless medium is a powerful source of domain-specific information that can complement and enhance traditional security mechanisms. In this article we argue that new security paradigms which exploit physical layer properties of the wireless medium, such as the rapid spatial, spectral, and temporal decorrelation properties of the radio channel, can enhance confidentiality and authentication services. We outline some basic constructions for these services, and then provide a case study for how such strategies can be integrated into a broader security framework for a wireless network.
Application of wireless sensor networks in critical infrastructure protection: challenges and design options [Security and Privacy in Emerging Wireless Networks]	The protection of critical infrastructures provides an interesting application area for wireless sensor networks. Threats such as natural catastrophes, criminal or terrorist attacks against CIs are increasingly reported. The large-scale nature of CIs requires a scalable and low-cost technology for improving CI monitoring and surveillance. WSNs are a promising candidate to fulfill these requirements, but if the WSN becomes part of the CI in order to improve its reliability, then the dependability of the WSN itself needs to be significantly improved first. In this article we discuss the challenges and potential solutions to achieve dependability of WSNs taking into account accidental failures as well as intentional attacks. We inspect the whole system starting from individual sensor nodes via the protocol stack to the middleware layer above.
Toward dependable networking: secure location and privacy at the link layer	WLAN and other radio broadcast technologies are now commonplace. However, the widespread usage of these technologies comes at the price of loss of location privacy. Although a number of network-level solutions exist to lessen the problem, we describe an improved approach to location privacy at the link layer. We present a generic mechanism and then map it to the common IEEE 802.11 protocol set. The article finally provides an analysis of our mechanism in terms of privacy and performance.
Non-cryptographic authentication and identification in wireless networks [Security and Privacy in Emerging Wireless Networks]	Lower/physical layer characteristics have been considered as potential alternatives/complements to provide security services in wireless networks. This article provides an overview of various noncryptographic mechanisms for user authentication and device identification in wireless networks using lower/physical layer properties or information. We discuss merits and demerits of these authentication/identification schemes and the practical implementation issues. Future research on cross-layer security design concludes this article.
Security and privacy of collaborative spectrum sensing in cognitive radio networks	Collaborative spectrum sensing is regarded as a promising approach to significantly improve the performance of spectrum sensing in cognitive radio networks. However, due to the open nature of wireless communications and the increasingly available software defined radio platforms, collaborative spectrum sensing also poses many new research challenges, especially in the aspect of security and privacy. In this article, we first identify the potential security threats toward collaborative spectrum sensing in CRNs. Then we review the existing proposals related to secure collaborative spectrum sensing. Furthermore, we identify several new location privacy related attacks in collaborative sensing, which are expected to compromise secondary users┬┐ location privacy by correlating their sensing reports and their physical location. To thwart these attacks, we propose a novel privacy preserving framework in collaborative spectrum sensing to prevent location privacy leaking. We design and implement a real-world testbed to evaluate the system performance. The attack experiment results show that if there is no any security guarantee, the attackers could successfully compromise a secondary user┬┐s location privacy at a success rate of more than 90 percent. We also show that the proposed privacy preserving framework could significantly improve the location privacy of secondary users with a minimal effect on the performance of collaborative sensing.
Security and privacy in emerging wireless networks [Invited Paper]	Wireless communication is continuing to make inroads into many facets of society and is gradually becoming more and more ubiquitous. While in the past wireless communication (as well as mobility) was largely limited to the first and last transmission hops, today's wireless networks are starting to offer purely wireless, often mobile, and even opportunistically connected operation. The purpose of this article is to examine security and privacy issues in some new and emerging types of wireless networks, and attempt to identify directions for future research.
Privacy and emergency response in e-healthcare leveraging wireless body sensor networks	Electronic healthcare is becoming a vital part of our living environment and exhibits advantages over paper-based legacy systems. Privacy is the foremost concern of patients and the biggest impediment to e-healthcare deployment. In addressing privacy issues, conflicts from the functional requirements must be taken into account. One such requirement is efficient and effective response to medical emergencies. In this article, we provide detailed discussions on the privacy and security issues in e-healthcare systems and viable techniques for these issues. Furthermore, we demonstrate the design challenge in the fulfillment of conflicting goals through an exemplary scenario, where the wireless body sensor network is leveraged, and a sound solution is proposed to overcome the conflict.
Detecting wormhole attacks in delay-tolerant networks [Security and Privacy in Emerging Wireless Networks]	Delay-tolerant networks are especially useful in providing mission-critical services including emergency scenarios and battlefield applications. However, DTNs are vulnerable to wormhole attacks, in which a malicious node records the packets at one location and tunnels them to another colluding node, which relays them locally into the network. Wormhole attacks are a severe threat to normal network operation in DTNs. In this article we describe various methods that have been developed to detect wormhole attacks. However, most of them cannot work efficiently in DTNs. To detect the presence of a wormhole attack, we propose a detection mechanism that exploits the existence of a forbidden topology in the network. We evaluated our approach through extensive simulations using both Random Way Point and Zebranet mobility models. Our results show that the proposed method can detect wormhole attacks efficiently and effectively in DTNs.
Protocols for stimulating packet forwarding in wireless ad hoc networks [Security and Privacy in Emerging Wireless Networks]	A wireless ad hoc network is a self-organized wireless network without centralized infrastructure. In such a network, nodes rely on each other to forward packets to remote destinations. A threat to such multihop transmission is posed by selfish nodes, which may drop others' packets to save their own bandwidth and battery life. Therefore, stimulating packet forwarding is a fundamental problem for wireless ad hoc networks. Most solutions proposed so far are either reputation-based or credit-exchange-based, which are fundamentally context-based solutions. They need to accurately identify selfish behaviors, securely maintain the context, and appropriately punish selfish nodes. These requirements are difficult to satisfy. Recently a solution from a new angle is proposed: a context-free protocol that does not rely on observation and selfish behavior detection. Given a path, a context-free protocol can transmit packets through it without knowing whether the intermediate nodes are selfish or not. It can get rid of all troubles caused by establishing and maintaining the context, and has some significant advantages over context-based solutions. In this article we first provide an overview of traditional context-based solutions, then introduce the recently proposed context-free solution, and finally analyze them extensively.
Security, privacy, and accountability in wireless access networks	The presence of ubiquitous connectivity provided by wireless communications and mobile computing has changed the way humans interact with information. At the same time, it has made communication security and privacy a hot-button issue. In this article we address the security and privacy concerns in wireless access networks. We first discuss the general cryptographic means to design privacy-preserving security protocols, where the dilemma of attaining both security and privacy goals, especially user accountability vs. user privacy, is highlighted. We then present a novel authentication framework that integrates a new key management scheme based on the principle of separation of powers and an adapted construction of Boneh and Shacham's group signature scheme, as an enhanced resort to simultaneously achieve security, privacy, and accountability in wireless access networks.
Source-Location Privacy Based on Directed Greedy Walk in Wireless Sensor Networks	Wireless sensor networks are used to monitor sensitive objects, the privacy about monitored object' locations become an important issue. Flooding-based phantom has a problem that message latencies become larger and energy costs become higher. In this paper, DGWK (Directed Greedy Walk) is proposed to make it difficult for an adversary to backtrack hop-by-hop to the origin of the sensor communication. Compared to Flooding-based phantom, DGWK has smaller message latencies and lower energy costs. Especially, Directed Greedy Walk has bigger safety period when intermediate node has multi-parent-nodes.
Data Privacy Management in a Multi-Organizational RFID Authentication	The growing popularity of Radio Frequency Identification (RFID) systems cannot be overlooked due to their wide range of application areas. However, some RFID applications face security and privacy threats due to the exposure of tags over wider distances. There are security methods but these can lack security and scalability when authenticating RF tags in multi-organizational RFID system. RFID systems operating within a single domain have only security and privacy issues due to the security method on tags, but in a multi-organizational system there are even more security and privacy issues in the system architecture rather than just in the security method on tag side. In this paper, we have designed a broker service to EPC Network for secure and confidential data management of the RFID data events. Secure and confidential authentication broker service is an extension to the EPC network architecture for a multi-organizational RFID system. The central authentication broker service ensures to avoid any illicit access to the confidential RFID tag's data such as EPC code, whilst managing a large-scale authentication data to ensure secure and deterministic response to the authentic entities of the system.
Context-Aware Trust and Privacy Application for Mobile Identification System	The trend on the proliferation of handheld devices triggered an increase on the development of pervasive and personalized mobile applications that exploit and support peer-to-peer/ad-hoc networks. This creates the conditions and motivation for a mobile electronic ID system, preferably one which provides a friendly privacy solution. The existing mobile identification solutions place the interviewer in a more authoritative position than the interviewee, while little or no privacy control is applied by the interviewee. With the mobile ID system (MobIS), this paper proposes a universal mobile ID system which is suitable for various scenarios (e.g. for professional, medical, or official uses) in a heterogeneous network environment. Such systems are highly prone to security and privacy threats, so a context aware privacy mechanism is developed in the proposed framework. The security and privacy frameworks are elaborated, and a demonstration of the prototype is presented in this paper.
A Location Privacy Preserving Authentication Scheme in Vehicular Networks	As an emerging application scenario of wireless technologies, vehicular communications have been initiated not only for enhancing the transportation safety and driving experiences, but also for a new commercial market of on-board Internet services. Due to extraordinarily high mobility of vehicles in a vehicular network, frequent handover requests will be a norm, which initiates the demand for an effective and fast authentication scheme that can maintain the service continuity in presence of the frequent handover events. However, previously reported authentication schemes, although with minimized handover latency and packet loss rate, may disclose the location information of the mobile user to the third party, which will seriously violate the location privacy of the user. In this paper, we propose a location privacy preserving authentication scheme based on blind signature in the elliptic curve domain. The scheme cannot only provide fast authentication, but also guarantee the security and location anonymity to the public. To analyze the proposed scheme, a theoretical traceability analysis is conducted, which shows that the probability of tracing an vehicle's route is negligibly small. We will also examine the authentication speed of the scheme, and show that the scheme can satisfy seamless handover for fast moving vehicles.
Flexible Privacy Protection for RFID Tags via Selective Identifier Masking	In this paper, we propose a selective identifier masking scheme to prevent eavesdropping or unauthorized reading of the unique identifier of RFID tags. In our system, we differentiate between tags that require privacy protection (private tags) and tags that do not require protection (public tags). Under an environment whereby private and public tags co-exist, the proposed scheme uses an active RFID device to selectively transmit a secret mask when a tag identifier is reported to a reader. This induces bit collisions between the tag identifier and the mask. An eavesdropper or an unauthorized interrogator would not be able to resolve the collided bits without knowledge of the secret mask. Hence, the tag identifier is protected against disclosure. Simulations were conducted to investigate the overhead incurred under the scheme. In addition, theoretical analyses were carried out to examine the 'same-bit' problem and its effects on the scheme. In general, we find that our proposed scheme is simple, practical and secure under a realistic threat model as compared to other similar approaches.
TTP Based Privacy Preserving Inter-WISP Roaming Architecture for Wireless Metropolitan Area Networks	We propose a novel inter-WISP roaming architecture based on trusted third party (TTP) and partially blind signature technique in wireless metropolitan area networks (WMAN). The proposed architecture aims to not only greatly improve user privacy and identity anonymity even in the presence of cooperation between the wireless Internet service provider (WISPs) and the TTP, but also dramatically reduce the required size of central database devised to minimize any possible service abuse. In addition, an efficient billing scheme among mobile users (MUs), WISPs and TTP, is introduced to address billing issues associated with roaming. Moreover, a localized inter-WISP authentication scheme is also proposed to support seamless handoff. Detailed analysis on a number of important performance metrics, such as computation time, handoff latency and power consumption, is conducted to verify the performance of the proposed schemes.
Efficient 3GPP Authentication and Key Agreement with Robust User Privacy Protection	Zhang et al. (2005) proposed an authentication key agreement protocol for 3GPP-AKA protocol. They claim that their protocol can withstand the redirection attack, the attack in corrupted networks, and can solve the operational difficulty with the sequence numbers problem. In wireless communications, identity privacy is an important security issue we concern. There are two abnormal cases that a mobile station (MS) must send its real identity to a visited location register (VLR) when authenticating at location updating. One is that VLR can not verify EVISI of MS and the other is that VLR can not reach the previously visited VLR. We can find out that the identity of the user are exposed when the adversary carries out the location privacy attack at location updating. For preventing the location privacy attack, users' identities must be protected for 3GPP-AKA protocol. However, we point out that Zhang et al.'s improved 3GPP-AKA protocol is vulnerable to the location privacy attack, having higher space overhead on VLR, and having higher bandwidth consumption between HLR and VLR. In this paper, we propose an efficient authenticated key agreement scheme for 3GPP-AKA to overcome all the drawbacks of Zhang et al.'s scheme.
Enhancing wireless location privacy using silent period	The advance of ISM-band radio-based tracking systems (for example, wireless LAN-based tracking system) extends the application of location-based services (LBS), but it also threatens to allow the movement of users to be tracked when they are transmitting frames. Several protection methods based on periodic address updates have already been proposed. However, new correlation attacks, which utilize the correlation between the old and new addresses of the same node, can defeat current protection methods. To combat such attacks, we propose the concept of a silent period. A silent period is defined as a transition period between the use of new and old pseudonyms, when a node is not allowed to disclose either the old or the new address. Through analysis, we find that a silent period should contain a constant period and a variable period. The effect of the constant period is to mix the spatial relation between the node's disappearing points and emerging points. The variable period mixes the temporal relation between the node's disappearing times and emerging times. We evaluate the performance of the silent period through simulation. The results show that the silent period proposal significantly reduces the duration of time a node can be tracked continuously. There are still many open research problems before random address can be implemented to protect wireless location privacy, but silent period protocol is the first step to realizing it.
Application of trust-metrics for evaluating performance system in ad-hoc networks with privacy	Ad-hoc networks are usually constructed with a lot of nodes managed by unknown users and have a vague reliability level. In order to establish a reliable connection with the target node, users somehow need to evaluate the nodes and connection paths as correctly as possible. One of the solutions to this problem is to employ the trust-metrics to the node-and-path evaluation of the ad-hoc network. The trust-metrics are mainly used to evaluate the reliability (validity) of the public-keys of unknown users, e.g. in PGP. We, however, point out that there are some drawbacks when applying the ever known metrics to the node-and-path evaluation of the ad-hoc networks. We show that they are either low privacy - high utility or high privacy - low utility. To overcome these disadvantages, we propose the realization of high privacy high utility trust metrics and its application for evaluating the node's performances in ad-hoc networks (electronic power consumption, transmission speed, etc).
Providing end-to-end location privacy in IP-based mobile communication	As Internet protocol (IP)-based protocols move toward becoming the prevalent means for providing new forms of communication, for example, using IP for communication traditionally done via public Switched telephone network (PSTN), location privacy of mobile end users becomes an important problem to address. In an IP network, each packet carries IP addresses corresponding to the source (sender) and the destination (receiver) of the packet. Mobile hosts (laptop computers, PDAs, mobile phones etc.) usually acquire temporary IP addresses from the address spaces allocated to the access networks where they are currently connected to the Internet, and use these addresses for communication over the Internet. Due to a strong correlation between the address spaces used by the access networks and the geographic location of the access networks, location privacy of mobile users is compromised. If the recipient or an intermediate network node in the path of the packet analyzes the packet, the location of the sender of the packet is revealed. This may affect the widespread acceptance of IP based protocols. In this paper we present a novel protocol called LocPriv that preserves the location privacy in an IP based mobile communication network. The protocol works by employing an IP address encapsulation/swapping scheme at the access nodes to conceal the IP address of the mobile host, without affecting the route that the packets should follow in the network. We compare the protocol with existing techniques for providing location privacy and also analyze the effect of the protocol on the complexity of routing elements.
On wireless communications privacy and security evaluation of encryption techniques	Some arguments more are presented to illustrate a need for careful security evaluation of the encryption algorithms for possible use in the wireless networks. Particularly, the security evaluation of a previously proposed fast encryption for multimedia FEA-M is presented. It is shown that the effective secret key size is much smaller than its nominal one, which is a very undesirable and potentially dangerous characteristic.
Subscriptionless mobile networking: anonymity and privacy aspects within personal area networks	The foreseeable popularity of mobile devices using ad hoc wireless network technologies introduces a new class of user: The wandering communication participant, who instantly decides to establish a wireless network connection to a peer or information provider that happens to be in physical reach of his wireless network device. Typically, there has not been any registration process at the network or service level prior to a communication event. The instant and transient nature of this type of communication sessions as well as the user's justifiable desire for anonymity and privacy require a security association management that is different from the classic security associations that prevail in today's registration-based network and service architectures.
A secure and privacy-preserving communication protocol for V2G networks	The concept of vehicle-to-grid (V2G) is that electric vehicles (EVs) communicate with the smart grid to sell demand response services by delivering electricity into the grid. The operation of V2G networks is based on continuously monitoring the status of individual EVs as well as a designed incentive scheme to attract sufficient participating EVs. However, the close monitoring might raise privacy concerns from the EV owners about identity and location information leakage. To the best of the authors' knowledge, V2G communication protocol with privacy-preserving has been proposed rarely in the literature. Therefore, we propose a secure and privacy-preserving communication protocol for V2G networks, which utilizes the restrictive partially blind signature to protect the identities of the EV owners and is also based on certificateless public key cryptography to simplify the certificate management as in traditional public key infrastructure and to overcome the key escrow problem as in identity-based public key cryptography. The proposed protocol can achieve the property of completeness, identity and location privacy, confidentiality and integrity of the communications, and known-key security, and is secure against the replay attacks and existential adaptively chosen message attacks.
A dual-active spatial cloaking algorithm for location privacy preserving in mobile peer-to-peer networks	Very often, network users expect to access services relevant to their locations, whilst preserve their privacy without disclose their exact locations. The well-known privacy preserving method is the spatial cloaking technique where exact user locations are blurred into a cloaked region to meet the privacy requirement, e.g. k-anonymity. Most of current solutions are designed with a centralized architecture in mind and rely on a third trustworthy party, i.e. a location anonymizing server (LAS). Unfortunately, these solutions cannot be directly applied to the mobile peer-to-peer (P2P) networks where no centralized servers are possible. In this paper, we present a dual-active spatial cloaking algorithm for mobile P2P networks. The key difference between the suggested algorithm and two existing algorithms, on-demand and proactive, is that: our algorithm allows peers not only actively collect but also actively disseminate location information to others. The three approaches are assessed through extensive simulation experiments for a range of P2P network scenarios. The experimental result shows that the dual-active approach uses the least anonymizing time and has the best anonymization success rate at the price of acceptable communicating cost.
A lightweight privacy-preserving protocol using chameleon hashing for secure vehicular communications	Many services and applications in vehicular ad-hoc networks (VANETs) require preserving and secure data communications. To improve driving safety and comfort, the traffic-related status information will be broadcasted regularly and shared among drivers. Without the security and privacy guarantee, attackers could track their interested vehicles by collecting and analyzing their traffic messages. Hence, anonymous message authentication is an essential requirement of VANETs. On the other hand, when a vehicle is involved in a dispute event of warning message, the certificate authority should be able to recover the real identity of this vehicle. To deal with this issue, we propose a new privacy-preserving authentication protocol with authority traceability using elliptic curve based chameleon hashing. Compared with existing schemes, our approach possesses the following features: (1) mutual and anonymous authentication, (2) unlinkability, (3) authority tracking capability and (4) high efficiency. We also demonstrate the merits of our proposed scheme through extensive security analysis and performance evaluation.
Privacy-preserving interest-casting in opportunistic networks	Message forwarding is a fundamental brick to spread information among users in opportunistic networks. In this paper, we consider the recently proposed interest-casting networking primitive for opportunistic networks, according to which a packet generated by a sender should be delivered to all users in the network - potentially unknown to the sender - sharing similar interests. However, the current implementation of interest-casting assume users exchange their interest profiles to take forwarding decisions, thus revealing very sensitive information to strangers. In this work, we approach for the first time the problem of designing an interest-casting protocol while not revealing sensitive information during the forwarding and message delivery process. In particular, we present a privacy-preserving mechanism based on the well-known Millionaires' problem allowing users to discover whether they have similar interests without disclosing private information. Based on this mechanism, we propose four different privacy-preserving forwarding protocols to realise interest-casting in opportunistic networks, and we compare their performance on a real-world mobility trace.
Context-Aware Privacy Protection for Wireless Sensor Networks in Hybrid Hierarchical Architecture	Sensor networks (SNs) placed on human bodies and in the environment can intelligently and unobtrusively support professional teams (for example health care professionals) to improve their work and on the other hand their subjects (for example patients and elderly at hospital or at home). In pervasive healthcare settings, protecting the privacy of the medical care subjects and the medical staff is very important, because the lack of privacy may hinder the broad acceptance of pervasive health technology. Moreover, there is a need of empowering end-users with flexible personalized controls for their personal data collected, processed and communicated via SNs. The privacy protecting mechanisms must be non-obtrusive and context-aware to support the daily private and professional life of the persons. Since the devices/nodes used by patients and medical professionals will have diverse capabilities, many of them with very limited resources, an important question is the implication of the privacy protection mechanisms on the overall system performance. This paper proposes novel flexible privacy protection framework suitable for diverse set of ubiquitous applications; describes evaluation frames for it and investigates the cost of privacy protection. Evaluation of the influence of the context complexity and policy-based management is also presented.
Privacy-aware and energy-efficient geofencing through reverse cellular positioning	Location-based services (LBSs) are gaining a significant increase in popularity these days and are about to take the next step towards proactive LBSs. In comparison to conventional LBSs, their proactive variant makes use of continuous position tracking to detect changes in spatial relationships between a user and surrounding objects and proactively perform according actions, a concept that is also known as geofencing. But tracking so far also results in tremendous battery drain in mobile devices and may conceal serious privacy issues for their users which can be seen as the biggest inhibitors to making proactive LBSs available for the masses. This paper proposes a method to detect the relationship between a user and a target location without significant overhead in power consumption by exploiting signals broadcasted from cellular radio network infrastructure at that location. In opposite to conventional cellular location determination mechanisms like WiFi or Cell-Id positioning where a radio beacon will be resolved as soon as it is detected, our proposal has to resolve only one request initially. This not only saves energy, but also preserves the user's privacy since no consecutive requests have to be sent to a location lookup server, for translating radio beacons into locations. Instead, the radio beacons that can be detected at the target location will be queried once and afterwards only compared to the currently received cellular radio signals. In some outlying areas only rudimentary cellular coverage might be provided, which leads to inaccurate positioning. In that case, the method can still serve as a basis mechanism to further improve accuracy by shortly utilizing additional positioning methods like GPS. Relying on an almost global wireless data connectivity, smartphones can access data from the internet almost anywhere, which allows this approach to be broadly available as an energy-efficient and privacy-aware alternative to conventional cellular location d- termination.
Privacy-aware probabilistic sampling for data collection in wireless sensor networks	The rising popularity of web services and their applications to sensor networks enables real-time data collection and queries by users. Unlike traditional periodic data collection, the traffic patterns generated from real-time data collection may expose the interests of users or the locations of unusual events to the attackers. To provide privacy in data collection, we propose a novel probabilistic sampling mechanism that can hide user queries and unusual events in the network, while supporting both routine and on-demand data reporting. Our goal is to prevent attackers from locating the unusual events and identifying interests of users by eavesdropping and analyzing the network traffic. In our probabilistic sampling scheme, the data are carefully reported at random times in order to mask the unusual events and user queries. In the meantime, our scheme can provide users with high data accuracy at minimized communication overheads. Extensive simulations have been conducted to evaluate the security strength, data accuracy and communication overheads of the proposed scheme.
A probabilistic model for lifetime measurement in privacy-aware sensor networks	Considering the resource-constraint metrics in sensor networks, it is necessary to develop the energy-efficient techniques to save the limited power while applying the security and privacy protection mechanisms during the data transmission. In this paper, we propose to define the probabilistic lifetime model of a single sensor node to measure the energy-efficient solutions towards the privacy-aware sensor networks. In addition, we tailor our model with three typical stochastic distributions in terms of typical application scenarios in reality. Finally, the probabilistic network lifetime model is formally defined and the experimental simulations validate our theoretical results, which shows its availability in sensor networks.
Two-phase demand response based on privacy-preserving billing for smart grid	In the future smart grid, the large volatility of renewable energy resources (e.g., solar and wind power) and Plug-in Vehicles (PEVs) present severe challenges to a reliable network operation. These difficulties can be alleviated by utilizing extensive information exchange between the power suppliers and customers. Demand response (DR) refers to such mechanisms that coordinate supply/demand information to match the power supply or shape the power demand. In this paper we propose a two-phase DR algorithm that allows the utility to address the problem of supply deficit. Specifically, we define the load factor to characterize customers' heterogeneous demand curves and the rate-of-disutility to quantify their willingness for adjusting demand. Based on that, we design a privacy-preserving billing function that reflects different contributions of the customers. Our proposal finally seeks the optimal allocation of network resources through prioritizing load shedding of different customers. This work serves as a starting point to include communication and security constraints for designing practical demand-response schemes for the smart grid.
LPDA: A lightweight privacy-preserving data aggregation scheme for smart grid	Security and privacy are challenging issues in smart grid. Failure to address them will hinder the flourish of smart grid. In this paper, aiming at resolving the electricity consumption data security and residential user privacy, we proposed an efficient lightweight privacy-preserving aggregation scheme, called LPDA, for smart grid. The proposed LPDA is characterized by employing one-time masking technique to protect user's privacy while achieving lightweight data aggregation. Detailed security analysis has shown that the proposed LPDA scheme is robust against many security and privacy threats in smart grid. Furthermore, performance evaluation via extensive simulations demonstrates its efficiency in terms of low average aggregation delay.
Internet of Things and radio frequency identification in care taking, facts and privacy challenges	Internet of things technologies such as radio frequency identification are about to be able to help aging and sick people and even compensate for some disabilities. The use of these technologies in health care represents a promising development in information technology, but also raises important ethical, legal and social issues. This paper explores the use of these technologies in health care environments and formulates recommendations for further research that can ensure that the patients' privacy and dignity is preserved.
Internet of things and privacy preserving technologies	In this paper we consider different approaches to technological protection of users' privacy in the world of internet of things. Particularly, we consider what kind of problems and which level of protection can be achieved by applying approaches using secure multi-party computations.
Ensuring privacy in vehicular communication	The paper deals with the problem of the privacy/authentication trade-off in vehicular communications (VC). The paper introduces the widely accepted solution known as the ldquopseudonymous authenticationrdquo approach and discusses the limitations of some of the schemes proposed. The paper introduces a new proposal that helps to solve some of these limitations.
Security and privacy in the cloud a long-term view	In this paper we analyze security and privacy aspects of the cloud. We take a long-term view since the scope of privacy is potentially the lifetime of the privacy subject. We investigate trust issues and privacy aspects for cloud service users, using subjective logic as a primary tool. We also present promising solution for credible privacy in a cloud environment.
Privacy Protection Mechanisms for Hybrid Hierarchical Wireless Sensor Networks	In the emerging hybrid hierarchical network model for wireless sensor networks, confidential and private data for end users is processed in some distinctive scenarios. In this respect, preserving privacy and establishing trust is a challenging task. This paper presents solutions to privacy issues based on context aware privacy protection and trust establishment mechanisms in hybrid hierarchical architecture. Based on two scenarios where this framework can be applied to - a medical scenario and vehicle network scenario-relevant privacy mechanisms are derived. It is shown, that context aware privacy protection is crucial for networks applying the HHA and hence context aware anonymization and trust establishment algorithms are introduced. An evaluation of the algorithms and analysis of the influence of the complexity of the context attributes are presented.
Efficiently managing location information with privacy requirements in Wi-Fi networks: a middleware approach	The growing availability of wireless portable devices is leveraging the diffusion of location based services (LBSs) that provide service contents depending on the current position of clients, servers, and involved distributed resources. When a wide public of final users use LBSs, two primary issues are crucial: how to guarantee the proper level of user privacy given the need to disclose, to some extent, client location information; how to effectively manage the exchange of positioning information (and of its variations) notwithstanding the high heterogeneity of connectivity technologies and device hardware/software capabilities. The paper presents the privacy-related extension of our proxy-based mobile agent middleware to support personalized service provisioning to Wi-Fi portable devices, in particular, our middleware prototype adopts a two-level proxy-based architecture to provide LBSs with middleware-mediated effective access to location data, which are exposed at the proper level of granularity depending on privacy/efficiency requirements dynamically negotiated between clients and LBSs.
Location privacy and the personal distributed environment	The personal distributed environment is a new concept being developed within the mobile VCE core 3 research programme whereby users have access to their services and data through a distributed set of terminals, wherever their location: ubiquitous access. Devices are co-ordinated by device management entities (DMEs), which are either Local DMEs, controlling devices within a single PDE subnetwork at a user's home or office. For example, or an overall root DME providing universal co-ordination and a single point of contact. While such a structure allows very flexible service delivery, it has serious security concerns, as the presence of signalling between root and local DMEs will allow the location of the user to be determined at all times. In this paper, we analyse the security threats to the DME structure proposed for the PDE, and introduce a system of tunnelling and mix networks to provide security and privacy.
Data perturbation and feature selection in preserving privacy	Privacy Preserving plays a vital role; in designing various security-related data mining applications. Protecting sensitive information in data mining has become an important issue. Data distortion or data perturbation is a critical component, widely used to protect sensitive data. Many approaches try to preserve privacy by adding noise or by matrix decomposition methods. In this paper we propose data distortion methods such as singular value decomposition (SVD) and sparsified singular value decomposition (SSVD) technique along with feature selection to reduce feature space. Various privacy metrics have been proposed to measure the difference between original dataset and distorted dataset and degree of privacy protection. Our experimental results use a real world dataset. It shows a feasible solution using sparsified singular value decomposition along with a feature selection, which could better preserve privacy. Extracting accurate information from datasets will make reasonable decisions using data mining algorithms. The mining utility on perturbed data is tested with a well known classifiers such as SVM, ID3 and C4.5.
Shared and secured data partitioning for privacy preserving of collaborative file transfer in multi path computational mining	Many techniques have been presented earlier to share the data online with privacy terms. But the downside is that the privacy preservation of data is unreliable when large set of data has been shared. The previous work describes only the data sharing process in a secure manner using session based secured multiparty combination and there is none other reliable approach yet to be defined for file sharing concepts through online in a secure manner. To present a file sharing approach online in a reliable manner, the proposal in this work presented collaborative file sharing (CFS) mechanism using Anchor technique by preserving the privacy of data. An Anchor technique (AT) will be used here for file partitioning schemes based on the location of the file. In addition to this, file sharing mechanism in a secured way will be handled using multiparty computation with association rule mining which allows the files to be shared for more than one user and reduces the adversary attack and the session overhead problem. The parties whoever involved in file sharing approach in CFS with AT can share their valid data without disclosing their privacy of data with each other. To evaluate the privacy performance of the proposed CFS with AT, the experimental evaluation is done with several user clients in terms of communication key round, number of participants and the size of the file for exchange. The outcome of the experiment clearly shows that the proposed collaborative file sharing (CFS with AT) mechanism provides better improvement in file sharing concepts contrast to an existing SMC for collaborative data.
VANET privacy by ΓÇ£defending and attackingΓÇ¥	A major concern regarding Vehicular Ad Hoc Networks (VANETs) is the protection of the participants' privacy. Through the frequent transmission of beacons containing pseudonyms and telematic data like speed, acceleration and location of the vehicles, attackers are able to track VANET users. To address this problem, several privacy concepts have been proposed in the past to protect the participants. These concepts often work with a single centralized provider, require radio silence or are restricted to defense only. This can lead to weak protection or to major restrictions of VANET functionality. In this paper we propose the concept of ΓÇ£Defending and AttackingΓÇ¥ to overcome these issues.
A privacy preserving solution for the protection against sybil attacks in vehicular ad hoc networks	Services provided by vehicular Adhoc Networks (VANETs) would be impaired if faced to sybil attacks, by which malicious vehicles claim multiple identities at the same time. The prevention of these attacks, which could occur in or out of the Road Side Units (RSUs) coverage, is challenging, as it should meet a compromise between the ability to identify the real identity of the malicious vehicle, and prevention of vehicles from being tracked by malicious entities. We propose in this paper a solution to prevent and detect Sybil attacks in VANETs. The identification of attackers is based on two types of authentication techniques. The first uses RFID tags embedded in the vehicle to authenticate them to the RSU and obtain short lifetime certificates. The second uses certificates to authenticate vehicles to their neighbors. The vehicular network we are considering is divided into different zones brought under the control of different certification authorities, forcing a vehicle to change its certificate when moving from a zone to another. One important characteristic of the proposed solution is that it prevents attackers from tracking the mobility of the vehicles. Avoiding false negatives is also addressed using observers (e.g., software components in charge of monitoring) in vehicle nodes. A set of simulation scenarios are conducted to evaluate the performance of the solution.
A privacy aware media gateway for connecting private multimedia clouds to limited devices	Multimedia availability is exceeding our capacity of management in home environment and outside it. For that reason, solutions as Media Cloud have brought the concept of Cloud Computing to home environments. Media Cloud provides a comprehensive and efficient solution for managing content among federated home environments. However, when consuming those contents outside a home environment some problems should be addressed as dealing with limited devices and protecting user generated and commercial contents from eavesdroppers. This article describes a solution that enables limited devices to access contents located in private clouds, as Media Cloud, with the cooperation of network providers.
Non-repudiation of consumption of mobile Internet services with privacy support	Today's Internet technology is able to support different quality-of-service (QoS) classes to meet different application and user requirements. Combined with the support of user mobility, service providers offer differentiated services not only to their own customers, but also to roaming users. This offer is accompanied normally by more complex pricing schemes which require a complex accounting of the real service consumption. As commercial provisioning of Internet services needs to meet security requirements of providers as well as users, the service consumption must be provable to justify billing and to protect users and providers against other malicious parties. This paper develops the NorCIS architecture (non-repudiation of the consumption of Internet services) and its detailed protocol interactions which allow for the generation and transfer of non-repudiation evidences of service consumptions in a mobile Internet protocol (IP)-based environment. An evidence structure is proposed, supporting a variety of accounting schemes and including information which are used to protect against various attacks. In addition, NorCIS proposes the use of virtual identifiers within evidences to support the privacy of users' identities.
Path privacy protection in continuous location-based services over road networks	The spatial query has been one of the highly demanded services in mobile computing system recently. To protect users' location privacy, existing architecture provides a trustworthy anonymizer to blur users' location from the service provider. However, with mobile capability, users' location extends from one spot to a continuous traveling route. For such continuous spatial query, it raises much more challenges for an anonymizer to protect users' continuous privacy. This paper conducts research on ensuring users' location privacy under the network-constrained road network environments. We first argue that the concept of continuous location privacy should be transferred to users' path privacy, which are consecutive road segments that needs to be protected. A novel M-cut requirement is proposed to achieve the goal of user path privacy. Mobile users can customize their privacy level through M-cut requirement. Last, two methods of constructing the cloaked spatial region are provided in our research, namely Random Selection and Junction Sharing. These algorithms support path privacy and also take system computation and communication overhead into consideration.
Simulation-based evaluation of techniques for privacy protection in VANETs	In vehicular ad hoc networks (VANETs) tracking of participants is an issue that is examined by many research groups. These groups came up with several different concepts of counter measures against tracking attacks. All of these presented techniques seem to offer a pretty good protection. We pick out two very promising concepts - the Mix Zones and the Silent Periods - to examine them in a simulation environment to actually identify their strengths and weaknesses. Our simulation results show rather high success rates for attackers with relatively unsophisticated attack heuristics. Furthermore we confirm the correlation between several influencing factors and the success rates of attacks and study the connection to the common metrics k-anonymity and entropy.
An on-demand mobile advertising system that protects source privacy using interest aggregation	Organizations are starting to realize the significant value of advertising on mobile devices, and a number of systems have been developed to exploit this opportunity. From a privacy perspective, however, all ΓÇ£privacy-concernedΓÇ¥ systems developed so far are based on either a trusted third-party model or on some generalized architecture. We propose a system for delivering location and preference-aware advertisements to mobiles with a novel architecture to preserve privacy. The main adversary in our model is the server distributing the ads trying to identify users and track them, and to a lesser extent, other peer in the wireless network. When the need for tailored ads arises, the node will form a group of nearby nodes seeking ads and will cooperate to achieve privacy. Peers combine their interests using a ΓÇ£shufflingΓÇ¥ mechanism in an ad-hoc network and send them through a ΓÇ£primary peerΓÇ¥ to the ad server. The result is that preferences of multiple peers are accumulated and masqueraded to request custom ads which are then distributed by the primary peer. Another mechanism is also proposed to implement the billing process without disclosing user identities.
Secure compression of privacy-preserving witnesses in vehicular ad hoc networks	Vehicular ad hoc networks (VANETs) are designed to improve traffic safety and efficiency. To this end, the traffic communication must be authenticated to guarantee trustworthiness for guiding drivers and establishing liability in case of traffic accident investigation. Cryptographic authentication techniques have been extensively exploited to secure VANETs. Applying cryptographic authentication techniques such as digital signatures raises challenges to efficiently store signatures on messages growing with time. To alleviate the conflict between traffic liability investigation and limited storage capacity in vehicles, this paper proposes to aggregate signatures in VANETs. Our proposal can preserve privacy for honest vehicles and trace misbehaving ones, and provides a practical balance between security and privacy in VANETs. With our proposal, cryptographic witnesses of safety-related traffic messages can be significantly compressed so that they can be stored for a long period for liability investigation. Our proposal allows a large number of traffic messages to be verified as if they were a single one, which speeds up the response of vehicles to traffic reports.
Pre-broadcast based time efficient privacy protocol for secure vehicular communications	Privacy and security are two important issues in vehicular networks. Users wish to maintain location privacy and anonymity, meaning the identity, location/direction of move of their vehicles remains unknown to everybody with possible exception law enforcement authorities responsible by law to know and maintain such private information. In this paper, we propose a Pre-broadcast based Time Efficient Privacy (PTEP) scheme, which, instead of performing any asymmetric verification, uses Message Authentication Code (MAC) functionality and HASH operations to authenticate messages. Moreover, we use two-level key (upper-level hash chain and low-level hash chain) which assists avoiding message losses. Analysis shows that the proposed PTEP scheme superior performance in terms of packet loss rate and packet latency. In addition, it can be used to serve emergency and routine messages as well, while most of existing solutions can only work with routine messages.
A privacy-aware location service for VANETs using Chaum's mixes	Protecting the privacy of VANET users is an important issue. We present in this paper an architecture that aims at this goal by integrating Chaum's mix network into a distributed but infrastructure-based location service for position-based routing. In addition we enable the user to decide when he wants to reveal his position to anyone else. Thus neither entity of the VANET is in full knowledge about the location and the identity of any user at the same time. The proposed system can be integrated in most published VANET security frameworks and our evaluation shows that an implementation is feasible.
Mobile systems location privacy: ΓÇ£MobiPrivΓÇ¥ a robust k anonymous system	With the rapid advancement of positioning and tracking capabilities (mobile phones, on-board navigation systems) location based services are rapidly increasing. Privacy in location based systems is addressed in many papers. Our work is focused on the trusted third party privacy framework that utilizes the concept of k-anonymity with or without l-diversity. In previous anonymization models k may be defined as a personalization parameter of the mobile user or as uniform system parameter for all mobile users . Clearly, k other users may not be available at the time of request in these systems. These requests are discarded because the quality of service (QoS) they require cannot be satisfied. In this paper we introduce a novel suite of algorithms called MobiPriv that guarantees a 100% success rate of processing a mobile request using k-anonymity with diversity considerations. We evaluated our suite of algorithms experimentally against previously proposed anonymization algorithms using real world traffic volume data, real world road network and mobile users generated realistically by a mobile object generator.
CA Based RFID Authentication Protocol for Privacy and Anonymity	Okubo et al. proposed a hash-chain based authentication protocol which protects users' location privacy and anonymity with strong forward security. However, Li et al. claimed that the hash-chain calculation must be a burden on low-cost RFID tags and gives back-end servers heavy calculation loads since the numbers for hash computation are required in a hash chaining technique. Thus, the non-group cellular automata chaining technique is adopted composed only of logical bitwise operations, in order to maintain both security guarantees and a low-cost construction.
Privacy-enhancing Call Management in an IP-based Infrastructure	The cellular world and the Internet, the two standard communication mediums in use today, is converging through the IP Multimedia Subsystem. This creates the opportunity to develop innovative and powerful services that increase the productivity of communications. Maintaining user privacy is a primary factor that should be kept in mind when creating such services. In this paper the authors propose and elaborate on a call management solution which enhances user privacy while utilising an IP-based infrastructure.
S3P: A Secure and Privacy Protecting Protocol for VANET	In order to deploy vehicular communication system, security and privacy issues have to be resolved. In this paper, for achieving secure and privacy preserving communications, an easily implementable PKI-based protocol is proposed. Security requirements for vehicular communications are defined and a detailed definition of the scheme, which uses shared asymmetric keys and PKI techniques to provide anonymous and secure communications, is given. Furthermore, evaluation of the proposed protocol against the previously defined security requirements is made. Providing privacy and security, the proposed scheme does not introduce any complexity and computational overheads.
Privacy Preserving Data Aggregation in Wireless Sensor Networks	Privacy preservation is an important issue in today's context of extreme penetration of Internet and mobile technologies. It is more important in the case of Wireless Sensor Networks (WSNs) where collected data often requires in-network processing and collaborative computing. Researches in this area are mostly concentrated in applying data mining techniques to preserve the privacy content of the data. These techniques are mostly computationally expensive and not suitable for resource limited WSN nodes. In this paper, a scheme is developed to provide privacy preservation in a much simpler way with the help of a secure key management scheme and randomized data perturbation technique. We consider a scenario in which two or more parties owning confidential data need to share only for aggregation purpose to a third party, without revealing the content of the data. Through simulation results the efficacy of our scheme is shown by comparing the results with one of the established schemes.
A Holistic View On The Opportunities and Risks Faced by Saudi Arabia Government in Their Adoption Of The New Law Regulating Electronic Privacy and	The increasing use of personal information in Internet-based applications has created privacy concerns worldwide, especially in the Kingdom of Saudi Arabia where there is no uniform e-Privacy Act. The following research aims to present a holistic view on the opportunities and risks faced by Saudi organizations and citizens in their adoption of the e-Privacy Act. This paper is a response to the request of the Ministry of Communications and Information Technology (MCIT), Kingdom of Saudi Arabia, for public consultation in connection with the proposed law regulating electronic privacy and data protection, the e-Privacy Act.
Set-Expression Based Method for Effective Privacy Preservation	Anonymization is proposed to alleviate the problem of privacy disclosure in recent years. Previous approaches typically generalize the specific values in the original data table to achieve anonymization. However, these solutions suffer from information loss in different degrees. In this paper, we propose the concept of set-expression, which causes less data distortion and equipments the anonymized table with better aggregate query answerability. Furthermore we propose a greedy algorithm and conduct a set of extensive experiments to show the advantages of our approach. We also introduce a novel Information Loss Metric to measure the quality of our proposed method.
Challenges in Preserving Location Privacy in Peer-to-Peer Environments	In location-based services (LBS), users have to continuously report their locations to the database server to entertain the service. For example, a user asking about her nearest gas station has to report her exact location to the database server. With untrustworthy servers, LBS may pose a major privacy threat on its users. In other words, the existing model of LBS trades service for user privacy. To tackle this privacy threat, several centralized privacy-preserving frameworks are proposed for LBS, in which a third trusted party is used as a middleware to blur user exact locations into spatial regions, in order to achieve k-anonymity, i.e., a user is indistinguishable among other k - 1 users. However, the centralized third trusted party could be the system bottleneck or single point of failure. The state-of-the-art peer-to-peer (P2P) communication technology adds a new dimension to the privacy-preserving techniques in LBS. The users holding P2P communication devices possess the ability to collaborate with one another to blur their exact locations into spatial regions without any help from centralized third trusted parties. In this paper, we present the challenges and research issues that emerge from deploying the P2P privacy-preserving framework in LBS.
Simple data transformation method for privacy preserving data re-publication	As growing interest in data publishing and analysis, privacy preserving data publication has become more important today. When a table containing the sensitive information is published, privacy of each individual should be protected. On the other hand, a data holder also considers minimizing information loss for analysis as long as the privacy is preserved. A few years ago, k-anonymity and l-diversity models have been suggested in order to protect privacy. However, these solutions are limited to static data release. Recently, the m-invariance model has been proposed to apply publication of dynamic environments. However, m-invariance generalization technique causes high information loss. In this paper, we propose a simple and safe anonymization technique without generalization while assuring high data utility in dynamic environments.
Privacy Time-Related Analysis in Business Protocols	To automate the analysis of service descriptions, [?] proposed a simple and expressive business protocol model (the specification of possible message exchange sequences) based on state machines, supporting rich timing constraints. Furthermore, developers of client applications need to be aware not only of functional aspects but also of non-functional aspects including privacy. In fact, the major concerns of a client are the disclosure of its personnel data conveyed during the message exchange. The aim of the paper is to study the ability of business protocol to handle the privacy and its time-related properties.
Service-Oriented Architecture for Privacy-Preserving Data Mashup	Mashup is a Web technology that combines information from more than one source into a single Web application.This technique provides a new platform for different data providers to flexibly integrate their expertise and deliver highly customizable services to their customers. None the-less, combining data from different sources could potentially reveal person-specific sensitive information. In this paper, we study and resolve a real-life privacy problem in a data mashup application for the financial industry in Sweden. Therefore we propose a service-oriented architecture for privacy-preserving data mashup together with a multi-party protocol to securely integrate private data from different data providers, whereas the integrated data still retains the essential information for supporting general data exploration or a specific data mining task, such as classification analysis. Experiments on real-life data suggest that our proposed method is effective for simultaneously preserving both privacy and information usefulness.
Privacy-Aware Web Service Protocol Replaceability	Business protocols are becoming a necessary part of Web services description [4]. The work presented in [4] investigates mechanisms for analyzing the compatibility and the substitution (i.e., replaceability) of Web services based on their functional properties. In this paper, we focus on the replaceability analysis. Whether a service can replace another depends not only on their functional properties but also on non functional requirements (e.g., privacy policies). We propose a privacy-aware protocol replaceability approach to extend the work presented in [4] by privacy properties. We introduce a rule-based privacy model and we extend business protocols, leading to what we call private business protocols. Finally, a private replaceability analysis of private business protocols is discussed. We mainly investigate compatibility issues, that is whether one private business protocol can support the same set of conversations with respect to the privacy requirements.
Web Services Security and Privacy	Web services are becoming widely deployed to implement the automation of business processes such as supply chain management, inventory tracking, and healthcare management, just to name a few. A Web service is a new breed of web application that supports interoperable application-to-application interaction over a network based on a set of XML standards.
A Situation-aware Access Control based Privacy-Preserving Service Matchmaking Approach for Service-Oriented Architecture	Service matchmaking is an important process in the operation of Service-Oriented Architecture (SOA) based systems. In this process, information from both service providers and requestors are used. How to protect the privacy of participating parties during the matchmaking process imposes a challenge. In this paper, a privacy- preserving service matchmaking approach is presented to support semantic-based service matchmaking and avoid privacy leakages to untrusted parties. The approach uses situation-aware access control (SA-AC) mechanism to ensure the appropriate disclosure and use of private information by modeling, specifying and enforcing SA-AC policies. It provides an owner-centric mechanism for both service providers and requestors in SOA-based systems to protect their private information during service matchmaking.
Visual Analysis of Privacy Risks in Web Services	The growth of the Internet has been accompanied by the growth of web services (e.g. e-commerce, e- health) leading to the need to protect the privacy of web service users. However, before privacy can be protected, it is necessary to understand the risks to privacy that come with the service. Indeed, such understanding is key to protecting privacy throughout the service lifecycle. Unfortunately, there does not appear to be any existing method for privacy risk analysis specifically designed for web services. This paper presents a straightforward method for web services privacy risk analysis that uses visual techniques to improve effectiveness and illustrates the method with an example.
Measuring Privacy Protection in Web Services	The growth of the Internet has been accompanied by the growth of Web services (e.g. e-commerce, e-health) leading to the need to protect the personal privacy of Web service users. However, it is also important to be able to measure a Web service in terms of how well it protects personal privacy. Such a capability would benefit both users and developers. Users would benefit from being able to choose (assuming that such measures were made public) the service that has the greatest ability to protect user privacy (this would in turn encourage Web service providers to pay more attention to privacy). Developers would benefit by being able to incrementally measure and modify their services during development until certain target levels of privacy protection are reached. This paper presents an approach for measuring how well a Web service protects personal privacy and illustrates the approach with an example
A Framework for Building Privacy-Conscious Composite Web Services	The rapid growth of Web applications has prompted increasing interest in the area of composite Web services that involve several service providers. The potential for such composite Web services can be realized only if consumer privacy concerns are satisfactorily addressed. In this paper, we propose a framework that addresses consumer privacy concerns in the context of highly customizable composite Web services. Our approach involves service producers exchanging their terms-of-use with consumers in the form of "models". Our framework provides automated techniques for checking these models at the consumer site for compliance of consumer privacy policies. In the event of a policy violation, our framework supports automatic generation of "obligations" that the consumer generates for the composite service. These obligations are automatically enforced through a dynamic program analysis approach on the Web service composition code. We illustrate our approach with the implementation of two example services
Dynamic trust establishment with privacy protection for Web services	The lack of effective trust establishment mechanisms for Web services impedes the deployment of trust models for online services. One important issue is the lack of privacy protection in trust establishment. Current Web service technology encourages a client to reveal all its attributes in a standard credential to the service provider for trust establishment. We propose a mechanism whereby the client formulates a single trust primitive by associating a subset of required attributes in a standard credential to negotiate a trust relationship. Client privacy is preserved because only those required attributes are revealed. After negotiation, a trust group element with dynamic validation is used to represent this trust relationship.
Towards standardized Web services privacy technologies	A Web service is defined as an autonomous unit of application logic that provides either some business functionality or information to other applications through an Internet connection. Web services are based on a set of XML standards such as universal description, discovery and integration (UDDI), Web services description language (WSDL), and simple object access protocol (SOAP). Recently there are increasing demands and discussions about Web services privacy technologies in the industry and research community. In general, privacy policies describe an organization's data practices what information they collect from individuals (e.g., consumers) and what (e.g., purposes) they do with it. To enable privacy protection for Web service consumers across multiple domains and services, the World Wide Web Consortium (W3C) published a document called "Web services architecture (WSA) requirements" that defines some specific privacy requirements for Web services as a future research topic. At this moment, there is still no standardized Web services privacy technology. This paper briefly overviews the research issues of Web services privacy technologies.
Privacy policy compliance for Web services	The growth of the Internet has been accompanied by the growth of Web services (e.g. e-commerce, e-health). This proliferation of Web services and the increasing regulatory and legal requirements for personal privacy have fueled the need to protect the personal privacy of Web service users. We advocate a privacy policy negotiation approach to protecting personal privacy (Yee and Korba, 2003; ). We provided semiautomated approaches for deriving personal privacy policies (Yee and Korba, 2004). However, it is evident that approaches are also needed to ensure that providers of Web services comply with the privacy policies of service users. In this paper, we examine privacy legislation to derive requirements for privacy policy compliance systems. We then propose an architecture for a privacy policy compliance system that satisfies the requirements and discuss the strengths and weaknesses of our proposed architecture.
Providing privacy for Web services by anonymous group identification	In this paper we present a SOAP extension for protecting the privacy of users of a Web service. This extension allows a user to prove to a remote SOAP server to be member of a trusted group without revealing his/her identity. Our extension has been designed as to ensure interoperability among SOAP applications written in different programming languages. We developed also some implementations of our extension using different programming languages. Moreover, we conducted an extensive experimentation of our implementation to prove its feasibility in a real-world context. In sums, our work suggests that privacy can be added to Web services with very little impact on the application developer and without compromising the performance of Web services.
An Approach for Producing Privacy-Aware Reusable Business Process Fragments	Businesses are, nowadays, keen on organizing their business processes in the most flexible way, as to cope with the tough competition. Two major concerns are emerging, while dealing with the construction of new process functionalities: (1) shortening the development periods, and (2) managing the privacy risks. An effective solution for dealing with both concerns, consists of reusing fragments of existing business processes. These fragments need to be declared as safe, however, from a privacy perspective. In this paper, we propose a comprehensive approach for decomposing existing business processes into reusable fragments, that are privacy-aware; i.e., these fragments do not allow the disclosure of so-called sensitive associations.
Privacy-Preserving Business Process Outsourcing	Many cloud providers offer on demand applications as Business Process as a Service (BPaaS), allowing companies to outsource their processes. For cost saving, some process fragments can be reused on the cloud regardless of privacy risks. In this paper, we propose an anonymization-based approach to preserve client business activity while sharing process fragments between organizations on the cloud.
Servicization of Australian Privacy Act for Improving Business Compliance	Organizations of handling personal or sensitive information have the pressure of complying with relevant privacy laws or regulations. Since the laws or regulations are always written with complex legal terms, it is not easy for information system designers to understand precisely such laws and regulations and adopt them directly in their designs. In this paper, we propose the method of formalizing the Australian Privacy Act into executable processes and the method of modeling business in a privacy-aware way. Thus, by executing the processes over the privacy-aware business models, the information system designers can easily check the compliance of their designs with the privacy laws or regulations. In addition, the executable formalization of the Privacy Act makes it more efficient for law enforcement officers to process privacy violation cases. As an example, the clauses NPP 1.3 and NPP 2.1(s) of Australia Privacy Act are formalized and executed over a retailer's privacy-aware business model. The execution shows the same result as the investigation performed by the law enforcement officers.
A Framework for Building Privacy-Conscious DaaS Service Mashups	Data Mashup is a special class of mashup application that combines information on the fly from multiple data sources to respond to transient business needs. Data mashup is a difficult task that would require an important programming skill on the side of mashups' creators, and involves handling many challenging privacy and security concerns raised by data providers. This situation prevents non-expert users from mashing up data at large. In this paper, we present a declarative approach for mashing-up data. The approach allows data mashup creators to build data mashups without any programming involved. The approach builds the mashups automatically and takes into account the data's privacy concerns. We evaluate the efficiency of the approach via a thorough set of experiments. The results show that handling data privacy introduces only a negligible cost in the mashup building time.
A Privacy-Preserving Approach for Web Service Selection and Provisioning	The growing success of WS-related technologies has resulted in a large number of providers, which implement services of varying degree of sophistication and complexity. While on the one hand the availability of a wide array of services has created a competitive and flexible market that suits well the needs of different type of users, on the other hand, it requires them to select among possibly hundreds of similar services. As such, Web service selection plays a crucial role in Web service life-cycle. Here, several application-dependent requirements might constrain the selection of the best service. In this paper, we study the privacy implications caused by the exchange of large amount of potentially sensitive data required by optimized strategies for service-selection. In particular, we propose a comprehensive framework to uniformly protect users' and service providers' privacy needs, at the time of service selection. We define a solution that allows matching of the search criteria against the Web services attributes in a private fashion such that both criteria and service attributes are kept private during the matching. Further, we propose an approach to protect service provisioning rules from unwanted disclosure, both from the user and the service provider's perspective. Our experimental evaluation and complexity analysis demonstrate that our algorithms are efficient.
Privacy Preserving Personalized Access Control Service at Third Service Provider	With the convenient connection to network, more and more individual information including sensitive information, such as contact list in Mobile Phone or PDA, can be delegated to the professional third service provider to manage and maintain. The benefit of this paradigm is, on one hand to avoid the sensitive information leakage when individual devices failed or lost, on the other hand to make only the authorized users access and share the delegated information online anytime and anywhere. However, in this paradigm the critical problems to be resolved are to guarantee both the privacy of delegated individual information and the privacy of authorized users, and what is more important to afford the owners of communication devices to have high level of control and power to create their own particular access control policies. In this paper, we present an approach to implement the personalized access control at third service provider in a privacy preserving way. Our approach implements the critical problems above in this paradigm by using selective encryption, blind signature and the combination of role based access control and discretionary access control.
Towards Privacy-Preserving XML Transformation	In composite web services one can only either hide the identities of the participants or provide end-to-end confidentiality via encryption. For a designer of inter-organizational business processes this implies that she either needs to reveal her suppliers or force her customers to reveal their information. In this paper we present a solution to the encrypted data modification problem and reconciliate this apparent conflict. Using a generic sender-transformer-recipient example scenario, we illustrate the steps required for applying XML transformations to encrypted data, present the cryptographic building blocks, and give an outlook on advantages and weaknesses of the proposed encryption scheme. The transformer is then able to offer composite services without itself learning the content of the messages.
Aggregated Privacy-Preserving Identity Verification for Composite Web Services	An aggregated privacy-preserving identity verification scheme is proposed for composite Web services. It aggregates multiple component providers' interactions of identity verification to a single one involving the user. Besides, it protects users from privacy disclosure through the adoption of zero-knowledge of proof of knowledge. This approach can dramatically reduce the computation time, independently on the number of identity attributes and component providers.
Privacy Model and Annotation for DaaS	Data as a Service (DaaS) builds on service-oriented technologies to enable fast access to data resources on the Web. However, this paradigm raises several new concerns that traditional privacy models for Web services do not handle. First, the distinction between the roles of service providers and data providers is unclear, leaving the latter helpless for specifying and verifying the enforcement of their data privacy requirements. Second, traditional models for privacy policies focus only on the service interface without taking into account privacy policies related to data resources. Third, unstructured data resources, as well as user permissions and obligations related to data that are utilized in DaaS are not taken into account. In this paper, we study data privacy as one of these concerns, which relates to the management of private information. The main contribution of this paper consists in: 1) devising a model for making explicit privacy constraints of DaaS, and 2) on the basis of the proposed privacy model, developing techniques that allow handling the privacy concern when querying DaaS. We validate the applicability of our proposal with some experiments.
Privacy-Preserving Reasoning on the SemanticWeb	Many semantic web applications require selective sharing of ontologies between autonomous entities due to copyright, privacy or security concerns. In such cases, an agent might want to hide a part of its ontology while sharing the rest. However, prohibiting any use of the hidden part of the ontology in answering queries from other agents may be overly restrictive. We provide a framework for privacy- preserving reasoning in which an agent can safely answer queries against its knowledge base using inferences based on both the hidden and visible part of the knowledge base, without revealing the hidden knowledge. We show an application of this framework in the widely used special case of hierarchical ontologies.
Privacy Preserving Multiagent Probabilistic Reasoning about Ambiguous Contexts: A Case Study	Contexts in ubiquitous environments, either sensed or interpreted, are usually ambiguous. However, to provide context-aware services and applications, agents in the environments need to have an as clear as possible understanding of their contexts. Ambiguous contexts can be made clearer by agents using inference based on their domain knowledge, local and global evidence. Bayesian networks have been proposed to represent and reason about uncertain contexts under the single agent paradigm. In distributed multiagent systems, multiply sectioned Bayesian networks (MSBNs) provide a coherent framework for distributed multiagent probabilistic inference, where agents' privacy is respected. In this paper, we propose to apply MSBNs to uncertain contexts representation and reasoning in ubiquitous environments
QTIP: multi-agent NLP and privacy architecture for information retrieval in usable Web privacy software	We present a generic natural language processing (NLP) architecture, acronym QTIL, based on a system of cooperating multiple agents (Q/A, T, I, and L agents) which can be used in any information system incorporating Internet information retrieval. We then introduce a hybrid multi-agent system (MAS) architecture, acronym QTIP, for the privacy domain through integrating the PeCAN (personal context agent networking) and QTIL MAS architectures. There are two areas where NLP is used: in the user-MAS interaction and in the process of resource indexing and matching. These two areas map to the Q/A-agent and to the I-agents. We propose using a lightweight head-driven phrase structure grammar (HPSG) natural language method for the Q architectural layers and qualitatively justify its applicability. We provide an example of employing the HPSG formalism for information retrieval using natural language capability via privacy Web services in one instantiation of the QTIP architecture. Independent preliminary results for HPSG on the Q level show that our approaches for enhancing the usability of PET tools are promising.
Privacy-preserving top-N recommendation on horizontally partitioned data	Collaborative filtering techniques are widely used by many e-commerce sites for recommendation purposes. Such techniques help customers by suggesting products to purchase using other users' preferences. Today's top-N recommendation schemes are based on market basket data, which shows whether a customer bought an item or not. Data collected for recommendation purposes might be split between different parties. To provide better referrals and increase mutual advantages, such parties might want to share data. Due to privacy concerns, however, they do not want to disclose data. This paper presents a scheme for binary ratings-based top-N recommendation on horizontally partitioned data, in which two parties own disjoint sets of users' ratings for the same items while preserving data owners' privacy. If data owners want to produce referrals using the combined data while preserving their privacy, we propose a scheme to provide accurate top-N recommendations without exposing data owners' privacy. We conducted various experiments to evaluate our scheme and analyzed how different factors affect the performance using the experiment results.
Meeting Scheduling Guaranteeing n/2-Privacy and Resistant to Statistical Analysis (Applicable to any DisCSP)	Distributed problems raise privacy issues. The user would like to specify securely his constraints (desires, availability, money) on his computer once. The computer is expected to compute and communicate for searching an acceptable solution while maintaining the privacy of the user. Even without computers infested with spy viruses that capture the interaction with the user, most agent based approaches reveal parts of one agent's secret data to its partners in distributed computations [Using privacy loss to guide decisions in distributed CSP search]. Some cryptographic multi-party computation protocols [Completeness theorems for non-cryptographic fault-tolerant distributed computating] succeed to avoid leaking secrets at the computation of some functions with private inputs. They have been applied to find the set of all solutions for the meeting scheduling problem [On securely scheduling a meeting]. However, nobody yet succeeded to apply those techniques for finding a random solution to the meeting scheduling problem. Note that revealing all solutions, when you only need a single one, leaks a lot of data about when others are, or are not, available. Some answers were proposed in our previous approaches to distributed constraint problems [Solving a distributed CSP with cryptographic multi-party computations, without revealing constraints and without involving trusted servers]. They guarantee that no agent can infer with certitude a secret from the identity of the solution of the problem (other than the acceptance of the solution), but guarantee nothing about inference of probabilistic information about secrets. Our new technique answers this problem, too.
PRIMO - Towards Privacy Aware Image Sharing	A growing number of users in Web 2.0 based social network sites and photo sharing portals upload millions of images per day. In many cases, this leads to serious privacy threats. The images reveal not only the personal relationships and attitudes of the uploader, but of other persons displayed in the images as well. In this paper, we propose the PRIMO system architecture for privacy-aware image sharing. Our approach is based on semantic annotations, face recognition and user-defined privacy rules. PRIMO connects to many social network sites and photo sharing portals via the OpenSocial API and proprietary interfaces.
Discovering the Scope of Privacy Needs in Collaborative Search	Collaborative search engines (CSE) are an upcoming trend in WWW search. CSE let knowledge workers concert their efforts and support user collaboration. However, search terms and links clicked that are shared among users reveal their interests, habits, social relations and intentions. Thus, CSE might put the privacy of the users at risk. In this paper, we describe our first steps towards discovering the scope of privacy needs in CSE. We identify common components of CSE, and we describe typical use cases and user groups. Based on these information, we explore the range of privacy threats that might arise from query and link sharing. Furthermore, we outline a conceptual framework to explore the privacy needs of CSE users. Finally, we describe two findings from preliminary study results: first, our participants were less concerned about what providers might learn, but wanted to restrict information disclosed to people in their social network. Second, we have identified a new class of reciprocal privacy preferences, which allow or prohibit information disclose depending on the behavior of others.
Privacy Guarantees through Distributed Constraint Satisfaction	The reason for using distributed constraint satisfaction algorithms is often to allow agents to find a solution while revealing as little as possible about their variables and constraints. So far, most algorithms for DisCSP do not guarantee privacy of this information. This paper describes some simple techniques that can be used with DisCSP algorithms such as DPOP, and provide sensible privacy guarantees based on the distributed solving process without sacrificing its efficiency.
Obligations with Deadlines and Maintained Interdictions in Privacy Regulation Frameworks	We aim at providing artificial agents with logical tools to reason specifically on privacy-related regulations, in order to comply with them. In order to express these regulations, we propose a deontic and temporal logic based on predicates dealing with personal data management. Using an example, we show the need for specific operators to express obligations with deadlines and maintained interdictions. We define a set of eight specific requirements for such operators, we evaluate the existing proposals with respect to these requirements and we adapt our own ones, to better suit to our formalism.
Linking Privacy and User Preferences in the Identity Management for a Pervasive System	Two important concepts in developing ubiquitous or pervasive computing technologies that are acceptable to the end user are personalization and privacy. On the one hand it is essential to take account of user needs and preferences to personalize decision making within such a system, on the other hand it is equally important to protect user privacy. One approach to handling user privacy is through the use of virtual identities. This has the advantage that it can also benefit the handling of user preferences. In particular, virtual identities can be used as a substitute for roles. On the other hand user preferences can be used in identity management to assist in selecting a virtual identity to hide the real identity of the user, thereby improving user-friendliness of the system. This paper describes this symbiosis and how it is implemented in the Daidalos pervasive system.
Privacy with Web Serivces: Intelligence Gathering and Enforcement	This paper focuses on agent-based enterprise information technology infrastructure support for privacy in the Web services architecture (WSA) in order to enforce privacy policies on private information (PI) used by applications. We provision the Web services platform (WSP) with mechanisms to not only enforce privacy policies on PI used by a Web service, but also gather intelligence about PI that is exchanged in invoking and executing Web services. Gathered information written in logs is then analyzed by a privacy agent to update a privacy knowledge base (KB) that captures information on applications, Web services they invoke, context of invocation, and PI stored, managed, and used by the enterprise. This loop-observe execution of Web services, update the knowledge base with observations, and then update rules governing privacy enforcement, provides for adaptive learning about the use of PI in the organization and also enforcement of privacy policies in Web services executions.
Workshop on Web Security, Integrity, Privacy and Trust (WSIPT 2007)	
Graph-Based Abstraction for Privacy Preserving Manifold Visualization	With the next-generation Web aiming to further facilitate data/information sharing and aggregation, providing data privacy protection support in an open networked environments becomes increasingly important. Learning-from abstraction is a recently proposed distributed data mining approach which first abstracts data at local sources using the agglomerative hierarchical clustering (AGH) algorithm and then aggregates the abstractions (instead of the data) for global analysis. In this paper, we explain the limitation of the use of AGH for local manifold preserving data abstraction and propose the use of the graph-based clustering approach (e.g., the minimum cut) for local data abstraction. The effectiveness of the proposed abstraction approach was evaluated using benchmarking datasets with promising results. The global analysis results obtained based on the minimum cut abstraction was found to outperform those based on the AGH abstraction, especially when the underlying manifold was complex
A Bayesian Network Approach to Detecting Privacy Intrusion	Personal information privacy could be compromised during information collection, transmission, and handling. In information handling, privacy could be violated by both the inside and the outside intruders. Though, within an organization, private data are generally protected by the organization's privacy policies and the corresponding platforms for privacy practices, private data could still be misused intentionally or unintentionally by individuals who have legitimate access to them in the organization. In this paper, we propose a Bayesian network-based method for insider privacy intrusion detection in database systems
Adding User-Level SPACe: Security, Privacy, and Context to Intelligent Multimedia Information Architectures	We provide a unified architecture, called SPACe, for secure, privacy-aware, and contextual multimedia systems in organizations. Many key and important architectural components already exist which contribute to a unified platform, including the classic data mining, security, and privacy-preserving components in conventional intelligent systems. After presenting an overview of our unified architecture, we focus on the state-of-the-art architectural components for user interaction in future systems - particularly multimedia voice interaction with intelligent systems. This paper shows how user-level conversational data mining (CDM) methods, coupled with biometric security, and enhanced with privacy-awareness, may be used with any Web information system architecture. Finally, we provide an example of our unified architecture through integrating a knowledge architecture for an e-finance application in the financial services domain. The resulting architectures benefit from added security, privacy-awareness, and contextual filtering at the user-level
Intelligent Content-Based Privacy Assistant for Facebook	Although most online social networks now offer fine-grained controls of information sharing, these are rarely used, both because their use imposes additional burden on the user and because there are too many control settings for an average user to handle. To mitigate this problem, we have developed an Intelligent Privacy Assistant for Face book that partially automates the assignment of sharing permissions, taking into account the content of the information published and user's high-level sharing policies. The Assistant uses a novel social web privacy language, employs named entity recognition algorithms to annotate sensitive parts of published information and an answer set programming system to evaluate user's privacy policies and determine the list of safe recipients. On a test scenario, the Assistant reached 73.8% and 95.2% performance in correctly determining safe and unsafe recipients, respectively.
Pistis: A Privacy-Preserving Content Recommender System for Online Social Communities	With the explosive growth of online social communities and massive user-generated content, privacy-preserving recommender systems, which identify information of interest to individual users without disclosing personal interests to other parties, have become increasingly important. Collaborative filtering (CF), a widely used recommendation technique, recommends content that similar users have liked. As a result, CF-based recommender systems may expose sensitive personal interest information. This is demonstrated by a privacy attack model we present that targets online social communities. To solve this problem, we propose an interest group based privacy-preserving recommender system called Pistis. By identifying inherent item-user interest groups and separating users' private interests from their public interests, Pistis can make recommendations based on aggregated judgments of group members and local personalization, thus avoiding the disclosure of personal interest information. Pistis has been deployed and evaluated in an online social community with over 63,000 users, 20,000 daily posts, and 180,000 daily reads. Compared with two representative CF-based methods, our evaluation results demonstrate that Pistis achieves better performance in privacy preservation, recommendation quality, and efficiency.
Meerkat - A Dynamic Privacy Framework for Web Services	In this paper, we present Meerkat, a dynamic framework for preserving privacy in Web services. We define a Web service-aware privacy model that deals with the privacy of input data, output data, and operation usage. We introduce a matching protocol that caters for partial and total privacy compatibility. Finally, we propose a negotiation model to reconcile clients' requirements with providers' policies in case of incompatibility.
Content-Based Privacy Management on the Social Web	Protection of privacy is a major concern for users of social web applications, including social networks. Although most online social networks now offer fine-grained controls of information sharing, these are rarely used, both because their use imposes additional burden on the user and because they are too complex for an average user to handle. To mitigate the problem, we propose an intelligent privacy manager that automates the assignment of sharing permissions, taking into account the content of the published information and user's high-level sharing policies. At the core of our contribution is a novel privacy policy language which explicitly accounts for social web concepts and which balances the expressive power with representation complexity. The manager employs named entity recognition algorithms to annotate sensitive parts of published information and an answer set programming system to evaluate user's privacy policies and determine the list of safe recipients. We implemented a prototype of the manager on the Face book platform. On a small test scenario, the manager reached the F-measure value of 0.831 in correctly recommending safe recipients.
Reachability Analysis in Privacy-Preserving Perturbed Graphs	Many real world phenomena can be naturally modeled as graph structures whose nodes representing entities and whose edges representing interactions or relationships between entities. The analysis of the graph data have many practical implications. However, the release of the data often poses considerable privacy risk to the individuals involved. In this paper, we address the edge privacy problem in graphs. In particular, we explore random perturbation for privacy preservation in graph data, and propose an iterative derivation process to analyze node reachability within the graph. We specifically focus on deriving the probability that the shortest path linking two nodes in a directed graph is of a particular length. This allows us to determine the expected length of the shortest path between two nodes, and determine whether they are linked or not. The performance of the proposed method is demonstrated via extensive experiments on both real and synthetic datasets.
Towards Privacy Preserving Information Retrieval through Semantic Microaggregation	In this paper we introduce the problem of providing privacy preserving information for Web indexing, classification, and other information retrieval task. Web pages are represented by a frequency term vector that preserves k-anonymity for all the Web pages. This vector can then be used, for example, to build indexes of classifiers. Our proposal makes use of semantic micro aggregation.
Towards Fully Distributed and Privacy-Preserving Recommendations via Expert Collaborative Filtering and RESTful Linked Data	Expert Collaborative Filtering is an approach to recommender systems in which recommendations for users are derived from ratings coming from domain experts rather than peers. In this paper we present an implementation of this approach in the music domain. We show the applicability of the model in this setting, and show how it addresses many of the shortcomings in traditional Collaborative Filtering such as possible privacy concerns. We also describe a number of technologies and an architectural solution based on REST and the use of Linked Data that can be used to implement a completely distributed and privacy-preserving recommender system.
Improving Privacy-Preserving NBC-Based Recommendations by Preprocessing	Providing accurate predictions efficiently with privacy is imperative for both customers and e-commerce vendors. However, privacy, accuracy, and performance are conflicting goals. Although producing referrals with privacy is possible; however, online performance and accuracy degrade due to underlying privacy-preserving measures. We investigate how to improve both efficiency and accuracy of naive Bayesian classifier-based private recommendations by utilizing preprocessing. We preprocess masked data by selecting the best similar items to each item off-line. Moreover, we fill some of the unrated items' cells to improve density. We perform real data-based experiments to investigate how preprocessing affects online performance and accuracy. Our experiment results show that efficiency and preciseness improve due to preprocessing.
WPT'2009: Workshop on Web Privacy and Trust	Provides a listing of current committee members and society officers.
Preserving Privacy in Social Networks: A Structure-Aware Approach	Graph structured data can be ubiquitously found in the real world. For example, social networks can easily be represented as graphs where the graph connotes the complex sets of relationships between members of social systems. While their analysis could be beneficial in many aspects, publishing certain types of social networks raises significant privacy concerns. This brings the problem of graph anonymization into sharp focus. Unlike relational data, the true information in graph structured data is encoded within the structure and graph properties. Motivated by this, we propose a structure aware anonymization approach that maximally preserves the structure of the original network as well as its structural properties while anonymizing it. Instead of anonymizing each node one by one independently, our approach treats each partitioned substructural component of the network as one single unit to be anonymized. This maximizes utility while enabling anonymization. We apply our method to both synthetic and real datasets and demonstrate its effectiveness and practical usefulness.
Secure Keyword Auction: Preserving Privacy of Bidding Prices and CTRs	We develop a secure keyword auction mechanism in which winners and payments are calculated without making bidding prices and CTRs public. First, we show that even if we utilize cryptographic techniques, the auctioneer can learn most bidding prices in existing keyword auction mechanisms, such as the Generalized Second Price (GSP) and the Vickrey-Clarke-Groves (VCG) mechanism. Thus we propose a new auction mechanism by introducing a simple but sufficient payment rule to prevent the leakage of bidding prices. The existing GSP is not strategy-proof, and neither is our new mechanism. However, possible manipulations are limited. We also propose a secure keyword auction scheme that securely realizes our mechanism by utilizing cryptographic techniques.
Web-Based Sharing of Electrocardiograms: Privacy and Access Control	Health information exchange (HIE) across multiple organizations via the Internet is a current trend in medicine and healthcare. Protection of the sensitive data contained in health information from disclosure to unauthorized persons is challenging. In this paper, we present an access control architecture based on XACML and SAML to address privacy and security issues in our HIE application, Web-based sharing of electrocardiograms (ECGs). We also introduce a prototypical implementation of this access control architecture and a use case scenario for the experiment. It shows that the access control architecture can protect the ECGs shared among organizations from disclosure to both the individuals who have no job-related need to access them and the individuals who have been denied the privilege to access them by a patient's privacy consent.
Study of Recent Development about Privacy and Security of the Internet of Things	This paper depicts the current situation of the development of the Internet of Things(IoT). RFID system is vulnerable to various attacks, because there is no physical or visible contact in its communication process. The research on security and privacy domain also increasingly causes the attention of academia. And this paper is mainly underlined that security and privacy issues exist ubiquitously, these problems are not completely solved until now. In succession, different approaches recently been proposed to address security and privacy issues are discussed and analysised specifically in the world of the Internet of Things. Meanwhile, the challenges and future trends of the IoT are also mentioned.
A Method for Privacy Preserving Mining of Association Rules Based on Web Usage Mining	Data mining basing on Privacy preservation has become a research hot point now. Web usage mining is one kind of data mining applications, and how to prevent data leakiness in web usage mining is also an important issue. In this paper, we present an effective method for privacy preserving association rule mining in the web usage mining, Secondary Random Response Column Replacement (SRRCR) to improve the privacy preservation and mining accuracy. Then, a privacy preserving association rule mining algorithm based on SRRCR is presented, which can achieve significant improvements in terms of privacy and efficiency. Finally, we present experimental results that validate the algorithms by applying it on real datasets.
Hybrid Fragmentation to Preserve Data Privacy for SaaS	SaaS is a novel software model that data and applications of service are outsourced to service provider. Although SaaS model offers many benefits for small and medium enterprises, data privacy issue is the most challenge for the development of SaaS. In this paper we propose a new hybrid fragmentation approach which is different from traditional data encryption to protect data. We define three kinds of privacy constraints to support finger-grained privacy customization. We also give a heuristic hybrid fragmentation algorithm which considers query efficiency to produce a hybrid fragmentation. We make some experiments to analyze our approach in the paper.
Policy Generation for Privacy Protection Based on Granular Computing	Privacy is an increasingly cited concept in the large-scale deployment of web services in pervasive computing. The necessity of putting data-owners' personal information online and unwanted intentions to access data-owners' information augment the risk of privacy disclosure. To address this problem, we propose a policy-based privacy protection mechanism that protects personal information by policy from privacy violations. The policy is automatically generated based on granular computing, which attains policies about information disclosure degree from the historical access records, and data-owner's feedback improves the accuracy of our algorithm. Due to the obvious advantages to describing problem spaces at different granularities and hierarchies in granular computing, we present Infospace, a framework for storage and description of personal information in different predefined hierarchies. Besides, through case study we show the effectiveness of our new mechanism.
Protecting Location Privacy Using Cloaking Subgraphs on Road Network	Mobile users traveling over roads often issue KNN queries based on their current locations with their mobile terminals (e.g. where is the nearest gas station?). However, exact location information transmitted to an unsecure server will easily lead the mobile user to be tracked. Thus it is important to protect mobile users' location privacy while providing location-based services. People traveling over roads always follow a road network. We observe that two cloaking subgraph structures, which we name cloaking cycle and cloaking tree, can be used to protect mobile users' location privacy effectively in road network environment. Based on these two subgraph structures, we propose a novel location privacy preserving approach using cloaking cycle and forest, which can effectively protect mobile users' location privacy while efficiently providing exact location-based services.
Increasing user's privacy control through flexible Web bug detection	People usually provide personal information when visiting Web sites, even though they are not aware of this fact. In some cases, the collected data is misused, resulting on user privacy violation. The existing tools which aim at guaranteeing user privacy usually restrict access to personalized services. In this work, we propose the Web bug detector. Upon detecting and informing users about browsing tracking mechanisms which invisibly collect their personal information when visiting sites, it represents an alternative that provides a better control over privacy while allowing personalization. Through experimental results, we demonstrate the applicability of our strategy by applying the detector to a real workload. We found that about 5.37% of user's requests were being tracked by third-party sites.
My own private kiosk: privacy-preserving public displays	Ubiquitous, high-resolution, large public displays offer an attractive complement to wearable displays. Unfortunately, the inherently public nature of these public displays makes them unsuitable for displaying sensitive information. We present EyeGuide, a wearable system that allows the user to obtain information quickly from a public display without sacrificing privacy. To this end, EyeGuide employs a lightweight head-worn eye-tracker for hands-free object selection and an earphone for private communication. Our system supports public displays that are dynamic (e.g., a large plasma screen) and static (e.g., a large printed map). In our printed map scenario, EyeGuide whispers verbal directions via earphone to a user, based on where they are looking on the map. Using a technique we call "gaze steering," the system guides the user's eye position to specific locations. In our dynamic public display scenarios, EyeGuide presents documents (e.g., maps) that contain sensitive data in a way that preserves privacy.
Privacy, Wearable Computers, And Recording Technology	Technology is rarely neutral. Wearable computer technology is opening up capabilities to record more details of "reality" from life and work experiences than have ever been possible. Although this area is new, privacy issues have already surfaced and potential opportunities for new intrusions or protections are on the horizon.
The survey of location privacy protection	For the past few years, the Location-Based Service (LBS) is becoming more and more important for people's life. On the one hand, it is easy to told people that where is they are anytime, On the other hand, the privacy of location issues attract more and more attention. This paper analyzes the key problems of location privacy protection, and gives a survey of existing work including the model of privacy protection, the anonymous model and the system architecture; finally, some open issues are given.
Effective Privacy Preserved Clustering Based on Voronoi Diagram	Consider a scenario like this: a data holder, such as a hospital (data publisher) wants to share patients' data with researcher (data user). However, due to privacy issue, the hospital could not publish the exact original data while the published data need to retain as much as possible the correlation of the original data for utility consideration. The entire existing models for publishing private data could not perfectly resolve the tradeoff between privacy and utility of the private data. This paper presents a novel private information publishing model Semi-Delaunay Diagram (SDD) based on Voronoi diagram and gives a clustering algorithm VDC based on SDD. This model not only protects privacy but also achieves a perfect clustering correlation. Extensive experiments show the different clustering results with the different input area parameter, and confirm that our VDC algorithm discovers clusters with arbitrary shape as DBSCAN algorithm does.
Adaptive Privacy-Preserving Visualization Using Parallel Coordinates	Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.
Compressive sensing based video scrambling for privacy protection	Surveillance video privacy protection has drawn significant attention recently. In this paper, we describe a privacy protected video surveillance system which utilizes the emerging compressive sensing (CS) theory. Privacy regions are scrambled through block based CS sampling on quantized coefficients during compression. Security is ensured by key controlled chaotic sequence which is used to construct CS measurement matrix. To prevent drift error caused by scrambling, a coding restricted scheme is exploited. Experimental results show that the proposed system effectively protects privacy with the scene intelligible. Compared with the existing ones, this system has high security and dramatic coding efficiency improvement.
AMMP-EXTN: Managing User Privacy and Cooperation Demand in a Collaborative Molecule Modeling Virtual System	We present a novel design for managing competing user interests and privacy protection cooperation in a collaborative virtual environment for molecular modeling. Based on the user feedback, this design includes four levels of access control for collaborative sessions and provides dynamic action priority specification for manipulations on shared molecular models. Furthermore, we implement a messaging system that includes a text chatting tool and system broadcasting functions. Our design supports flexible user group formation and interaction. We have implemented our design on a set of Microsoft Windows PCs connected to a Linux molecule simulation server. A GUI interface developed in Python is also illustrated
GSIS: A Secure and Privacy-Preserving Protocol for Vehicular Communications	In this paper, we first identify some unique design requirements in the aspects of security and privacy preservation for communications between different communication devices in vehicular ad hoc networks. We then propose a secure and privacy-preserving protocol based on group signature and identity (ID)-based signature techniques. We demonstrate that the proposed protocol cannot only guarantee the requirements of security and privacy but can also provide the desired traceability of each vehicle in the case where the ID of the message sender has to be revealed by the authority for any dispute event. Extensive simulation is conducted to verify the efficiency, effectiveness, and applicability of the proposed protocol in various application scenarios under different road systems.
Noise reduction in single channel radio bearers employing privacy	Frequency inversion of the voice spectrum is a common method of providing simple privacy on single channel radio links. When combined with exponential modulation this method produces an increase in system noise of 8.00 dB. Alternative inversion methods are analyzed. The methods involve partitioning the voice spectrum into two halves, inverting one or both of these halves and, in some cases, incorporating a bandshift. The optimum method, entitled "dual inversion with down-shift," reduced the increase in system noise performance to 0.99 dB for a small increase in residual intelligibility. This was measured at 36 percent using a voice test incorporating digit identification. Frequency inversion had a residual intelligibility of 31 percent.
<formula formulatype="inline"> <img src="/images/tex/20331.gif" alt="{cal CPAS}"> </formula>: An Efficient Conditional Privacy-Preserving Authentication Scheme for Vehicular Sensor Networks	In this paper, we propose a conditional privacy-preserving authentication scheme, called <i>CPAS</i>, using pseudo-identity-based signatures for secure vehicle-to-infrastructure communications in vehicular ad hoc networks. The scheme achieves conditional privacy preservation, in which each message launched by a vehicle is mapped to a distinct pseudo-identity, and a trust authority can always retrieve the real identity of a vehicle from any pseudo-identity. In the scheme, a roadside unit (RSU) can simultaneously verify multiple received signatures, thus considerably reducing the total verification time; an RSU can simultaneously verify 2540 signed-messages/s. The time for simultaneously verifying 800 signatures in our scheme can be reduced by 18%, compared with the previous scheme.
<formula formulatype="inline"> <img src="/images/tex/19526.gif" alt="\hbox {EP}^{2}\hbox {DF}"> </formula>: An Efficient Privacy-Preserving Data-Forwarding Scheme for Service-Oriented Vehicular Ad Hoc Networks	Service-oriented vehicular ad hoc networks (VANETs) are expected to support the diverse infrastructure-based commercial services, including Internet access, real-time traffic concerns, video streaming, and content distribution. The success of service-oriented VANETs depends on the underlying communication system to enable the user devices to connect to a large number of communicating peers and even to the Internet. This poses many new research challenges, particularly on the aspects of security and user's privacy. In this paper, we propose a novel privacy-preserving data-forwarding scheme based on our proposed novel Lite-CA-based public key cryptography and on-path onion encryption technique. The proposed scheme is expected to not only thwart the traffic tracing attack at the minimized computational overhead but to provide an efficient way to relieve workload and deployment complexity of certificates as well. Performance comparisons and security analysis show that the proposed schemes are very efficient and suitable for service-oriented VANETs.
Morality-Driven Data Forwarding With Privacy Preservation in Mobile Social Networks	Effective data forwarding is critical for most mobile social network (MSN) applications such as content distribution and information searching. However, it could severely be interrupted or even disabled when the privacy preservation of users is applied, because users become unrecognizable to each other, and the social ties and interactions are no longer traceable to facilitate cooperative data forwarding. Therefore, how we can enable efficient user cooperation in MSNs without intruding on user privacy is a challenging issue. In this paper, we address this issue by introducing social morality, which is a fundamental social feature of human society, to MSNs and accordingly design a three-step protocol suite to achieve both privacy preservation and cooperative data forwarding. First, the developed protocol adopts a novel privacy-preserving route-based authentication scheme that notifies a user's anonymized mobility information to the public. Second, it measures the proximity of the user's mobility information to a specific packet's destination and evaluates the user's forwarding capacity for the packet. Third, using a game-theoretical approach, it determines the optimal data-forwarding strategy according to users' morality level and payoff. Using analysis and examples, we show that the developed protocol suite can effectively protect user personal information such as identity and visited locations. Last, we conduct extensive trace-based simulations and show that the proposed protocol suite is effective for efficiently exploring the user cooperation and attain near-optimal performance in data forwarding.
Trustworthy Privacy-Preserving Car-Generated Announcements in Vehicular Ad Hoc Networks	Vehicular ad hoc networks (VANETs) allow vehicle-to-vehicle communication and, in particular, vehicle-generated announcements. Provided that the trustworthiness of such announcements can be guaranteed, they can greatly increase the safety of driving. A new system for vehicle-generated announcements is presented that is secure against external and internal attackers attempting to send fake messages. Internal attacks are thwarted by using an endorsement mechanism based on threshold signatures. Our system outperforms previous proposals in message length and computational cost. Three different privacy-preserving variants of the system are also described to ensure that vehicles volunteering to generate and/or endorse trustworthy announcements do not have to sacrifice their privacy.
Editorial Special Section on Wireless Network Security and Privacy	The four selected papers in this special section focus on various security and privacy issues in wireless mesh networks and vehicular networks.
PPAB: A Privacy-Preserving Authentication and Billing Architecture for Metropolitan Area Sharing Networks	Wireless metropolitan area sharing networks (WMSNs) are wide-area wireless networks with nodes owned and managed by independent wireless Internet service providers (WISPs). To support seamless roaming in emerging WMSNs, in this paper, we propose a localized and distributed authentication and billing architecture that aims at enabling efficient and privacy-preserving mutual authentication between mobile users (MUs) and WISPs. User anonymity and identity privacy can be protected, even in the presence of collusion between WISPs and a roaming broker (RB), which is considered to be the strongest user privacy protection. An efficient billing architecture is introduced and performed in the same stage of roaming, where U-tokens are defined and can be purchased by MUs from an RB as authentication credentials for the MUs to access the wireless network. The WISPs, thus, can cash the collected U-tokens in the RB for payment. We show that the proposed authentication and billing architecture can support localized inter-WISP authentication through the divisible blind signature scheme and a local witness strategy. A detailed analysis on a number of performance metrics, such as computation time and power consumption, is given to validate the performance of the proposed architectures.
Pseudonym Changing at Social Spots: An Effective Strategy for Location Privacy in VANETs	As a prime target of the quality of privacy in vehicular ad hoc networks (VANETs), location privacy is imperative for VANETs to fully flourish. Although frequent pseudonym changing provides a promising solution for location privacy in VANETs, if the pseudonyms are changed in an improper time or location, such a solution may become invalid. To cope with the issue, in this paper, we present an effective pseudonym changing at social spots (PCS) strategy to achieve the provable location privacy. In particular, we first introduce the social spots where several vehicles may gather, e.g., a road intersection when the traffic light turns red or a free parking lot near a shopping mall. By taking the anonymity set size as the location privacy metric, we then develop two anonymity set analytic models to quantitatively investigate the location privacy that is achieved by the PCS strategy. In addition, we use game-theoretic techniques to prove the feasibility of the PCS strategy in practice. Extensive performance evaluations are conducted to demonstrate that better location privacy can be achieved when a vehicle changes its pseudonyms at some highly social spots and that the proposed PCS strategy can assist vehicles to intelligently change their pseudonyms at the right moment and place.
Balanced Trustworthiness, Safety, and Privacy in Vehicle-to-Vehicle Communications	Vehicular ad hoc networks (VANETs) are being designed to improve traffic safety and efficiency. To meet this goal, the messages disseminated in VANETs must be trustworthy. We propose a privacy-preserving system that guarantees message trustworthiness in vehicle-to-vehicle (V2V) communications. Vehicle privacy is provided as long as a vehicle does not attempt to endorse the same message more than once. In spite of a message having been validly endorsed, if it is later found to be false, the system offers the possibility of <i>a posteriori</i> tracing the message generator and its endorsers. Our proposal demonstrates a number of distinctive features. The system is equipped with both <i>a priori</i> and <i>a posteriori</i> countermeasures. The threshold used for <i>a priori</i> endorsement can adaptively change according to the message urgency and traffic context, rather than being preset in the system design stage as in existing schemes. The verification of authenticated V2V messages is accelerated by batch message-processing techniques. Simulation results illustrate that the system maintains its performance under various traffic conditions.
An Intelligent Secure and Privacy-Preserving Parking Scheme Through Vehicular Communications	There are always frustrations for drivers in finding parking spaces and being protected from auto theft. In this paper, to minimize the drivers' hassle and inconvenience, we propose a new intelligent secure privacy-preserving parking scheme through vehicular communications. The proposed scheme is characterized by employing parking lot RSUs to surveil and manage the whole parking lot and is enabled by communication between vehicles and the RSUs. Once vehicles that are equipped with wireless communication devices, which are also known as onboard units, enter the parking lot, the RSUs communicate with them and provide the drivers with real-time parking navigation service, secure intelligent antitheft protection, and friendly parking information dissemination. In addition, the drivers' privacy is not violated. Performance analysis through extensive simulations demonstrates the efficiency and practicality of the proposed scheme.
A Cross-Layer Approach to Privacy-Preserving Authentication in WAVE-Enabled VANETs	We present an anonymous authentication and verification scheme for the IEEE Wireless Access in Vehicular Communications (WAVE)-based vehicular ad hoc networks (VANETs). Our contribution includes vehicular message authentication and an efficient prioritized verification strategy for periodic road safety messages. A variation of elliptic curve digital signature algorithm (ECDSA) is used in combination with the identity-based (ID-based) signature, where current position information on a vehicle is utilized as the ID of the corresponding vehicle. This waives the need for a third-party public key certificate for message authentication in VANETs. A high-density road traffic condition poses a challenge for authentication of vehicular messages since the required verification time is often much longer than the average interarrival time. To mitigate the issue, messages of each traffic class are verified following the VANET's medium access control (MAC) layer priorities and the application relevance of individual safety messages. Performance analysis and simulation results have shown that our approach is secure, privacy preserving, scalable, and resource efficient.
MixZone in Motion: Achieving Dynamically Cooperative Location Privacy Protection in Delay-tolerant Networks	Delay-tolerant networks (DTNs) are typically sparse ad hoc networks where node density is low, and contacts between nodes in the network do not occur very frequently. The existing location privacy protection methods, which require mobile nodes to collectively change their pseudonyms in special regions, called mix zones, may not work well in DTNs due to its unique characteristics including low network density and limited contact duration. In this study, we propose a novel cooperative location privacy protection scheme, called AVATAR, for sparse DTNs. The main idea of AVATAR is to generate a certain number of virtual nodes in the proximity of a node and allow both of virtual nodes and real nodes to make a coordinated pseudonym change in an enlarged region, named Virtual Mix Zones. Each AVATAR participant benefits from an increased location privacy protection at the cost of generating a series of signed position messages, named footprint signatures. To stimulate each node to contribute more footprint signatures to the Virtual Mix Zones, AVATAR proposes a rewarding mechanism, which is modeled as a multi-unit discriminatory auction game. Extensive simulations and analysis have been provided to demonstrate the effectiveness and efficiency of the proposed scheme.
A Novel Anonymous Mutual Authentication Protocol With Provable Link-Layer Location Privacy	Location privacy of mobile users (MUs) in wireless communication networks is very important. Ensuring location privacy for an MU is an effort to prevent any other party from learning the MU's current and past locations. In this paper, we propose a novel anonymous mutual authentication protocol with provable link-layer location privacy preservation. We first formulate the security model on the link-layer, forward-secure location privacy, which is characterized by the fact that even when an attacker corrupts an MU's current location privacy, the attacker should be kept from knowing how long the MU has stayed at the current location. Then, based on the newly devised keys with location and time awareness, a novel anonymous mutual authentication protocol between the MUs and the access point (AP) is proposed. To the best of our knowledge, this is the first developed anonymous mutual authentication scheme that can achieve provable link-layer, forward-secure location privacy. To improve efficiency, a <i>preset</i> <i>in</i> <i>idle</i> technique is exercised in the proposed scheme, which is further compared with a number of previously reported counterparts through extensive performance analysis.
A novel privacy preserving authentication and access control scheme for pervasive computing environments	Privacy and security are two important but seemingly contradictory objectives in a pervasive computing environment (PCE). On one hand, service providers want to authenticate legitimate users and make sure they are accessing their authorized services in a legal way. On the other hand, users want to maintain the necessary privacy without being tracked down for wherever they are and whatever they are doing. In this paper, a novel privacy preserving authentication and access control scheme to secure the interactions between mobile users and services in PCEs is proposed. The proposed scheme seamlessly integrates two underlying cryptographic primitives, namely blind signature and hash chain, into a highly flexible and lightweight authentication and key establishment protocol. The scheme provides explicit mutual authentication between a user and a service while allowing the user to anonymously interact with the service. Differentiated service access control is also enabled in the proposed scheme by classifying mobile users into different service groups. The correctness of the proposed authentication and key establishment protocol is formally verified based on Burrows-Abadi-Needham logic
An Efficient Pseudonymous Authentication Scheme With Strong Privacy Preservation for Vehicular Communications	In this paper, we propose an efficient pseudonymous authentication scheme with strong privacy preservation (PASS), for vehicular communications. Unlike traditional pseudonymous authentication schemes, the size of the certificate revocation list (CRL) in PASS is linear with the number of revoked vehicles and unrelated to how many pseudonymous certificates are held by the revoked vehicles. PASS supports the roadside unit (RSU)-aided distributed certificate service that allows the vehicles to update certificates on road, but the service overhead is almost unrelated to the number of updated certificates. Furthermore, PASS provides strong privacy preservation to the vehicles so that the adversaries cannot trace any vehicle, even though all RSUs have been compromised. Extensive simulations demonstrate that PASS outperforms previously reported schemes in terms of the revocation cost and the certificate updating overhead.
Blend-In: A Privacy-Enhancing Certificate-Selection Method for Vehicular Communication	This paper presents and analyzes a method for enhancing the privacy of vehicles that use the public-key infrastructure (PKI) to secure communications. In particular, it examines the privacy limitations of a PKI system, where certificates are shared among multiple vehicles using a combinatorial certificate scheme. Such a system was implemented in the U.S. Vehicle Infrastructure Integration (VII) proof-of-concept trial to secure vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication and preserve vehicle privacy. The analysis shows that, in low vehicle densities, there is a high probability that a vehicle may have a locally unique certificate that is not shared by other vehicles. Vehicles using unique certificates may be vulnerable to being tracked or identified. This paper proposes a vehicle-based certificate-selection method for enhancing the privacy of vehicle communications. In our method, a vehicle monitors the certificates in use by neighboring vehicles and identifies those certificates that it also possesses. The vehicle then selects a certificate already in use to secure its own communication. This allows a vehicle to ldquoblend inrdquo to its environment but without substantially increasing an attacker's ability to evade exposure. We provide an analysis of the anonymity and unlinkability properties of the method and demonstrate that it rapidly reduces the number of vehicles using unique certificates to increase privacy.
Anonymous User Communication for Privacy Protection in Wireless Metropolitan Mesh Networks	As a combination of ad hoc networks and wireless local area network (WLAN), the wireless mesh network (WMN) provides a low-cost convenient solution to the last-mile network-connectivity problem. As such, existing route protocols designed to provide security and privacy protection for ad hoc networks are no longer applicable in WMNs. On the other hand, little research has focused on privacy-preserving routing for WMNs. In this paper, we propose two solutions for security and privacy protection in WMNs. The first scheme relies on group signatures, together with user credentials, to deliver security and privacy protection. By enforcing access control using user credentials, the user's identity has to be disclosed to mesh routers. To avoid this, our second scheme employs pairwise secrets between any two users to achieve stronger privacy protection. In the second scheme, the user is kept anonymous to mesh routers. Finally, we analyze these two schemes in terms of security, privacy, and performance.
A Secure and Privacy Aware Data Dissemination For The Notification of Traffic Incidents	Recently, Vehicular Ad-hoc Networks (VANETs) employing a combination of Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) wireless communication have been proposed to alert drivers about different traffic events. NOTICE, a secure and privacy-aware architecture for the Notification Of Traffic InCidEnts that provides drivers with up-to-the-minute notification about highway conditions, is introduced in. NOTICE moves the responsibility for making decisions about traffic-related incidents to the infrastructure rather than leaving those decisions with the vehicles, which may have incomplete or incorrect knowledge. This paper introduces a secure data dissemination technique that could be used in NOTICE or can be easily adapted to enhance other existing data routing or dissemination techniques.
Secure and Privacy-Enhancing Vehicular Communication: Demonstration of Implementation and Operation	With a number of projects developing vehicular communication systems, there is rising awareness on threats and the need to introduce security and privacy-enhancing mechanisms. With recent results, in principle in agreement across different major projects, there has been little work on implementation and demonstration of security and privacy-enhancing mechanisms. The contribution of this work is exactly in this direction: we present a demonstration of our system, comprising a range of mechanisms, developed to secure vehicular communications (VC) and enhance the location privacy of the users of VC systems.
Privacy in VANETs using Changing Pseudonyms - Ideal and Real	Vehicular ad hoc networks (VANETs) and vehicular communications are considered a milestone in improving the safety, efficiency and convenience in transportation. Vehicular ad hoc networks and many vehicular applications rely on periodic broadcast of the vehicles' location. For example, the location of vehicles can be used for detecting and avoiding collisions or geographical routing of data to disseminate warning messages. At the same time, this information can be used to track the users' whereabouts. Protecting the location privacy of the users of VANETs is important, because lack of privacy may hinder the broad acceptance of this technology. Frequently changing pseudonyms are commonly accepted as a solution to protect the privacy in VANETs. In this paper, we discuss their effectiveness and different methods to change pseudonyms. We introduce the context mix model that can be used to describe pseudonym change algorithms. Further, we asses in which situations, i.e. mix contexts, a pseudonym change is most effective and improves the privacy in vehicular environments.
A novel scrambling algorithm for a robust WEP implementation [wired equivalent privacy protocol]	Internet enabled wireless devices continue to proliferate and are expected to surpass traditional Internet in the near future. However, data security and privacy remain major concerns in the current generation of wireless connectivity. The wired equivalent privacy (WEP) protocol used within the 802.11 standard has "major security flaws" thus WLANs using the protocol are vulnerable to attacks. We propose a scrambling algorithm that reduces the vulnerability of the WEP. Both the software and hardware implementations of the algorithm reveal at least 10,000 times improvement in security.
Minimizing the average cost of paging on the air interface-an approach considering privacy	Location management of mobile users in a cellular network is considered from a performance and privacy point of view. Location management covers tracking functionality and paging (searching) functionality. After a risk analysis of location management w.r.t. privacy, we focus on the paging strategy. A sequential search strategy is proposed which reduces the signaling on the air interface and also considers the user's privacy
Design and performance of a digital voice privacy system for land mobile radio	This paper presents the design and performance of a 9600 bits/sec digital voice privacy system. The system has been applied in commercially available mobile radio products. Various aspects of the design such as speech bandwidth compression, encryption and radio engineering will be discussed. The resulting performance from a radio frequency standpoint is presented. Performance characteristics will show that certain limitations of previously available commercial mobile radio voice privacy products are overcome in this design.
Land mobile voice privacy communications	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01622860.png" border="0">
PPC: Privacy-Preserving Chatting in Vehicular Peer-to-Peer Networks	In this paper, a privacy-preserving chatting scheme is proposed to secure vehicular communication and achieve user privacy preservation in vehicular peer- to-peer networks. In specific, we first introduce identity-based-encryption technique which can protect the confidentiality of chatting content. Furthermore, to preserve user privacy, our scheme employs ring signature technique, which not only provides message authentication but also guarantees unconditional source anonymity. With the proposed scheme, vehicles change their pseudo identities periodically and make attackers unable to link users' transactions in different periods. As a result, the proposed scheme can achieve data confidentiality, efficient authentication, and privacy violation elimination. In addition, through detailed security and efficiency analyses, it is demonstrated the proposed scheme resists most of existing attacks in vehicular peer-to-peer networks and provides efficient sending and receiving operations.
An Efficient Authentication Scheme for Security and Privacy Preservation in V2I Communications	In this paper, we propose a mutual authentication and key agreement scheme for V2I communications. Our scheme improves security and privacy protection compared with the existing protocols. We consider common driver's tendency to design a more efficient scheme. The results of the security and performance analysis show that our scheme is suitable for practical use in terms of security, privacy, and performance.
A Simple Privacy Preserving Route Tracing Mechanism for VANET	Route tracing allows authorities to determine the route traversed by a vehicle, which can be used valuably in crime investigations. In VANETs (Vehicular Ad hoc NETwork), a conditional anonymity scheme is normally used to meet the conflicting demands of the government (authentication) and users (privacy). These schemes provide a mechanism to revoke the anonymity of individual beacons sent by vehicles. However, using this mechanism to trace a route of a vehicle violates privacy of many other vehicles. In this paper, we provide a simple route tracing mechanism that reveals only the route of the targeted vehicle. The proposed method can be easily added to any existing VANET solutions and also includes a way to prevent authorities from abusing this new function.
Enhancing Security and Privacy in C2X Communication by Radiation Pattern Control	In this paper we propose a new approach to enhance security and privacy in C2X communication directly on the physical layer. Instead of using a single omni-directional antenna, our approach relies on an uniform linear antenna array, which enables beam forming. By this means, our approach allows adjusting the radiation and the reception patterns of the vehicle, which is essential for excluding undesired communication parties trying to eavesdrop exchanged messages or to distribute corrupted information. To specify the antenna array configuration appropriate to some important use cases, a simulation-based approach is deployed. A dedicated simulator is exploited, which produces field patterns and visualizes them according to a mobility model and on user settings. Based on the visual simulation results the antenna array has been specified and evaluated.
Safe Distance Based Location Privacy in Vehicular Networks	To enhance driving safety in vehicle ad-hoc networks (VANETs), vehicles periodically broadcast safety messages with information of their precise positions to others. These broadcast messages, however, make it easy to track vehicles and will likely lead to violations of personal privacy. Unfortunately, most of the current location privacy enhancement methodologies in VANETs suffer some shortcomings and do not take driving safety into consideration. In this paper, we propose a safe distance based location privacy scheme called SafeAnon, which can significantly enhance location privacy as well as traffic safety.
Strong and affordable location privacy in VANETs: Identity diffusion using time-slots and swapping	Public acceptance, and thus the economical success of Vehicular Ad Hoc Networks (VANETs), is highly dependent on the quality of deployed privacy mechanisms. Neither users nor operators should be able to track a given individual. One approach to facilitate this is the usage of pseudonym pools, which allow vehicles to autonomously switch between different identities. We extend this scheme with that of a time-slotted pseudonym pool of static size, reducing the storage and computation needs of the envisioned Intelligent Transportation System (ITS) while further improving users' privacy. In addition, we allow the exchange of pseudonyms between nodes, eliminating the mapping between vehicles and pseudonyms even for operators of the VANET. Here, we support the exchange of both the currently used pseudonym and those of future time-slots, further enhancing users' privacy. We evaluate the feasibility of our approach and back up privacy claims by performing a simulative study of the system using the entropy of nodes' anonymity sets as the primary metric.
SLOW: A Practical pseudonym changing scheme for location privacy in VANETs	Untraceability of vehicles is an important requirement in future vehicle communications systems. Unfortunately, heartbeat messages used by many safety applications provide a constant stream of location data, and without any protection measures, they make tracking of vehicles easy even for a passive eavesdropper. One commonly known solution is to transmit heartbeats under pseudonyms that are changed regularly in order to obfuscate the trajectory of vehicles. However, this approach is effective only if some silent period is kept during the pseudonym change and several vehicles change their pseudonyms nearly at the same time and at the same location. Unlike previous works that proposed explicit synchronization between a group of vehicles and/or required pseudonym change in a designated physical area (i.e., a static mix zone), we propose a much simpler approach that does not need any explicit cooperation between vehicles and any infrastructure support. Our basic idea is that vehicles should not transmit heartbeat messages when their speed drops below a given threshold, say 30 km/h, and they should change pseudonym during each such silent period. This ensures that vehicles stopping at traffic lights or moving slowly in a traffic jam will all refrain from transmitting heartbeats and change their pseudonyms nearly at the same time and location. Thus, our scheme ensures both silent periods and synchronized pseudonym change in time and space, but it does so in an implicit way. We also argue that the risk of a fatal accident at a slow speed is low, and therefore, our scheme does not seriously impact safety-of-life. In addition, refraining from sending heartbeat messages when moving at low speed also relieves vehicles of the burden of verifying a potentially large amount of digital signatures, and thus, makes it possible to implement vehicle communications with less expensive equipments.
Security and privacy for in-vehicle networks	Mobile devices such as smartphones have gained more and more attention from security researchers and malware authors, the latter frequently attacking those platforms and stealing personal information. Vehicle on-board networks, in particular infotainment systems, are increasingly connected with such mobile devices and the internet and will soon make it possible to load and install third party applications. This makes them susceptible to new attacks similar to those which plague mobile phones and personal computers. The breach of privacy is equally sensitive in the vehicular domain. Even worse, broken security is a serious threat to car safety. In this paper, we show how traditional automotive communication systems can be instrumented with taint tracking tools in a security framework that allows to dynamically monitor data flows within and between control units to achieve elevated security and privacy.
Privacy Enhanced Pixel-Level Image Processing in the Clouds	Image processing and storage are enormously resource intensive tasks that can benefit from cloud computing. Lack of robust mechanisms for controlling the privacy of the data outsourced to clouds is one of the concerns in using clouds for image processing. This paper presents a new image encoding scheme that enhances the privacy of the images outsourced to the clouds while allowing the clouds to perform certain forms of computations on the images. Our prototype shows the feasibility of performing a class of image processing tasks on images encoded for privacy.
Towards engineering HCI - Privacy requirement in Malaysia: A preliminary study on Small-Medium e-commerce privacy adoptions	The emerging area of Human Computer Interaction - Privacy (HCI-P) is evolving to include research on engineering HCI requirement and localizing privacy protection to include socio-cultural requirement, legal protection by countries and user privacy preferences. `Personal Data Protection Act 2009', passed in April 2010 by Malaysia's Parliament demonstrated the infancy level of privacy protection in Malaysia. In addition, there is little study in Malaysia to investigate; (i) the privacy protection awareness among public and (ii) the practice of privacy adoption among companies. This study aims towards bridging this understanding by investigating the adoption of privacy policy among Malaysia e-commerce website. A sample of 210 Small Medium Enterprises (SME) websites was selected by using convenient sampling from various categories of Malaysia e-commerce portal available at http://www.shoppe.com.my. The evaluation process was done by using personal observation using an adopted indicators of privacy policies from Jamal, Maeir and Sunder (2002) by observing the `privacy policy statements', `privacy policy notice' and `privacy policy' provided by the companies. The study revealed several issues pertaining privacy policy adoption among Malaysia e-commerce websites. We end our study with few recommendations for further improvement of the privacy policy adoption and future feasible work within this line of study.
Voice and data privacy using chaotic time sequences	A voice and data privacy system which is both very secure, and a powerful error correction algorithm, is described. A convolved, random, chaotic sequence of impulses is used to transmit data along the channel. The resultant signal in the channel closely resembles gaussian random noise, yet it is confined to the same bandwidth as that of the original data. A second, complementary sequence of pseudorandom, chaotic impulses is then derived which deconvolves the data and returns it to a normal signal for demodulation. Privacy is assured by the unique nature of the random code, and trillions of codes are possible in a given channel. Errors are corrected by the bridging effect of the long sequence, and correction of as many as 100 errors in series has been demonstrated by using very long time sequences
A study on security and privacy in RFID	Small RFID tag is a wireless device for identifying individuals and item. RFID tags are frequently used to track goods, personal properties and sometimes humans. The following research presents the latest technical studies on security and privacy in RFID. To achieve this, privacy and authentication are defined firstly, and then, various strategies are presented for each part to provide security.
Protecting location privacy through Identity Diffusion	With the proliferation of new online services and wireless personal devices, location-based services and applications for mobile users are widespread in use today. But the privacy of these users exposes to others increasingly in accessing those location based services. Exposure of the location information may result in privacy threat by malicious servers and hackers. In this paper, we propose a new framework that mobile users can enjoy conveniently the services provided by location-based server (LBS), and also protect their location information. This framework prevents mobile users' location information from exposing in two ways: providing the server with fake identities; two different ways of diffusing a number of fake queries with the real query hidden when and where it was issued.
A Patient Privacy-Aware E-health System Based on Passive RFID	In recent years, many researches have introduced RFID-based solutions to enhance patient medication safety and avoid human errors during e-Health process. Although such RFID-based procedures are more efficient than traditional eHealth process, patient's information may be explored in the data transmission period and this will cause inappropriate medication use or medical errors. In this paper, we propose a RFID-based eHealth system which strengthens patient's privacy as well as enhances the efficiency of out-patient clinic procedure in Taiwan's hospital environment.
Privacy, Security and Trust in Cloud Computing: The Perspective of the Telecommunication Industry	The telecommunication industry has been successful in turning the Internet into a mobile service and stimulating the creation of a new set of networked, remote services. In this paper we argue that embracing cloud computing solutions is fundamental for the telecommunication industry to remain competitive. However, there are legal, regulatory, business, market related and technical challenges that must be considered. In this paper we list such challenges and define a set of privacy, security and trust requirements that must be taken into account before cloud computing solutions can be fully integrated and deployed by telecommunication providers.
Efficiently Preserving Data Privacy Range Queries in Two-Tiered Wireless Sensor Networks	Wireless Sensor Networks (WSNs) gain popularity these days. WSNs have been one of key technologies for the future with broad applications from the military to everyday life. There are two kinds of WSNs model models with sensors for sensing data and a server for receiving and processing queries from users, and models with special additional nodes, their common names are storage nodes, between the sensors and the sink. Among the latter type, a two-tiered model has been widely adopted because of its storage and energy saving benefits for weak sensors, as proved by the advent of commercial storage node products such as Stargate and RISE. In this paper, we consider two-tiered WSNs model that consists of sensor nodes receiving data from the environment and transferred to storage nodes, the queries from the server will be done through these storage nodes. In this model, the problem is how to ensure privacy of data at the storage nodes, which is mostly located in the hostile area. Data encryption is the popular solution to make the unreadable for storage node. However, if the server needs data in the range, then storage node must read the data to reply server's query. In order to solve this problem, we proposed to use a d-disjunct matrix, an order-preserving function and a permutation function that encode data of each sensor. An order-preserving function is used to query. Simultaneously, the permutation function and d-disjunct matrix will be used to encrypt data and determine the exact frequency of any value. With this approach, we have proved that our solution guarantees to preserve data-privacy while allowing the range query efficiently. In particular, it just takes less than 60 seconds when we encrypt or query less than 200000 values.
Accuracy of Privacy-Preserving Collaborative Filtering Based on Quasi-homomorphic Similarity	We study the problem of predicting a rating for an unseen item based on a distributed dataset owned by two honest-but-curious parties without revealing their private datasets to each other. Our proposed idea uses a new similarity measure such that the similarity aggregated from two local similarities is approximately equal to the global similarity. We evaluate the accuracy of prediction of rating and clarify the lower bound of estimation error and the expected value of error to be small enough to approximate the global prediction. We also show a new privacy preserving collaborative protocol with light weight overhead.
A Method of Privacy Preserving in Mobile Wireless Environments	The current mobile wireless standard 802.16e can provide data confidentiality, integrity and mutual authentication in wireless metropolitan area networks (WMANs). However, secure communication can only be provided after successful authentication and a robust security network association is established. In this paper, we propose our solution to patch the current 802.16e standard and address all vulnerable issues with a new simple authentication key-establishment protocol and an efficient way for privacy-preserving. In simple authentication, we smoothly apply the public-key cryptography-based key-establishment technique to the 802.16 MAC protocol. Our solution can provide link-layer data encryption in initial network entry procedure, separate session encryption keys to preserving privacy of different users, and protection for important frames such as management and Extensible Authentication Protocol (EAP) messages.
A New Privacy Scheme for Providing Anonymity Technique on Sensor Network	Research on sensor network had been focused on security services that provide authentication, confidentiality, integrity and availability until recently, but now there is growing interest in tackling the problem of actual sensor IDs being exposed. Many techniques for providing anonymity to the source in an ad-hoc network have been proposed, but they are not suitable. Thus, a technique that is well-suited to the characteristics of sensor networks is needed. This paper, limiting the type of attack against a sensor network to that of eavesdropping, proposes a new technique for providing anonymity using Phantom ID and SMAC. The degree of anonymity provided by the proposed technique was analyzed using an entropy-based modeling technique. The results showed that the anonymity is high when the proposed technique is used. The key factor responsible for the improved anonymity had to do with disguising the sensor ID so that it cant be found easily.
Maintenance and privacy in unstructured GeoCast overlays for smart traffic applications	In times of increasing mobility and climate change, there is a need for new services to cope with the special challenges of electric vehicles, like recuperation and charging management. Established systems of so called smart traffic applications are usually server-based and bear the risk of uncontrollable gathering of private data by service providers. In this paper we propose a decentralized overlay protocol for smart traffic applications that meets the requirements of several scenarios of future traffic. Our system offers a scalable GeoCast [1] service, where participants (e.g. vehicles) are able to gain information from specific geographic regions. In the following, we briefly describe three scenarios that would benefit from such a GeoCast service. After that, the main part of this paper discusses maintenance and privacy issues regarding the GeoCast overlay.
Privacy-preserving web search	Since there are many sources of potentially identifying information in web search (e.g. IP address), we need to ways to hide major clues to the user's identity. Although there have been prior attempts to address this problem, all of them incur linear round complexity in the number of users. In this paper, we construct a constant-round private web search protocol using decomposable encryption, secure in the honest-but-curious model.
Design and implementation of privacy-enhanced operation history middleware for smartphones	Operation history middleware collects various operation data on smartphones. Because of privacy concerns about sensitive operation data, it needs to meet fine-grained collection needs including collection based on temporal-spatial conditions and temporary suppression of the collection of specific operation types. The on-demand collection method proposed herein dynamically determines the minimum collection set of operation types and their storage period. We develop an Android-based prototype that implements five collection techniques and a selective encryption function to protect sensitive data in the local database. Our evaluation shows that the collection techniques incur low overhead. Encryption overhead in recording is less than 26 milliseconds.
Composite sensor model and security agent to improve privacy of ubiquitous computing	With the development of electronic and networking technologies, ubiquitous computing is now an exploring focused area. Due to characteristics of ubiquitous computing, privacy and security issues are always quite challenging for application development. This paper presents a novel paradigm to enhance the privacy and security in ubiquitous environments. Unlike previous context model, the proposed composite sensor-based context model (ComSensor) captures both complicated context entities and security requirements. Security agent governs security and privacy by privacy rules defined in ComSensor. One security agent is responsible for privacy management for one context objects. Sensitive context raw data and information are kept only in distributed security agents, from which context queries are processed and context information is disclosed in different accurate levels according to privacy rules. Based on ComSensor and security agent, decentralized trust management architecture is proposed, which is appropriate for different kinds of ubiquitous applications. Examining results on a prototype show that this paradigm is scalable and runs in real-time mode.
A case study: The deficiency of information security assurance practice of a financial institute in the protection of privacy information	Driven by business efficiencies and the need for a competitive advantage, enterprises are now collecting more clientspsila information to increase market share and to offer better services. The hyper-growth of business and competition increases the implementation of ubiquitous and pervasive computing. Such implementations have created a privacy void, in which clientspsila information is sent over from machines to machines without the assurance of information security. information security assurance (IA) aims to restore clientspsila confidence level by ensuring confidentiality, integrity and availability of their information. This paper suggests a holistic and systems approach to deploying information security assurance and illustrates the approach by using a case of inappropriate information privacy practices in a large Canadian financial institute.
CA2P: An Approach for Privacy-Safe Context-Aware Services for Mobile Phones	Plenty mobile applications nowadays offer location-based services. To differentiate one from the many others, there is an emerging trend where developer adds more context information beyond the location information. The aim of using more context information is to offer better user experiences. However there is a tradeoff between offering better user experiences and having to gather and store a huge amount of data. From the user perspective, there is a tradeoff between having better experience and allowing their contextual information being gathered and stored by the application developers. The latter concern is commonly known as user privacy concern. In this paper we present a method called Context Aware Profile Packages (CA2P). CA2P allows the provision of privacy-safe context-aware recommendation services. Moreover, as compared to the other context-aware architectures, CA2P architecture gives the users the possibility to use the data network on request base without limitation of the quality of the service.
Lightweight Privacy-aware yet Accountable Secure Scheme for SM-SGCC communications in smart grid	Smart grid is envisioned as a critical application of cyber-physical systems and of the internet of things. In the smart grid, smart meters equipped with wireless sensors can upload meter readings (data) to smart grid control and schedule centers via the advanced metering infrastructure to improve power delivery efficiency. However, data gathered in short intervals, such as 15 minutes, will expose customers' detailed daily activities (for example, when they get up and when they use oven) using nonintrusive appliance load monitoring. Thus, data must be hidden to protect customers' privacy. However, data accountability is still required for emergency responses or to trace back suspected intrusions, even though the data is anonymous. In addition to desired security requirements, this imposes two extra tasks: Sensors in smart meters usually have resource constraints; thus, the desired security protocols have to remain lightweight in terms of computation and storage cost. Furthermore, scalability and flexibility are required since there exist vast meters. This paper presents a lightweight Privacy-aware yet Accountable Secure Scheme called PASS which guarantees privacy-aware accountability yet tackles the above challenges in the smart grid. A formal security analysis justifies that PASS can attain the security goals, while a performance analysis verifies that PASS requires few computations, and is scalable and flexible.
A designated query protocol for serverless mobile RFID systems with reader and tag privacy	Recently, a new type of Radio Frequency IDentification (RFID) system with mobile readers is introduced. In such a system, it is more desirable for mobile readers to identify tags without a back-end server, and thus it is frequently referred as a serverless mobile RFID system. In this paper, we formalize a serverless mobile RFID system model and propose a new encryption-based system that preserves the privacy of both tags and readers in the model. In addition, we define a new adversary model for the system model and show the security of the proposed system. Throughout comparisons between ours and the other alternatives, we show that our proposed system provides a stronger reader privacy and robustness against a reader forgery attack than the competitors.
A Combined Clustering Scheme for Protecting Location Privacy and Query Privacy in Pervasive Environments	Privacy protection in pervasive environments has attracted great interests in recent years. Two kinds of privacy issues, location privacy and query privacy, are threatening the security of the users. In this paper, a novel combined clustering algorithm for protecting location privacy and query privacy, namely ECC, is proposed. ECC applies a iterative K-means clustering method to group the user requests into clusters for providing location safety while utilizing a hierarchical clustering method for preserving the query privacy. ECC provides the mobile users with their desired anonymity levels and spatial tolerances. Experimental results manifest that the ECC algorithm shows merits in shorter cloaking time and is able to preserve location privacy and query privacy in continuous location based services.
Enhancing User Identity Privacy in LTE	Identity privacy is a security issue that is crucial for the users of a cellular network. Knowledge of the permanent identity of a user may allow an adversary to track and amass comprehensive profiles about individuals. Such profiling may expose an individual to various kind of unanticipated risks, and above all may deprive an individual of his right to privacy. With the introduction of sensitive services like online banking, shopping, etc. through cellular phones, identity privacy has now become a bigger security issue. In GSM and UMTS, the problem of user identity privacy vulnerability is proven to exist. In both these systems, there are situations where the permanent identity of a subscriber may get compromised. Long Term Evolution (LTE), which evolved from GSM and UMTS, is proposed by 3GPP for inclusion into the fourth generation of cellular networks. Although security of LTE has evolved from the security of GSM and UMTS, due to different architectural and business requirements of fourth generation systems, LTE security is substantially different and improved compared to its predecessors. However, the issue of identity privacy vulnerability continue to exist in LTE. In this paper, we discuss how the security architecture of LTE deals with identity privacy. We also discuss a possible solution that may be utilised to overcome the problem of user identity privacy in LTE.
On Designing Privacy-Aware Data Upload Mechanism -- Towards Information-Gathering System for Disasters	A key issue for an organization that is responsible for disaster and emergency management becomes how to gather reliable and useful information during a major disaster. We consider an information-gathering platform for large-scale disasters and emergencies based on mobile terminals. A simple solution to realize an information-gathering system is to construct a server where information is uploaded and published. However, such a centralized approach is not flexible nor is it robust. For example, it is very hard to find an appropriate system to which the user can upload information during a disaster, and the centralized server may be down because of overload or has been physically destroyed. We must consider a distributed and dynamic architecture for the system. Security and privacy issues are another concern that should be addressed for providing information from user's mobile terminals. We focus on a design of a privacy preserving data upload mechanism for the information-gathering system. We design the mechanism that accommodates privacy requirements and present a feasibility analysis of the mechanism.
Practicable Unified Security, Trust and Privacy (STP) Framework for Federated Access Management (FAM)	In open environment there are always challenges in bridging the gap between Security, Trust and Privacy (STP) in Federated Access Management (FAM) systems. This challenge is mainly due to difficulties in providing a practical and efficient framework to handle the often conflicting requirements and expectations of STP in a unified manner. Many of the existing researches address the gap between mainly two areas i.e. security and privacy or security and trust. In this paper, we describe our efforts to narrow the STP gap in FAM and present some implementation experiences in crafting two distinct Unified STP Frameworks (UnifiedSTPFs), namely emergent and practicable, for federated access. We propose the use of the combined strengths of user authentication (AuthN), Trustworthy Mutual Attestation (TMutualA) protocol, and privacy enhancement via Shibboleth. We also presented some lessons learnt during implementation of the practicable UnifiedSTPF for FAM systems in Web Single Sign-On (WSSO) environment and possible future works.
Role Based Privacy-Aware Secure Routing in WMNs	Wireless Mesh Networks (WMNs) have drawn much attention for emerging as a promising technology to meet the challenges in next generation networks. Security and privacy protection have been the primary concerns in pushing the success of WMNs. However, the solutions proposed to ensure the security of the routing protocol and the privacy information in WMNs are still not robust. In this paper, we propose a role based privacy-aware secure routing protocol (RPASRP), which combines a new dynamic reputation mechanism with the role based multi-level security technology and a novel hierarchical key management protocol to defend against the internal attacks and to achieve better security and privacy protection. Simulation results show that RPASRP implements the security and privacy protection against the inside attacks more effectively and efficiently and performs better than the classical hybrid wireless mesh protocol (HWMP) in terms of packet delivery ratio.
Efficient Privacy Preserving Matchmaking for Mobile Social Networking against Malicious Users	Making friends with some common attributes is one of the most popular applications in the mobile social networking (MSN). However, how to preserve the users' privacy while matchmaking has been considered as the key security issue for such applications. In this paper, based on the definitions of the privacy level, a new privacy preserving matchmaking system and protocol for MSN is proposed, which can help users to find their friends without leaking their privacy information. A user (called initiator) can find the best match among the candidates, and only exchange attributes intersection set with the best matched, while other users only know the size of the attributes intersection set mutually. The analyzing and simulation results show that our protocol is efficient with the ability to resist the semi-honest and malicious attacks while providing higher matchmaking efficiency.
Privacy-Preserving Statistical Analysis Method for Real-World Data	We propose a method for obtaining statistical results such as averages, variances, and correlations without leaking any raw data values from data-holders by using multiple pseudonyms. At present, to obtain statistical results using a large amount of data, we need to collect all data in the same storage device. However, gathering real-world data that was generated by different people is not easy because they often contain private information. Thus, our method solves the problem and protects data-holders from data-user's malicious attacks. Finally, we evaluate the suitability of our method through implementation and experimentation.
Towards Understanding Source Location Privacy in Wireless Sensor Networks through Fake Sources	Source location privacy is becoming an increasingly important property in wireless sensor network applications, such as asset monitoring. The original source location problem is to protect the location of a source in a wireless sensor network from a single distributed eavesdropper attack. Several techniques have been proposed to address the source location problem, where most of these apply some form of traffic analysis and engineering to provide enhanced privacy. One such technique, namely fake sources, has proved to be promising for providing source location privacy. Recent research has concentrated on investigating the efficiency of fake source approaches under various attacker models. In this paper, we (i) provide a novel formalisation of the source location privacy problem, (ii) prove the source location privacy problem to be NP-complete, and (iii) provide a heuristic that yields an optimal level of privacy under appropriate parameterisation. Crucially, the results presented show that fake sources can provide a high, sometimes optimal, level of privacy.
Privacy-Preserving Digital Rights Management in a Trusted Cloud Environment	We present a privacy-preserving DRM scheme for a (future) cloud computing software market. In such a market, applications are packed into virtual machines (VMs) by software providers and the VMs can be executed at any computing center within the cloud. We propose the introduction of a software TPM as a container for VM-specific keys within the VM that moves around with the VM within the cloud. The software TPM is coupled to a virtual TPM at a computing center to constitute the root of trust for a local DRM enforcement system within the VM that checks the license before each application execution. This allows flexible price models, e.g. execute at most n times-like models. Users have proof that their personally identifiable information, stored and processed within the VM at a computing center, cannot be obtained by the computing center. A feature of our solution is that neither software provider nor computing center are able to build usage profiles of the software executions.
A Lightweight Privacy Preserving Approach for Analyzing Communication Records to Prevent VoIP Attacks Using Toll Fraud as an Example	Voice-over-IP systems are quite frequently attacked with the intent of service theft. While VoIP security has been intensively researched in the past, devised solutions often demand significant changes to the VoIP systems. In addition, several solutions propose the filtering of telephone calls, but these solutions only have a limited focus on the privacy rights of the call participants. We propose a method for analyzing communication records with the primary purpose to prevent VoIP attacks. Moreover, our approach integrates with little effort into common VoIP usage scenarios. As an example we use the prevention of toll-fraud attacks as a running example. The analysis of the communication records, however, requires investigating personal information in the communication records, e.g., call habits and phone numbers. Consequently we give an overview of major US and EU laws and regulations to elicit privacy requirements. We also demonstrate how these requirements can be implemented using Comercial-Off-The-Shelf VoIP systems.
An Architecture for the Enforcement of Privacy and Security Requirements in Internet-Centric Services	This paper focuses on the problem of how to protect personal data and privacy in the context of internet-centric services. Two main challenges are considered: how to enable individuals to express data protection requirements on their data in a disclosure request; and how to ensure data is actually protected and processed according to the intended purpose of use after being disclosed. As part of our solution, we introduce the notion of a distinctive online service and architectural component, called the Privacy and Security Broker (PSB), responsible for the protection of personal data. The PSB enables a user to express their data protection requirements and translates them into "Data Protection Property Policies" (DPPPs). A high level architecture and the corresponding protocols involving the interaction of the main actors of our solution are presented.
A Framework for Privacy-Preserving Mobile Payment on Security Enhanced ARM TrustZone Platforms	Modern smartphones with the capability to be always online and equipped with data transfer interfaces such as NFC allow to take advantage of a wide variety of services and pave the way for new classes of services. Naturally, not every service will be available for free, some providers will charge money for the services provided. Usually, users are uniquely identified by the provider of a service for billing purposes and providers therefore maintain user profiles. This allows to personalize services with respect to user's interests and preferences. However, it is problematic regarding user's privacy since users disclose lots of sensitive information to the service provider. Different mobile payment solutions have been proposed to date, but privacy aspects are usually not considered at all. In this paper, we demonstrate how privacy friendly payment can be realized using a recent payment mechanisms in combination with an ARM processor platform with TrustZone enhancements. We discuss the public transport ticket domain as an example. Then we propose a platform framework that can be used for arbitrary applications requiring a privacy preserving online remote prepaid payment system suitable for micro as well as macro payments.
A Data-Reachability Model for Elucidating Privacy and Security Risks Related to the Use of Online Social Networks	Privacy and security within Online Social Networks (OSNs) has become a major concern over recent years. As individuals continue to actively use and engage with these mediums, one of the key questions that arises pertains to what unknown risks users face as a result of unchecked publishing and sharing of content and information in this space. There are numerous tools and methods under development that claim to facilitate the extraction of specific classes of personal data from online sources, either directly or through correlation across a range of inputs. In this paper we present a model which specifically aims to understand the potential risks faced should all of these tools and methods be accessible to a malicious entity. The model enables easy and direct capture of the data extraction methods through the encoding of a data-reachability matrix for which each row represents an inference or data-derivation step. Specifically, the model elucidates potential linkages between data typically exposed on social-media and networking sites, and other potentially sensitive data which may prove to be damaging in the hands of malicious parties, i.e., fraudsters, stalkers and other online and offline criminals. In essence, we view this work as a key method by which we might make cyber risk more tangible to users of OSNs.
Reputation Diffusion Simulation for Avoiding Privacy Violation	When people expose their private life in online social networks, this doesn't mean that they do not care about their privacy, but they do lack tools to evaluate the risks and to protect their data. To address this issue, we have previously designed the FORPS system (Friends Oriented Reputation Privacy Score) that evaluates the dangerousness of people who suggest to become our friends, by computing their propensity to propagate sensitive information. In this paper, we introduce a multi-agent simulation model that allows evaluating the long-term and large scale effects of our system based on high number of interactions between simulated users. We show that in comparison with a simple decision process, different variants of the FORPS system produce better results in terms of estimation of the requestor's dangerousness, the convergence speed and the resistance to rumor phenomena.
Analysis and Improvement of Privacy-Preserving Frequent Item Protocol for Accountable Computation Framework	Nowadays, data collection and processing becomes ubiquitous in social and business areas, especially in Internet of Things. However, sensitive information leakage is a critical issue. To solve problem, privacy-preserving techniques are strongly needed. Jiang et al. proposed a protocol of finding frequent item in accountable computing (AC) framework which enables two parties to conduct collaborative computation on their transactional databases to find out the common frequent items without disclosing their private data to the other party. Their scheme was proposed in a secure two-party computation model against malicious adversaries. In this paper, we analyze the implementation details of AC-framework and identify some security weaknesses in their scheme. Furthermore, we clarify the security requirements for the AC-framework and present an augmented solution to enhance security.
AnonymousCloud: A Data Ownership Privacy Provider Framework in Cloud Computing	A means of reliably concealing ownership of cloud data without impeding computation over the data is presented and evaluated. This facilitates information privacy enforcement in cloud environments by withholding data ownership information from cloud nodes that compute using the data. As a result, nodes that have access to private data in unencrypted form do not know who owns it, what role their computations play in the larger computational task, or to whom their computation results are ultimately delivered. To provide this data ownership privacy, the cloud's distributed computing resources are leveraged to implement an anonymizing circuit based on Tor, through which users submit private data and jobs. A tunable parameter k controls a trade-off between the degree of anonymity and the computational overhead imposed by the system. Anonymous authentication based on publickey cryptography safely links jobs and data to customers for billing purposes without revealing these associations to untrusted computation nodes. Simulation results demonstrate the potency of the system in presence of attackers.
A Privacy Preserving Scalable Architecture for Collaborative Event Correlation	We propose an efficient software architecture for private collaborative event processing, enabling information sharing and processing among administratively and geographically disjoint organizations over the Internet. The architecture is capable of aggregating and correlating events coming from the organizations in near real-time, while preserving the privacy of sensitive data items even in the case of coalition of attackers. Although there is a rich literature in the field of secure multiparty computation techniques that preserve the privacy in a distributed systems, the ability of such systems to scale up horizontally (number of participants) and vertically (dataset per participant) is still limited. The key novelty of the architecture is the usage of a pseudo-random oracle functionality distributed among the organizations participating to the system for obfuscating the data, that allows for achieving a good level of privacy while guaranteing scalability in both dimensions. Some preliminary performance results are provided.
Design and Evaluation of SensorSafe: A Framework for Achieving Behavioral Privacy in Sharing Personal Sensory Information	Continuous collection of sensory information using smartphones and body-worn sensors is now feasible with recent advancement of technologies. Sharing such personal information enables many useful applications such as medical behavioral studies, personal health-care, and participatory sensing. However, sharing such information along with inferences that can be drawn from the data increases user's various privacy concerns. This paper proposes SensorSafe, an application framework that enables users to share adequate amounts of their private data and supports obfuscation of sensitive information to protect user privacy. Our framework provides rule-based sharing with context-awareness and conflicting rule detection. In addition, our framework includes several optimization techniques for database processing of rule-based sharing and data obfuscation. We evaluate the optimization techniques with a large amount of accelerometer data from the fine-grained posture recognition application, which is about 6.25 GB.
An Efficient Trust Management System for Balancing the Safety and Location Privacy in VANETs	In VANETs, how to determine the trustworthiness of event messages has received a great deal of attentions in recent years for improving the safety and location privacy of vehicles. Among these research studies, the accuracy and delay of trustworthiness decision are both important problems. In this paper, we propose a road-side unit (RSU) and beacon-based trust management system, called RaBTM, which aims to prorogate message opinions quickly and thwart internal attackers from sending or forwarding forged messages in privacy-enhanced VANETs. To evaluate the performance and efficiency of the proposed system, we conducted a set of simulations under alteration attacks and bogus message attacks with various adversary ratios. The simulation results show that the proposed system RaBTM is highly resilient to adversarial attacks and performs at least 15% better than weighted vote (WV) scheme.
Assuring Data Privacy in Cloud Transformations	Cloud transformations require dynamic redistribution of resources across cloud infrastructure. From a legal perspective this movement of data from one data processor to another without the explicit consent of the data subject is a threat to data privacy. Levels of assurance and accountability have to be provided from the cloud infrastructure providers to the data subject in order to maintain trust. In cases of Cloud Transformation multiple providers are present and passing accountability down the chain is essential. Existing Service Level Agreements (SLA) and policy based privacy implementations fail to provide the flexibility and accountability needed in establishing these new relationships. By introducing combined risk and privacy assessment alongside SLA negotiation, the legal and data management implications of Cloud Transformation events can be better accounted for. This will better protect the privacy of data subjects and increase confidence and trust in the Cloud computing platform.
Trustworthy Infrastructure Services for a Secure and Privacy-Respecting Internet of Things	Security is an important cornerstone for the Internet of Things (IoT). Due to the expected pervasion of IoT and its relevance in all fields of human activity, it will likely become a critical asset. Thus, the integrity of data and trust in the services offering the data is crucial. Further, to protect important data and user interests, confidentiality of data and privacy of users must be ensured. Moreover, each request and response in the frame of IoT has to be authenticated in a proper and secure way to ensure accountability and proper operation. Finally, with the usage of IoT for vital functionalities, availability becomes increasingly important, although availability is out of the scope of this document. The resolution infrastructure introduced in this work is a crucial component of the overall IoT architecture and most security goals are anchored here. Our suggested architecture ensures privacy and security for the resolution functions and offers as well a basis for other security functionalities needed outside the resolution infrastructure.
Privacy Protecting by Multiattribute Clustering in Data-Intensive Service	With the explosive growth of big data, organizations are strongly encouraged to release their micro-data to support data-intensive analysis services, to provide new business opportunities and to allow every kind of scientific study as well. However, releasing medical records about individuals violates their privacy thus, privacy-preserving data publishing has become a critical issue for companies and organizations. Existing privacy protection anonymous technique mainly conducts operation directing at quasi-identifier attributes without consideration of specific relation between different values of sensitive attribute, which results in revealing of individual privacy information. The paper conducts detailed research in allusion to correlation between valuing of sensitive attribute, carries forward the idea of conducting protection to initial data by lossy join, and proposes Twice-privacy algorithm based on utility matrix and multiattribute clustering. Twice-privacy conducts a clustering of sensitive values to protect similarity, sets different weight to retain quasi-identifier attribute to query service; data obtained by clustering algorithm are of high accuracy and high value. Experimental results on real datasets show the effectiveness and efficiency of Twice-privacy algorithm. Our solutions reduce the similarity attack rate to 0%. Meanwhile, the query correction rate and analysis correction rate of the proposed have obvious promotion, inquire accuracy and analysis accuracy are also enhance.
A Privacy Preserving Application Acquisition Protocol	In the smart card industry, the application acquisition process involves the card issuers and application providers. During this process, the respective card issuer reveals the identity of the smart card user to the individual application providers. In certain application scenarios it might be necessary (e.g. banking and identity applications). However, with introduction of the Trusted Service Manager (TSM) architecture there might be valid cases where revealing the card user's identity is not necessary. At the moment, the secure channel protocols for traditional smart card architecture including the TSM does not preserve the privacy of the card users. In this paper, we propose a secure and trusted channel protocol that provide such feature along with satisfying the requirements of an open and dynamic environment referred as User Centric Smart Card Ownership Model (UCOM). A comparison is provided between the proposed protocol and selected smart card protocols. In addition, we provide an informal analysis along with mechanical formal analysis using CasperFDR. Finally, we provide the test implementation and performance results.
Distributed Privacy Preserving Classification Based on Local Cluster Identifiers	This paper addresses privacy preserving classification for vertically partitioned datasets. We present an approach based on information hiding that is similar to the basic idea of microaggregation. We use a local clustering to mask the dataset of each party and replace the original attributes by cluster identifiers. That way, the masked datasets can be integrated and used to train a classifier without further privacy restrictions. We apply our approach to four standard machine learning datasets and present the results.
K-Anonymous Cloaking Algorithm Based on Weighted Adjacency Graph for Preserving Location Privacy	The propagation of position identifying devices, such as GPS (Global Positioning System), becomes increasingly a privacy threat in location-based services (LBSs). However, in order to enjoy such services, the user must precisely disclose his/her exact location to the LBS. So, it is a key challenge to efficiently preserve user's privacy while accessing LBS. For this, the existing method employs a 2PASS cloaking framework that not only hides the actual user location but also reduces bandwidth consumption. However, it suffers from privacy attack. Therefore, we aim to provide the solutions which can preserve user privacy by utilizing k-anonymity mechanism. In this paper, we propose a weighted adjacency graph based k-anonymous cloaking technique that can provide protection to user and also reduce bandwidth usages. Our cloaking approach efficiently supports k-nearest neighbor queries without revealing private information of the query initiator. We demonstrate via experimental results that our algorithm yields much better performance than the existing one.
Privacy-Preserved Access Control for Cloud Computing	The problem of access control on outsourced data to "honest but curious" cloud servers has received considerable attention, especially in scenarios involving potentially huge sets of data files, where re-encryption and re-transmission by the data owner may not be acceptable. Considering the user privacy and data security in cloud environment, in this paper, we propose a solution to achieve flexible and fine-grained access control on outsourced data files. In particular, we look at the problem of defining and assigning keys to users based on different attribute sets, and hiding access policies as well as users information to the third-party cloud servers. Our proposed scheme is partially based on our observation that, in practical application scenarios each user can be associated with a set of attributes which are meaningful in the access policy and data file context. The access policy can thus be defined as a logical expression formula over different attribute sets to reflect the scope of data file that the kind of users is allowed to access. As any access policy can be represented as such a logical expression formula, fine-grained access control can be accomplished.
Balancing Security and Performance for Enhancing Data Privacy in Data Warehouses	Data Warehouses (DWs) store the golden nuggets of the business, which makes them an appealing target. To ensure data privacy, encryption solutions have been used and proven efficient in their security purpose. However, they introduce massive storage space and performance overheads, making them unfeasible for DWs. We propose a data masking technique for protecting sensitive business data in DWs that balances security strength with database performance, using a formula based on the mathematical modular operator. Our solution manages apparent randomness and distribution of the masked values, while introducing small storage space and query execution time overheads. It also enables a false data injection method for misleading attackers and increasing the overall security strength. It can be easily implemented in any DataBase Management System (DBMS) and transparently used, without changes to application source code. Experimental evaluations using a real-world DW and TPC-H decision support benchmark implemented in leading commercial DBMS Oracle llg and Microsoft SQL Server 2008 demonstrate its overall effectiveness. Results show substantial savings of its implementation costs when compared with state of the art data privacy solutions provided by those DBMS and that it outperforms those solutions in both data querying and insertion of new data.
A Privacy-Friendly RFID Protocol Using Reusable Anonymous Tickets	A majority of the existing privacy-friendly RFID protocols use the output of a cryptographic hash function in place of real identity of an RFID tag to ensure anonymity and untraceability. In order to provide unique identification for the tags, these protocols assume that the hash functions are collision resistant. We show that, under this assumption on the hash functions, a substantial number of the existing protocols suffer from a traceability problem that causes differentiating a tag from another. We propose a scalable privacy-friendly RFID protocol and describe its design and implementation issues. Our protocol substitutes the hash functions used for identification with anonymous tickets, thus avoiding the aforementioned traceability problem. The anonymous tickets are reusable. They nevertheless identify the tags uniquely, at any given point in time. The query and search algorithm of our proposed protocol is of O(1) time complexity, and it imposes small storage overhead on the back- end database. We show that the protocol is scalable, and compare its storage and computational requirements to some existing protocols. We formally prove the security requirements of our protocol, and mechanically analyze some of its requirements using the model checker OFMC.
Key Privacy in McEliece Public Key Cryptosystem	The research on the anonymity of original McEliece PKC points out that the original McEliece PKC fails to hold the property of key privacy. A novel semantically secure variant of McEliece PKC is proposed, and proved its anonymity formally in standard model. As far as we know, this is the first attempt to investigate the property of key privacy in McEliece PKC in literature.
Attack Vector Analysis and Privacy-Preserving Social Network Data Publishing	This paper addresses the problem of privacy- preserving data publishing for social network. Research on protecting the privacy of individuals and the confidentiality of data in social network has recently been receiving increasing attention. Privacy is an important issue when one wants to make use of data that involves individuals' sensitive information, especially in a time when data collection is becoming easier and sophisticated data mining techniques are becoming more efficient. In this paper, we discuss various privacy attack vectors on social networks. We present algorithms that sanitize data to make it safe for release while preserving useful information, and discuss ways of analyzing the sanitized data. This study provides a summary of the current state-of-the-art, based on which we expect to see advances in social networks data publishing for years to come.
Privacy, Identity and Trust in Context-Aware Mobile Services	Mobile services are increasingly utilizing context information, e.g. user location. There is an intriguing interplay between privacy, identity, security and trust in this domain. Technologies are presented that can help in managing this interplay. Several of these technologies have also been tested in trials carried out recently by Nokia Research Center in Lausanne, Switzerland. We take a look at some key results obtained from these trials. Examples of used technologies are pseudonym management for location privacy purposes, usage control for protection of privacy-sensitive context data and secure multiparty computations for minimizing the amount of needed information exchange.
Parity Cloud Service: A Privacy-Protected Personal Data Recovery Service	As more and more data are generated in an electronic format, the necessity of data recovery service became larger and the development of more efficient data backup and recovery technology has been an important issue during the past decade. While lots of effective backup and recovery technologies, including data dedeplication and incremental backup, have been developed for enterprise level data backup service, few works have been done for efficient personal data recovery service. Since the privacy protection is a crucial issue for providing a personal data recovery service, a plain data backup-based recovery service is not adequate for public service. Users are not expected to upload their critical data to the internet backup server until they can fully trust the service provider in terms of the privacy protection. In this paper, we propose a novel data recovery service framework on cloud infrastructure, a Parity Cloud Service (PCS) that provides a privacy-protected personal data recovery service. The proposed framework does not require any user data to be uploaded to the server for data recovery. Also the necessary server-side resources for providing the service are within a reasonable bound.
User Privacy Issues in Eucalyptus: A Private Cloud Computing Environment	The highly scalable nature of Cloud Computing enables its users to utilize distributed computational resources and access large amounts of data using different interfaces. Cloud entities including cloud users, service providers and business partners share the available resources at different levels of technological operations. However, the Cloud Computing framework is inherently susceptible to a great number of security threats due to the amalgamation of different computing technologies that make it a complex architecture. Among all the potential threats, those targeting the users' data are significantly important and must be thwarted in precedence to facilitate effective cloud functionality. This paper focuses on the potential threats to users' cloud resident data and metadata and suggests possible solutions to prevent these threats. We have used UEC (Ubuntu Enterprise Cloud) Eucalyptus, which is a popular open source cloud computing software, widely used by the research community. In this work, we have simulated some of the potential attacks to users' data and metadata stored in Eucalyptus database files in order to provide the intended reader with the requisite information to be able to anticipate the grave consequences of violation of cloud users' data privacy.
Learning Whom to Trust in a Privacy-Friendly Way	The topics of trust and privacy are more relevant to users of online communities than ever before. Trust models provide excellent means for supporting users in their decision making process. However, those models require an exchange of information between users, which can pose a threat to the users' privacy. In this paper, we present a novel approach for a privacy preserving computation of trust. Besides preserving the privacy of the recommenders by exchanging and aggregating recommendations under encryption, the proposed approach is the first that enables the trusting entities to learn about the trustworthiness of their recommenders at the same time. This is achieved by linking the minimum amount of information that is required for the learning process to the actual recommendation and by using zero-knowledge proofs for assuring the correctness of this additional information.
A Privacy-Preserving Defense Mechanism against Request Forgery Attacks	One top vulnerability in today's web applications is request forgery, in which an attacker triggers an unintentional request from a client browser to a target website and exploits the client's privileges on the website. To defend against a general class of cross-site and same-site request forgery attacks, we propose DeRef, a practical defense mechanism that allows a website to apply fine-grained access control on the scopes within which the client's authentication credentials can be embedded in requests. One key feature of DeRef is to enable privacy-preserving checking, such that the website does not know where the browser initiates requests, while the browser cannot infer the scopes being configured by the website. DeRef achieves this by using two-phase checking, which leverages hashing and blind signature to make a trade-off between performance and privacy protection. We implement a proof-of-concept prototype of DeRef on FireFox and WordPress 2.0. We also evaluate our DeRef prototype and justify its performance overhead in various deployment scenarios.
Internet Users' Security and Privacy While They Interact with Amazon	Amazon is the world's largest e-shopping site, with its market capitalization having just passed $100 billion [1]. Internet users interaction with its web site is an example of a widespread security ceremony - a ceremony focuses on security- related human interaction with technology, including security protocols and on-line service consumption [2]. This paper focuses on how Amazon's ceremony manages the users' security and privacy through the digital identities they may create with the popular web site. It leverages on the cognitive walkthrough method [3] to distill tasks, steps and walkthroughs of the ceremony, and then to pinpoint four risks affecting the users' security and privacy. It formulates four corresponding recommendations for technical web site updates that would resolve the noted risks. In particular, the recommendations address common contexts such as users accessing Amazon from their smartphones. A possible explanation of the coexistence of such risks with the late capitalization achievements is that users are more driven by familiarity and confidence than by trust. These findings are meant to be complemented with a homologous assessment from Amazon's standpoint.
Towards a Holistic Privacy Engineering Approach for Smart Grid Systems	Protecting energy consumers's data and privacy is a key factor for the further adoption and diffusion of smart grid technologies and applications. However, current smart grid initiatives and implementations around the globe tend to either focus on the need for technical security to the detriment of privacy or consider privacy as a feature to add after system design. This paper aims to contribute towards filling the gap between this fact and the accepted wisdom that privacy concerns should be addressed as early as possible (preferably when modeling system's requirements). We present a methodological framework for tackling privacy concerns throughout all phases of the smart grid system development process. We describe methods and guiding principles to help smart grid engineers to elicit and analyze privacy threats and requirements from the outset of the system development, and derive the best suitable countermeasures, i.e. privacy enhancing technologies (PETs), accordingly. The paper also provides a summary of modern PETs, and discusses their context of use and contributions with respect to the underlying privacy engineering challenges and the smart grid setting being considered.
Privacy Crisis Due to Crisis Response on the Web	In recent disasters, the web has served as a medium of communication among disaster response teams, survivors, local citizens, curious onlookers, and zealous people who are willing to assist victims affected by disasters. To encourage and speed up information dissemination, the availability and convenience of use are normally the top concerns in designing disaster response web services, where a design of free-formed inputs without access control is commonly adopted. However, such design may result in personal information disclosure and privacy leakage. In this paper, using a case study of a real-life disaster response service, the MKER (Morakot Event Reporting) forum, we show that the disclosure of personal information and the resulting privacy disclosure is indeed a serious problem that is currently happening. In our case, we have successfully mapped 1,438 unique cell phone numbers and 1,383 unique addresses to individuals using an automated method, not to mention the much greater invasion of privacy that could be effected by manual analysis of the messages posted on the forum. To resolve this issue, we propose several means to mitigate and prevent the mentioned privacy leakage on disaster response services from being happened.
A Property-Based Attestation Scheme with the Variable Privacy	The binary attestation mechanism is a basic remote attestation way for Trusted Platform Module (TPM) in Trusted Computing Group (TCG) specification. To improve the security and complexity of the binary attestation, the concept of property-based attestation (PBA) has been proposed by convincing the remote verifier that the platform satisfies the security properties without exposure of the configuration privacy. The existing PBA schemes have the disadvantage of the complex property revocations. To overcome this problem, we propose a simplified property based attestation model on the online TTP in this paper. During the attestation the prover attests the platform configuration property as well as the validation of the property certificate without verifying the property revocation. More concretely it presents a property based attestation protocol with variable privacy, which is provable security under the q-SDH assumption, discrete logarithm problem and the perfect hidden property of the commitment. We conduct the experiment to evaluate efficiency of our scheme in final. The experiment shows that the privacy parameter does not have the significant impacts on the performance, and we can adjust the parameter to make a trade-off between the performance and privacy.
Semantics-Enhanced Privacy Recommendation for Social Networking Sites	Privacy protection is a vital issue for safe social interactions within social networking sites (SNS). Although SNSs such as MySpace and Facebook allow users to configure their privacy settings, it is not a simple task for normal users with hundreds of online friends. In this paper, we propose an intelligent semantics-based privacy configuration system, named SPAC, to automatically recommend privacy settings for SNS users. SPAC learns users' privacy configuration patterns and make predictions by utilizing machine learning techniques on users' profiles and privacy setting history. To increase the accuracy of the predicted privacy settings, especially in the context of heterogeneous user profiles, we enhance privacy configuration predictor by integrating it with structured semantic knowledge in the SNS. This, in turn, allows SPAC to make inferences based on additional source of knowledge, resulting in improved accuracy of privacy recommendation. Our experimental results have proven the effectiveness of our approach.
Privacy Preserving Access Control Policy and Algorithms for Conflicting Problems	This paper proposes a framework for privacy preserving access control policies and mechanisms, and describes algorithms for access policy conflicting problems. The mechanism enforces access policy to data containing personally identifiable information. The key component of the framework is purpose involved access control models (PAC) that provide full support for expressing highly complex privacy-related policies, taking into account features like purposes, conditions and obligations. Policy conflicting problems may arise when new access policies are generated that are possible to be conflicted to existing policies. As a result of the policy conflicts, private information cannot be well protected. The structure of access control policy including conditions and obligations is studied. Based on the access policy, authorization models and policy operations are analysed. Finally comparisons to related works EPAL are presented.
Trusted identity attribute service method with privacy protection in cyberspace	With the cyber society booming rapidly, cyber trusted service and privacy protection have been more and more focused on. The paper presents a new method for user identity attribute service in cyberspace, and the method based on the service model of multilevel cyber identity management provides user identity attribute service for cyber applications, and implements the descriptive mechanism of multilevel privacy protection policy, which permits users, identity service provider, and identity service relying party to prescribe attribute privacy protection policy, attribute disclosure policy and attribute request policy individually. As a result, security of web applications along with user privacy is protected by providing fine-grained access control with user identity attribute and strong authentication services.
Design and implementation of a SoC for privacy storage equipment	Aiming at the issues of slow speed and low security of the removable storage equipment nowadays, this paper proposed a high performance cipher SoC. It integrates an special-designed cipher coprocessor which can realize kinds of cryptographic algorithms. A t-EC w-bit parallel Bose-Chaudhuri-Hocquengham (BCH)error-correction code (ECC) was designed for correcting the random bit errors of the flash memory chip, which is suitable for the randomly bit errors property and parallel I/O interface of the NAND-type flash memory. Based on the architecture of Nand Flash Controller, this paper proposed techniques to accelerate the access speed of NAND Flash. The result verified by the development board shows that the proposed SoC can improve the data access performance in both read and program operation of NAND Flash. The built-in coprocessor can support cipher operations with high security, high flexibility and high data throughput.
Privacy-Preserving Attribute Distribution Mechanism for Access Control in a Grid	This paper presents a privacy-preserving attribute distribution mechanism for an identity federation framework. Attribute-based access control (ABAC) is a highly flexible and scalable access control scheme which can deal with diverse security requirements in grid environment. However, in ABAC the user attributes delivered by the Identity Providers for authorization decisions may cause some privacy violation. We developed an attribute release control scheme that can improve the privacy protection capability of the current security systems in grids. The Shibboleth identity provider, GridShib, and Globus toolkit are used for our implementation.
Sequence Mining Without Sequences: A New Way for Privacy Preserving	During the last decade, sequential pattern mining has been the core of numerous researches. It is now possible to efficiently discover users' behavior in various domains such as purchases in supermarkets, Web site visits, etc. Nevertheless, classical algorithms do not respect individual's privacy, exploiting personal information (name, IP address, etc.). We provide an original solution to privacy preserving by using a probabilistic automaton instead of the original data. An application in car flow modeling is presented, showing the ability of our algorithm to discover frequent routes without any individual information. A comparison with SPAM is done showing that even if we sample from the automaton, our approach is more efficient
Beyond Concern: Understanding Net UsersΓÇÖ Attitudes about Online Privacy	This chapter contains sections titled: Introduction, Survey Methodology, Attitudes about Current and Anticipated Online Information Practices, Attitudes about Privacy Regulation and Self-Regulation, Technical Implications, Policy and Business Implications, Acknowledgments, References
A novel privacy preserving approach for database security	A lot of information of individuals is published by hospitals, insurance companies, medical administrations and governments, which may cause a major risk of sensitive information leakage in recent years. Thus, privacy preserving in data publishing has become an important research topics in database security field. In this paper, we propose a novel privacy preserving approach based on k-anonymity model and multidimensional model, which combines global recoding and local recoding technology and provides privacy preserving in data publishing. The novel anonymity strategy can efficiently and dynamically designate sensitive information according to the requirements of users. Then we develop an anonymous strategy algorithm which adapts to the anonymity strategy and achieves the purpose of preventing homogeneity attack and background knowledge attack. Finally, we conclude the paper and introduce the research directions for future work.
(╬▒, ╬▓, k)-anonymity: An effective privacy preserving model for databases	Publishing the data with multiple sensitive attributes brings us greater challenge than publishing the data with single sensitive attribute in the area of privacy preserving. In this paper, we propose a novel privacy preserving model based on k-anonymity called (╬▒, ╬▓, k)-anonymity for databases. (╬▒, ╬▓, k)-anonymity can be used to protect data with multiple sensitive attributes in data publishing. Then, we set a hierarchy sensitive attribute rule to achieve (╬▒, ╬▓, k)-anonymity model and develop the corresponding algorithm to anonymize the microdata by using generalization and hierarchy. We verify (╬▒, ╬▓, k)-anonymity approach can effectively protect privacy information of individual and resist background knowledge attack in publishing the data with multiple sensitive attributes by specific example.
Providing privacy preserving in cloud computing	People can only enjoy the full benefits of Cloud computing if we can address the very real privacy and security concerns that come along with storing sensitive personal information in databases and software scattered around the Internet. There are many service provider in the internet, we can call each service as a cloud, each cloud service will exchange data with other cloud, so when the data is exchanged between the clouds, there exist the problem of disclosure of privacy. So the privacy disclosure problem about individual or company is inevitably exposed when releasing or sharing data in the cloud service. Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. Our paper provides some privacy preserving technologies used in cloud computing services.
A privacy preserving Jaccard similarity function for mining encrypted data	Due to advances in data collection and increasing dependency on data mining experts, preserving privacy of the data is a major concern when mining the data. Most of the classifier implementations for data mining have the tradeoff between classification accuracy and maintenance of data privacy. Another important aspect in distance-based classifiers is to accurately compute distance (or similarity) between two or more data points. In privacy preserving data mining techniques, providing a suitable distance measure to classify the data while maintaining data privacy is a challenging task. In this paper, we present an approach to compute similarity between two encrypted data points. We augmented Jaccard similarity function with Private Equality Test protocol facilitating a semi honest third party to conduct the equality test. The proposed privacy preserving scheme provides an efficient mechanism for similarity computation with reduced communication cost for mining the data.
CRYPPAR: An efficient framework for privacy preserving association rule mining over vertically partitioned data	Building a real system is one of the major challenges of privacy-preserving data mining (PPDM). In this paper, we propose CRYPPAR, a novel, full-fledged framework for privacy preserving association rule mining based on a cryptographic approach. We use secure scalar product protocols and public-key cryptosystems in CRYPPAR to efficiently mine association rules over vertically partitioned data. We also introduce a partial topology to lower communication cost as much as possible. Empirical results show that the framework is efficient in privacy-preserving association rules and may become a general framework for PPDM systems.
Privacy preservation in k-means clustering by cluster rotation	The use of clustering as a data analysis tool has raised concerns about the violation of individual privacy. This paper proposes a data perturbation technique for privacy preservation in k-means clustering. Data objects that have been partitioned into clusters using k-means clustering are perturbed by performing geometric transformations on the clusters in such a way that the object membership of each cluster and orientation of objects within a cluster remain the same. This geometric transformation is achieved through cluster rotation, i.e., every cluster is rotated about its own centroid. The clusters are first displaced away from the mean of the entire dataset so that no two clusters overlap after the subsequent cluster rotation. We analyze the privacy measure offered by this data perturbation technique and prove that a dataset perturbed by this method cannot be easily reverse engineered, yet is still relevant for cluster analysis.
Privacy protection in anonymous computational grid services	Privacy of message during transactions between grid nodes belonging to public realm has become a mounting apprehension for nodes engaged in the communication. While it is imperative to ensure a high level of security for geographically dispersed distributed nodes, privacy issues for concealing individual profiles and identities are worth concerning. Privacy in the user profile management is prime concern of this paper. We explored an extension of onion routing with dynamic token exchange for protecting from intruders within service oriented computational grid backbone. Our scheme allows anonymous connections with protection of identities of the communicating nodes.
Privacy Protection of Grid Services in a Collaborative SOA Environment	Grid computing has emerged as a powerful extension of Web for a request-response interaction between service providers and service consumers. Grid computing caters to this collaboration need of service providers and consumers on business need within a service-on-demand style. While collating responses from multiple service providers, the master service provider or broker has to open individual sections of the form. But, the individual service provider is supposed to open the portion of the form designated for its own filling up and not to intervene with anyone else's area. This requires that the XML document be multi-parted and have individual private key used for lock to undesired service provider. Our work explores possibilities of encrypting or signing a portion of a XML document so that same XML document can float through multiple service providers with different sections locked for view by a particular server.
Tunable privacy for access controlled data in peer-to-peer systems	Peer-to-peer paradigm is increasingly employed for organizing distributed resources for various applications, e.g. content distribution, open storage grid etc. In open environments, even when proper access control mechanisms supervise the access to the resources, privacy issues may arise depending on the application. In this paper, we introduce, PANACEA, a system that offers high and tunable privacy based on an innovative resource indexing approach. In our case, privacy has two aspects: the deducibility of a resource's existence/non-existence and the discovery of the provider of the resource. We systematically study the privacy that can be provided by the proposed system and compare its effectiveness as related to conventional P2P systems. Employing both probabilistic and information-theoretic approaches, we analytically derive that PANACEA can offer high privacy, while preserving high search efficiency for authorized users. Our analysis and the effectiveness of the approach have been experimentally verified. Moreover, the privacy offered by the proposed system can be tuned according to the specific application needs, which is illustrated with a detailed simulation study.
Privacy and data protection in technology-enhanced professional learning	Privacy provision and data protection are basic requirements for professional learning, especially when personalized systems are used that adapt to sensitive learner personal data. In this paper we discuss important topics that need to be investigated before technology-enhanced professional learning is introduced in corporate settings. Although the paper is focused on privacy and personal data protection, specific issues such as digital rights management are also briefly described. As an example of introducing privacy-enhancing technologies into learning environments we give a Smart Space for Learning that has been developed in the context of the ELENA1 project. Future research issues related to privacy and data protection in professional learning, one of the topics of the PROLEARN network of excellence in professional learning, are presented as well.
An analysis of signaling traffic for authentication and privacy protocols in cellular and PCS systems	An overview of the security mechanisms for cellular phone systems and the emerging PCS systems and a description of the signal flow due to authentication and privacy protocols are presented. Using a mobility model for cellular systems we make an analysis of signaling traffic for these protocols
A location and privacy service enabler for context-aware and location-based services in NGN	The migration from legacy networks to next generation networks (NGN) requires network-spanning service enablers to offer network features (e.g. location or presence services) to value-added services. This paper introduces a location service enabler for legacy and future networks. The enabler supplies location information to value-added services taking into account privacy issues. Value-added services are for example context-aware and location-based mobile applications as well as emergency services
A generalization-based approach for personalized privacy preservation in trajectory data publishing	Trajectory data are becoming more popular due to the rapid development of mobile devices and the widespread use of location-based services. They often provide useful information that can be used for data mining tasks. However, a trajectory database may contain sensitive attributes that are associated with trajectory data. Therefore, improper publishing of the trajectory database could put the privacy of moving objects at risk. Removing identifiers from the trajectory database before the public release, is not effective against privacy attacks, especially, when the adversary employs some background knowledge. The existing approaches for privacy preservation in trajectory data publishing apply the same amount of privacy preservation for all moving objects, without regard to their privacy requirements. The consequence is that some moving objects may be offered insufficient privacy preservation, while some others may not need high privacy protection. In this paper, we address this issue and present a novel approach for privacy preservation in trajectory data publishing based on the concept of personalized privacy. It consists of two main steps: (1) identifying primary critical trajectory data records and generalizing sensitive attributes according to them, and (2) identifying remaining critical trajectory data records and eliminating moving points with minimum information loss. The results of experiments on a trajectory dataset show that our proposed approach achieve the conflicting goals of data utility and data privacy in accordance with the privacy requirements of moving objects.
Location privacy in processing location dependent queries in mobile database systems	Emergence of the mobile computing paradigm helps people to work in a much more convenient and efficient way, anywhere and anytime. Today its application areas such as traffic reports, weather forecast, bill paying and healthcare are so popular. The field of data management is also extended with such new services and applications. A mobile database system is a special heterogonous distributed system that supports mobile computing. One of the most important types of queries in mobile environments is location dependant query. Its answer is dependent to the mobile user's location. However, revealing location information raises privacy concerns. This paper concentrates on query processing in this paradigm.
A privacy-preserving cache management system for MANETs	Mobile Ad hoc Networks (MANETs) have become increasingly popular with the rapid emergence of hand-held devices and advanced communication technologies. As a result, several MANET applications have been proposed one of which is the data access application. To enhance the performance of this application cache management systems have been suggested; however, they have been designed regardless of the privacy concerns they raise. We study the cache management system COACS (a COoperative and Adaptive Caching System for MANETs) and its weaknesses in terms of privacy to propose a privacy-preserving protocol to render such a caching system well protected against all kind of internal or external privacy breaches. We also provide a mathematical analysis to measure the system's degree of anonymity.
Optimized conditional privacy preservation in VANETs	In this paper, we present an optimized conditional privacy preservation model for vehicle ad-hoc networks (VANETs). This model includes an ID-based cryptosystem to assure users' anonymity using pseudonyms; however the model provides a backdoor for law enforcement authorities to trace misbehaving and suspicious users. In this model, we propose a heuristic that optimizes the pseudonym update process. This heuristic permits vehicles to switch pseudonyms at different times and locations in a way that maximizes the anonymity degree.
Home Wireless Security and Privacy: A Practical Protocol Mixing	With the rising of wireless technologies, a lot of wireless devices have started to reach the domestic domain. Most of them are intended to simplify common tasks avoiding the use of cables. Home users buy wireless devices because of their simplicity and because they are way more practical. But few people think of their data privacy and security. They feel save behind their home walls without knowing that anyone will be able to listen to their wireless traffic without notice. Is our privacy compromised? Are our home connections secured? How can we ensure nobody is hacking our traffic? This and other several related questions are beginning to concern the home users. In an effort to put everything together, this document is intended to show the wireless technologies that coexist nowadays in the domestic domain, and how they affect the home privacy and security. Thus, the main output of this paper is to explore the lines to follow in a way to build a much secure environment, through the definition of a framework for a protocol mixing system.
Security and privacy issues in Social Networking sites from user's viewpoint	Although the use of Social Networking web sites and applications is increasingly on the rise, many users are not properly informed of the risks associated with using these sites and application. Understanding these risks and challenges should be addressed to avoid potential loss of private and personal information. While some studies concerning this issue have been conducted within the context of developed countries, very few studies have been conducted within the context of developing countries. This paper examines the issues of security, privacy, and trust in social networking sites from users' viewpoint, and within the context of two developing countries, namely Thailand and the UAE. Both countries have witnessed a significant increase in the use of social networking tools in the last few years.
Privacy and ethical issues in location-based tracking systems	Location-based tracking systems (LTSs) use a variety of technologies to record the locations of objects. An LTS can increase the risks to the privacy and security of individuals. Previous studies have failed to distinguish between losses and violations of privacy when the locations of individuals are recorded by an LTS. We argue that individual privacy is threatened not by the collection of public location information but by the centralization of aggregated information, and by the combination of location information with other personal information. Further, informed consent should be required when the collection of information might cause a violation of privacy.
The PIPWatch toolbar: Combining PIPEDA, PETs and market forces through social navigation to enhance privacy protection and compliance	This paper describes the prototype development of the PIPWatch toolbar, a software interface device embedded within a Web browser designed to enable consumers to easily assess and compare the compliance of on-line businesses with Canadian private-sector privacy legislation - the Personal Information Protection and Electronic Documents Act. (PIPEDA). It represents a new form of privacy enhancing technology (PET) that employs social navigation techniques to help an on-line community of individuals concerned about the handling of their personal information to build and share a database that tracks the privacy performance and regulatory compliance of Websites they visit.
Privacy: personal information, threats, and technologies	The three primary thrusts of this paper are: first, that people do not think enough about their own privacy, in particular, they may not know enough about their privacy that they can really make informed decisions about sharing information; second, that technologies exist that can mitigate some of the problems associated with information sharing; and third, that services (in addition to to technologies) might be a reasonable way to think about addressing the privacy problem.
Verizon vs the RIAA: implications for privacy and democracy	In January 2003, a US district court in the District of Columbia ruled that Verizon must comply with a subpoena by the Recording Industry Association of America (RIAA) requesting the name of a subscriber who allegedly made available more than 600 copyrighted music files over the Internet. This ruling rocked the Internet community, especially those critics who saw the decision as one advancing the interests of copyright owners at the expense of broader democratic values in cyberspace such as freedom of speech and privacy for individual users. In an appeals ruling on December 19, 2003, however, the United States Court of Appeals for the District of Columbia overturned the lower court's decision. A particular challenge for computer ethicists is to determine how arguments on both sides of this case can be sorted out and evaluated from a moral perspective. The purpose of the present essay is to elucidate the issues surrounding this case by analyzing arguments advanced by both Verizon and the RIAA, and to examine some of the implications that the outcome of this ruling may have for future activities in cyberspace. Section 1 of the paper sets the background for understanding the arguments and ruling involved in both lawsuits, while Section 2 examines the infrastructure of the peer-to-peer (P2P) distribution model and how it supports the values inherent in democracy and democratic ideals. Section 3 examines some interrelationship between privacy and democracy, and shows why the former is essential for the latter. We conclude this essay in Section 4 by supporting Verizon's refusal to hand over the names, on the grounds that doing so would have violated the privacy of the individual subscribers which, in turn, would undermine any goals of achieving democracy in cyberspace.
Video surveillance for the rest of us: proliferation, privacy, and ethics education	The ethics of video surveillance has focused on policy and professional issues. But more individuals will use and encounter remote video surveillance technology as these devices become cheaper and easier to use. We propose an educational approach to the ethics of the emerging practice of non-professional remote video surveillance. Extending the approach to ethics and technology used in our Robot Ethics Lab, we first sketch an abstract model to explain some of the value issues surveillance technology generates. Second, using widely available robotic toys and networking software, we show how working within a technologically and ethically rich environment can move us from a crude remote surveillance prototype towards a more acceptable social contract covering this technology.
Personal, private, secret, public [ethics of data privacy]	Although discussions of privacy and technology are often issue centered, some do address fundamental questions such as what a "right to privacy" might entail. This paper proposes to address a still more fundamental question. Arguing that a better understanding of "privacy" hinges on the better understanding of the related terms, "personal," "private," "secret," and "public," this paper first suggests an analysis of the meaning of these terms. Building on this analysis to advance discussion of the topic of privacy and technology, the paper then provides a consistent ethical position, and discusses the consequences of its analysis on the understanding of privacy within the democratic state. Finally, as an example application, the paper revisits the issue of ownership of personal data.
A critique of the U.S. Genetic Privacy Act	The paper critiques and revises the US Genetic Privacy Act that proposes Federal legislation to ΓÇ£protect the genetic privacy of individualsΓÇ¥. The Act safeguards the privacy of an individual from whom genetic information is gathered (the sample source), but fails to protect the privacy of others genetically related to the sample source. E.g., the Act does not prevent a sample source from giving a DNA sample to some third party such as an insurance company, so that the insurance company could gather genetic information on the source's sibling. The paper notes this lacuna in the Act and proposes remedies
Internet marketing, consumer surveillance and personal privacy: social exchange or panoptic control?	The purpose of the paper is to address the tension between Internet marketers' routine collection and use of personal information, and consumer privacy concerns. Specifically, the paper identifies two contrasting perspectives into consumer surveillance associated with Internet marketing mechanisms and privacy concerns: the social exchange approach and the panoptic control approach. Following the basic assumptions of each perspective, the underlying meaning of consumer surveillance and its ramifications for personal privacy are explicated. Implications for Internet marketing are also assessed
Privacy protection on the Internet: the marketplace versus the state	There is a battle being fought in the USA and elsewhere, with respect to the protection of privacy on the Internet. In response to public concern, various government bodies in the USA, Canada and Europe have explored approaches to the protection of personal privacy on the Internet, with differing results. At the same time, Internet consumer and civil liberties groups, and business and newly emerging industry groups have proposed their solutions to the perceived problems. In this paper, we articulate the various positions and attempt to identify and evaluate the dominant themes. At the end, we propose an approach that requires government intervention, sometimes referred to as the European model
Privacy and security in the Digital Age	A serious problem of security has developed because of the popularity in the use of the Internet for all kinds of communications by both individuals and companies. This potential security issue has forced many to evaluate the need for even connecting to the Internet. Connecting has many benefits, but is it worth the risk of possible loss of confidential information, damage to files and systems, hackers and viruses? The goal of this paper is to examine the implications of rapidly expanding Internet technology on society's desire to maintain privacy and security of information. This is accomplished by discussing a variety of issues, including: (1) an overview of privacy and security issues; (2) encryption as one potential solution to the privacy and security issues; and (3) congressional legislation affecting privacy and security
Technology and Personal Data Privacy	
Control, trust, privacy, and security: evaluating location-based services	Location-based services (LBS) are those applications that utilize the position of an end-user, animal, or thing based on a given device (handheld, wearable, or implanted), for a particular purpose. This article uses scenario planning to identify the possible risks related to location-based services in the context of security and privacy. The original contribution of this article is that the dilemma has been related specifically to LBS, under the privacy-security dichotomy. Here, each side of the dichotomy is divided into three key components that combine to greatly magnify risk. Removing one or more components for each set decreases the privacy or security risk. Where more elements are present in conjunction, the risk is increased
Privacy Issues and Solutions in Social Network Sites	The security of private information of users online is a critical topic, particularly since social networking applications became popular. According to Cutillo et al. [1], beyond the usual vulnerabilities that threaten any distributed application over the Internet, online social networks raise specific privacy concerns due to their inherent handling of personal data.
Guidelines Governing the Protection of Privacy and Transborder Flows of Personal Data	
Information and medical ethics: protecting patient privacy	As medical records become electronic, pieces of everyone's health history will reside in public and private computer repositories. The paper discusses issues of medical ethics, including the protection of patient privacy
Privacy in the Age of Google and Facebook	Google and Facebook look to be at best naive, and at worst inept, when it comes to managing data privacy.Privacy is a key protection for intellectual, polit ical, and religious freedom, as well as the dignity of the individual. We cannot underestimate the power of the online revolution unleashed by Google and Facebook, but we can not ignore the inherent vulnerabili ties their size brings to digital social databases.
PIPWatch Toolbar: Using Social Navigation to Enhance Privacy Protection and Compliance	The main goal of this project is to evaluate the prospects of combining social navigation techniques into a PET that helps Internet users identify which Websites comply with Canadian privacy legislation and to honor the concerns common among Canadians who conduct personal transactions via the Web. Our PIPWatch tool allows users to collect and share information about the privacy practices of various Websites.
Privacy: A non-existent entity	The development and implementation of new technologies has led to a significant erosion of privacy. In this circumstance, it is an arduous struggle to control one's personal information. Now we need to determine the best ways to protect individuals from abuse when their personal information is collected and distributed.
Mental models of privacy and security	The mental models approach could significantly improve risk communication in the case of computer security. The particular mental models that will be discussed here are: physical, medical, criminal, warfare, and market models. Our strongest conclusion is that mental models can be used to improve risk communication. The second, untested, conclusion is that the best model may be the medical model.
Privacy and security as ideology	Privacy and data protection are among the prime problems of the information society. The terms privacy and security promotes a particular ideology and uses the ethical recognition of the concepts to limit critical discourses. This article uses a critical approach in the tradition of critical theory and its developments in critical research in information systems (CRIS) to expose and overcome these discursive closures. The author begins with a review of the literature on privacy and security, which will support the contention that these are ethical concepts. The concept of ideology and critical research is discussed. This will lead to a critical discourse analysis of a text from a commercial software vendor, which will provide empirical evidence of the ideological use of the terms privacy and security
Privacy management service contacts as business opportunity	The article discusses the service level agreement (SLA) and the privacy aspect. Economic and business considerations around privacy, and privacy of information in general have different levels of analysis and enforcement, as mentioned in the article. Economic and business considerations, require economic and business value to be defined and transacted upon. It should also be stressed that legal aspects are essential, as they may determine the nature of some privacy features as well as limits. Legal aspects obviously also apply to the fulfillment of the transactions between the economic individual and economic agents, directly or indirectly. The paper defines the framework and implementation of SLA management for privacy, as well as privacy metrics. A case study implementation in Cisco was mentioned. This article recognizes that privacy SLA's business value does not extend to all domains. But there are application domains where their introduction would be a major incentive scheme to increase controlled information and business interactions.
The Challenging World of Privacy Advocacy	The power and reach of government agencies and corporations have increased greatly in the last few decades, and the prospects, and threats, inherent in so-called ΓÇ£public private partnershipsΓÇ¥ now loom large. The terrorist attacks of the first decade of the new century have been ruthlessly exploited by national security agencies not only to recover but to considerably extend their powers, to give them even greater freedom from democratic controls, and to increase their resources. Law enforcement agencies and even social control agencies have gained powers as well, in part by clinging to the coat-tails of national security.
Defending a Context-Based Framework of Privacy [Book Review]	Nissenbaum's book clearly qualifies as one that is very "important" to any reader who is eager to acquire a better understanding of the concept of privacy and a sharper awareness of the kinds of privacy-related policy challenges that currently confront us. I suspect that many who read this book will be grateful to Helen Nissenbaum for sharing with us her extraordinary insights, both on the concept of privacy and the contemporary technology-based issues surrounding that concept.
Continuous RFID-Enabled Authentication: Privacy Implications	Radio frequency identification (RFID) technology has been used in many application areas, including tracking shipments, inventory control, tracking livestock, locating missing pets, and studying wildlife. Recent years saw a rise in applications where RFID is used to track and monitor people with a broad objective of improving safety and productivity. RFID is now used to track military and law enforce ment personnel, locate lost children in amusement parks, and improve critical response time and efficien cy in hospitals by tracking medical personnel. RFID tags for tracking people can be either worn or implanted, but both methods pose significant ethical challenges to privacy. Applications involving subdermally implanted RFID tags and their ethical and privacy implications have been surveyed. The main focus of this article is on RFID systems that use wearable tags that can be embedded in badges or clothing for employee tracking at the workplace.
Protecting privacy in the cyber era	Issues related to privacy and technology go to the heart of concepts of individual rights, corporate power, the role of government, and law enforcement needs. The author considers various means to protect individual privacy and concludes that encryption may be the best solution
Privacy - The times they are a-changin' [Introduction]	This special section is dedicated to privacy in the information age. In particular, since the rise of mobile social media and the advent of cloud computing, few can dispute that the times have indeed changed. Privacy is now understood "in context" and within a framework that is completely different from what it once was. The right to be let alone physically seems to have been up turned by the right to give away virtually as much information as we like. We have endeavoured here to offer an international Special Section with a wide range of perspectives. Some articles digress on viewpoints, but all of our expert authors are willing to have open dialogue and to seriously engage in the public forum. We must capture these and other consonant opportunities to speak now while we can, that we might together come up with a global approach to arrest alarming developments that threaten to turn privacy into a thing of the past. Privacy does matter. It is both the stuff of dreams and of identity.
Opinion - A critique of the U.S. genetic privacy act	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01035229.png" border="0">
Privacy vs. Security in National Emergencies	Emergence of a shared global risks rhetoric over the past few years has paralleled growth in some countries of political efforts to achieve national security. These efforts are characterized by the introduction and implementation of unprecedented measures to counter growing threats and to attempt to eliminate all identifiable potential human- and natural-caused risks and hazards. As every risk has the intrinsic potential to severely affect, not just individuals, but a country's infrastructure, the accession of socially constructed security measures has been justified to the public as an absolute necessity to sustain the uninterrupted order of civil society. However, some citizens and lobbying groups have perceived the extent of the measures as a substantial move towards blanket and intrusive covert/overt policing practices on our lives, leading down the path towards a nationwide surveillance society.
Millennials and Privacy in the Information Age: Can They Coexist?	Rapid advancement in information technologies (IT) has created dramatic changes in many aspects of society. Changes in communication's economics now enable fast, easy, and cheap mass dissemination of information. This dissemination triggers new and innovative solutions, which already affect our lives. Many other potential changes will follow.
Face recognition technology: security versus privacy	Video surveillance and face recognition systems have become the subject of increased interest and controversy after the September 11 terrorist attacks on the United States. In favor of face recognition technology, there is the lure of a powerful tool to aid national security. On the negative side, there are fears of an Orwellian invasion of privacy. Given the ongoing nature of the controversy, and the fact that face recognition systems represent leading edge and rapidly changing technology, face recognition technology is currently a major issue in the area of social impact of technology. We analyze the interplay of technical and social issues involved in the widespread application of video surveillance for person identification.
Privacy by Design [Leading Edge]	Privacy by design is the international standard for assuring privacy in the information era. In this paper a privacy by design (PbD) framework is developed to proactively embed privacy directly into information technology, business practices, physical design, and networked infrastructures.
Right to Privacy: Telephone Interception and Access in Australia	In its first thirty years of operation, the 1979 Australian Telecommunications (Interception and Access) Act moved from providing a strict prohibition on telephone interception (wiretapping), to legislating rights of access for law enforcement and revenue protection agencies [5], [6], [12][14], [18]. Currently, Australian legislation permits access to call content through the use of a warrant issued by a member of the Administrative Appeals Tribunal [5]. The legislation also allows bureaucratic authorization for access to a suspect's location information [13]. Here we consider whether the impacts of this regime are appropriate for Australians in terms of financial costs and in term of impositions on privacy rights.
Privacy in pervasive computing environments - a contradiction in terms?	Technical progress in electronics allows the transformation of visions of pervasive computing into real world options. This perspective has raised deep concerns about the survival of privacy, as central building blocks of pervasive computing are in direct conflict with the fundaments of privacy protection. Considerable efforts have been undertaken to cope with these concerns with only limited success. While pertinent efforts have resulted in solutions for single aspects, they proved insufficient to eliminate the fears; on the contrary, they highlighted the principal incompatibility of privacy and pervasive information systems. Technical concepts alone, regardless how complex they are, cannot be sufficient; rather, a mix of privacy enhancing technologies, restrictions on the utilization of pervasive computing, and new regulations required to preserve some remnants of privacy.
Commercializing public sector information privacy and security concerns	The enhanced development of information and communication technologies in government has created new opportunities for agencies to collect, share and re-use data. At the same time, the commercial worth of governmental data sets and value-added information products/services have increased. Government agencies are finding that data they have routinely collected to fulfil their statutory and business functions can now more easily be re-used for commercial purposes. The prospect of increasing revenue through the commercial re-use of public sector information (PSI) is clearly appealing for governments and their agencies. Examples of PSI that have been re-used commercially include residential property transaction details, land title information, ordanance survey data and street address registers. This article examines those shifting boundaries, particularly in light of information privacy and national security concerns arising from governmental commercialization of PSI that includes personal information. I seek to show that information privacy laws can be subverted in the face of overt commercialization by government agencies; that commercialization can have a negative impact on individuals; and can also give rise to societal concerns relating to privacy, security, and the open governance of the information society.
Privacy Compliance Risks for Facebook	Facebook is an Internet and societal phenomenon. In just a few years it has claimed a significant proportion of the world's population as regular users, becoming by far the most dominant Online Social Network (OSN). With its success has come a good deal of controversy, especially over privacy. Does Facebook and its kin herald a true shift in privacy values, or despite occasional reckless revelations, are most users actually as reserved as ever? We argue it's too early to draw conclusions about society as a whole from the OSN experience to date. However, Facebook in particular brings a number of compliance risks in jurisdictions that have enacted modern Information Privacy Law.
Privacy Implications of Automated GPS Tracking and Profiling	The automobile has gradually evolved from an analog machine with mostly mechanical and hydraulic components to an electronic system with a growing number of computer-based systems. Within this "smart car" revolution, GPS vehicle navigation has attracted significant attention. There are efforts underway to use GPS vehicle navigation infrastructure for additional value-added services, for instance, mobility pricing of insurance infrastructure-less electronic toll collection, and GPS enabled parking fee collection. This article aims to raise awareness about privacy issues created as a result of GPS-based surveillance by conducting an experiment involving collecting positional data from a number of volunteers. A software protocol is implemented that takes this GPS data as input and generates a range of personal information about the individual including their home addresses, and social and work activities.
A critique of privacy	In this polemical paper we present a Socratian dialogue that both critiques privacy and addresses its value. The purpose of this dialogue is to address questions that are often begged in the contemporary discourse around privacy, surveillance and technology - a discourse that assumes that privacy is a personal and social good without necessarily arguing the case. To prosecute the debate we have Aspicio - who will argue that privacy is a condition that is not only limited as a personal and social good, but is undesirable in many important respects. Aspicio is confronted by Occulto, who will argue that privacy is a condition that can and should be obtained and defended. In the course of the dialogue our interlocutors discuss privacy as a right; privacy and modernity; privacy, the public sphere and the private sphere; privacy and individualism; the value of surveillance; and privacy, embarrassment and shame.
Digital natives and mobile phones: A survey of practices and attitudes about privacy and security	The generation of young people who do not remember life before the Internet, who grew up surrounded by computing technology and mobile phones, are often referred to as `digital natives'. This generation has a special affinity to mobile devices - young people often carry their mobile phones with them at all times to keep a constant connection with their friends while also consuming and creating digital media. This paper presents the results of a survey of over 330 young people aged 18 to 25, which attempts to evaluate their use of mobile technology, their attitudes about security and privacy as it relates to mobile phones, as well as their perceptions of different ways how security and privacy could be improved in future mobile devices. Despite a commonly held belief that digital natives are technologically savvy, their self-assessment does not appear to support this statement. Furthermore, despite the respondents' awareness of various threats to security and privacy, very few of them actually take any concrete steps to protect their devices from unauthorized access. This paper discusses these findings and analyzes the views of young people on different authentication technologies.
The impact of personality on acceptance of privacy-sensitive technologies: A comparative study of RFID and finger vein authentication systems	The wide and rapid diffusion of ICT has created an environment where consumers must interact with new technology with which they may not be comfortably familiar. Although they often do not fully understand the technological details of these products, consumers find that they need to use a variety of services based on newly introduced ICT, such as Radio Frequency Identification Technology (RFID), Near Field Communication (NFC), or contactless Finger Vein Authentication System (FVAS). Questions regarding whether or not consumers are comfortable with a new technology and how they react when the new technology is introduced need to be addressed, especially in the case where privacy sensitive technology is concerned. This paper investigates the differences in two systems and the reaction to these differences by comparing the results of a questionnaire administered to two separate groups of subjects. It also presents findings from applying the Big-Five Test for Personal Traits to these same groups in an analysis that examines the correlation between Neuroticism and attitudes toward new ICT.
Continuous RFID-enabled authentication and its privacy implications	Radio-frequency identification (RFID) technology has gained a broad popularity in many application areas including supply chain management, retail shopping and access control. This paper explores the use of RFID at the workplace and its implications to employee privacy. In particular, we discuss the use of RFID for continuous authentication in a corporate environment. Continuous authentication provides the benefit of constant or highly periodic verification that the same authorized user accesses the computer system. In a case study presented here, employees use a knowledge- or biometric-based authentication scheme to gain initial entry to a computer system, while RFID is used subsequently to continuously verify the presence of a valid user. This paper studies the relationship between usability of such an authentication scheme and the degree of protection it provides. We also examine the balance between the increased security brought by adopting an RFID-enabled continuous authentication system and the impact that it could have on employee privacy as a result of increased tracking of many aspects of the users' activity.
Privacy, cryptography and free research	Early in July 1977, Mr. E.K. Gannett, IEEE Staff Director of Publishing Services, received a letter (with enclosures) from IEEE member J.A. Meyer of Bethesda, Maryland. The letter warned that some of those presenting papers at the forthcoming International Symposium on Information Theory sponsored by the IEEE Professional Group on Information Theory and possibly the Institute itself might be subject to prosecution by the Federal Government for violation of the Arms Export Control Act.
Towards a privacy management framework for distributed cybersecurity in the new data ecology	Cyber security increasingly depends on advance notice of emerging threats as individuals, groups or nations attempt to exfiltrate information or disrupt systems and services. Advance notice relies on having access to the right information at the right time. This information includes trace digital evidence, distributed across public and private networks that are governed by various privacy policies, inter-agency agreements, federal and state laws and international treaties. To enable rapid and assured information sharing that protects privacy, the US government needs a means to balance privacy with the need to share. In this paper, we review US laws and policies governing government surveillance and describe key elements for a privacy management framework that seeks to enable government investigations while protecting privacy in a systematic way. The framework aligns existing Federal investigative guidelines for attributing a cyberattack with concerns for automated decision making that arise from the Fourth Amendment ΓÇ£reasonable expectation of privacyΓÇ¥ and several fair information practice principles. We discuss technical challenges for those seeking to implement this framework.
FISIP: A Distance and Correlation Preserving Transformation for Privacy Preserving Data Mining	This paper devises a transformation scheme to protect data privacy in the case that data have to be sent to the third party for the analysis purpose. Most conventional transformation schemes suffer from two limits, i.e., the algorithm dependency and the information loss. In this work, we propose a novel privacy preserving transformation scheme without these two limitations. The transformation is referred to as FISIP. Explicitly, by preserving three basic properties, i.e., the first order sum, the second order sum and inner products, of the private data, mining algorithms which depend on these three properties can still be applied to public data. Specifically, any distance-based or correlation-based algorithm has the same performance on the transformed public data as on the original private data. Special perturbation can be added into FISIP transformations to increase the protection level. In the experimental results, FISIP attains data usefulness and data robustness at the same time. In summary, FISIP is able to provide a privacy preserving scheme that preserves the distance and the correlation of the private data after the transformation to the public data.
A study of trust & privacy models in pervasive computing	The pervasive systems are weaving themselves in our daily life, making it possible to collect user information invisibly, in an unobtrusive manner by even unknown parties. So trust and privacy would be a major issue in these environments. The huge number of interactions between users and pervasive devices necessitate a comprehensive trust and privacy models which unifies different technologies to precisely calculate trustworthiness of each party and maintain privacy. In this paper we review previous trust and privacy models in pervasive systems and analyze them to highlight the importance of trusted computing platforms in tackling their weaknesses.
A Quantitative Evaluation of Privacy in Location Based Services	Location based services like finding nearest restaurants or finding friends have increasingly became more common, especially to mobile users. Nevertheless, misuse of location information could represent some threats to users' privacy. Great effort has been placed to propose new techniques which try to deal with these threats, but in most of these cases, techniques were not tested in real environments. In this work we implemented some techniques and tested in a mobile environment. We conclude that the implementation of privacy techniques in this environment is feasible and presented acceptable response time.
A modular concept of e-voting system that protects user privacy using random password distribution	We present a modular concept of e-voting system which ensures that registered voter can vote only once, while at the same time voters privacy is protected. This means that user identity can not be linked to a vote casted by the user. This is ensured by using random password distribution, where there is no trace in the system about the password that certain voter used for the voting session. Concept is simple, and is described using modules with basic assignments. Because of this, within this system, it is easy to recognize a place for any process defined in existing e-voting systems. This way, solution for password distribution given in this paper can be applied to different e-voting systems without many complicated modifications.
Privacy-Preserving Collaborative Recommender Systems	Collaborative recommender systems use various types of information to help customers find products of personalized interest. To increase the usefulness of collaborative recommender systems in certain circumstances, it could be desirable to merge recommender system databases between companies, thus expanding the data pool. This can lead to privacy disclosure hazards during the merging process. This paper addresses how to avoid privacy disclosure in collaborative recommender systems by comparing with major cryptology approaches and constructing a more efficient privacy-preserving collaborative recommender system based on the scalar product protocol.
Normality Mining: Privacy Implications of Behavioral Profiles Drawn From GPS Enabled Mobile Phones	There is growing interest in the ways in which the location of a person can be utilized by new applications and services. Recent advances in mobile technologies have meant that the technical capability to record and transmit location data for processing is appearing in off-the-shelf handsets. This opens possibilities to profile people based on the places they visit, people they associate with, or other aspects of their complex routines determined through persistent tracking. It is possible that services offering customized information based on the results of such behavioral profiling could become commonplace. However, it may not be immediately apparent to the user that a wealth of information about them, potentially unrelated to the service, can be revealed. Further issues occur if the user agreed, while subscribing to the service, for data to be passed to third parties where it may be used to their detriment. Here, we report in detail on a short case study tracking four people, in three European member states, persistently for six weeks using mobile handsets. The GPS locations of these people have been mined to reveal places of interest and to create simple profiles. The information drawn from the profiling activity ranges from intuitive through special cases to insightful. In this paper, these results and further extensions to the technology are considered in light of European legislation to assess the privacy implications of this emerging technology.
Privacy-Preserving Outlier Detection Through Random Nonlinear Data Distortion	Consider a scenario in which the data owner has some private or sensitive data and wants a data miner to access them for studying important patterns without revealing the sensitive information. Privacy-preserving data mining aims to solve this problem by randomly transforming the data prior to their release to the data miners. Previous works only considered the case of linear data perturbations - additive, multiplicative, or a combination of both - for studying the usefulness of the perturbed output. In this paper, we discuss nonlinear data distortion using potentially nonlinear random data transformation and show how it can be useful for privacy-preserving anomaly detection from sensitive data sets. We develop bounds on the expected accuracy of the nonlinear distortion and also quantify privacy by using standard definitions. The highlight of this approach is to allow a user to control the amount of privacy by varying the degree of nonlinearity. We show how our general transformation can be used for anomaly detection in practice for two specific problem instances: a linear model and a popular nonlinear model using the sigmoid function. We also analyze the proposed nonlinear transformation in full generality and then show that, for specific cases, it is distance preserving. A main contribution of this paper is the discussion between the invertibility of a transformation and privacy preservation and the application of these techniques to outlier detection. The experiments conducted on real-life data sets demonstrate the effectiveness of the approach.
An Analysis of Random Projection for Changeable and Privacy-Preserving Biometric Verification	Changeability and privacy protection are important factors for widespread deployment of biometrics-based verification systems. This paper presents a systematic analysis of a random-projection (RP)-based method for addressing these problems. The employed method transforms biometric data using a random matrix with each entry an independent and identically distributed Gaussian random variable. The similarity- and privacy-preserving properties, as well as the changeability of the biometric information in the transformed domain, are analyzed in detail. Specifically, RP on both high-dimensional image vectors and dimensionality-reduced feature vectors is discussed and compared. A vector translation method is proposed to improve the changeability of the generated templates. The feasibility of the introduced solution is well supported by detailed theoretical analyses. Extensive experimentation on a face-based biometric verification problem shows the effectiveness of the proposed method.
PUPDroid - Personalized user privacy mechanism for android	The technological progress of mobile devices, the low cost of this device and the facility of use are increasing the usability of mobile devices. Since these devices provide access to network, its owner has access to almost limitless amount of data and can store more information than in his personal computer (like phone call record, list of contact and calendar). A point of attention is that these devices have some resources that, if misused, can be dangerous to the owner. The major number of existing mobile devices Operational System does not allow the owner to manage how the installed application installed is using hardware device and personal information. In this paper we will present a mechanism to transfer the control of access permission to the owner's device with personalized roles. The idea behind the mechanism is to provide to the device owner a way to control the access permission by installed applications providing flexibility to personalize the application privacy. Since the platform does not allow the user to change the application permission after it is installed, Android was chosen to develop the proof of concept of the mechanism because it is an open source mobile operational system. The results show that the mechanism will allow Android user to improve his device privacy and control how it is used since the roles of access for each application can be personalized. The mechanism will also provide a way for enterprises to build an application to manage the employee's device privacy.
Addressing health information privacy with a novel cloud-based PHR system architecture	Patient Health Records (PHRs) shift the ownership of health data from health providers to patients. Such a shift poses important challenges from the data privacy point of view. Patients would like to be able to selectively reveal information to other stakeholders and, at the same time, be assured that their health information will not be used improperly once shared. Current PHR systems partially fail to satisfy these requirements. In this paper, we show that both requirements can be satisfied fully when adopting a novel cloud-based PHR system architecture.We expain the role of remote virtual machines in this architecture and use interaction models to reason about privacy implications. Finally, we evaluate MyPHRMachines, a prototypical implementation of the architecture: we demonstrate that the system enables the execution of third party genome analysis services on patientowned genome data while ensuring that (1) such services cannot maliciously store this data and (2) patients can show the analysis results to experts without sharing along their full genome.
Secure and privacy-preserving biometrics based active authentication	User authentication is critical in preventing system breaches. Existing authentication approaches usually do a onetime log-in authentication, but rarely incorporate mechanisms to differentiate the initial log-in user and the user who is currently taking control of the system, which may cause post-authentication breaches. In this paper, we study user authentication for both login session and post-authentication session and propose a biometrics based active authentication approach. Moreover, concerning the usage of biometrics, the system is biometrics-secure and privacy-preserving. Security analysis and experimental results prove that the proposed approach is secure, resilient to various attacks and effective.
Trust-based privacy preservation for peer-to-peer data sharing	Privacy preservation in a peer-to-peer (P2P) system tries to hide the association between the identity of a participant and the data that it is interested in. This paper proposes a trust-based privacy-preservation method for P2P data sharing. It adopts the trust relation between a peer and its collaborators (buddies). The buddy works as a proxy to send the request and acquire the data. This provides a shield under which the identity of the requester and the accessed data cannot be linked. A privacy measuring method is presented to evaluate the proposed mechanism. Dynamic trust assessment and the enhancement to supplier's privacy are discussed
A scheme for privacy-preserving data dissemination	An adequate level of trust must be established between prospective partners before an interaction can begin. In asymmetric trust relationships, one of the interacting partners is stronger. The weaker partner can gain a higher level of trust by disclosing private information. Dissemination of sensitive data owned by the weaker partner starts at this moment. The stronger partner can propagate data to others, who may then choose to spread data further. The proposed scheme for privacy-preserving data dissemination enables control of data by their owner (such as a weaker partner). It relies on the ideas of bundling sensitive data with metadata, an apoptosis of endangered bundles, and an adaptive evaporation of bundles in suspect environments. Possible applications include interactions among patients and healthcare providers, customers and businesses, researchers, and suppliers of their raw data. They will contribute to providing privacy guarantees, which are indispensable for the realization of the promise of pervasive computing
Secure knowledge management: confidentiality, trust, and privacy	Knowledge management enhances the value of a corporation by identifying the assets and expertise as well as efficiently managing the resources. Security for knowledge management is critical as organizations have to protect their intellectual assets. Therefore, only authorized individuals must be permitted to execute various operations and functions in an organization. In this paper, secure knowledge management will be discussed, focusing on confidentiality, trust, and privacy. In particular, certain access-control techniques will be investigated, and trust management as well as privacy control for knowledge management will be explored
Hierarchical Pareto Curve model for privacy skyline	Privacy is an essential issue in database publishing. Since the introduction of skyline operator in database community, there was a few researches working on the privacy skyline and related the privacy theory, framework and model in last few years. For those algorithms (e.g. Skyline Check and Privacy Diagnostics), centralized database is assumed and the consideration of concurrency and parallelism is in lack. In this paper, we propose the hierarchical Pareto curve (HPC) model for private skyline processing. In HPC, answers to the skyline query are interpolated by spline function and represented by a set of polynomial Pareto curves. Hence, skyline querying requests can be satisfied without disclosing the actual data points. Moreover, the accuracy of a skyline query can be controlled by setting the order of the polynomial expression and total number of Pareto curves. The HPC model can be extended for distributed and cooperative computing environments. With privacy embedded in piecewise Pareto curves and merging operators developed, distributed skyline processing becomes practical. From our preliminary experiments, the results show supportive indications towards the HPC model.
Privacy preserving K-Medoids clustering	Privacy is an important issue in the collaborative data mining since privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties collaboratively conduct data mining without breaching data privacy presents a challenge. This paper seeks to investigate solutions for privacy- preserving K-Medoids clustering which is one of data mining tasks.
Research on context-aware architecture for personal information privacy protection	In pervasive environment, context-aware service provider can use personal information to customize the adequate services for end users. Personal information is people's privacy concern. Therefore, people need privacy control methods. In this paper, we analyzed privacy control from two aspects: personal privacy model about information disclosure and the function of context-aware service provider. According to the analysis, we designed the components about context-aware privacy control in order to minimize the burden of personal privacy decision about personal information disclosure. The simulation experiment shows that it is possible method for the proposed privacy protection mechanism. Finally, we also proposed conceptual context-aware architecture to control personal information disclosure.
Privacy preserving database access through dynamic privacy filters with stable data randomization	There are scenarios where using production databases for testing are unavoidable. In a time/mission-critical situation where a developer is required to fix a bug immediately the only option is use production database for testing. However, this may pose a violation of privacy. In this paper, we describe a different approach utilizing a privacy filter that examines queries from an application to match with predefined privacy policy to decide the result return. The approach is illustrated using a prototype which was implemented with query modification and data randomization techniques.
Privacy of encrypted voice-over-IP	In this paper, we present an early study on how timing-based traffic analysis attacks can be used to reconstruct the communication on end-to-end VOIP systems by taking advantage of the reduction or suppression of the generation of traffic whenever the sender detects a voice inactivity period. We describe a simple Bayesian classifier to identify simple voice signals from the pattern of packet timings. We then proceed to incorporate context awareness by using a Hidden Markov model. Experiments with very simple symbols show that the effectiveness to reconstruct the voice signal depends significantly on the quality of collected silence suppression information. We conclude by identifying a number of problems that need to be further studied in order to effectively assess the danger of silence suppression based attacks on VOIP systems.
Privacy management system using social networking	The worldwide growth of e-services has brought to the forefront the importance of private data management for an organization. However, the advancement of computer and networking technologies has made privacy management very challenging. In this paper, we expose the limitations of existing privacy management systems, and present a privacy management system that exploits social network analysis, which can automatically discover the privacy-related workflow models, and support automated privacy management within an organization.
Privacy-Oriented Collaborative Learning Systems	This paper addresses the problem of data sharing among multiple parties in the following scenario: without disclosing their private data to each other, multiple parties, each having a private data set, want to collaboratively construct support vector machines using a linear, polynomial or sigmoid kernel function. To tackle this problem, we develop a secure protocol for multiple parties to conduct the desired computation. In our solution, multiple parties use homomorphic encryption and digital envelope techniques to exchange the data while keeping it private. All the parties are treated symmetrically: they all participate in the encryption and in the computation involved in learning support vector machines.
Privacy Enhanced and Light Weight RFID System without Tag Synchronization and Exhaustive Search	Radio frequency identification systems (RFID systems) are becoming popular in various applications, such as supply chain management, animal husbandry and so on. They are useful to manage not only things but also living things. Privacy, however, must be taken in account when they are used around people since people with RFID tags can easily be tracked and traced. While several solutions have been proposed to solve this problem, they have drawbacks that the back-end servers (or the readers) must exhaustive-search all the registered IDs to identify the RFID tags and/or that database must synchronize with the tags. The former is not desirable when a huge number of RFID tags must be managed, and the latter is not desirable when restoring database from backup (since tags and the database are not synchronous after restoration). In this paper, we propose how to solve these problems without deteriorating the privacy protection ability.
Construction of the Enterprise-level RFID Security and Privacy Management Using Role-Based Key Management	The RFID technique is extensively applied in e-Business scope. It mainly supports the quickly and accurately work for the advanced assets management. But it is still lack of privacy protection on the EPC code. For the worse case, some hackers may steal the code content easily during the cooperative business transmissions. It will cause the business secret leaking or even the consumer privacy damage. To encrypt the EPC code, we propose a two phase identification and authentication protocol with RBAC architecture to assure security. The EPC code is separates randomly into two parts by the secret sharing method. Only the one half of the EPC code is encrypted and stored in the RFID tags. The other part of the EPC code was encrypted by the private key and stored at the backend system for later decrypted used. The EPC code is decrypted when these two parts are decrypted and merged. When the owner of the tag is changed, the encrypt EPC code is merged then separated again. In this way, it is impossible has the same encrypt EPC code on the RFID tag when the owner is changed. The reader must be authorized to get the secret key before scanning and extracting the corresponding product information. Hence, it can ensure that RFID tag will not reveal important information even though it is scanned by fake or non-authorization reader. We also proposed a key management based on role-base access control method to distribute the access key and the encryption/decryption key, which aligns well with the role and the business process in a supply chain. The secret keys are managed by the role-based assignment at the enterprise level rather than at the individual level. It not only provides with more efficiency and flexibility on the role's key management, but also enhances the security of the enterprise-level RFID system. Therefore, the number of the secret key to be managed is also reduced. With the proposed identification and authentication protocol, the RFID content is can encrypted ef- ficiently to avoid the information eavesdropping on the RFID system.
Lightweight Privacy for Ubiquitous Devices	In this paper, we survey the recent research results on privacy-preserving Identification suitable for limited-resource devices such as RFID, contactless smartcards, and introduce our recent results on a light-weight privacy-preserving identification scheme. The proposed scheme only requires (1) random bit generators, (2) simple bit-wise operations and (3) short storage for keys less than 1 Kbits. No cryptographic algorithms such as SHA-1 are required. On the other hand, security of the scheme is reducible to learning parity -with noise problem (LPN problem) which is further reducible to a problem in NP-complete.
Minimally privacy-violative system for locating human by ultrasonic radar embedded on ceiling	Violating the privacy of individuals with systems that measure daily human activities is unacceptable in our society. In this paper, the authors propose a system using ultrasonic radar embedded in the ceiling of a room to locate human individuals with a minimum violation of privacy. It is expected that this system is used in the prevention of accidents among aged persons suffering from Alzheimer's disease. The proposed system determines the three-dimensional position of a person's head by assuming that the human head is an object that will move at a relatively high vertical position within a living area. In this study, the method used to locate the human head is analyzed theoretically from the perspective of acoustics. The feasibility of the proposed system is confirmed by experimental results using a system constructed by the authors.
Privacy issues in the ubiquitous information society and law in Japan	It is said that the ubiquitous information society is overcome by technological developments. It seems that privacy and other legal issues that have been not thought so far is the cause in the society. To realize safe and reliable ubiquitous information society, it is important to prescribe privacy guidelines that ubiquitous information systems should meet and examine legal issues from an initial stage of the development of technology. This paper points out privacy issues in the ubiquitous information society, presents privacy guidelines and systems to protect privacy and examines legislation problems in Japan.
Privacy issues of combining ubiquitous computing and software agent technology in a life-critical environment	Ubiquitous computing and software agents allow a high degree of decentralization, the capability to process an increasing amount of information and the ability to react in real-time on changes in the environment. They are thus capable to support highly dynamic environments like logistics processes in hospitals. However, giving up centralized control means also a dependency upon common rule sets and the question how decentralized entities can be enforced to adhere to regulations and definitions which are deemed imperative by the human systems designer and to assure acceptability. The paper shows the methods and concepts applied in EMIKA and their reflection regarding the specific requirements of the hospital application.
Towards users driven privacy control	For widely available and acceptable dynamic Web and mobile applications, users privacy concerns should be well considered and effectively maintained. Users should be able to control their private information collection by most Web applications and third parties. A functional architecture is proposed that allows users to automatically control coming requests for their private information either based on fuzzy reasoning or by predefined users privacy preferences. In addition, users are given manual control capabilities in cases of uncertain automatic behavior. The proposed approach has been implemented in the MIES platform in the university campus. Results obtained are promising.
Role based privacy applied to context-aware mobile applications	Sharing of personal information in context aware applications challenges the application design since users wish to restrict and control the information access according to in which situation and with whom the information is shared. We introduce a mobile application, privacy studio, which enables the user to define different information sharing levels for distinct user groups. This is done by defining privacy profiles, which are applied in certain usage situations to define information sharing access rights to different target groups. We have demonstrated privacy studio mobile application with a mobile phone, and evaluated and assessed the users' perceptions in relation to information sharing and privacy with user tests. Positive feedback related to the efficient and easy way of information sharing was gained, whereas potential privacy risks were seen as a major concern with the application.
Hiding sensitive items in privacy preserving association rule mining	Privacy-preserving data mining [Agrawal, R., et al., May 2000] has recently emerged to address one of the negative sides of data mining technology: the threat to individual privacy. For example, through data mining, one is able to infer sensitive information, including personal information or even patterns, from non-sensitive information or unclassified data. There have been two broad approaches for privacy-preserving data mining. The first approach is to alter the data before delivery to the data miner so that real values are obscured. The second approach assumes the data is distributed between two or more sites, and these sites cooperate to learn the global data mining results without revealing the data at their individual sites. Given specific rules to be hidden, many data altering techniques for hiding association, classification and clustering rules have been proposed. However, to specify hidden rules, entire data mining process needs to be executed. For some applications, we are only interested in hiding certain sensitive items. In this work, we assume that only sensitive items are given and propose two algorithms to modify data in database so that sensitive items cannot be inferred through association rules mining algorithms. Examples illustrating the proposed algorithms are given. The efficiency of the proposed approach is further compared with Dasseni etc. (2001) approach. It is shown that our approach required less number of databases scanning and prune more number of hidden rules. However, our approach must hide all rules containing the hidden items on the right hand side, where Dasseni's approach can hide specific rules.
Privacy-oriented discovery of interesting pattern from numeric attributes	The use and dissemination of the sensitive information is one of the major issues causing concern surrounding knowledge discovery. Existing mining algorithm use the discretization method to partition each numeric attribute into a set of interval during data prepossessing phase. However, not only can such method bring the problem of producing many irrelevant and uninteresting patterns, but also the information is disclosed. In this paper, we propose a new framework to address this issue. The new approach first perturbs and transforms the original data set based on a set of different belief level without information loss. After that, the transformed data are sent to the data mining consultancy, then rules under different belief levels are generated. After that, the interesting filter is used to eliminate the redundant rules. Rules are useful only in the context of partition performed by the data provider and there is no information disclosure. The proposed technique has been applied to a number of sensitive real life data sets. Experiments results show that our proposed technique is very effective especially when there are many numeric attributes in the data set.
Distributed planning and monitoring in a dynamic environment: trade-offs of information access and privacy	Distributed planning and monitoring relies on wide, lateral information access that may promote anticipatory behaviour, opportunistic planning and redundant checking and monitoring. The reliability of the resulting system performance is thus enhanced. However, information access control is often critical given the wide adoption of information technology. After presenting findings of several field studies related to the strategies used by distributed team members in managing information access control, we highlight how inefficiencies in information flows are exploited to achieve information access control. We then present implementation strategies for a video-based coordination platform to resolve the trade-off between information access and privacy. In particular, a role-based assignment of information access, along with mechanisms of controlling levels of information access was used to balance the potential loss of privacy with the gain in coordination efficiency.
Selected privacy and security issues in digital government	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01173443.png" border="0">
Securing our nation and protecting privacy	In recent times, our nation's network infrastructure has continually been under attack by hackers from around the globe. From career criminals to other government agencies outside the U.S., network attacks and intrusions are increasing. Their attacks including the 2009 Distributed Denial of Service (DDoS) attacks caused massive outages for website of government agencies. Additionally, the 2010 and ongoing WikiLeaks attack led to catastrophic results that threaten U.S. diplomacy. Unfortunately, the United State response has been slow and painstaking. In 2009, our nation faced a massive DDoS attack that caused many government websites that include White House, Department of Defense, Homeland Security, and the Federal Aviation Administrators to lose service. Approximately 60,000 infected computers were used to launch the attacks. In addition, the 2009 DDoS attacks also targeted commerce and news media sites. In response to these attacks, the Department of Defense and the Department of Homeland Security have increased their methods and resources to help secure our nation's infrastructure. This research will ask, if this is enough to secure the nation, and what other new technologies can these agencies employ to thwart the attacks? As much as our government is facing countless attacks, corporations and businesses have also faced attacks. Attacks including the2007 TJX Security Breach resulted in millions of credit card numbers and other confidential consumer information to be compromised. In 2009, the Heartland Payment Systems followed resulting in 100 million credit cards being compromised. Both cases, information was captured by hackers; it was distributed to illegal ΓÇ£so calledΓÇ¥ dump sites and trading forums in which confidential data ranging from PIN to social security numbers are traded online and distributed worldwide. What new technologies can the corporate sector explore to secure consumers' information? Consumers' privacy has also been an issue- - for Information Security. In the United States, privacy laws have favored the corporate interest. Consumers' information is constantly distributed to other third party members without acknowledgement. In contrast, European laws have favored the individual by enforcing strict privacy laws that prevents the corporate sector to distribute information without acknowledgment. This research will determine if these tough privacy laws better protect consumers' information from security breaches. If so, can they implement them here in the United States? As the number of attacks and security breaches continue to rise, we must act now to the growing demands of security. Our nation and its economy rely heavily on our information infrastructure; we must build the defenses that ensure confidentiality, integrity, and availability within our nation and its infrastructure.
Using User Preferences to Enhance Privacy in Pervasive Systems	With the increasing interest in developing pervasive computing technologies there is growing recognition of the problems of maintaining user privacy. In the Daidalos pervasive system this is achieved primarily through the use of virtual identities, which are used to conceal the real identity of the user. One problem with this lies in determining to what extent the user should be engaged in the decisions relating to the selection of virtual identities, and what can be done automatically. The solution lies in creating a set of user preferences to assist in taking these decisions, refining them through the use of machine learning techniques. This paper outlines the approach being investigated and describes how this will be achieved when the processes involved in building up user preferences are not trusted.
Security and privacy aspects of SmartFlow Internet payment system	Smart cards are replacing traditional magnetic cards for payment transactions. One of the main reasons is enhanced security capabilities that can be built in a smart card. With the high popularity of web technology, there is a trend towards smart cards being used as an electronic wallet for payment transactions on Internet. Most of the related work of smart card payment transactions concentrates only on the security aspects of hardware/firmware, encryption method and key management, or they only propose the online shopping protocol for uni-directional payment transaction based on the scenery of exact payment from the elastomer to merchant during business activity. We developed a prototype system called "SmartFlow" to demonstrate these kinds of business activities on Internet by smart card. The main focus of this paper is to present the framework of "SmartFlow" and some important security and privacy issues for bi-directional payment transaction with change among more than two parties involved business activity. Further, we present the application of downloading software license key from Internet into smart card in SmartFlow environment. We have already implemented a prototype "SmartFlow" system with these functionalities.
Human-Factor-Aware Privacy-Preserving Aggregation in Smart Grid	Privacy-preserving metering aggregation is regarded as an important research topic in securing a smart grid. In this paper, we first identify and formalize a new attack, in which the attacker could exploit the information about the presence or absence of a specific person to infer his meter readings. This attack, coined as human-factor-aware differential aggregation (HDA) attack, cannot be addressed in existing privacy-preserving aggregation protocols proposed for smart grids. We give a formal definition on it and propose two novel protocols, including basic scheme and advanced scheme, to achieve privacy-preserving smart metering data aggregation and to resist the HDA attack. Our protocol ensures that smart meters periodically upload encrypted measurements to a (electricity) supplier/aggregator such that the aggregator is able to derive the aggregated statistics of all meter measurements but is unable to learn any information about the human activities. We present the formal security analysis for the proposed protocol to guarantee the strong privacy. Moreover, we evaluate the performance of our protocol in a Java-based implementation under different parameters. The performance and utility analysis shows that our protocol is simple, efficient, and practical.
Practical Minimalist Cryptography for RFID Privacy	The fear of unauthorized, hidden readouts has dominated the radio frequency identification (RFID) privacy debate. Virtually all proposed privacy mechanisms so far require consumers to actively and explicitly protect read access to their tagged items-either by jamming rogue readers or by encrypting or pseudonymizing their tags. While this approach might work well for activists and highly concerned individuals, it is unlikely (and rather undesirable) that the average consumer should be outfitted with RFID jamming devices before stepping outside, or that anyone would bother pseudonymizing every can of soda they buy with a personal PIN code. Juels' ldquominimalist cryptographyrdquo offers a simple, yet effective, identification and tracking protection based on simple ID rotation, but it requires that the corresponding mappings (i.e., from pseudonyms to real IDs) are electronically exchanged whenever a product changes hands (e.g., for buying a pack of chewing gum at a kiosk)-a rather impractical requirement. Our work extends Juels' concept in order to alleviate the need for passing ID mapping tables. Using carefully assembled sets of IDs based on the cryptographic principle of secret shares, we can create RFID tags that yield virtually no information to casual ldquohit-and-runrdquo attackers, but only reveal their true ID after continuous and undisturbed reading from up-close-something that can hardly go unnoticed by an item's owner. This paper introduces the underlying mechanism of our extension to Juels' proposal, called ldquoShamir Tag,rdquo analyzes its tracking resistance and identification performance, and discusses deployment aspects.
Adversaries and Countermeasures in Privacy-Enhanced Urban Sensing Systems	Today's digital society increasingly relies on the interconnection of heterogenous components, encompassing assorted actors, entities, systems, and a variety of (often mobile) computing devices. Revolutionary computing paradigms, such as people-centric urban sensing, have focused on the seamless collection of meaningful data from a large number of devices. The increasing complexity of deployed urban systems and related infrastructures, along with the growing amount of information collected, prompts a number of challenging security and privacy concerns. In this paper, we explore a number of scenarios where nodes of a urban sensing system are subject to individual queries. In this setting, multiple users and organizations (e.g., infrastructure operators) co-exist, but they may not trust each other to the full extent. As a result, we address the problems of protecting: 1) secrecy of reported data, and 2) confidentiality of query interests from the prying eyes of malicious entities. We introduce a realistic network model and study different adversarial models and strategies, distinguishing between resident and nonresident adversaries, considering both randomly distributed and local attackers. For each of them, we propose a distributed privacy-preserving technique and evaluate its effectiveness via analysis and simulation. Our techniques are tunable, trading off the level of privacy assurance with a small overhead increase, and independent from the complexity of the underlying infrastructures. We additionally provide a relevant improvement of data reliability and availability, while only relying on standard symmetric cryptography. The practicality of our proposals is demonstrated both analytically and experimentally.
Privacy-Preserving Mining of Association Rules From Outsourced Transaction Databases	Spurred by developments such as cloud computing, there has been considerable recent interest in the paradigm of data mining-as-a-service. A company (data owner) lacking in expertise or computational resources can outsource its mining needs to a third party service provider (server). However, both the items and the association rules of the outsourced database are considered private property of the corporation (data owner). To protect corporate privacy, the data owner transforms its data and ships it to the server, sends mining queries to the server, and recovers the true patterns from the extracted patterns received from the server. In this paper, we study the problem of outsourcing the association rule mining task within a corporate privacy-preserving framework. We propose an attack model based on background knowledge and devise a scheme for privacy preserving outsourced mining. Our scheme ensures that each transformed item is indistinguishable with respect to the attacker's background knowledge, from at least k-1 other transformed items. Our comprehensive experiments on a very large and real transaction database demonstrate that our techniques are effective, scalable, and protect privacy.
How to Enhance Privacy Within DaaS Service Composition?	The composition of data-as-a-service (DaaS) services is a powerful solution for building value-added applications on top of existing ones. However, privacy concerns are still among the key challenges that keep hampering DaaS composition. Indeed, services may follow different, conflicting privacy specifications with respect to the data they use and provide. In this paper, we propose an approach for the privacy-aware composition of DaaS services. Our approach allows us to specify privacy requirements and policies and verify the compatibility of services involved in a composition. We propose an adaptation protocol that makes it possible to reconcile the privacy specifications of services when incompatibilities arise in a composition. We validate the applicability of our proposal through a set of experiments.
Reclaiming Location Privacy in Mobile Telephony NetworksΓÇöEffects and Consequences for Providers and Subscribers	Mobile telephony (e.g., Global System for Mobile Communications [GSM]) is today's most common communication solution. Due to the specific characteristics of mobile communication infrastructure, it can provide real added value to the user and various other parties. Location information and mobility patterns of subscribers contribute not only to emergency planning, general safety, and security, but are also a driving force for new commercial services. However, there is a lack of transparency in today's mobile telephony networks regarding location disclosure. Location information is generated, collected, and processed without being noticed by subscribers. Hence, by exploiting subscriber location information, an individual's privacy is threatened. We develop a utility-based opponent model to formalize the conflict between the additional utility of mobile telephony infrastructure being able to locate subscribers and the individual's privacy. Based on these results, measures were developed to improve an individual's location privacy through a user-controllable GSM software stack. To analyze and evaluate the effects of specific subscriber provider interaction, a dedicated test environment will be presented, using the example of GSM mobile telephony networks. The resulting testbed is based on real-life hardware and open-source software to create a realistic and defined environment that includes all aspects of the air interface in mobile telephony networks and thus, is capable of controlling subscriber-provider interaction in a defined and fully controlled environment.
Efficient Constructions of Anonymous Multireceiver Encryption Protocol and Their Deployment in Group E-mail Systems With Privacy Preservation	We first propose an efficient anonymous multi-receiver encryption scheme to achieve the security properties of confidentiality and anonymity, which protects the receiver identity privacy and keeps the message confidential. The anonymity of proposed scheme is secure against outer attackers and inner attackers simultaneously. Based on the first construction, we also present a dual-anonymous multireceiver encryption that supports the security properties such as identity privacy of both sender and receiver, sender undeniability, forward security, and forward anonymity, which has a perfect premise for privacy-carrying e-mail systems. We design a deployment in a secure e-mail delivery system and give some experimental results. We evaluate the performance in theoretical analysis and practical assessment, and show that our proposed schemes achieve an effective balance in strong security, low computation cost, and light communication load.
Evaluation of Privacy and Security Risks Analysis Construct for Identity Management Systems	This paper evaluates a taxonomy of privacy and security risks contributing factors with the Delphi method. The taxonomy was introduced in a previous work, and it is based on characteristics of tokens used in identity management systems (IDMSs). The taxonomy represents a construct for risk analysis in IDMSs. Constructs are concepts, terms, or vocabularies and symbols adopted or developed to describe, conceptualize, or define the problems and solutions within a domain. We can determine the performance and utility of a construct through evaluation. Evaluation can determine constructs' completeness, simplicity, elegance, ease of use, and understandability. Evaluation of a construct can be done with the Delphi method. The Delphi method solicits expert opinions on a subject matter in a structured group communication process. The Delphi evaluation of the taxonomy led to additional privacy and security risks contributing factors that were not covered in the initial taxonomy. Furthermore, the evaluation identified three key risk indicators and showed that the experts mostly agreed with our initial risk analysis construct for IDMSs.
Outer system flow privacy protection	Nowadays, social networks, information networks and technological networks have already become main media of information publication and exchange. Meanwhile, the information diffusion in these networks is well studied. However, most privacy protection technologies, e.g., access control, have not considered the influence of these networks systematically. In this paper, a concept of outer system flow privacy control is proposed. In addition, system privacy requirements are reconsidered. Furthermore, in user case, role base access control (RBAC) is analyzed and improved based on the outer system flow control.
Intelligent strategies for secure complex systems integration and design, effective risk management and privacy	There has been increasing challenges in the effective design of engineering complex integrated systems and systems-of-systems in engineering and network systems. This is largely due to the integration of complex large data transfers across multiple zones of systems and network integration. The increase in transmission of highly sensitive data and challenges of data protection and of privacy, data loss prevention has major significant implications for systems engineering, systems integration, and systems analysis, design and validation. Furthermore, the design and development of complex integrated systems engineering and network systems lack effective transparency, auditability, validation and implementation of adequate security measures for transfers of highly sensitive metadata across global networks using third party and outsourced networks and the Internet and global privacy regulatory requirements for such data transfer across international borders. The major problem with current state of art approaches of controls for global critical infrastructures of virtual private networks (VPN) depend on inadequate third-party systems. Thus current approaches lack transparency, auditability and validation of the implementation of adequate privacy and security controls for data transfers of highly sensitive metadata across global networks. The additional problem of obscurity has resulted in increasing concealing of unauthorized access, identity thefts, privacy and security breaches of highly sensitive data, interception through the man-in-the-middle and intermediary systems. The paper examines the effectiveness, resiliency, robustness, scalability and adaptability in the design, safety, security and usability of engineering complex integrated systems and network systems for complex large data transfers across multiple zones of systems and network integration and security.
Situating anonymization within a privacy risk model	Privacy risk analysis of complex socio-technical systems suffers from an inadequate risk model that focuses primarily on some form of Fair Information Practice Principles (FIPPs). Anonymization as a privacy risk control suffers from an emphasis on risk of failure, neglecting the circumstances surrounding its selection as a risk control in the first place. By interrelating an enhanced privacy risk model that goes beyond FIPPs and an integrated anonymization framework, the selection and implementation of anonymization as a privacy risk control can be more systematically considered and carried out. The Science and Technology Directorate of the U.S. Department of Homeland Security has sponsored development of both an integrated anonymization framework and an enhanced privacy risk model to support more effective privacy risk management. Both of these are described at a high level and their interoperability illustrated by application to the Google Street View controversy.
HIP Tags Privacy Architecture	This paper describes an innovative and highly secure networking architecture, dedicated to the Internet of things (IoT). We propose an infrastructure that works with a new type of tags, supporting the recently standardized host identity protocol (HIP). Our main concern is to ensure RFID tags privacy, while enabling things to things communications.
Privacy-Invasive Software and Preventive Mechanisms	Computers are increasingly more integrated into peoples├é┬┐ daily lives. In this development, user privacy is affected by the occurrence of privacy-invasive software (PIS), sometimes loosely labelled as spyware. The border between legitimate software and PIS is vague and context dependent, at best specified through End-User License Agreements (EULA). This lack of spyware definition result in that current countermeasures are bound to noticeable misclassification rates. In this work we present a classification of PIS from which we come to the conclusion that additional mechanisms that safeguard users├é┬┐ consent during software installation is needed, to effectively counteract PIS. We further present techniques that counteract PIS by increasing user awareness about software behaviour, which allow users to base their software installation consent on more informed decisions.
A System for Managing Vehicle Location Data with Optimal Privacy Features	The high amount of vehicle location data, which come from various sources, raises serious privacy concerns. In this paper, we describe a system to store location data in such a way that privacy can be enforced according to standard requirements. The system maximizes the precision of location data in order that they can be profitable exploited for positive purposes, like crime fighting. The core of the system is the strategy used to reach this goal that combines the approaches of k-anonymity and location obfuscation to preserve privacy and uses a dynamic-programming technique to find the solution compliant with the privacy requirements and having the best accuracy.
An Approach for Protecting Privacy on Social Networks	Social networking has become a part of our life. We redundantly share our personal information with people in social networks and Internet. These networks allow users to share just about everything: data, photos, videos, favorite music, status updates, and more applications. Sharing large amounts of information causes privacy and security problems for users in these networks. To prevent privacy problems, we can provide built-in applications that help to protect our privacy by limiting the friends who get access to our personal information. Many users still do not make use of these applications. Users fail to use the application either because they are not aware that it exists or because of the tedious process that is involved when manually grouping friends into different categories to form a friends list. The privacy problem has prompted us to provide a solution that offers the social networks users an opportunity to protect their privacy. In this study, a privacy and security technique, its algorithm and design were mentioned. Our approach proposes an API, which provides grouping of friends through an automated system into different social groups by analyzing the user's social graph and depending on what common information they would like to share that should not be accessed by other friends. We assume that a user shares the same information in a group, as we call social circles. Finding these social circles will help users to group their friends easily and meaningfully.
Protecting Digital Data Privacy in Computer Forensic Examination	Privacy is a fundamental human right defined in the Universal Declaration of Human Rights. To enable the protection of data privacy, personal data that are not related to the investigation subject should be excluded during computer forensic examination. In the physical world, protection of privacy is controlled and regulated in most countries by laws. Legislation for handling private data has been established in various jurisdictions. In the modern world, the massive use of computers generates a huge amount of private data and there is correspondingly an increased expectation to recognize and respect human rights in digital investigation. However, there does not exist a forensically sound model for protecting private data in the context of digital investigation, and it poses a threat to privacy if the investigation involves the processing of such kind of data. In this paper, we try to address this important issue and present a cryptographic model designed to be incorporated into the current digital investigation framework, thereby adding a possible way to protect data privacy in digital investigation.
Privacy Preserving Decision Tree Mining from Perturbed Data	Privacy preserving data mining has been investigated extensively. The previous works mainly fall into two categories, perturbation and randomization based approaches and secure multi-party computation based approaches. The earlier perturbation and randomization approaches have a step to reconstruct the original data distribution. The new research in this area adopts different data distortion methods or modifies the data mining techniques to make it more suitable to the perturbation scenario. Secure multi-party computation approaches which employ cryptographic tools to build data mining models face high communication and computation costs, especially when the number of parties participating in the computation is large. In this paper, we propose a new perturbation based technique. In our solution, we modify the data mining algorithms so that they can be directly used on the perturbed data. In other words, we directly build a classifier for the original data set from the perturbed training data set.
Privacy Concerns, Trust in Government and Attitudes to Identity Cards in the United Kingdom	In the present paper, the links between privacy concerns, trust in the Government and compulsion are examined in light of people's attitudes towards Identity Cards in the United Kingdom. A total of 404 respondents from both politically active and student groups were presented with scenarios for the implementation of ID Cards in which the degree of compulsion was varied. Their levels of privacy concern about ID Cards and trust in the Government were also measured. The perceived degree of compulsion, privacy concerns and trust in the Government predicted attitudes to Identity Cards. Mediation and moderation analyses were conducted to examine the relationship between privacy, trust and ID Card attitudes. It was found that the impact of privacy concern on attitudes was moderated by trust, such that amongst respondents with lower privacy concerns, lack of trust moderated this to lead to negative attitudes towards Identity Cards. Implications are discussed.
Identity Inference as a Privacy Risk in Computer-Mediated Communication	New Web 2.0 applications, with their emphasis on collaboration and communication, hold the promise of major advances in social connectivity and coordination; however, they also increase the threats to user privacy. An important, yet under-researched privacy risk results from social inferences about user identity, location, and activities. In this paper, we frame the 'social inference problem'. We then present the results from a 292 subject experiment that highlights: (1) the prevalence of social inference risks; (2) people's difficulties in accurately predicting social inference risks; and (3) the relation between information entropy and social inference. We also show how to predict possible social inferences by modeling users' background knowledge and calculating information entropy and discuss how social inference support systems can be deployed that protect user privacy.
A Privacy Control Theory for Online Environments	Extant literature in information systems often reports a significant level of unease among the Internet community with regard to threats to online privacy but fails to identify a comprehensive set of specific online privacy concerns. Moreover, out of the concerns that have been identified by a number of surveys, it is unclear whether any have adequate theoretical foundations. This paper uses the existing privacy literature and in particular the work of two prominent privacy theorists, Westin and Altman, to devise an online privacy model which outlines the components of the online privacy concept and their interdependencies. A theory for online privacy is then derived from this model.
Cost-Effective Investments in Customer Information Privacy	Extensive personal information is gathered explicitly or implicitly when a customer interacts with a firm. Significant risks are associated with handling such personal information. Providing protection may reduce risk of misuse or loss of private information, but it imposes some costs on the firm and its customers. Risk is associated with improper handling of sensitive customer information. Profits from e-commerce that are earned when there is improper use of private customer information are subject to lawsuits, restitution and other undesirable outcomes. So a firm will want to ensure appropriate privacy protections are in place to safeguard customer information. We present a profit optimization model for customer privacy protection investments considering the potential value implications that arise. We employ a profit-at-risk approach based on value-at-risk methods from financial economics.
Security and Privacy Trust in E-Government: Understanding System and Relationship Trust Antecedents	This research proposes an E-Government security trust model and develops a typology of antecedents in the context of citizen tax software use and e-filing. We propose that tax software use and electronic filing (e-filing) offer a novel and interesting research setting that is relevant to E-Government and security because of (1) the use of software to complete tax returns by a large portion of the citizenry, (2) the necessity of security for transmittal of information during e-filing, (3) the privacy of the subject matter, (4) the current promotion of e-filing by the American tax collection agency (IRS), and (5) individual taxpayer ambivalence or negative attitude toward taxes and the government in general. We suggest that when the information system serves as surrogate for a tax domain expert several antecedents to security and privacy trust are potential determinants of use.
Information Privacy Values, Beliefs and Attitudes: An Empirical Analysis of Web 2.0 Privacy	The commercial potential and rapid growth of Web 2.0 phenomenon have been accompanied by concerns regarding the collection, dissemination, and re-identification of personal information by Web site operators, marketers, and other users on the social networks. To address critical and acute concerns for information privacy, this study investigated users' privacy perceptions in the Web 2.0 context by integrating privacy values, beliefs and attitudes into a theoretical framework. The research model was tested through a survey study among 218 users of Web 2.0-related sites. In addition to enhancing our theoretical understanding of privacy issues in the Web 2.0 context, this research is also potentially useful to privacy advocates, the Web site operators, and marketers to help shape or justify their decisions concerning the development and deployment of Web 2.0 features.
A Survey of Location Privacy and an Approach for Solitary Users	Location-based systems (LBS) continue to grow in popularity as applications are developed to use an estimate of a user's location. Location estimates can be created using a variety of information including true location sources and network information. Regardless of the source or type of location information, aggregating all available information may produce a more accurate estimate of a user's location. A user cannot manage the use of location and network information once it has been sent to the LBS, and must assume that an observer has access to this information and can use it to estimate the user's location. Anyone with access to this information can use the same algorithm to estimate the user's location. This creates an issue of location privacy that must be addressed. This survey frames the problem of location privacy through related work and presents an alternate approach to preserving a user's privacy for consideration
Enabling Web Services Policy Negotiation with Privacy preserved using XACML	In recent Web services research, there are increasing demands and discussions about negotiation technologies for different Web services applications. One of the important topics is the policy negotiation. As many business activities become automated, policy compliance negotiation between human agents can be a bottleneck. In this paper, we focus on the policy negotiation research issues in privacy policy. We adopt the extensible Access Control Markup Language (XACML) as a policy description language and explore its potential in privacy policy negotiation. We first formalize the negotiation process in the context of Web services. Then, we illustrate the policy negotiation model by introducing a policy negotiation point (PNP) between the policy enforcement point (PEP) and policy decision point (PDP) in the XACML policy management architecture. We discuss different phases in a privacy policy negotiation and finally we illustrate how PNP can help on negotiating policies through an example scenario
Analyzing Online Information Privacy Concerns: An Information Processing Theory Approach	The advent of the Internet has made the transmission of personally identifiable information common and often inadvertent to the user. As a consequence, individuals worry that companies misuse their information. Firms have tried to mitigate this concern in two ways: (1) offering privacy policies regarding the handling and use of personal information, (2) offering benefits such as financial gains or convenience. In this paper, we interpret these actions in the context of the information processing theory of motivation. Information processing theories, in the context of motivated behavior also known as expectancy theories, are built on the premise that people process information about behavior-outcome relationships. We empirically validate predictions that the means to mitigate privacy concerns are associated with positive valences resulting in an increase in motivational score. Further, we investigate these means in trade-off situation, where a firm may only offer partially complete privacy protection and/or some benefits
Information Privacy and Trust in Government: a citizen-based perspective from New Zealand	Increasing use of e-government has raised issues about the privacy of information provided by citizens to government. This paper explores the experiences and concerns of New Zealanders in relation to information privacy, and the impact of these concerns on the trust they place in government. A series of focus groups were conducted among a range of community groups. The findings reflect a range of attitudes about information privacy and the trustworthiness of government, and centre around two major themes: the use of technology and concerns about the competency of and practices of government employees. Most respondents were unaware of their existing protections; preferred face to face communication; had low levels of confidence in the privacy of online communication but made use of it for convenience sake; had greater confidence in government than in commercial organizations but made distinctions between individual agencies. Breaches of privacy were shown to have a negative impact on trust in government
Individual Privacy and Organizational Privacy in Business Analytics	The use of business analytics to reveal useful information from transactional and operational databases involves accessing private information of both individuals and organizations. This practice has raised the privacy concern of individuals and policy makers. In this paper, we propose a privacy preserving approach for business analytics based on keyed bloom filters. We illustrate this approach using market basket analysis, and then evaluate its performance using real datasets from a point-of-sale and Web clickstream. The major advantage of this approach is the positive relationship for the level of privacy security and analysis precision. In other words, the tradeoff of the level of privacy protection for our solution is data storage space; whereas for other existing methods, there is always a tradeoff between analysis precision and the level of privacy protection
Privacy Policy Representation in Web-based Healthcare	The Health Insurance Portability and Accountability Act of 1996 (HIPAA) has resulted in the presence of very descriptive privacy policies on healthcare Web sites. These policies are intended to notify users about the organization's privacy practices. However, these policies are typically not easy to read, and as a result, few people actually read them. Given the fact that these policies are not optional, but required by HIPAA, they should be presented in a more usable manner that encourages consumers to read them. This, in turn, could encourage users to feel more comfortable when interacting with online healthcare organizations. In this paper, we present the preliminary results of our study that compares various ways to present privacy management information to online healthcare consumers. The study involved a survey of 993 Internet users. We also provide recommendations to managers and Web site designers who focus on usability
The Ethics of Knowledge Transfers and Conversions: Property or Privacy Rights?	Closely related to organizational learning, knowledge creation, knowledge codification, and knowledge reuse, knowledge transfers of tacit knowledge between individuals and conversions of tacit knowledge to explicit knowledge raise important issues regarding the use of ethics and self-interest as counter determinants. Do organizations "own" the knowledge of their employees, or is this knowledge an "attribute" of an autonomous individual and subject to protection under human rights to privacy or security-of-person? This paper explores these opposite viewpoints from the perspectives of knowledge management and human rights. Consequently, organizational knowledge may fall under the intellectual property theory and organizations have the right to buy, sell and use their corporate knowledge as it suits their needs, while personal knowledge may fall under the personal privacy theory and individuals have the right to protect the security of their personal knowledge. Thus, knowledge management practices may differ with regard to the two types of knowledge.
Online Privacy at a Premium	Online privacy has been a significant concern of customers in online transactions. Several technical, economics based, and regulatory mechanisms have been proposed to address online privacy. One proposed market-based mechanism is the privacy seal. In this paper, we present some empirical evidence of the impact of displaying a privacy seal on the product prices of online firms. Using data carefully collected on homogeneous products sold by pairs of online firms ΓÇö one firm in the pair with a privacy seal, and the other firm without the seal ΓÇö we find that firms with a privacy seal in fact do charge a price premium on their products, compared to firms without a seal. The amount of this price premium is affected by the product prices, but is not affected by the product demand. Based on the data, we also quantify the magnitude of this privacy seal induced price premium.
Protecting Privacy of Health Information through Privacy Broker	Concerns about the protection of personally identifiable information are not unique to the health care industry; however, consumers view their medical records as more "private" than other information because involuntary disclosure can affect jobs or health insurance status. EPAL is a convenient way of capturing privacy policies. This paper presents an EPAL based privacy middleware architecture called Privacy Broker which attempts to reduce privacy violation risk and enforce committed privacy policy in health information system. This paper also provides a translation of SQL queries into Authorization Request in EPAL.
Exploring the Moderating Effect of Trust and Privacy in the Adoption of Application Service Providers in the Healthcare Industry	Understanding the antecedents to the adoption of information technology is important to both technology firms and policy analysts that study the effects of technology adoption on healthcare. This paper uses a transactional cost approach to investigate the role of trust and privacy as moderators in the adoption of Application Service Providers (ASPs) as a new form of information technology outsourcing in the healthcare industry within the current regulatory climate created by HIPAA (Health Insurance Portability and Accountability Act). The analysis utilized a seven-stage measure to capture adoption. Our analysis showed that Transactions costs and the antecedents of transaction costs were highly significant in the ASP adoption process. The direct and moderated effects of Trust and Privacy were not significant.
Business Compliance to Changing Privacy Protections	On the 21st December, 2001 Australia introduced a new privacy law titled the Privacy Amendment Private Sector Act, which extended the Privacy Act (1988) to apply to private sector companies. Previous literature has examined the gap between self-regulation and legislation, but no research had investigated Australia's transformation from self-regulation to legislation. The methodology used in this paper employs a triangulation method, which includes literature research into the background of privacy in Australia and research into the Privacy Amendment (Private Sector) Act 2000 itself, a longitudinal web site assessment and questionnaire. The study also outlines whether the new law brought into force at the end of 2001 meets government and consumer expectations in Australia, and how this method of privacy protection compares with different privacy protection methods such as (i)self-regulation, found within the US, and (ii)legislation found within the EU.
A Research Model for Studying Privacy Concerns Pertaining to Location-Based Services	Location-based services (LBS) are services that take into account the geographic location of a user. With the rapid growth of mobile devices, LBS are expected to spread rapidly. While LBS promise efficiency and effectiveness gains, their use also raises fundamental privacy issues. In a market survey, 24% of the respondents mentioned that they are seriously concerned about the privacy implications of disclosing their location. Thus the focus of this paper is to understand what antecedents determine intentions to use LBS. A research model is developed that incorporates constructs, such as personality traits, task and technology characteristics, perceived privacy, trust and risk, and usefulness as antecedents of LBS usage intentions.
Privacy and Access Control Issues in Financial Enterprise Content Management	Financial Enterprise Content Management Systems (FECMS) have been recently deployed not only in intra-enterprises but also over the Internet to interact with customers. As FECMS contains a lot of sensitive and confidential information, there is an urgent need for tackling privacy and access control issues in these systems. In this paper, we proceed with our case study in an international banking enterprise on these issues. The FECMS is based on Web services technologies and we demonstrate the key privacy and access control policies for internal content flow management (such as content editing, approval, and usage) as well as external access control for Web portal and institutional programmatic users. Through the modular design of an integrated FECMS, we illustrate how we can systematically specify privacy and access control policies in each part of the system with the technology of Enterprise Privacy Authorization Language (EPAL)..
Mini Track: 'Ethical, Legal and Economic Issues in the Digital Economy: Intellectual Property Rights, Piracy, Trust, Security and Privacy'	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01385597.png" border="0">
Cool Hunting the Kids' Digital Playground: Datamining and the Privacy Debates in Children's Online Entertainment Sites	This paper takes up the social and theoretical implications surrounding the information management practices found within children's online entertainment sites. Although the increasing integration of information and data gathering systems is oriented towards enhancing organizational efficiency and consumer service provisions, explicating the administration of online gaming community information infrastructures reveals the threats of "digital redlining" or "weblining." Empirical data from ongoing case studies of popular children's game sites are presented to reflect on discourses of privacy, data protection and the ethical dimensions of data mining. These issues are seen as especially relevant in view of the recent implementation of national privacy legislation which apply to children's online culture. Child users are not only highly targeted by data mining and market research practices but also disadvantaged by a limited awareness of the legal and ethical implications of their online interactions with commercial spaces.
Mini track: 'ethical, legal and economic issues in the digital economy: intellectual property rights, piracy, trust, security and privacy'	
Volunteering personal information on the Internet: effects of reputation, privacy initiatives, and reward on online consumer behavior	Internet has made it easier for firms to collect consumer information. However, consumers are reluctant to provide personal information or tend to provide false information online because of their concern of the privacy violation risks. Researchers have proposed several instruments to assuage consumers' privacy concern, and to induce them to provide personal information. However, the effectiveness and applicability of these instruments regarding firm's reputation have yet been sufficiently assessed. This study employed a 2*2*2 experimental design to examine the effects of reputation, fair information practices, and reward on the online consumer behavior of volunteering two types of personal information - demographic and personal identifiable information - on the Internet. Theoretical and practical implications of findings were drawn.
A commutative encrypted protocol for the privacy protection of watermarks in digital contents	Analysis by Forrester research revealed that 18% of global exports will flow online in 2004 and that the volume of e-commerce will surpass $400 billion. Digital rights protection is a major issue in the e-commerce of multimedia contents. Watermarking technology has been proposed as a promising enabling technology for the rights protection of multimedia digital contents. A unique watermark is embedded in each piece of multimedia contents before it is distributed to a customer. When unauthorized copies of a piece of contents are found, the customer who owns the contents can be readily identified by means of the embedded watermark. However, the unauthorized copies may also come from the content provider itself. It is therefore a challenging problem to determine whether an unauthorized copy is distributed by an unethical customer or by an unethical content provider. In this paper, we propose a watermarking protocol to address the problem using cryptographic technologies. Our protocol employs a commutative encryption algorithm to protect the privacy of watermarks. Information is doubly locked by two encryption keys kept separately by a customer and a content provider. In the protocol, a customer only gets a piece of watermarked multimedia contents in a transaction and the content provider has no idea how the watermark is formed. This facilitates the authority to determine the unethical party in case of unauthorized distribution of digital contents. We also discuss a couple of common attacks and show that our protocol can defend successfully against them.
On privacy-preserving access to distributed heterogeneous healthcare information	Regional healthcare initiatives seek to improve the quality of healthcare by collecting, analyzing, and disseminating information about chronic diseases such as diabetes. The data required to support such initiatives comes from several organizations such as insurers, physicians, hospitals, pharmacies and labs each of which gather and maintain data for the purpose of healthcare delivery. Accessing data in this distributed and heterogeneous environment is difficult and has to deal with well-documented issues such as resolving semantic conflicts, multiple query languages etc. Data warehousing and mediator-based architectures are often proposed and used in these settings. In this paper, we focus on mediator-based architectures and the privacy problems that arise in the healthcare context owing to the linkage of information about patients, physicians, and diseases enabled by the mediator. Current proposals for security-conscious mediators do not address inferential disclosure resulting from record linkage. In particular, we study the problem of interval inference, a specific kind of disclosure that arises when participants are able to compute tight bounds on sensitive values of other participants, based on the aggregate information published by the mediator. We illustrate our approach with a real world example and propose an "audit and aggregate" methodology that chooses the optimal level of aggregation of the data taking into account both the risk of disclosure as well as the utility of the released data to legitimate users.
Privacy issues in location-aware mobile devices	Location awareness, the ability to determine geographical position, is an emerging technology with both significant benefits and important privacy implications for users of mobile devices such as cell phones and PDAs. Location is determined either internally by a device or externally by systems and networks with which the device interacts, and the resultant location information may be stored, used, and disclosed under various conditions that are described. Thirteen specific privacy issues are enumerated and discussed as examples of the challenges we face as these technologies and their associated products and services are deployed. Regulation by governments, standards organizations, industry groups, public interest groups, and marketplace forces are discussed as it may help address privacy issues.
Public attitudes towards a national identity "smart card:" privacy and security concerns	Tracking technologies use pervasive information systems to scan and record the location of individuals and to transfer information about them to and from a central database. One potential application is a "smart" national identity card (NID). National polls have shown a strong majority of Americans favor an NID in recent months. This study uses a telephone poll with 400 respondents and semistructured interviews with 29 New Jersey adults to explore in depth the concerns and opinions that explain the "surface" opinion that is elicited with a single question. The results indicate that most people actually have very mixed feelings, with strong reservations about privacy and civil rights implications and also the security of the information on the card itself from theft or misuse.
Adding value to online privacy for consumers: remedying deficiencies in online privacy policies with an holistic approach	We present findings from a longitudinal, empirical study of online privacy policies. Our research found that although online privacy policies have improved in quality and effectiveness since 2000, they still fall well short of the level of privacy assurance desired by consumers. This study has identified broad areas of deficiency in existing online privacy policies, and offers a solution in the form of an holistic framework for the development, factors and content of online privacy policies for organizations. Our study adds to existing theory in this area and, more immediately, will assist businesses concerned about the effect of privacy issues on consumer Web usage.
Location privacy in the Alipes platform	An increasing number of systems use contextual information about their users. Such contextual information can be used to design applications that survey usage and adapt thereafter, or simply just use context information to optimize presentation. Context information could therefore be used to create applications for the benefit of the users of the system, but the same information could cause serious violations of personal integrity if misused. Locality may be the most widely used, but also the most sensitive contextual information. The Alipes platform makes it easy to create location-based services while enforcing user privacy and integrity. The platform handles privacy through rules that describe how and under what circumstances a user's context may be distributed to other users, for example rules describing limitations concerning the user's context, a certain time period, the number of queries and the type of applications. This paper presents how location privacy is enforced in the Alipes platform.
Privacy in distributed electronic commerce	In recent years there has been a movement toward deployment of distributed approaches for electronic commerce. Intelligent software agents, for instance, may be instructed to act oh behalf of human users in electronic transactions. A challenge with this approach is that the agents would be entrusted with access to sensitive personal or business information. How can this sensitive information be protected from unauthorized access? How can agents negotiate across jurisdictional boundaries; both corporate, and country? The latter question is of particular concern when one considers the potential for considerable variance between the regulations and policies of different governments and corporations. This is especially evident with the disparity of legislation for privacy in different countries. How can disparate regulations be accommodated effectively? What technologies are appropriate for maintaining user privacy and for protecting sensitive information for agent-based e-commerce? In this paper, we describe the issues that provoke privacy challenges for agent-based e-commerce due to current and impending privacy legislation as well as an approach for policy-driven privacy negotiation for use in distributed agent-based systems.
Privacy and security shield for health information systems (e-Health)	The objective of this work is to develop a platform supporting the secure and quick deployment of distributed medical applications creating an environment and associated tools for the usage of medical personnel in their interaction with patients. We adopted the electronic health record (EHR) architecture blueprint as developed by Canada Health Infoway, which proposes Web service technology as an integration platform. We developed this environment for distributed and collaborative use by selected medical personnel using the combination of communication networks such as the Ca*net 4, ORION, NETERAnet and NCIT*net. This intelligent platform will enable the mining, retrieval, modification, management, and synchronization of various databases used by doctors in handling data in regards to patients and their illnesses, and last but not least, will examine and provide the security requirements associated with Web services in the context of e-Health applications.
Mine or ours: email privacy expectations, employee attitudes, and perceived work environment characteristics	In spite of the growing importance of ethical and privacy concerns in the information age, there is a surprising paucity of academic literature on the subject. The research reported in this paper attempts to address this gap by focusing on privacy perceptions related to email. We adopt a behavioral perspective on the use of email in that we treat email policy as an embodiment of managerial beliefs and values about the employer-employee relationship and the role of communication in the workplace. Specifically, we examine employee attitudes towards email, their perceptions and expectations regarding the privacy and ownership of email, and a variety of work environment characteristics. Drawing upon prior theoretical work in organizational behavior and the use of email in work contexts, we propose a variety of research hypotheses. Data gathered from a sample of 193 respondents which includes email users from two different national contexts with different email policies in the host organizations is used to test the hypotheses. While we do not examine the effects of a specific policy in this study, our results nonetheless have interesting implications for organizations desirous of constructing an email policy. Theoretical implications as well as guidelines for practicing managers are offered.
Privacy issues on the Internet	An increasing number of people are using the Internet, in many instances unaware of the information being collected about them. In contrast, other people concerned about the privacy and security issues are limiting their use of the Internet, abstaining from purchasing products online. Businesses should be aware that consumers are looking for privacy protection and a privacy statement can help to ease consumers' concerns. New Zealand based Web sites are expected to have privacy statements on their Web sites under the New Zealand Privacy Act 1993. The incidence of the information gathered from New Zealand Web sites and their use of privacy statements is examined. In particular, Web sites utilizing cookies and statements about them are scanned. Global consistency on Internet privacy protection is important to boost the growth of electronic commerce. To protect consumers in a globally consistent manner, legislation, self-regulation, technical solutions and combination solutions are different techniques that can be implemented.
Data protection in the university setting: employee perceptions of student privacy	The right to privacy is not absolute and is often established by context and the need to know. The nature of the university environment sometimes distorts the sanctity of privacy because the "need to know" is so profuse. Although students are guaranteed the right to keep essential but confidential information private under the Family Educational Rights and Privacy Act of 1974, student data are vulnerable because of the need for academic departments to share and manage these data. Recent articles in the popular press suggest consumers as a whole are questioning organizational practices that are designed to protect their personal information. Similar practices occur in the university setting, but fewer concerns are being publicized. Because of the vast amount of data sharing that occurs in an academic setting, it is imperative that we ensure the employees adhere to privacy policies that are structured to impose conscientious behaviors. University privacy policies are in practice, but there is no method of determining their effectiveness. This research seeks to ascertain the attitudes of employees regarding student privacy. Using a 15-item instrument, this study explores employees' privacy perceptions of a large university located in the Southeastern USA. Our study examines the level of concerns employees have concerning errors in, unauthorized secondary use of, improper access to and collection of data.
The role of identification in the privacy decisions of information system students	This research is aimed at understanding the ethical decision-making process of information systems students, particularly when those decisions involve online privacy. The research model on which the hypotheses are based includes both deontological and teleological factors, as well as something heretofore overlooked by IS ethics researchers. Organizational identification is hypothesized to serve a filtering role, to help the individual faced with an ethical decision to focus on those stakeholders that are most relevant. The research model was tested using survey methods with a sample of senior-level IS undergraduates. The main effects of the deontological and teleological factors explained 35% of the variance in an individual's moral judgment about online privacy. Contrary to expectations, organizational identification did not moderate these two effects. However, the interaction of all three factors was significant, both practically and statistically.
Managing the costs of informational privacy: bundling as a strategy in the individual health insurance market	Advances in genetic testing and data mining technologies have increased the availability of genetic information to insurance companies and insureds (applicants and policy holders) in the individual health insurance market (IHIM). Regulators, concerned that insurance companies will use this information to discriminate against applicants who have a genetic risk factor but who are still healthy, have implemented genetic privacy legislation in at least 18 states. However, in previous work we have demonstrated that such legislation will have unintended consequences-it will reduce consumer participation in the market without making those remaining better off. This paper identifies a mechanism, a bundling strategy, that insurance companies may implement in this regulatory environment to restore (or maximize) consumer participation in the market and to discourage such discrimination among insureds. This problem is examined through simulation modeling. The results will have significant implications for policy designs implemented by insurance companies, for legislation implemented by industry regulators, and therefore, for the insurability of the individuals that rely on this market for health insurance coverage.
A plugin-based privacy scheme for World-Wide Web file distribution	Existing security mechanisms for serving documents on the World Wide Web typically require use of either an underlying security transport mechanism (e.g. SSL) or alternate servers, browsers and data streams (e.g. SHTTP). We introduce a simpler method using plugins which provides moderate security for serving private documents within the standard HTTP mechanism and socket layer. This new method operates by providing a security plugin within a standard Web browser environment. It provides a somewhat lower level of functionality and security than the alternatives mentioned above but requires much less overhead, especially on the server end, and appears to be very appropriate for serving low security, non-public documents, files and images over the World Wide Web. The method can be easily adapted to provide other advantages, such as automatic ΓÇ£water markingΓÇ¥ of decoded material with the name of the decoder, and the deployment of content specific compression algorithms
Technology transfer in Sandia's scientific areas. The engineering sciences Technology Information Environment. Systematic approach to security, privacy and appropriate access	This paper describes the need for faster and more efficient technology transfer mechanisms. It outlines the design of a computerized technology transfer mechanism for the engineering sciences area based on Sandia National Laboratories' Technology Information Environment for Industry (TIE-IN). It explains the security, privacy and appropriate access issues that arose in the design of the system
A Privacy-Aware Design for the Vehicle-to-Grid Framework	The vehicle-to-grid (V2G) framework proposes integration of battery-powered electric drive vehicles into the grid, enabling them to be recharged as necessary and to act as suppliers in the ancillary service electricity markets. This is expected to create incentives for the production and adoption of electric vehicles in the automotive industry. V2G frameworks require that the utility company or a third party aggregator has access to each vehicle's charging status via a two-way communication network for billing and planning purposes. We establish that there exist consumer privacy risks associated with current concepts for V2G implementation and argue that consumer preferences and behaviors can be inferred from charging information if privacy is not a primary concern from the outset of V2G design. Finally, we outline a privacy-aware architecture for V2G systems.
The Sealed Letter: Safeguarding the Public System of Privacy Protection in a Digital World	Amongst the casualties of the electronic age has been a number of institutions and the values and services associated with them. One example of such is the postal service and the concept of sealed, private correspondence. The universal postal service was one of the great social developments of the 19th century. Today, while such services continue to exist in almost every country in the world, much of the traffic that they formerly managed has been displaced by various forms of electronic communication. While this has brought benefits, it has also involved some losses. One loss has been the privacy of the sealed letter. This paper describes a project to develop a system to reinstate the concept of private correspondence in an electronic age.
Privacy Settings in Online Social Networks -- Preferences, Perception, and Reality	To approach privacy threats stemming from interacting with other users on Online Social Networks (OSN), effective Social Identity Management (SIdM) is a key requirement. SIdM refers to the deliberate and targeted disclosure of personal information to a subset of one's contacts on OSN. Yet, unlike the physical world, SIdM on OSN is compromised by unavailable or insufficient settings as well as by properties of mediated communication (e.g. persistence). In this paper, we employ a novel approach based on the participants' Facebook profiles content to study privacy settings in OSN. Our results indicate a mismatch between perceived, preferred, and actual settings that can be reduced to lack of awareness and control by the user.
Exploring Privacy and Trust Issues in a Future Immersive Videoconferencing System	Existing standard videoconferencing tools have failed in creating an experience equal to formal face-to-face meetings. In an effort to overcome this challenge, ICOCOON was developed to create an immersive meeting experience. In its current state this videoconferencing tool displays video streams of all participants and a Virtual Meeting Room (VMR) portraying participants as avatars around one table. To create an effortless meeting experience in the immersive environment, the Virtual Director (VD) translates behaviors such as speaking and raising one's hand from the video stream to the VMR with the help of smart software. However, when delegating power to technology, privacy concerns arise. By creating a video prototype of the tool, we probed and discussed topics such as privacy and trust in technology. We found that users trade off their privacy concerns with benefits of using the proposed technology. To illustrate this trade-off, we extended an existing privacy perception model.
Introduction to Personalization, Privacy and Identity Disclosure in Virtual Society Minitrack	None
The Effects of Notice versus Awareness: An Empirical Examination of an Online Consumer's Privacy Risk Treatment	Notice of an entity's personal information collection and usage practices is considered to be a prerequisite to an online user being able to make informed decisions on personal information disclosure. Notice is typically provided in privacy policies that are often characterized as vague, lengthy, and misleading. As such, notice typically does not equate to awareness of privacy threats. This study evaluates the effects of notice and threat awareness on an online user's decision to treat risk through mitigation, avoidance, or acceptance. Study findings indicate opposite effects of notice versus threat awareness on risk treatment. Whereas notice had a positive effect on acceptance, threat awareness had a negative effect on acceptance and a positive effect on avoidance. Thus, notice appears to invoke a false sense of assurance that encourages online users to adopt acceptance as a risk treatment, while awareness of privacy threats discourages online users from passive acceptance.
Monitoring of Electronic Communications at Universities: Policies and Perceptions of Privacy	This paper presents the results of a research study on the use of electronic communications by college students at public universities. We examine student perceptions and attitudes towards electronic communications, such as email, web browsing, using social networks, and other online activities, as well as their views and expectations of privacy and trust. We discuss a number of important characteristics of information technology as a facilitator of electronic communications on campus and their impact on the perceived privacy. We paid special attention to the effects of institutional policies concerning the monitoring of electronic communications and the resulting possible loss of privacy and trust. The results of our study indicate that regardless of their awareness of such policies, individuals have an inherent expectation that their on-campus electronic communications will stay private. Our results also suggest that average users do not understand the implications of electronic monitoring policies on their privacy. However, as a result of their understanding of these policies, users often adjust their communications in response to the possibility of diminishing privacy.
Using Multi Shares for Ensuring Privacy in Database-as-a-Service	Database-as-a-service (DAAS) is a new model for data management, where a service provider offers customers software management functionalities as well as the use of expensive hardware. This service enables data integration and access on a large scale in cloud computing infrastructures. Addressing data privacy in DAAS is considered a significant issue for any organizational database. Due to the fact that data will be shared with a third party, an un-trusted server is dangerous and unsafe for the user. This paper proposes the architecture of a new model appropriate for NetDB2 architecture, known as NetDB2 Multi-Shares (NetDB2-MS). It is based on multi-service providers and a secret sharing algorithm instead of encryption, which is used by the existing NetDB2 service. The evaluation is done through simulations. It shows a significant improvement in performance for data storage and retrieval for various query types.
Cloud Hooks: Security and Privacy Issues in Cloud Computing	In meteorology, the most destructive extratropical cyclones evolve with the formation of a bent-back front and cloud head separated from the main polar-front, creating a hook that completely encircles a pocket of warm air with colder air. The most damaging winds occur near the tip of the hook. The cloud hook formation provides a useful analogy for cloud computing, in which the most acute obstacles with outsourced services (i.e., the cloud hook) are security and privacy issues. This paper identifies key issues, which are believed to have long-term significance in cloud computing security and privacy, based on documented problems and exhibited weaknesses.
A Privacy-Aware Architecture for Demand Response Systems	We explore the privacy issues implicated by the development of demand response systems. We begin by highlighting the invasive nature of fine-granularity power consumption data, showing that the data collected by Advanced Metering Infrastructure (AMI) reveals detailed information about behavior within the home. We then show how privacy-aware design principles lead to novel system architectures that realize the benefits of demand response without requiring that AMI data be centrally collected. The resulting systems avoid both harm to subscribers and the potential need to scrap AMI-based demand response efforts in the face of public outcry. We also show that Trusted Platform Modules can be used to develop privacy-sensitive metering infrastructure.
Individual Privacy and Online Services	We explore consumer trade-offs between better performance through tailoring of online services to their individual needs and greater privacy as a result of reduced disclosure of personal information. We show that individuals have different willingness to accept loss of privacy that is a function of (1) the individual and his/her preferences, because the variation in demands for privacy is not uniform across individuals, (2) the service Domain, because individuals demand more privacy in some Domains than they do in others and (3) these differences themselves differ among consumers as well.
Issues in the Development of Location Privacy Theory	Issues in the development of location privacy theory are identified and organized based on both technological considerations and more general privacy theories. Three broad categories containing six issues are described: location (including sensing methods and location properties), privacy (including definition and subject identification), and information flows (from location information acquisition through storage, use, and sharing). An influence diagram model is presented which relates these issues in context and may serve as a basis for further theory development, empirical research, and public policy discussion.
Privacy Calculus on Social Networking Sites: Explorative Evidence from Germany and USA	Worldwide social networks, like Facebook, face fierce competition from local platforms when expanding globally. To remain attractive social network providers need to encourage user self-disclosure. Yet, little research exists on how cultural differences impact self-disclosure on these platforms. Addressing this gap, this study explores the differences in perceptions of disclosure-relevant determinants between German and US users. Survey of Facebook members indicates that German users expect more damage and attribute higher probability to privacy-related violations. On the other hand, even though American users show higher level of privacy concern, they extract more benefits from their social networking activities, have more trust in the service provider and legal assurances as well as perceive more control. These factors may explain a higher level of self-disclosure indicated by American users. Our results provide relevant insights for the social network providers who can adjust their expansion strategy with regard to cultural differences.
Developing Reliable Measures of Privacy Management within Social Networking Sites	Social networking sites and other examples of online social spaces have greatly expanded their members' opportunities for self expression and social interaction, while creating significant challenges for online privacy management. Within offline social spaces, privacy management is an active part of everyday life, influencing where, when and to whom we decide to reveal private information. Just as technology mediation changes the nature of communication, so will technology mediation of social interaction change the nature of privacy management. This paper describes work done to establish reliable measures of online privacy management based on Adaptive Structuration Theory (AST). AST provides a framework for modeling the use of technology in a social setting, includes a way to measure appropriation, the process by which users adapt and adopt technology. These measures have been used to examine appropriation patterns within two US based social networking sites (Facebook and MySpace), and StudiVZ, a site based in Germany. The measures demonstrated an acceptable level of reliability, and the results exposed differences in the privacy management strategies employed by the members of these sites. The result of this research is the establishment of theory based measures that can be used to capture the structure of online privacy management.
Pseudonymization with Metadata Encryption for Privacy-Preserving Searchable Documents	The average costs of data leakage are steadily on the rise. As a consequence, several data security and access control mechanisms have been introduced, ranging from data encryption to intrusion detection or role-based access control, doing a great work in protecting sensitive information. However, the majority of these concepts are centrally controlled by administrators, who are one of the major threats to corporate security. This work presents a security protocol for data privacy that is strictly controlled by the data owner. Therefore, we integrate pseudonymization and encryption techniques to create a methodology that uses pseudonyms as access control mechanism, protects secret cryptographic keys by a layer-based security model, and provides privacy-preserving querying.
Self Discrepancy, Perceived Privacy Rights, and Contribution in Virtual Communities	Virtual communities enable one to pretend to be a different person or to possess a different identity at little or no cost. Despite the ubiquity of such communities, there is limited theoretical and empirical research on how taking on a different identity is associated with one's contributive behavior in those communities. Drawing on the social psychology literature, we adopt the concept of self-discrepancy rooted in self-identity and derive an index for self-discrepancy by using the differences between actual and virtual self-identities. Next, we link the self-discrepancy with perceived privacy rights and with the quality and quantity of contribution. An analysis of 299 respondents showed that self-discrepancy significantly influenced perceived privacy rights and indirectly reduced quality and quantity of contribution in virtual communities. Furthermore, sub-group analysis revealed that the effects of self-discrepancy varied depending on whether the virtual community was utilitarian or hedonic.
Provider-Independent Online Social Identity Management--Enhancing Privacy Consistently Across Multiple Social Networking Sites	The rising pervasiveness of social networking sites (SNS) poses new privacy risks and prompts adjusting one's online appearance to the current context of usage. This includes the deliberate and targeted disclosure of selected information to a subset of one's contacts, also known as social identity management (SIdM). Yet, when performing SIdM across multiple SNS, it is difficult to maintain a consistent representation of oneself. We introduce a global model to perform SIdM which is independent of particular SNS. Then we show how to apply modifications of the global model to particular sites. We evaluate the feasibility of the approach by surveying currently available settings and APIs in the most important SNS.
Evaluation and Neuronal Network-Based Classification of the PHRs Privacy Policies	There has been growing interest by health services providers in providing PHRs (Personal Health Records) which can store individual's personal health information. In PHRs, access to data is controlled by the patient, not by the health care provider. Although a number of benefits can be achieved with the PHRs, important security and privacy challenges of PHRs arise. In this paper a review of the privacy policies of 22 free web-based PHRs is presented. Our objective is to measure the effects of adoption of international standards and cost on privacy and security characteristics. Security and privacy characteristics were extracted according to the standard ISO/TS 13606-4. A statistical analysis was conducted and a neural network-based classification of PHRs was performed. Some improvements can be done to current privacy policies of PHRs to enhance management of other users' data, notification of changes in privacy policy to users and access audits.
Privacy and Value Co-creation for IT-Enabled Service Systems: Cui Bono?	Almost all IT enabled service systems such as Google, Face book, Apple, Microsoft, Skype are facing criticisms on their use of customer data and their failure to protect customer privacy. These service companies rely on customers to participate actively in the co-creation of value by providing personal information, data and preferences. Such important resources and assets, if mishandled by companies, can cause harm to customers. Misuse and poor privacy protection for customer information can create ethical, legal, and business consequences, diminish trust and inhibit relationship building between customers and service providers, and affect future value co-creation. This paper identifies the different facets of privacy, explores the intersection of privacy and co-creation of value, and offers suggestions for future research regarding how businesses and customers can benefit from the service while ensuring privacy is protected.
Building a Long Term Strategy for International Collaboration in Trustworthy ICT: Security, Privacy and Trust in Global Networks and Services	This paper contains a summary of a significant amount of findings carried out collectively by a global research community specifically aimed at determining mutually beneficial and hot topics for international collaboration on the research and development of Trustworthy ICT. The paper highlights a sampling of these topics that were deemed to produce the most impact and it provides an introduction to the final recommendations of the INCO-Trust project, which was the main catalyst behind this initiative. The paper doesn't cover the extensive platforms, mechanisms, and systematic consensus building process in working groups based on workshops organised by the project to achieve its goals but instead focuses on the outcomes of the project. The key recommendations of the project will be used as a starting point for the recently start BIC project, whose objective is to include a number of new countries (Brazil, India and South Africa) into this already formed global community of ICT Trust and security researchers.
CLEARER: CrySyS Laboratory Security and Privacy Research Roadmap	The Laboratory of Cryptography and System Security (CrySyS) is dedicated to conduct research in the field of computer security and user privacy. This paper shows a research roadmap of the CrySyS Lab from its inception in 2003 until today. We will present the major achievements in the past with a particular emphasis on the research and teaching curriculum in security and privacy. We will discuss network- and wireless system security, the core competences of CrySyS. Building on the research foundation and competences in these areas, we will lead the laboratory into new territories of security and privacy in wireless embedded computing systems and the future Internet.
Privacy, additional information, and communication	Two parties which hold <e1>n</e1>-b inputs <e1>x</e1> and <e1>y </e1>, respectively, wish to cooperate in computing a predetermined function <e1>f</e1>(<e1>x</e1>,<e1>y</e1>). For most functions <e1>f</e1>, this task cannot be accomplished privately, namely, without revealing some additional information to at least one of the parties. The authors initiate a quantitative study of <e1>T</e1>(<e1>f</e1>), the minimum amount of additional information revealed in any computation of <e1>f</e1>. This quantity is formally defined, and a combinatorial characterization which determines the value <e1>T</e1>(<e1>f</e1>) (up to a multiplicative factor of 2) is found. This enables the authors to give tight lower and upper bounds on the amount of additional information required for computing various (explicit and random) functions. It is shown that additional information is a resource which can be traded for communication complexity
Reusable low-error compressive sampling schemes through privacy	A compressive sampling algorithm recovers approximately a nearly sparse vector x from a much smaller ΓÇ£sketchΓÇ¥ given by the matrix vector product ╬ª<sub>x</sub>. Different settings in the literature make different assumptions to meet strong requirements on the accuracy of the recovered signal. Some are robust to noise (that is, the signal may be far from sparse), but the matrix ╬ª is only guaranteed to work on a single fixed x with high probability-it may not be re-used arbitrarily many times. Others require ╬ª to work on all x simultaneously, but are much less resilient to noise. In this note, we examine the case of compressive sampling of a RADAR signal. Through a combination of mathematical theory and assumptions appropriate to our scenario, we show how a single matrix ╬ª can be used repeatedly on multiple input vectors x, and still give the best possible resilience to noise.
Privacy and Reliability in Crowdsourcing Service Delivery	Due to the anonymity and low pay of workers in crowd sourcing platforms, there may be concerns regarding reliability and privacy-preservation when using such platforms to deliver services. This paper describes a technique for jointly providing privacy and reliability through stochastic perturbation of micro task definitions and fusion rules to combine the work of several workers. A mathematical model of a crowd sourcing system using this technique is proposed and precise threshold conditions on loss of privacy when workers collude are provided. Tradeoffs between privacy, reliability, and cost are determined.
THE PRIVACY PROBLEM	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00477449.png" border="0">
International data wars are brewing: U.S. telecommunications deregulation, Third World protectionism, and European privacy regulations may complicate or curtail data flow across borders	An `information war' could threaten the international telecommunications grid on which modern business depends for moving data around the world. Three areas of concern are: the extension of the deregulation of US domestic telecommunications in a way that affects the international network; protectionist policies, already growing in the trade of goods, could start to spill over into the exchange of information services; and the ratification by the Council of Europe, an organization of European States, of a treaty regulating privacy protection in the international exchange of information.
Database nation; the death of privacy in the 21st century [Books]	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00880950.png" border="0">
(Re)butting Heads Over Privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00694341.png" border="0">
The illusion of web privacy	The author discusses how, for the ordinary netizen, it's surprisingly hard to be anonymous online.
Slipping down the privacy slope	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00946641.png" border="0">
Data security-cryptography=privacy?	Concerns about the main encrypting and enciphering schemes being proposed as a way to ensure data security are examined. To elucidate the issues involved, public-key cryptography is explained. The collision between the interests of government intelligence agencies and private groups as evidenced by the controversy over the Digital Signature Standard (DSS) proposed by the US National Institute of Standards and Technology is discussed. Weaknesses of the DSS and possible curbs on cryptography are addressed.<<ETX>>
Privacy and the computer age	By the year 2000, Americans could have computers and robots in the home├é┬┐and virtually no privacy. This prediction is part of the discussions of the Commission On The Year 2000, which were published in the summer issue of Daedalus, the Journal of the American Academy of Arts and Sciences.1 The implications of this technological attack on privacy are reflected in the increasing interest in the protection of this vital right. The computer-electronics industry has recognized this issue, and has addressed itself to it on many occasions, including many professional gatherings.2 Businessmen are also concerned with the inherent implications,3 and many governmental agencies are studying the possibility of controls of some type. The Federal Communications Commission, for example, has initiated a public inquiry into the computer-communications interface.4 One of the specific items of response to the FCC inquiry is ``privacy and security.''
Privacy, publicness, and the web: A manifesto	The internet is the greatest agent of change since at least Gutenberg. Its leaders, Google and Facebook, are transforming business, society, our relationships, and even our worldview in so many ways. They're also transforming our notions of privacy and publicness. Will this new world be a better one? Facebook and Google-and I-believe a public society is a better society. "On balance, making the world more open is good", Facebook's founder, Mark Zuckerberg, told me. "Our mission is to make the world more open and connected." And Google's is to organize the world's public knowledge. Many benefits accrue to a public society. Sir Tim Berners-Lee, inventor of the Web, has been calling for opening up as much data as possible- save for that which jeopardizes privacy- to move the Web to its next phase. Because when data are layered upon data and connections are made, value can grow dramatically.
Next-generation impacts: Technology watchers discuss industrial and office automation, knowledge-based systems, computer privacy, and education	More and more technology watchers say that next-generation computing is likely to affect virtually all professional and personal endeavors. To find out which institutions and individuals might be changed and to what degree, Spectrum invited eight engineers and social scientists from industry, government, and academia to discuss projected impacts.
The unwanted gaze: the destruction of privacy in america [Book Review]	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00963263.png" border="0">
Computers: Data privacy: The European community grapples with protecting individual rights in the midst of rampant computer progress	When a computer project in France proposed giving everyone in the country a reference number so government authorities could exchange all kinds of information about citizens, the public became alarmed. The name of the project, Safari, gave rise to an article in Le Monde that was headlined: ΓÇ£Safari, or Hunting the French.ΓÇ¥
Improving security, preserving privacy	Although terrorism is probably the focus of most people's current concern, the need for protection from such nightmares as workplace and school violence has been fanning a demand for more secure environments for some time. Proposed solutions range from the simple, like putting better locks on doors, to the experimental, like automatic face-recognition systems. On a long-term basis, they even include architectural measures: designing buildings so that bomb-laden trucks cannot readily approach them. The privacy aspects of such surveillance are discussed in this article
Zero privacy [Reflections]	Examines the state of privacy today.
Privacy preserving e-negotiation protocols based on secure multi-party computation	In this paper, we have presented several algorithms based on distributed secure multiparty computation. We have applied these algorithms to develop e-negotiation protocols for collaborative supply chain planning. Preserving the privacy of the participants' data is an important issue in these protocols. The first protocol supports a policy of non-discriminatory pricing where the buying firms do not want to reveal their bids regarding price and demand before the supplier announces a fixed selling price common for all the buyers. Price is never disclosed for any buyer in this negotiation. In the second protocol we relax the assumption for the discrimination of prices for different buyer agents. The protocol attempts to find the joint gains between the buyers and seller by optimizing the total cost of the supply chain without disclosure of total cost or individual costs to each other or the mediator agent used for the purpose.
Wireless E-mail Security: A State-of-the-Art Review for Message Privacy and Protection from Application Perspective	This paper presents a state-of-the-art review of primary schemes for wireless e-mail security. It attempts to discuss most common standards available in the market place for e-mail security as well as their applicability on message privacy and protection. The main focus is given on e-mail security standards, message format types, email certificate and trust management systems and issues associated with each of these concepts from privacy and message integrity protection perspectives. Their applications on these two main security service areas are examined and real-world applied solutions are analyzed. The most common security standards, which are overviewed here, are 3DES, PEM, MOSS, PGP, PGP/MIME and S/MIME. It is assumed readers have basic knowledge on MIME specification.
A privacy paradigm that tradeoffs anonymity and trust	The protection of a principalpsilas private information over a network is problematic. It is even more so in non-hierarchical settings such as the Web 2.0, where each node both provides and requires data. Two paradigms exist to tackle these issues: one relies on the principalpsilas trust over the network, the other one insists on the principalpsilas anonymity. A new paradigm is advanced as a natural tradeoff between the two: it sees the principal act using her real identity but only circulate statistical information about the resource she requires. This signifies that the privacy requirement is shifted from the principalpsilas identity to her data. If evaluated with respect to the existing ones, the new paradigm appears simpler and more lightweight.
Security and privacy in a middleware for large scale mobile and pervasive augmented reality	Ubiquitous or pervasive computing is a new kind of computing, where specialized elements of hardware and software will have such high level of deployment that their use will be fully integrated with the environment. Augmented reality extends reality with virtual elements but tries to place the computer in a relatively unobtrusive, assistive role. In this paper we propose, test and analyse a security and privacy architecture for a previously proposed middleware architecture for mobile and pervasive large scale augmented reality games, which is the main contribution of this paper. The results show that the security features proposed in the scope of this work do not affect the overall performance of the system.
Privacy and security protection of RFID data in e-passport	E-passport is a biometric passport that combines both paper and electronic chip. It includes biometrics information and ID using RFID chip or tag. The goal of e-passport is to provide strong authentication through documents that unambiguously identify the passport holder. An e-passport can protect forging of ID and can make rapid progress in immigration. The use of RFID tag may cause privacy violation of users using the tag. Due to the unique identification number of the RFID tag, this is subjected to different privacy and security threats such as information leakage of a tag, traceability of the person, denial of service attack, and impersonation of a tag. This paper investigates different privacy and security problems in RFID systems used in e-passport and proposes the implementation of a proposed authentication protocol to overcome those privacy and security problems. Simulation experiments show that the protocol is secure for larger entropy.
Personal privacy and secondary-use dilemma (social aspects of automation)	A draft EC directive that threatens an embargo on personal information to any nation that does not satisfy its privacy requirements is discussed. The directive seeks to harmonize privacy laws to allow the free flow of personal data because many different approaches might impede economic ventures among members. A historical outline of the proscription of secondary use of personal information in the US is presented. The interpretation of the secondary use principle and two recent cases that demonstrate the wide range of disagreement on secondary use are also discussed.<<ETX>>
Software and privacy: revising Orwell	It is argued that employers frequently use computers as a surveillance device and a means to monitor almost every aspect of employee performance. Employers justify such conduct by asserting that this helps ensure job safety and workplace security, reduce costs and limit liability; and increase productivity, efficiency, and product quality. Taken too far, however, surveillance can make employees overstressed and anxious, ultimately hindering the employers' objectives. The use of impairment tests and computerized impairment tests are discussed. The privacy issues raised by computerized impairment tests are discussed.<<ETX>>
A Framework for Managing Privacy-Enhancing Technology	The changing global business environment and continued introduction of new technologies are significantly affecting organizations' privacy practices. In this environment, privacy-enhancing technology (PET) often becomes a key to protecting personal information. A considerable amount of literature has discussed PET technologies and their benefits. However, the lack of clear organizational accountability can become a roadblock to effectively designing and implementing PET solutions. For organizations that don't employ these solutions, the result is increased regulatory and privacy risk and potential costs related to privacy breaches. Establishing a multidisciplinary privacy committee with clear roles and responsibilities assigned to various members is a possible approach to help address accountability.
Security and privacy: promising advances	The paper discusses some promising advances in computer security. Security system designers and implementers must consider several factors: security policy, privileges, authentication, correctness and auditing. The paper presents an overview of some sub-fields and their successes: trusted systems, operating systems, database management systems, distributed systems, cryptography, protocols, system correctness, intrusion detection and mobile code
Privacy, security concerns take on new meaning	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00965812.png" border="0">
Employing Privacy-Preserving Techniques to Protect Control-Flow Graphs in a Decentralized, End-to-End Regression Test Selection Framework for Web Services	In an end-to-end, regression testing framework employing a safe regression test selection (RTS) technique that uses control-flow graphs (CFGs) to model Web service interactions, service providers must share their CFGs to participate. However, CFGs are sensitive implementation details and service providers are unwilling to expose them especially across autonomous systems. In order to encourage participation in the proposed framework, several privacy-preserving techniques are employed designed to protect the sensitive information contained within CFGs while still maintaining the overall effectiveness of the approach. The privacy-preserving techniques protect the information contained within CFGs by sanitizing individual nodes and altering the shape of the CFG. A case study will be presented to help illuminate the framework and provide a measure of the overall effectiveness of the approach.
Enabling Privacy in Cross-Organisational Information Mediation &#8212; An Application in Health Care	Establishing electronic exchange of information among collaborating organisations is a key goal in the public and private sector today. The desire to reduce costs while providing higher quality of service are two main drivers for this development. Confidential information about individual clients is often part of the information to be exchanged. Today, the handling of such information is governed by increasingly stringent privacy legislations. Ensuring compliance of such legislations during cross-organisational information mediation requires advanced middleware mechanisms. In this paper, we analyse requirements on such mechanisms and describe their prototypical realisation in the application domain of health care
Source-location privacy for networks of energy-constrained sensors	Wireless sensor networks are currently being investigated for ubiquitous computing applications. Privacy is a critical issue for these networks as adversaries may be able to eavesdrop or observe the presence of sensor data to infer information that was not intended to be revealed. The devices that constitute sensor networks are low-powered, compute-constrained devices. Any privacy solution should carefully consider the tradeoffs between supporting location-privacy and energy consumption. We explore two main classes of privacy issues: content privacy and originator location privacy. Content privacy can be maintained through conventional cryptographic methods that provide data confidentiality. We briefly discuss system design techniques that are needed to prevent an adversary from correlating observations from multiple messages to infer the content of encrypted sensor readings. We then examine the issue of protecting the originating sensor's location by studying several multihop routing mechanisms for ad hoc networks. We focus our discussion on three classes of routing protocols: the class of the shortest path routing protocols, the class offloading protocols, and a hybrid class of routing.
Privacy-concern for context-aware environments	Context-aware computing offers attractive services by collecting information from various sensors, and the services are adapted according to the current condition of the real world. However, the danger of overflowing personal information is also getting high because the data retrieved by the sensors usually contain privacy information. In this paper, we study on the tradeoff between privacy and the quality of services, and we present the design of our system that we are currently developing. Our proposed system controls the tradeoff according to a user's requirement, and guarantees the trustworthy of the management of privacy information.
A Privacy Preserving Smart Metering System Supporting Multiple Time Granularities	Advanced smart meters generate meter readings in a time unit less than a second. Fine-grained meter readings enable various smart grid applications, such as load monitoring, automatic billing, and power generation planning. However, those meter readings threaten individuals' privacy by revealing details of one's daily activities. The time granularity of smart meters is often much finer than the one a smart grid application demands. Thus, the storage and access control mechanisms of meter readings are critical to balancing privacy requirements and application functionalities. Previous studies address the issue by considering a locally trusted storage device and using cryptographic primitives. We consider a storage outsourcing scenario, where the external storage environment is semi-trusted. We construct a privacy preserving metering system by using a trusted platform module in a smart meter and pseudorandom number generators inside the module. Our system guarantees the secure storage of meter readings and supports multiple time granularities. In our system, a user grants a service provider an access right over meter readings at a time granularity S. The granted service provider is only allowed to get the power consumption at a time unit of the granted time granularity. Our system provides a simple yet very practical solution to the privacy preserving smart metering system. Moreover, we provide a privacy model to capture the privacy requirement and show that our system is privacy preserving against honest-but-curious service providers.
Is Data Privacy Always Good for Software Testing?	Database-centric applications (DCAs) are common in enterprise computing, and they use nontrivial databases. Testing of DCAs is increasingly outsourced to test centers in order to achieve lower cost and higher quality. When releasing proprietary DCAs, its databases should also be made available to test engineers, so that they can test using real data. Testing with real data is important, since fake data lacks many of the intricate semantic connections among the original data elements. However, different data privacy laws prevent organizations from sharing these data with test centers because databases contain sensitive information. Currently, testing is performed with fake data that often leads to worse code coverage and fewer uncovered bugs, thereby reducing the quality of DCAs and obliterating benefits of test outsourcing. We show that a popular data anonymization algorithm called k-anonymity seriously degrades test coverage of DCAs. We propose an approach that uses program analysis to guide selective application of k-anonymity. This approach helps protect sensitive data in databases while retaining testing efficacy. Our results show that for small values of k = 7, test coverage drops to less than 30% from the original coverage of more than 70%, thus making it difficult to achieve good quality when testing DCAs while applying data privacy.
PLA-based runtime dynamism in support of privacy-enhanced Web personalization	Software product line architectures (PLAs) have been widely recognized as a successful approach in industrial software development for improving productivity, software quality and time-to-market. In this paper, we focus on the usage of a PLA for a quite different purpose, namely, handling privacy constraints in Web personalization. To provide personalized services such as customized recommendations, a personalized Website collects users' personal data, which raises various privacy concerns. We aim at reconciling the benefits of web personalization with privacy constraints that come from users themselves as well as from privacy legislations and regulations that apply to a given user. We propose a dynamic, privacy-enabling personalization infrastructure and conceive it as a PLA. This infrastructure allows for dynamically selecting and instantiating personalization architectures that provide personalized services to each individual user and comply with the prevailing privacy constraints
Balancing Privacy and Utility in Cross-Company Defect Prediction	BACKGROUND: Cross Company Defect Prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized but that privatization could severely damage the utility of the data. AIM: To enable effective defect prediction from shared data, while preserving privacy. METHOD: We explore privatization algorithms that maintain class boundaries in a data-set. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among ten defect data-sets from the PROMISE data repository. RESULTS: We find: (a) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; (b) In terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. CONCLUSIONS: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction.
Engineering Privacy	In this paper we integrate insights from diverse islands of research on electronic privacy to offer a holistic view of privacy engineering and a systematic structure for the discipline's topics. First we discuss privacy requirements grounded in both historic and contemporary perspectives on privacy. We use a three-layer model of user privacy concerns to relate them to system operations (data transfer, storage and processing) and examine their effects on user behavior. In the second part of the paper we develop guidelines for building privacy-friendly systems. We distinguish two approaches: "privacy-by-policy" and "privacy-by-architecture." The privacy-by-policy approach focuses on the implementation of the notice and choice principles of fair information practices (FIPs), while the privacy-by-architecture approach minimizes the collection of identifiable personal data and emphasizes anonymization and client-side data storage and processing. We discuss both approaches with a view to their technical overlaps and boundaries as well as to economic feasibility. The paper aims to introduce engineers and computer scientists to the privacy research domain and provide concrete guidance on how to design privacy-friendly systems.
Analyzing Regulatory Rules for Privacy and Security Requirements	Information practices that use personal, financial, and health-related information are governed by US laws and regulations to prevent unauthorized use and disclosure. To ensure compliance under the law, the security and privacy requirements of relevant software systems must properly be aligned with these regulations. However, these regulations describe stakeholder rules, called rights and obligations, in complex and sometimes ambiguous legal language. These "rules" are often precursors to software requirements that must undergo considerable refinement and analysis before they become implementable. To support the software engineering effort to derive security requirements from regulations, we present a methodology for directly extracting access rights and obligations from regulation texts. The methodology provides statement-level coverage for an entire regulatory document to consistently identify and infer six types of data access constraints, handle complex cross references, resolve ambiguities, and assign required priorities between access rights and obligations to avoid unlawful information disclosures. We present results from applying this methodology to the entire regulation text of the US Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule.
Security Enhancements for Privacy and Key Management Protocol in IEEE 802.16e-2005	Security is highly critical in wireless communication, as wireless media is vulnerable to attacks. Mobile WiMAX is a new standard and it opens new horizons for security researchers. In this paper, authorization protocol for both versions of PKM in WiMAX has been analyzed. Possible attacks are also considered including interleaving, replay and suppress replay attack and a methodology is presented to prevent these attacks. It also describes WiMAX architecture, privacy and key management (PKM) protocols, their shortcomings and existing solutions for providing security along with enhanced proposed security solution for mentioned attacks. Existing solutions address these problems using timestamp or nonce. A hybrid approach of nonce and timestamp has been proposed to prevent the authorization protocol from such attacks.
Privacy Preserving of Associative Classification and Heuristic Approach	In the era of data explosion, privacy preserving has become a necessary task for any data mining task. Therefore, data transformation to ensure privacy preservation is needed. Meanwhile, the transformed data must have quality to be used in the intended data mining task, i.e. the impact on the data quality with regard to the data mining task must be minimized. However, the data transformation problem to preserve the data privacy while minimizing the impact has been proven as an NP-hard. Also, for classification mining, each classification approach may use different approach to deliver knowledge. Therefore, data quality metric for the classification task should be tailored to a specific type of classification. In this paper, we focus on maintaining the data quality in the scenarios which the transformed data will be used to build associative classification models. We propose a data quality metric for such the associative classification. Also, we propose a heuristic approach to preserve the privacy and maintain the data quality. Subsequently, we validate our proposed approaches with experiments.
A Reputation System with Privacy and Incentive	Reputation systems are designed for reducing the risk entailed in interactions among total strangers in electronic marketplaces. Such systems can be used to collect and aggregate feedback on the past behavior of participants in electronic transactions, so as to derive reputation scores assumed to predict likely future behavior. Privacy and incentive are mainly concerns in secure reputation systems for feedback providers to providing rating. In this paper, a reputation system is proposed, in which, feedback providers ' privacy can be achieved through anonymous technique by using smart card, incentive for feedback provider to provide rating can be achieved through discount token technique by using hash chain.
Localized Flooding Backbone Construction for Location Privacy in Sensor Networks	Source and destination location privacy is a challenging and important problem in sensor networks. Nevertheless, privacy preserving communication in sensor networks is still a virgin land. In this paper, we propose to protect location privacy via a flooding backbone, which is modeled by a minimum connected dominating set (MCDS) in unit-disk graphs. We design an efficient and localized algorithm to compute an approximate MCDS. Theoretical analysis indicates that our algorithm generates a connected dominating set (CDS) with a size at most 148 ldr opt + 37, where opt is the cardinality of a MCDS. To our best knowledge, this algorithm is the first localized algorithm with a constant performance ratio for CDS construction in unit-disk graphs.
(a, d)-Diversity: Privacy Protection Based on l-Diversity	In recent years, privacy protection has been emphasized while publishing data with sensitive information. Existing proposals for privacy protection can well avoid identity disclosure; however they do not provide sufficient protection for privacy under background knowledge attack. This paper analyzes the cause of attribute disclosure and proposes a novel idea for privacy protection based on l-Diversity. It takes the semantic meaning of the sensitive attributes into consideration and gives a stronger definition of privacy protection. First, the sensitive attribute values are divided into groups, and then the records are grouped according to the sensitive attribute. Finally, the table is anonymized. The experiment results shown in the paper demonstrate the feasibility of the proposal.
Privacy for Low-Power Sensor Node based on Alias in Ubiquitous Network	The sensors in a ubiquitous network are limited because of the low electricity and because they are ultra light, so many studies have revolved around the sensor. This study suggests a way to improve the registration and authorization processes of a sensor node based on an alias for privacy. We introduce RA (relay agent) for the restrict function of sensor node, and improve anonymity for private information of each sensor node by assigning alias from SM (service manager) in procedure of registration and authentication. The private information in each sensor node should be secured during every procedure. In the results of the analysis, safe communication between nodes was guaranteed with the only partial increment of computation power of RA and SM without an increase in the amount of sensor nodes
Privacy Protection Mechanisms for Web Service Technology	The successful use of Web service technology in areas such as healthcare and government depends on its support to privacy preservation. As there is currently no privacy standard for Web services, several solutions have recently been proposed in the literature to deal with privacy in Web services. However, there is no solution that provides a suitable mechanism to describe privacy properties in Web services. When loosely-coupled components are involved, such as in Web service environments, a rich description of components is needed to determine whether they can interact in a manner that preserves privacy. The goal of this paper is to present privacy protection mechanisms for Web services, which use policies defined in the Web Services Policy Framework (WS-Policy) and an ontology defined in the Web Ontology Language (OWL) in order to support Web service interactions with suitable privacy preservation levels.
Adaptive security and privacy in smart grids: A software engineering vision	Despite the benefits offered by smart grids, energy producers, distributors and consumers are increasingly concerned about possible security and privacy threats. These threats typically manifest themselves at runtime as new usage scenarios arise and vulnerabilities are discovered. Adaptive security and privacy promise to address these threats by increasing awareness and automating prevention, detection and recovery from security and privacy requirements' failures at runtime by re-configuring system controls and perhaps even changing requirements. This paper discusses the need for adaptive security and privacy in smart grids by presenting some motivating scenarios. We then outline some research issues that arise in engineering adaptive security. We particularly scrutinize published reports by NIST on smart grid security and privacy as the basis for our discussions.
Metamodel for privacy policies within SOA	As service-oriented architecture (SOA) continues to grow as a viable approach to systems development, so too does the number of services available. The strength of services in an SOA environment to provide interoperability comes at the cost of reduced privacy, as more interactions between autonomous services require more information to be exchanged. In this paper we define a metamodel for privacy policy creation and comparison based on fair information practices introduced around the world to protect the privacy of individuals. We develop criteria for the comparison of the elements that compose the policies, creating hierarchical relationships between those elements that could not otherwise be directly compared. An example of two policies being compared is presented to demonstrate how this comparison can be done. We believe this definition of how to create and compare privacy policies forms a strong foundation from which a comprehensive solution to SOA privacy can be built.
Precision: Privacy Enhanced Context-Aware Information Fusion in Ubiquitous Healthcare	Ubiquitous computing is an emerging paradigm for health care environments in which expedited decision making is of paramount importance. The information obtained from heterogeneous devices in such dynamic environments constitute a high degree of complexity, and emphasize the need for fusion. The realization of context-aware ubiquitous computing exacerbates existing privacy concerns. In this paper, we present Precision, a system for privacy enhanced context-aware information fusion in ubiquitous computing environments. In our scheme, privacy is defined as a set of parameters encapsulated in composite data entities called privons. Precision is an ongoing work, and in this paper, we discuss the overview of Precision and present preliminary results.
Taking account of privacy when designing cloud computing services	Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. In this paper the privacy challenges that software engineers face when targeting the cloud as their production environment to offer services are assessed, and key design principles to address these are suggested.
Practical anonymous subscription system with privacy preserving data mining	To date, one interesting research topic in constructing anonymous subscription systems is how to allow client profiling, while keeping customers anonymous when they access one service. Though several solutions have been proposed, the service providers are only endowed with limited ability of utilizing and analyzing accumulated transaction transcripts at the cost of weakened privacy protection. To overcome this obstacle, we put forth the first anonymous subscription system with privacy preserving data mining, which is derived by applying the technique of Kiayias-Xu-Yung data mining group signature to the underlying multi-service subscription system by Canard and Jambert. The most prominent benefit of the new system is that service providers can obtain the desired output by a quorum of trusted data mining servers, and at the same time the customers can preserve maximum possible anonymity. Performance comparison shows that the proposed system is more practical than several related schemes published recently.
Testing Privacy Policies Using Models	Privacy policies are usually expressed at a high level using languages such as P3P, EPAL, which are independent of applications. To check if a system satisfies a privacy policy requires to link it with the behaviour of the system and its environment. We propose a framework which is based on models to support the automation of testing if a software system meets a policy. In our framework, policies and system's behaviour are expressed using formal models. These formal models are then combined and used to derive test cases. The main advantage of this approach is the automation of the testing process. We demonstrateits applicability via two examples..
Privacy-preserving distributed association rule mining based on the secret sharing technique	Due to privacy law and motivation of business interests, privacy is concerned and has become an important issue in data mining. This paper explores the issue of privacy-preserving distributed association rule mining in vertically partitioned data among multiple parties, and proposes a collusion-resistant algorithm of distributed association rule mining based on the Shamir's secret sharing technique, which prevents effectively the collusive behaviors and conducts the computations across the parties without compromising their data privacy. Additionally, analyses with regard to the security, efficiency and correctness of the proposed algorithm are given.
Analysing Countermeasures Against Privacy-Invasive Software	User privacy is widely affected by the occurrence of privacy-invasive software (PIS) on the Internet. Various forms of countermeasures try to mitigate the negative effects caused by PIS. We use a computer forensic tool to evaluate an anti-spyware tool, with respect to found PIS over a four years period. Within the anti-spyware tool PIS was slowly identified, caused classification problems, and formely classified PIS were sometimes excluded. Background information on both PIS and countermeasure techniques are also presented, followed by discussions on legal disputes between developers of PIS and vendors of countermeasures.
Privacy and utility for defect prediction: Experiments with MORPH	Ideally, we can learn lessons from software projects across multiple organizations. However, a major impediment to such knowledge sharing are the privacy concerns of software development organizations. This paper aims to provide defect data-set owners with an effective means of privatizing their data prior to release. We explore MORPH which understands how to maintain class boundaries in a data-set. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. The value of training on this MORPHed data is tested via a 10-way within learning study and a cross learning study using Random Forests, Naive Bayes, and Logistic Regression for ten object-oriented defect datasets from the PROMISE data repository. Measured in terms of exposure of sensitive attributes, the MORPHed data was four times more private than the unMORPHed data. Also, in terms of the f-measures, there was little difference between the MORPHed and unMORPHed data (original data and data privatized by data-swapping) for both the cross and within study. We conclude that at least for the kinds of OO defect data studied in this project, data can be privatized without concerns for inference efficacy.
Architecting Pervasive Computing Systems for Privacy: A Survey	In pervasive computing systems, a higher number of interactions will be mediated by computers, amplifying the menace to privacy. Privacy protection in pervasive environments is still a big issue, despite the growing number of works on this subject as evidenced by this survey. In this paper, we propose a taxonomy for privacy invasion attacks, classify existing privacy enhancing technologies according to the protection provided for those attacks, and introduce a service-oriented privacy-enhanced architecture for pervasive computing.
Electronic Medical Records privacy preservation through k-anonymity clustering method	Electronic Medical Records (EMRs) enable the sharing of patient medical data whenever it is needed and also are used as a tool for building new medical technology and patient recommendation systems. Since EMRs include patients' private data, access is restricted to researchers. Thus, an anonymizing technique is necessary that keeps patients' private data safe while not damaging useful medical information. k-member clustering anonymization approaches k-anonymization as a clustering issue. The objective of the k-member clustering problem is to gather records that will minimize the data distortion during data generalization. Most of the previous clustering techniques include random seed selection. However, randomly selecting a cluster seed will provide inconsistent performance. The authors propose a k-member cluster seed selection algorithm (KMCSSA) that is distinct from the previous clustering methods. Instead of randomly selecting a cluster seed, the proposed method selects the seed based on the closeness centrality to provide consistent information loss (IL) and to reduce the information distortion. An adult database from University of California Irvine Machine Learning Repository was used for the experiment. By comparing the proposed method with two previous methods, the experimental results shows that KMCSSA provides superior performance with respect to information loss. The authors provide a privacy protection algorithm that derives consistent information loss and reduces the overall information distortion.
Can Friends Be Trusted? Exploring Privacy in Online Social Networks	In this paper, we present a case study describing the privacy and trust that exist within a small population of online social network users. We begin by formally characterizing different graphs in social network sites like Facebook. We then determine how often people are willing to divulge personal details to an unknown online user, an adversary. While most users in our sample did not share sensitive information when asked by an adversary, we found that more users were willing to divulge personal details to an adversary if there is a mutual friend connected to the adversary and the user. We then summarize the results and observations associated with this Facebook case study.
Twins (1): Extending SQL to Support Corporation Privacy Policies in Social Networks	Twins are two extensions onto SQL to support user privacy in social networks: one is corporate-based and the other is user-centric, corresponding to well-known mandatory access control and discretionary access control models, respectively. This paper illustrates the former. The approach adds some predicates to the CREATE TABLE command to capture common corporate-based user privacy requirements, such as purpose, generalization, and retention, required by social networks desiring to support privacy. Hence, the corporation, when creating the underlying databases, defines what the mandatory privacy policies are with which all users must comply. The extension is supported with underlying catalogues, algorithms, and prototype. The key contribution is a low-cost mechanism to develop new systems-that are privacy-preserved-and to transform legacy database MAC models to their privacy preserving equivalents. Although our examples are from social networks, the results apply to data security and user privacy of other enterprises too.
SQL Privacy Model for Social Networks	This is a preliminary work to extend SQL to support user privacy in social networks. The proposal is to extend the data definition and data manipulation languages to capture privacy-preserved mandatory and discretionary access controls, respectively. Here, we focus on common user privacy requirements, such as purpose, generalization, and retention, used by social networks desiring to support privacy. Hence, each user can discretionarily control the set of privileges over the view representing their profile. We plan to support the extended language with underlying catalogues, algorithms, and prototypes. The objective is to develop a low-cost mechanism to preserve privacy in databases,with applications in social networks, e-health, e-business, e-government, etc.
Applications in Security and Privacy	Much of the difficulty in creating information technology systems that truly meet people's needs lies in the problem of pinning down system requirements. This book offers a new approach to the requirements challenge, based on modeling and analyzing the relationships among stakeholders. Although the importance of the system-environment relationship has long been recognized in the requirements engineering field, most requirements modeling techniques express the relationship in mechanistic and behavioral terms. This book describes a modeling approach (called the i* framework) that conceives of software-based information systems as being situated in environments in which social actors relate to each other in terms of goals to be achieved, tasks to be performed, and resources to be furnished. Social perspectives on computing have provided much insight for many years. The i* framework aims to offer a modeling approach to the relationships embedded in computer systems that is part of an engineering method that offers systematic techniques and tools providing smooth linkages to the rest of the system development process, including system design and implementation. The book includes Eric Yu's original proposal for the i* framework as well as research that applies, adapts, extends, or evaluates the social modeling concepts and approach.
A Case Study of Community Privacy	Information privacy is desired not only by individuals but also by a community of individuals to safeguard sensitive information for which they are collectively responsible. This paper reports on two aspects of privacy-aware communities that emerged from focus group interviews of three organizations: privacy awareness and situated disclosures. With respect to privacy awareness the study found that individuals within a community sought to limit the disclosure of information sensitive to their members, to their customers, or to the organization itself. The sensitivity resulted from a variety of factors ranging from legal mandates to concern for the dignity of co-workers. The complexity of the communities and the interactions between community factors and privacy were seen. With respect to situated disclosures it was found that compelling organizational interests motivated the disclosure of sensitive information outside of the usual community. However, these disclosures also involved securing internal agreement prior to disclosure, the weighing of the organizational interests against privacy concerns, and the recognition of varying levels of privacy. The relation of these findings to a community privacy model is also presented.
Preserve Your Privacy with PCO: A Privacy Sensitive Architecture for Context Obfuscation for Pervasive E-Community Based Applications	Context awareness is just beginning to revolutionize the ways we interact with networked devices. In order for context awareness to flourish, especially in a pervasive environment, users must be certain that their privacy is respected. Privacy in pervasive online community depends on the level of granularity of the provided information, user's relation to possible recipients, and the possible usage of user's data. Conventional privacy preservation techniques are not suitable for these pervasive applications. The notion of this paper is to present the preliminary results of using a unique architecture of obfuscation techniques to preserve users' privacy in e-community based applications. This paper describes our current work in developing a novel Privacy-sensitive architecture for Context Obfuscation (PCO) for privacy preservation in pervasive online community based applications. More specifically, PCO safeguards a user's privacy by generalizing the contextual data (e.g. the user's current activity) provided to the applications and distributed to the user's peers. To support multiple levels of granularity for the released contextual data, the obfuscation procedure uses an ontological description that states the granularity of object type instances. We have developed and evaluated a contextual instant messaging application (PCO application) in Android platform that incorporates level-based privacy of the user's contextual information. We also evaluate our prototype application through user evaluation survey.
Security and Privacy Risks of Using E-mail Address as an Identity	More and more websites are allowing or requiring users to input their e-mail addresses to be used either as identities or for other purposes. Although username-based identity and password problems resulting from user behaviors have been a research focus for quite some time, the serious issues related to using e-mail address as an identity and the associated online behaviors of users have not been well investigated in the literature. In this paper, we discuss and analyze security and privacy problems resulting from the use of e-mail address as identity via well-designed user behavior survey and by investigating website's design schemes. Our results illustrate that using e-mail address as an identity poses high security and privacy risks. This is mainly because of the multiple usages of e-mail addresses and users' improper online habits. Moreover, we discuss the drawbacks of existing solutions for e-mail address as identity and related password problems, and present two potential solutions that may secure online identity management systems in future.
Information Privacy in Two Dimensions - Towards a Classification Scheme for Information Privacy Research	The field of information privacy comprises of research from a number of different academic disciplines. The field has received increased attention in the last decade and is growing. Consequently, a risk exists that certain areas of research in the field may be neglected. In order to identify areas of neglect in a methodical manner it is first necessary to classify research in the field; however, no classification scheme designed for this purpose exists. This paper contributes by presenting, discussing and demonstrating such a classification scheme. The classification scheme presented consists of two broad dimensions that are designed to classify information research from various academic disciplines.
Enhanced Privacy ID from Bilinear Pairing for Hardware Authentication and Attestation	Enhanced Privacy ID (EPID) is a cryptographic scheme that enables the remote authentication and attestation of a hardware device while preserving the privacy of the device. EPID can be seen as a direct anonymous attestation scheme with enhanced revocation capabilities. In EPID, a device can be revoked if the private key embedded in the hardware device has been extracted and published widely so that the revocation manager finds the corrupted private key. In addition, the revocation manager can revoke a device based on the signatures the device has created, if the private key of the device is not known. In this paper, we introduce a new security notion of EPID including the formal definitions of anonymity and unforgeability. We also give a construction of an EPID scheme from bilinear pairing. Our EPID scheme is efficient and provably secure in the random oracle model under the strong Diffie-Hellman assumption and the decisional Diffie-Hellman assumption.
Evaluating Potentials of Internet- and Web-based Socialtv in the Light of Privacy	In the current information technology age, the demand of tools that meet social interaction needs, e.g. SocialTV and Internet-based media advertisement, is gaining in importance. Thus privacy becomes a matter of concern in this respect. Social interactions comprises privacy risks and threats that may enable abuse, e.g., man-in-the-middle attacks based on profile analysis at the server-side. Since in the area of SocialTV current software as well as hardware solutions are mostly server-centric, one cannot fully eliminate accidental or intentional risks and threats even by the reconstruction of users' personal information and their interdependencies. In this paper, we report on results of an evaluation of the potentials of SocialTV by considering end-users' privacy based on lab and field trials. In these trials we enabled eighteen people of various ages and expertise to use centralized as well as decentralized (group-centric) solutions for SocialTV by means of a Web-based software prototype. Further, we describe the followed methodology used by the evaluation in order to allow porting it for future evaluations in other social contexts.
CBPM: Context Based Privacy Model	Information centers in industries are facing privacy concerns in recent years. Though there exists persuasive models, the privacy is not assured for industries that no identifiable information will get into unauthorized entities hands. They are based on user, role or service identification. In this paper we proposed Context Based Privacy Model(CBPM), which is based on context identification of the consultant. The major contribution of the paper is to disseminate information according to it's privacy policy rather than the content. CBPM uses a matrix which holds permissions for each context over sets of pieces of information having similar privacy policy. The steps involved in implementing CBPM is presented as an algorithm. The paper also presents the usability of the model through discussing a case and by implementing Bell-LaPadula model, Ethical Wall model and Information Flow models using CBPM.
On Generating RFID Privacy Policies in Consideration of Openness and Enforcement	Several consumer protection groups and authorities in different countries have recently proposed guidelines for Radio Frequency Identification (RFID) privacy. Guidelines typically request that RFID application providers publish their privacy policies. Although several guidelines outline the primary components of privacy policies, few guideline have addressed how RFID application providers can establish privacy policies. This work proposes a scheme, which is going to be adopted by the RFID Applications for Campus Security and Safety Enhancement Project in Taiwan, to help RFID application providers establish RFID privacy policies in consideration of openness and enforcement. By using the proposed scheme, RFID application providers can clarify privacy practices for their applications in RFID privacy policies and communicate these policies to application users. Moreover, application providers can provide evidence to third parties trusted by both application providers and users to ensure that policies are enforced. While an increasing number of countries have started requesting that RFID application providers publish their privacy policies, this work will help countries develop guidelines and regulations for RFID application providers establishing application-based privacy policies.
Privacy Aspects of Mashup Architecture	Evolution of Web 2.0 applications has changed the outlook of business models and companies. Organizations need to rethink their communication, marketing and sale channels and how their employees and customers interact together internally and externally. Following this new trend, they also need to adopt their IT infrastructure and enhance their online presence and services in order to stay competitive in their businesses. Through this technological transition to Web 2.0 paradigm new security and privacy issues arise which should be taken into consideration to protect the whole Rich Internet Application (RIA) components. Web 2.0 has also introduced new possibilities for a better human computer interaction via rich internet applications such as Mashups that provide a user-driven micro-integration of web-accessible data. At the moment Mashups are mainly used for less important tasks such as customized queries and map-based visualizations; however they have the potential to be used for more fundamental, complex and sophisticated tasks in combination with business processes. In this paper, the security and privacy aspects of Mashup Architecture and some existing challenges will be discussed in more details.
Towards a Risk-Driven Methodology for Privacy Metrics Development	Large amounts of privacy-critical data are transferred, processed and stored in services like cloud computing. Sufficient and credible evidence of the actual privacy level of these kinds of services is needed to be able meet the increased privacy requirements. In this study, we propose a generic risk-driven methodology for development of privacy metrics. The methodology is based on privacy threat analysis, utilization of taxonomical information, and decomposition of privacy and system requirements. The stages of the methodology are discussed using cloud services as an example. Moreover, feasibility of the proposed approach is discussed.
A Vagueness-based Obfuscation Technique for Protecting Location Privacy	Technical evolution of location technologies has augmented the development and growth of location-based services. With widespread adoption of these services, threats to location privacy are increasing, entailing more robust and sophisticated solutions. This paper proposes an intuitive obfuscation-based scheme, which uses vagueness in human perception of nearness to provide a flexible and robust location privacy scheme. Key to this work is the concept of vagueness degree, which aims to enhance its robustness against privacy attacks. Furthermore, our scheme is totally in line with human perception of privacy and provides a solution, which mostly suits proximity-based services, social networking environments, and other similar applications. The solution is also applicable to various environments ranging from geographical locations to IP-based and mobile Networks. We propose three privacy-aware architectures for our scheme. In addition, it is shown that the time and space complexity of the scheme is polynomial. The robustness of the scheme against privacy attacks as well as its implementation issues are discussed.
Achieving Receiver Location Privacy in Mobile Ad Hoc Networks	Privacy attacks to ad hoc routing protocols become an important issue as mobile ad hoc networks enter security critical domains. The location privacy of end nodes remains to be solved even when identification anonymity issues are addressed in the wireless routing protocol. Location privacy attacks can be performed by tracing either route discovery messages or data packets in order to discover the message's origin or destination venue. In this work we propose a protocol to provide receiver location privacy in mobile ad hoc networks. In general, anonymity is achieved by hiding the entity of interest among a number of similar entities, the anonymity set, so that it is not obvious to outsiders which anonymity set member is the real entity. The main contribution of this paper is to perform the routing in a way that the location of the destination node cannot be discovered by the adversary. This protocol supports receiver location privacy even against a global traffic analyzer. We use both, privacy analysis and simulation, to study the anonymity and routing performance for the proposed approach.
A Privacy-Enabled Architecture for an RFID-based Location Monitoring System	In large hospitals, location discovery and contact discovery presents possibilities to quickly find someone in an emergency, to narrow the epidemiologic scope of an outbreak, and to reinforce good safety practices. An RFID architecture can make the necessary location data available for knowledge extraction. While people can carry RFID tags to help track their location, their location privacy must also be protected from unauthorized surveillance throughout its collection. This paper proposes a privacy-enabled architecture for an RFID-based hospital location tracing system that prevents network eavesdroppers from tracing a person's location after associating a person to a tag's identifier.
Correcting Codes in the Quantum Keys Reconciliation: Scenarios of Privacy Maintenance	The proposition of Buttler and his team to integrate the privacy maintenance into the errors correction stage of a quantum cryptography protocol, commonly called reconciliation, allowed the elaboration of a fast and efficient algorithm. A similar and parallel work which we shall develop along this article consists in targeting the insertion of various scenarios applied for the algorithms Winnow and Cascade. These scenarios are based on iterative methods of blocks subdivision, detection of the certain errors bits and the decrease of the information revealed to the eavesdropper. Comparative studies by simulation allow the correction power's estimation, the time complexity and the efficiency of each scenario.
2Ploc: Preserving Privacy in Location-based Services	Location-based services are becoming popular for mobile users. The mobile users' location plays a key role to provide the service from one side, but it can be considered as a dimension of their privacy and so necessary to keep it anonymous to the other parties. Since one important issue is to achieve an accurate service, it is important to use the mobile's accurate location. Using the location accurately raises some concerns on behalf of the user's privacy. One solution for meeting this requirement is using tickets by the means of a third party. The tickets should have some properties for not letting a mobile user to cheat and use the ticket more than one time. This paper proposes a protocol to preserve Preserve Privacy in Location based services, in short 2PLoc, aimed to provide anonymity of location, for location based services, based on onetime tickets regardless of the existence of any trusted third party. The protocol satisfies the requirement of accurate location use, as well as the ability of revoking anonymity on the ticket double spending. The user, location-based service provider, and the ticket issuer are the three untrusted parties in 2PLoc. 2PLoc is based on a special designed ticket that disconnects the relation between the location of the mobile user and its identity. The ticket is designed based on the blind signature and the concept of elliptic curves discrete logarithm.
User's Perspective: Privacy and Security of Information on Social Networks	The goal of this study was to test the broader applicability of the findings in the 2009 research by L. S├╕rensen and K. Skouby, titled "Next Generation Social Networks - What Users Want". Their small-scale study, that examined high-level user requirements of future web-based social networks, showed that "users have high concerns towards the handling of their private data in web-based social networks generally calling for a higher focus on securing trust and privacy". With a sample population from various age groups and backgrounds such as environmental health, math, chemistry and information technology we found their results are not directly applicable to the general population of social networking site users.
Residential Appliance DR Energy Management With Electric Privacy Protection by Online Stochastic Optimization	This paper explores electric privacy issues that may occur along with the residential appliance demand response (DR) energy management in smart meters. Three metrics are introduced to quantitatively measure the spatial and/or temporal similarity of metered power profiles. The online stochastic optimization adopts the scenario-based approach via Monte Carlo (MC) simulation for minimizing the sum of the expected electricity payment and the weighted difference among metered power profiles for the entire day, which are measured by the three similarity metrics, in order to balance the tradeoff between the electricity payment and the electric privacy protection. In addition, batteries are employed to disguise the actual appliance power profile along with the scheduling horizon and enhance the electric privacy protection. Numerical case studies illustrate the effectiveness of the proposed approach for protecting the electric privacy in residential appliance DR energy management.
Smart Meter Privacy: A Theoretical Framework	The solutions offered to-date for end-user privacy in smart meter measurements, a well-known challenge in the smart grid, have been tied to specific technologies such as batteries or assumptions on data usage without quantifying the loss of benefit (utility) that results from any such approach. Using tools from information theory and a hidden Markov model for the measurements, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. For a stationary Gaussian model of the electricity load, it is shown that for a desired mean-square distortion (utility) measure between the measured and revealed data, the optimal privacy-preserving solution: i) exploits the presence of high-power but less private appliance spectra as implicit distortion noise, and ii) filters out frequency components with lower power relative to a distortion threshold; this approach encompasses many previously proposed approaches to smart meter privacy.
Aggregated-Proofs Based Privacy-Preserving Authentication for V2G Networks in the Smart Grid	Vehicle-to-grid (V2G) as an essential network component of smart grid, provides services by periodically collecting the charging status of a battery vehicle (BV). A BV is normally associated with a default interest group (e.g., power grid operator). When the BV accesses its default charging or communication point, it works in the home mode. The BV may move around and temporarily access other aggregators, and then it works in the visiting mode. In this paper, we first identify that, for an aggregator, BVs have different security challenges when they work in different modes. Then, we propose an aggregated-proofs based privacy-preserving authentication scheme (AP3A) to achieve simultaneous identification and secure identification for different working mode BVs. In AP3A, BVs are differentiated into either home or visiting mode, and multiple BVs can be simultaneously authenticated by an aggregator to conserve communication resources. In addition, the aggregated pseudo-status variation is presented to realize that multiple BVs' power status can be collected as a whole without revealing any individual privacy. We perform comprehensive analysis on the proposed scheme, including attack analysis, security analysis, and performance analysis. It is shown that AP3A can resist major attacks for security protection and privacy preservation, and can be an efficient authentication approach for V2G networks.
<formula formulatype="inline"> <img src="/images/tex/19728.gif" alt="P^{2}"> </formula>: Privacy-Preserving Communication and Precise Reward Architecture for V2G Networks in Smart Grid	Vehicle-to-grid (V2G) networks are important components of the smart grid (SG) for their capability of providing better ancillary services and facilitating the adoption of renewable resources. The operation of the V2G networks is based on continuously monitoring the status of individual battery vehicle (BV) as well as a carefully designed incentive scheme to attract sufficient participating BVs. However, the close monitoring tends to raise privacy concerns from the BV owners about identity and location information leakage, which have not been considered in previous works. In this paper, we make the first attempt to identify the privacy-preserving issues and propose a precise reward scheme in V2G networks, both of which are important towards bringing the concept of V2G network into practice. In V2G networks, it is the service providers (individual BVs) who need privacy protection rather than the service consumer (power grid). This unique characteristic renders privacy protection solutions proposed for conventional network systems not directly applicable. To protect privacy of BVs in V2G networks, we present , a secure communication architecture which achieves privacy-preserving for both BVs' monitoring and rewarding processes. Extensive performance analysis shows that only incurs moderate communication and computational overheads.
Privacy-Aware Profiling and Statistical Data Extraction for Smart Sustainable Energy Systems	The growing population and global warming have been calling for more effective energy usage, which have stimulated the emergence of smart sustainable energy technology. The distinct feature of this newly emerging technology is the incorporation of advanced information and communication technologies (ICT), which collects more detailed information on how energy is generated, distributed, and consumed. Various smart metering technologies have also been proposed to support the optimization on sustainable energy usage. Despite the obvious benefits of these technologies, people may still hesitate to adopt them because of possible privacy breach. On the other hand, we observe that the major target information for making the sustainable energy system smart is the aggregated statistics of energy usage, not the full detailed usage profiles which would compromise customers' privacy. Thus, how to design schemes to collect aggregated statistics while preserving customers' privacy becomes an important research problem. In this paper, we propose two schemes to deal with this problem. The first one can support dynamic profiling, which can extract aggregated statistical information without compromising individual privacy. The second one aims to extract correlation information among various factors for the smart system design and can also be used as an underlying tool for baseline inference and association rule mining.
A Randomized Response Model for Privacy Preserving Smart Metering	The adoption of smart meters may bring new privacy concerns to the general public. Given the fact that metering data of individual homes/factories is accumulated every 15 min, it is possible to infer the pattern of electricity consumption of individual users. In order to protect the privacy of users in a completely de-centralized setting (i.e., individuals do not communicate with one another), we propose a novel protocol, which allows individual meters to report the true electricity consumption reading with a pre-determined probability. Load serving entities (LSE) can reconstruct the total electricity consumption of a region or a district through inference algorithm, but their ability of identifying individual users' energy consumption pattern is significantly reduced. Using simulated data, we verify the feasibility of the proposed method and demonstrate performance advantages over existing approaches.
UDP: Usage-Based Dynamic Pricing With Privacy Preservation for Smart Grid	Smart sensing and wireless communication technologies enable the electric power grid system to deliver electricity more efficiently through the dynamic analysis of the electricity demand and supply. The current solution is to extend the traditional static electricity pricing strategy to a time-based one where peak-time prices are defined to influence electricity usage behavior of customers. However, the time-based pricing strategy is not truly dynamic and the electricity resource cannot be optimally utilized in real time. In this paper, we propose a usage-based dynamic pricing (UDP) scheme for smart grid in a community environment, which enables the electricity price to correspond to the electricity usage in real time. In the UDP scheme, to simplify price management and reduce communication overhead, we introduce distributed community gateways as proxies of the utility company to timely respond to the price enquiries from the community customers. We consider both community-wide electricity usage and individual electricity usage as factors into price management: a customer gets higher electricity unit price if its own electricity usage becomes larger under certain conditions of the community-wide collective electricity usage. Additionally, we protect the privacy of the customers by restricting the disclosure of the individual electricity usage to the community gateways. Lastly, we provide privacy and performance analysis to demonstrate that the UDP scheme supports real-time dynamic pricing in an efficient and privacy-preserving manner.
ElecPrivacy: Evaluating the Privacy Protection of Electricity Management Algorithms	The data collected by a home smart meter can potentially reveal sensitive private information about the home resident(s). In this paper, we study how home energy resources can be used to protect the privacy of the collected data. In particular we: a) introduce a power mixing algorithm to selectively protect a set of consumption events; b) develop a range of different privacy protection metrics; c) analyze real smart metering data sampled twice a minute over a period of 13 days; and d) evaluate the protection offered by different power mixing algorithms. Major factors which determine the efficiency of the proposed power mixing algorithms are identified, such as battery capacity and power, and user preferences for privacy-based allocations of battery energy quotas.
Implementing Privacy by Design: The smart meter case	The principles of Privacy by Design are gaining increasing support by policymakers and regulators and have been put forth as guidelines for smart meter deployments both in Europe and North America. For concrete implementations, however, it can be daunting as to what an electricity network operator should do to design privacy principles into their system. In the following paper, we outline the case of smart meter implementations, and propose aggregation protocols and cryptographic technologies that can be used to concretely implement Privacy by Design at the level of meter data, leading to not only privacy protection but at the same time, achieving a positive business impact.
Analysis of privacy-enhancing protocols based on anonymity networks	In this paper, we analyze privacy-enhancing protocols for Smart Grids that are based on anonymity networks. The underlying idea behind such protocols is attributing two distinct partial identities for each consumer. One is used to send real-time information about the power consumption, and the other for transmitting the billing information. Such protocols provide sender-anonymity for the real-time information, while consolidated data is sent for billing. In this work, the privacy properties of such protocols are analyzed, and their computational efficiency is evaluated and compared using simulation to other solutions based on homomorphic encryption.
PeHEMS: Privacy enabled HEMS and load balancing prototype	Smart grid efficient load balancing and the need for privacy are, in principle, contradictory. While richer information obtained from frequent energy readings help improve both the prediction and the control of the demand, and, effectively, improve the efficiency of the energy equilibrium production problem, it also gives rise to consumer privacy concerns. This is possible by analysing energy signatures to detect appliance usage and home living patterns of behaviour, which in effect cascades to a range of privacy invasion risks. This paper argues that the objective of energy efficiency might not necessarily be contradictory to protecting user privacy. In particular, we introduce a new notion of smart meter privacy which we call reconciled privacy and we connect it with a simple energy management algorithm that caps the energy a home may consume in 30 minute intervals by using a rechargeable battery system. System benchmarking is underpinned by formulating a methodology to assess a) utility cost savings, b) wholesale energy savings, and c) privacy protection. Our results suggest that the proposed algorithm will protect customer privacy and will improve energy production efficiency as compared with other energy management schemes. This is due to the algorithm's principle of promoting a universal consumption pattern that is close to its average, which in retrospect allows individual usage differences to be absorbed. To support this work, we use data from trials in Bristol city, which forms part of the 3eHouses EU FP7 project, and we present a prototype implementation showcasing the visualisation of privacy and energy control.
Privacy constrained energy management in microgrid systems	We propose privacy-preserved joint supply- and demand-side energy management strategies for a microgrid system that consists of several cells and a control center, with each cell composed of a smart meter, a distributed energy generator and some energy consuming customers. It is assumed that the cells can cooperate by exchanging their locally generated energy and they can obtain external energy, both through the control center. The problem is formulated as privacy-constrained linear optimization problem to optimality regulate the energy utilization within the microgrid system for reducing the energy shortage which needs to be fulfilled by externally imported energy. To solve this problem, we develop a privacy-preserving scheme that performs the proposed dual decomposition-based algorithm in a distributed fashion with the limited information exchanges. Finally, the optimal energy schedule is obtained without the privacy violation and simulation results are provided to demonstrate the superior performance of the proposed techniques over the traditional methods.
Smart meter privacy in the presence of energy harvesting and storage devices	While increasing the efficiency in generation, distribution and storage of energy in a smart grid, smart meters also allow the utility provider to monitor the energy consumption behavior of the users, leading to important threats to privacy. In this paper, privacy in a smart metering system is studied from an information theoretic perspective in the presence of energy harvesting and storage units. It is shown that energy harvesting provides increased privacy by diversifying the energy source, while the storage device can be used to increase both the energy efficiency and the privacy of the user. For given input load and energy harvesting rates, it is shown that there exists a trade-off between the information leakage rate, which is used to measure the privacy of the user, and the wasted energy rate, which is a measure of the energy-efficiency. The impact of the energy harvesting rate and the size of the storage device on this trade-off is also studied.
P3: Privacy preservation protocol for appliance control application	To address recently emerging concerns on privacy violations, this paper investigates possible sensitive information leakages in the appliance control, which is one of the handiest and most visible applications in smart grids. Without a consistent privacy preservation mechanism, the appliance control system can capture, model and divulge customers' behavior, activities, and personal information at almost every level of society. We investigated a privacy threat model for the appliance control application and further design and implement a protection protocol. Experiment results demonstrate that our protocol merely incurs a substantially light overhead on the appliance control application, but is able to address and solve the formidable challenges both customers and utility companies are facing.
Competitive privacy in the smart grid: An information-theoretic approach	Advances in sensing and communication capabilities as well as power industry deregulation are driving the need for distributed state estimation at the regional transmission organizations (RTOs). This leads to a new competitive privacy problem amongst the RTOs since there is a tension between sharing data to ensure network reliability (utility/benefit to all RTOs) and withholding data for profitability and privacy reasons. The resulting tradeoff between utility, quantified via fidelity of its state estimate at each RTO, and privacy, quantified via the leakage of the state of one RTO at other RTOs, is captured precisely using a lossy source coding problem formulation for a two RTO network. For a two-RTO model, it is shown that the set of all feasible utility-privacy pairs can be achieved via a single round of communication when each RTO communicates taking into account the correlation between the measured data at both RTOs. The lossy source coding problem and solution developed here is also of independent interest.
PASS: Privacy-preserving authentication scheme for smart grid network	A smart grid power system is capable of adjusting the amount of electricity generated based on real-time requests from the smart meters of customers, thus avoiding excess electricity generation and facilitating reliable and effective transmission of electricity. To ensure that requests are sent from a valid user, all request messages must be authenticated. On the other hand, by analyzing the electricity usage pattern of a customer, the daily habit of the customer, such as when he is away, may be revealed. Thus, a proper privacy preserving mechanism has to be adopted. This paper attempts to develop a scheme to address these two seemingly contradicting requirements efficiently. By using a tamper-resistant device at the smart appliance and pseudo identities, we derive a privacy preserving authentication scheme to solve the problem. The authentication process is made very efficient by means of Hash-based Message Authentication Code (HMAC). Through simulation, we show that with our scheme, the transmission and signature verification delay induced are very small and the message overhead is only 20 bytes per request message. With our efficient verification process, even under attack, the substation can effectively drop all attack messages, allowing 6 times more valid messages to reach the control center when compared to the case without any verification. Thus our scheme is both efficient and effective.
Cooperative state estimation for preserving privacy of user behaviors in smart grid	Smart grid promises a reliable and secure electricity infrastructure to meet the future demand growth. However, the increase of data types and data amount from advanced smart grid introduce new privacy issues, which have to be resolved for customers. This paper presents a cooperative state estimation technique that protects the privacy of users' daily activities. By exploiting the kernel of an electric grid configuration matrix, we develop an error free state estimation technique that can hide the behavioral information of users effectively. The proposed scheme can obfuscate the privacy-prone data without compromising the performance of state estimation. We evaluate our obfuscation scheme using data from 1349 meters in 5 IEEE Electric Test Bus Systems. Our simulation results demonstrate high level of illegibility and resilience of our scheme with an affordable communication overhead.
Smart meter privacy: A utility-privacy framework	End-user privacy in smart meter measurements is a well-known challenge in the smart grid. The solutions offered thus far have been tied to specific technologies such as batteries or assumptions on data usage. Existing solutions have also not quantified the loss of benefit (utility) that results from any such privacy-preserving approach. Using tools from information theory, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. Specifically for a stationary Gaussian Markov model of the electricity load, it is shown that the optimal utility-and-privacy preserving solution requires filtering out frequency components that are low in power, and this approach appears to encompass most of the proposed privacy approaches.
GERI - Bell Labs Smart Grid Research Focus: Economic Modeling, Networking, and Security & Privacy	In this paper, we outline the Grid 2.0 Research, a collaborative Smart Grid research program between Gachon Energy Research Institute (GERI) of Kyungwon University and Bell Labs of Alcatel-Lucent. Salient features of the Grid 2.0 Research are the active role of distributed fixed and mobile energy storage, distributed renewable energy sources, and active load-side participation. Our focus is not on the energy storage itself but rather on the supporting infrastructure including communication network, security, and economics of the Smart Grid. Grid 2.0 Research views the Smart Grid as an ecosystem. In this regard, we pay close attention to the components and systems which require significant fundamental advancement or systems which do not exist today, thus requiring innovative solutions or greater sophistication. In order to realize a functioning ecosystem, critical components and tools of the envisioned Smart Grid are identified. This research work has been motivated by the Smart Grid roadmap of KEPCO and the Jeju Island Smart Grid Test-bed of Korea which will be discussed following the introduction section. Areas of research focus will be explained in a concise manner in the subsequent sections.
Smart Grid Privacy via Anonymization of Smart Metering Data	The security and privacy of future smart grid and smart metering networks is important to their rollout and eventual acceptance by the public: research in this area is ongoing and smart meter users will need to be reassured that their data is secure. This paper describes a method for securely anonymizing frequent (for example, every few minutes) electrical metering data sent by a smart meter. Although such frequent metering data may be required by a utility or electrical energy distribution network for operational reasons, this data may not necessarily need to be attributable to a specific smart meter or consumer. It does, however, need to be securely attributable to a specific location (e.g. a group of houses or apartments) within the electricity distribution network. The method described in this paper provides a 3rd party escrow mechanism for authenticated anonymous meter readings which are difficult to associate with a particular smart meter or customer. This method does not preclude the provision of attributable metering data that is required for other purposes such as billing, account management or marketing research purposes.
Privacy for Smart Meters: Towards Undetectable Appliance Load Signatures	Smart grid privacy encompasses the privacy of information extracted by analysing smart metering data. In this paper, we suggest that home electrical power routing can be used to moderate the home's load signature in order to hide appliance usage information. In particular, (1) we introduce a power management model using a rechargeable battery, (2) we propose a power mixing algorithm, and (3) we evaluate its protection level by proposing three different privacy metrics: an information theoretic (relative entropy), a clustering classification, and a correlation/regression one; these are tested on different metering datasets. This paper sets the ground for further research on the subject of optimising home energy management with regards to hiding load signatures.
Confronting Security and Privacy Threats in Modern RFID Systems	The modern form of RFID technology that is set to dominate is that enabled by low cost RFID technology. This paper presents an overview of the technological aspects vital to illuminating associated security and privacy threats The paper also describes a simple security model and briefly considers some of the vulnerabilities faced by such low cost RFID systems. Finally the authors would like to extend preliminary work published on a minimalist encryption method first published in [26] and [27].
Reasoning about privacy using axioms	In statistical privacy, privacy definitions are contracts that guide the behavior of algorithms that take in sensitive data and produce sanitized data. Historically, data privacy breaches have been the result of fundamental misunderstandings about what a particular privacy definition guarantees. Privacy definitions are often analyzed using a hit-or-miss approach: a specific attack strategy is evaluated to determine if a specific type of information can be inferred. If the attack works, the privacy definition is known to be too weak. If it doesn't work, little information is gained. Furthermore, these strategies will not identify cases where a privacy definition protects unnecessary pieces of information. A systematic analysis of privacy definitions is a long-standing open problem. In this paper, we present initial steps towards a solution. Using privacy axioms, we identify two mathematical objects that are associated with privacy definitions - the consistent closure and the row cone (which is constructed from the consistent closure). The row cone is a geometric object which neatly encapsulates Bayesian guarantees provided by a privacy definition. We apply these ideas to the study of randomized response to show that it provides unnecessarily strong protections on the parity of a dataset.
Competitive privacy in the smart grid	The requirement of wide-area monitoring in the deregulated electric grid is driving the need for distributed state estimation. This leads to a novel problem of competitive privacy amongst energy providers (operators) that captures the conflict between the need for collaboration to estimate the global system state with high fidelity (utility) and the need to withhold data (privacy) for competitive reasons. The precise tradeoff between utility and privacy is made explicit using rate distortion theory with privacy constraints for a two-operator network. Practical approaches are briefly discussed.
Session TA4b: Signal processing for cyber-security and privacy in networks (invited) [breaker page]	Start of the above-titled section of the conference proceedings record.
Cooperative multihop localization with privacy	We introduce a cooperative algorithm for self and target network localization with privacy. The algorithm differs form other cooperative localization algorithms in which it does not require nodes to disclose their location or even to measure (or share) their mutual distances. This is achieved by a combination of two factors: a) a novel closed-form statistical relationship between the hop- and Euclidean-distances of distributed random Breadth Search First (BSF) paths; and b) novel multihop localization algorithms. The results, compared against conventional multihop distance collection indicate that, remarkably, the privacy offered by the proposed cooperative localization algorithm does not incur any significant sacrifice in accuracy.
A minimal protocol with public key cryptography for identification and privacy in RFID tags	We propose a protocol that minimizes the cryptographic effort on an RFID tag without requiring a backend database record for each tag. The protocol allows a tag to identify itself only to its owner. When a product is sold, the tag ownership is changed in a secure way. Security is based on public key cryptography, which is becoming economically practical for RFID tags. With this protocol, tag owners need not share secrets with each other or any central database and therefore privacy will be provided by technology, which is inherently more robust than public policy.
SePTIS: Workshop on Security and Privacy in Telecommunications and Information System	
Privacy Preserving Risk Assessment of Credit Securities	Assessing the risk associated to structured financial products such as collateralized debt obligations, involves processing information about diverse risk factors: some information comes from the different sources directly in aggregated form, therefore it is not possible to estimate the correlation among different risk components. In this paper we address the problem of assessing the credit risk associated to a borrower or to a security by privacy preserving methods. Specifically we suggest use Secure Multiparty Computation to merge the information from the different sources so as to compute more accurately the overall risk profile of securitized assets, without disclosing the information from each individual source.
An Adaptive Privacy Preserving Data Mining Model under Distributed Environment	Privacy preserving becomes an important issue in the development progress of data mining techniques, especially in distributed data mining. Secure multiparty computation methods are proposed to protect the privacy in distributed environment, but shows low performance under massive nodes. This paper presents an adaptive privacy preserving data mining model based on data perturbation method to improve the efficiency while preserving the privacy. Security capability of basic data perturbation is firstly analyzed and an adaptive enhancement method is proposed according to the eigen value decomposition based attacks. A light-weight protocol with homomorphic technique is proposed to perform the perturbation process under distributed environments. The experiment results show that the model has high controllable security and shows more efficiency in large scale distribution environment comparing to secure multiparty related methods.
Privacy Management for Medical Service Application Using Mobile Phone Collaborated with RFID Reader	The RFID and sensor network based ubiquitous computing has great potential in medical and healthcare services. Most of medical accidents around patients are depended on misidentification of patient or medical articles. The accidents can be reduced, if information about the patient is managed automatically. In this aspect, the mobile device with RFID reader is useful device as a medical assistant. However, the security and privacy problem related RFID application has become a serious issue in real service environment. In this paper, we propose a customized policy based privacy management architecture for medical and healthcare application. The proposed mechanism is a useful solution for user centric privacy management in medical environment.
Designing Router Scheduling Policies: A Privacy Perspective	We study the privacy compromise due to a queuing side channel which arises when a resource is shared between two users in the context of packet networks. The adversary tries to learn about the legitimate user's activities by sending a small but frequent probe stream to the shared resource (e.g., a router). We show that for current frequently used scheduling policies, the waiting time of the adversary is highly correlated with traffic pattern of the legitimate user, thus compromising user privacy. Through precise modeling of the constituent flows and the scheduling policy of the shared resource, we develop a dynamic program to compute the optimal privacy preserving policy that minimizes the correlation between user's traffic and adversary's waiting times. While the explosion of state-space for the problem prohibits us from characterizing the optimal policy, we derive a suboptimal policy using a myopic approximation to the problem. Through simulation results, we show that indeed the suboptimal policy does very well in the high traffic regime. Adapting the intuition from the myopic policy, we propose scheduling policies that demonstrate good tradeoff between privacy and delay in the low and medium traffic regime as well.
Privacy preserving zero knowledge scheme for biometric authentication	The use of biometric features for authentication, obviously, requires privacy policies and usability solutions. In this work an online signature authentication with cryptographic zero knowledge protocol is proposed. In order to avoid storing the biometric key in whatever medium, the key is used as a private key for Schnorr protocol which employs a zero knowledge scheme and then destroyed.
Privacy in Video Surveillance [In the Spotlight]	This article comments on how recent advances in video surveillance threaten privacy and how emerging signal processing technologies can protect privacy without risking security
Privacy-preserving data aggregation in smart metering systems: an overview	Growing energy needs are forcing governments to look for alternative resources and ways to better manage the energy grid and load balancing. As a major initiative, many countries including the United Kingdom, United States, and China have already started deploying smart grids. One of the biggest advantages of smart grids compared to traditional energy grids is the ability to remotely read fine-granular measurements from each smart meter, which enables the grid operators to balance load efficiently and offer adapted time-dependent tariffs. However, collecting fine-granular data also poses a serious privacy threat for the citizens as illustrated by the decision of the Dutch Parliament in 2009 that rejects the deployment of smart meters due to privacy considerations. Hence, it is a must to enforce privacy rights without disrupting the smart grid services like billing and data aggregation. Secure signal processing (SSP) aims at protecting the sensitive data by means of encryption and provides tools to process them under encryption, effectively addressing the smart metering privacy problem.
Encrypted signal processing for privacy protection: Conveying the utility of homomorphic encryption and multiparty computation	In recent years, signal processing applications that deal with user-related data have aroused privacy concerns. For instance, face recognition and personalized recommendations rely on privacy-sensitive information that can be abused if the signal processing is executed on remote servers or in the cloud. In this tutorial article, we introduce the fusion of signal processing and cryptography as an emerging paradigm to protect the privacy of users. While service providers cannot access directly the content of the encrypted signals, the data can still be processed in encrypted form to perform the required signal processing task. The solutions for processing encrypted data are designed using cryptographic primitives like homomorphic cryptosystems and secure multiparty computation (MPC).
Privacy-preserving nearest neighbor methods: comparing signals without revealing them	Comparing two signals is one of the most essential and prevalent tasks in signal processing. A large number of applications fundamentally rely on determining the answers to the following two questions: 1) How should two signals be compared? 2) Given a set of signals and a query signal, which signals are the nearest neighbors (NNs) of the query signal, i.e., which signals in the database are most similar to the query signal? The NN search problem is defined as follows: Given a set S containing points in a metric space M, and a query point x !M, find the point in S that is closest to x. The problem can be extended to K-NN, i.e., determining the K signals nearest to x. In this context, the points in question are signals, such as images, videos, or other waveforms. The qualifier closest refers to a distance metric, such as the Euclidean distance or Manhattan distance between pairs of points in S. Finding the NN of the query point should be at most linear in the database size and is a well-studied problem in conventional NN settings.
Privacy-Preserving Biometric Identification Using Secure Multiparty Computation: An Overview and Recent Trends	This article presents a tutorial overview of the application of techniques of secure two-party computation (also known as secure function evaluation) to biometric identification. These techniques enable to compute biometric identification algorithms while maintaining the privacy of the biometric data. This overview considers the main tools of secure two-party computations such as homomorphic encryption, garbled circuits (GCs), and oblivious transfers (OTs) and intends to give clues on the best practices to secure a biometric identification protocol. It also presents recent trends in privacy-preserving biometric identification that aim at making it usable in real-life applications.
Privacy-preserving speech processing: cryptographic and string-matching frameworks show promise	Speech is one of the most private forms of communication. People do not like to be eavesdropped on. They will frequently even object to being recorded; in fact, in many places it is illegal to record people speaking in public, even when it is acceptable to capture their images on video [1]. Yet, when a person uses a speech-based service such as a voice authentication system or a speech recognition service, they must grant the service complete access to their voice recordings. This exposes the user to abuse, with security, privacy and economic implications. For instance, the service could extract information such as gender, ethnicity, and even the emotional state of the user from the recording-factors not intended to be exposed by the user-and use them for undesired purposes. The recordings may be edited to create fake recordings that the user never spoke, or to impersonate them for other services. Even derivatives from the voice are risky to expose. For example, a voice-authentication service could make unauthorized use of the models or voice prints it has for users to try to identify their presence in other media such as YouTube.
Secure signal processing in the cloud: enabling technologies for privacy-preserving multimedia cloud processing	In recent years, the paradigm of cloud computing has gained an increasing interest from the academic community as well as from the commercial point of view. The cloud is a very appealing concept both for the providers (who can benefit from hiring out their extra computation and storage resources) and for the users (who can avoid the initial investment on resources by outsourcing their processes and data to a cloud).
Special Issue on Privacy and Trust Management in Cloud and Distributed Systems	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Special Issue on Intelligent Video Surveillance for Public Security & Personal Privacy	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Special Issue on Privacy and Trust Management in Cloud and Distributed Systems	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Privacy Protection of Fingerprint Database	A fingerprint authentication system for the privacy protection of the fingerprint template stored in a database is introduced here. The considered fingerprint data is a binary thinned fingerprint image, which will be embedded with some private user information without causing obvious abnormality in the enrollment phase. In the authentication phase, these hidden user data can be extracted from the stored template for verifying the authenticity of the person who provides the query fingerprint. A novel data hiding scheme is proposed for the thinned fingerprint template. This scheme does not produce any boundary pixel in the thinned fingerprint during data embedding. Thus, the abnormality caused by data hiding is visually imperceptible in the marked-thinned fingerprint. Compared with using existing binary image data hiding techniques, the proposed method causes the least abnormality for a thinned fingerprint without compromising the performance of the fingerprint identification.
Special Issue on Intelligent Video Surveillance for Public Security & Personal Privacy	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Special Issue on Privacy and Trust Management in Cloud and Distributed Systems	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Special Issue on Intelligent Video Surveillance for Public Security & Personal Privacy	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers. "
Privacy Protection for Life-log Video	Recent advances in wearable cameras and storage devices allow us to record the holistic human experience for an extended period of time. Such a life-log system can capture audio-visual data anywhere and at any time. It has a wide range of applications from law enforcement, journalism, medicine to personal archival. On the other hand, there is a natural apprehension towards such an intrusive system as the audio-visual information of unsuspecting subjects captured in the life-log video may be misused. Thus, along with the technical challenges, the privacy and legal issues arising in such recordings must be carefully addressed. In this paper, we describe a wearable life-log system that combines real-time audio distortion and visual blocking to protect the privacy of the subjects captured in life-log video. For audio, our system automatically isolates the subject's speech and distorts it using a pitch-shifting algorithm to conceal the identity. For video, our system uses a real-time face detection, tracking and blocking algorithm to obfuscate the faces of the subjects. Extensive experiments have been conducted on interview videos to demonstrate the ability of our system in protecting the identity of the subject while maintaining the usability of the life-log video.
A critical review on RFID system towards security, trust, and privacy (STP)	Widespread deployment of RFID system across many applications creates a very good impact on users and it also simplifies a lot of business transactions. However, this situation may potentially impose security and privacy threats. We noted that previous RFID protocols provide solutions for security and privacy in silo and they usually focus more on security components as compared to privacy. We vide that the existing situation is not balanced and hence our approach in tackling it is unique because we propose an overall approach that considers security, trust and privacy (STP) together. We propose to use lightweight based encryption subsystem to handle security, trusted computing based subsystem to provide trust and integrity verifications and privacy enhanced system (anonymizer) to solve privacy issues for RFID system. This paper reviews previous works on RFID protocols and highlights the importance of RFID system with STP subsystems.
Security and privacy protection for automated video surveillance	In this paper, we present an automated video surveillance system designed to 1) ensure efficient selective storage of data, 2) provide means for enhancing privacy protection, and 3) secure visual data against malicious attacks. The proposed solution is a 3-module system processing captured video data before storage. Salient motion detection is used to retain relevant sequences and identify regions of interest with potential privacy-sensitive details. Then, an invertible and secure privacy preserving process is performed using a DCT-based scrambling technique on selected regions. To secure visual data and allow for data authentication, a self-embedding watermarking technique is applied on each image sequence. It offers the capability of proving authenticity as well as locating manipulated regions. Furthermore, this technique is also able to recover and reconstruct a good approximation of original lost content. In addition to a low computational complexity, simulation results show the effectiveness of the whole system in achieving its goals in terms of security and privacy enhancement of automated video surveillance data.
Dealing with privacy issues during the system design process	In the global information society, avoiding privacy violation is becoming an increasingly critical issue. Related literature includes a number of privacy enhancing technologies for ensuring system privacy. However, each of the above technologies focuses on specific issues without providing an integrated solution for meeting all four basic privacy requirements (i.e., anonymity, pseudonymity, unlinkability, and unobservability). Current research in the area of security requirements engineering advocates that privacy requirements should be considered earlier in the system development process, during the design rather than the implementation level. In this paper, we propose a new methodology, called PriS, which aims to incorporate privacy requirements into the system design process adopting a goal-oriented approach. Each privacy requirement is treated as a separate "goal" to be met during the system design process; goals are collaboratively realised by processes, which in turn are supported by IT systems. In this way, tracing between high-level organisational objectives and detailed support mechanisms is achieved. We argue that PriS provides a solution that overcomes some of the limitations of existing approaches
Security and privacy issues towards ENUM protocol	Public ENUM is used until now in trials and some "test-bed" or "production" VoIP environments with small volume. Very lately, another application of the ENUM protocol has emerged namely the "Carrier ENUM", becoming popular among VoIP and mobile providers. In this context, a new competitive to public and carrier ENUM, peer-to-peer approach promotes itself, stating to be more reliable and secure, called DUNDi. Although considerable arguing has been generated among various ENUM forums and standardization fora on ENUM implementations, until now, several issues remain obscured and unresolved. In this paper we address security and privacy issues raised by all the aforementioned solutions, presenting implementation details, general concerns, future trends, and possible solutions
A privacy-preserving and language-independent speaking detecting and speaker diarization approach for spontaneous conversation using microphones	Conversation conveys important social signals of human interaction that indicates interest, service-awareness, persuasiveness, etc. In this paper, the authors employ the most common setting of using microphones to capture spontaneous conversation, and introduce a privacy-preserving and language-independent speech processing approach that can detect speaking and separate speakers in high accuracy for such setting. Experimental results have validated that the approach can deliver accurate speaking recognition results in Japanese, English and Chinese conversation, and can be processed in real time applications.
Privacy protection against ubiquitous marketing	Privacy has been recognized as an important topic in the marketing for long time. Our society is growing and adopting a more ubiquitous information-filled world with previously isolated systems evolving and being adapted to operate in completely interconnected networks. This full access to real-time public and personal data is a logical evolutionary step forward. However, the security of the individual's confidential information and our right to privacy is at stake. Many questions need to be addressed regarding the scope and volume of personal information. Seemingly, there is a tradeoff between exploiting the tremendous benefits of having shared information available to enhance the people's life and giving away one's personal privacy either directly or indirectly. The most common use of user data is in marketing, for which profiles, as collected in traditional eCommerce, are supported by data-mining the explicit self-descriptions, the behavior, and the ratings of users. For example, from credit card companies that rate based upon where you shop, to pay-per-click advertisements based upon Google searches, behavioral targeting has become an ubiquitous, if effective marketing tool. This issue has become a hot button topic for many publishers, advertisers, and privacy protection groups. Critics are concerned whether or not behavioral tracking agencies are effectively disclosing how the targeting works, and whether or not they are offering consumers the ability to escape their radar by opting out of tracking. Despite numerous discussions on the regulation of behavioral marketing, no solution has been found that satisfies all parties. It can be said that privacy is a problem in ubiquitous marketing using consumer's situation awareness today. However, it is possible to overcome the privacy problem if careful consideration is done to the consumer. So, we should know that when does the consumer feel insecurity? How does the consumer think about the privacy problem? This - - paper examines the consumer's consideration to ubiquitous marketing.
A new sensor concept for a privacy protection by switching the detection capabilities	In this paper, a new sensor concept for developing a sensing system with the function of putting weight on a privacy protection of a monitored person is proposed, and then the new type of sensor based on the proposed concept was implemented. In this experiment, this sensor applied to a chair and the performance of this chair was tested. As a result, it was clarified that the possibility of the realization of the new type of sensing chair that can make the damage small if the data detected by this chair are stolen and analyzed were shown.
On privacy of famous users in active worlds	Collaborative virtual environments (CVEs) are being developed to support work and education, yet, research for entertainment is getting popular. A qualitative research was conducted in active worlds (AW). Some of AW users are famous in the virtual world, which affects their usage of the system.
Privacy Protecting in E-business Using Reasoning	Nowadays, the e-commerce plays a very important role in peoplespsila life; many people like to shop on internet. At the same time, people left so much information in Internet, which include the privacy information. Malicious users in internet can get userspsila privacy information with directly or indirectly way. Traditional way is to protect the directly privacy. In this paper, we proposed a schema to prevent malicious users reasoning privacy information with the information which considered as security information on Internet. In this schema, the single information set and multiple information sets are taken into count, based on the relations of the information, some information will be hidden, which can protect the privacy information. This schema will loss some information, but the privacy will protected.
Privacy and Social Effects in Location Sharing Services	Location-aware technologies enable users with increasing, and often invisible, interconnected location-aware information services with one another and with the Internet, especially on mobile devices such as smart phones. Considering that the services seamlessly support individual users in their daily tasks and life, as well as the services are increasingly dealing with personal information, user's privacy of revealing private information are encountering with significant raising challenges. Today our understanding of people's concerns about location sharing preferences remains very limited, including how privacy preferences are context dependent, and how social benefits counteract privacy concerns so that leading to location sharing behavior. By adopting the cost-effectiveness analysis principles, we have conducted an experiment, in which people's willingness to share according to social context and privacy concerns were observed. Interesting findings were found and some of them are different previous research findings. As a work in-progress study, our study also suggests that further economical exploration of whether social benefits could offset the privacy concern costs may be an important avenue of study.
A Privacy Preserving Repository for Data Integration across Data Sharing Services	Current data sharing and integration among various organizations require a central and trusted authority to first collect data from all data sources and then integrate the collected data. This process tends to complicate the update of data and to compromise data sources' privacy. In this paper, a repository for integrating data from various data sharing services without central authorities is presented. The major differences between our repository and existing central authorities are: 1) Our repository collects data from data sharing services based on users' integration requirements rather than all the data from the data sharing services as existing central authorities. 2) While existing central authorities have full control of the collected data, the capability of our repository is restricted to computing the integration results required by users and cannot get other information about the data or use it for other purposes. 3) The data collected by our repository cannot be used to generate other results except that of the specified data integration request, and hence the compromise of our repository can only reveal the results of the specified data integration request, while the compromise of central authorities will reveal all data.
Privacy-Enhanced Web Service Composition	Data as a Service (DaaS) builds on service-oriented technologies to enable fast access to data resources on the Web. However, this paradigm raises several new privacy concerns that traditional privacy models do not handle. In addition, DaaS composition may reveal privacy-sensitive information. In this paper, we propose a formal privacy model in order to extend DaaS descriptions with privacy capabilities. The privacy model allows a service to define a privacy policy and a set of privacy requirements. We also propose a privacy-preserving DaaS composition approach allowing to verify the compatibility between privacy requirements and policies in DaaS composition. We propose a negotiation mechanism that makes it possible to dynamically reconcile the privacy capabilities of services when incompatibilities arise in a composition. We validate the applicability of our proposal through a prototype implementation and a set of experiments.
Verification of Privacy Timed Properties in Web Service Protocols	In this work we propose an approach for verifying privacy timed-related properties of web service protocol. While in [anal] the addressed problem in business protocols is focused on the analysis and management of functional requirements that support rich timing constraints, our approach extends the previous results to capture the timed behavior of privacy constraints. Hence, we provide a model called Timed Private Business Protocol TPBP. Next, we emphasize the timed properties related to privacy in TPBP. Finally, we present the different types of timed property verification to achieve upon the timed private business protocol.
Rule-based XML Mediation for Data Validation and Privacy Anonymization	XML mediation for data validation and privacy anonymization of very large complicated XML messages defined in some industry-specific specifications such as HL7 is becoming increasingly important in SOA because a lot of applications depend on various kinds of hard-coded data validation and privacy anonymization functions, which makes it difficult to keep consistency of the functions among the applications in SOA when the schema of the XML messages in the specifications is updated. This paper proposes a uniform rule-based approach to realize the functions as an XML mediation separated from the applications, which makes it easy to maintain consistency of the functions even when they are updated in accord with the changes to the specifications. Therefore, application developers can readily utilize the mediation with many applications in SOA without additional modification to the applications. Our approach allows the developers to define a set of rules that consist of two components: 1) constraint conditions in a conceptual data notation in the XML message, and 2) actions performed only when the conditions are satisfied. In order to make the rules independent from both the implementation-specific data representation and the industry-specific knowledge, we automatically transform the rules into the implementation-specific data representation using two more factors; one is the data mappings from the data notation in the rules to the concrete data representation in the implementation, and the other is the implied data relationships hidden in the rules. It is very important to take into consideration a general way to import the implied knowledge because it often depends on the industry-specific data structure and it is usually given outside of the mediation system.
Managing Security and Privacy Integration across Enterprise Business Process and Infrastructure	Managing information security and privacy assurance are fiduciary responsibilities of all government and commercial organizations, but standing up a comprehensive fully-assured environment from the onset may be technically or financially impossible. Many organizations inadequately address this challenge from a 'bottom-up' or piece-meal perspective, certifying and accrediting individual systems or focusing on perimeter systems and portals. A systematic enterprise-wide risk-management approach to information security and privacy is both practical and economically feasible, but must holistically integrate such requirements into both business process management and the technical infrastructure to be effective. The authors' development of the roadmap for information security across the enterprise (RISE) methodology establishes a systematic approach to security and privacy management by leveraging enterprise architecture approaches, and ensures implementation control by integrating the processes and responsibility with enterprise-level portfolio management. RISE defines an iterative threat assessment and response cycle and integrates it with capital planning and investment control (CPIC) for both operational and infrastructure initiatives. This paper describes how RISE ensures risk-informed continuous process improvement and capital planning by maintaining an architecturally founded knowledge base supporting strategic planning and investment review.
A Customer-Centric Privacy Protection Framework for Mobile Service-Oriented Architectures	Mobile companions such as smart phones and PDAs carry a lot of sensitive data about their owners. With new services aimed at providing more targeted information retrieval through increased interactions with these devices, privacy concerns of individuals must be addressed. Existing mobile service computing solutions give users little control over the release of this information. In this paper, we present a privacy-aware information brokerage framework called MUPPET that incorporates three novel techniques to give users control over the release of their data. First, it introduces operation-focused access control, a purpose-based access control model that supports flexible and fine-grain policies using typed operation labels. Second, MUPPET includes a purpose detector that has a number of techniques to detect the active purpose in a pervasive environment. Third, our system allows reward-driven information exchange, a protocol for explicit communication and negotiation of justifications and rewards supporting tunable privacy policies based on ongoing evaluation of the information exchange. To validate our design, the MUPPET prototype has been integrated with a personalized coupon offering application for two different service providers in an experimental retail kiosk setting.
Web Services Security and Privacy	Web services are becoming widely deployed to implement the automation of business processes such as supply chain management, inventory tracking, and healthcare management, just to name a few. A Web service is a new breed of web application that supports interoperable application-to-application interaction over a network based on a set of XML standards. This new architecture and new set of protocols brings a new set of security challenges such as confidentiality, integrity, anonymity, authentication, authorization and availability. As security has become an essential component for all information systems, several security solutions for Web services data have been proposed such as WS-Security, SAML and XACML. To enable privacy protection for Web service consumers across multiple domains and services, the World Wide Web Consortium (W3C) published a document called "Web Services Architecture (WSA) Requirements" that defines some specific privacy requirements for Web services as a future research topic.
A Privacy Agreement Model for Web Services	Web services are among the applications involving closely the customers' private informations. In order to take into account the privacy concerns of the individuals, organizations (e.g Web services) provide privacy policies as promises describing how they will handle personal data of the individual. However, privacy policies do not convince potential individuals to disclose their personal data, do not guarantee the protection of personal information, and do not provide how to handle a possible evolution of the policies. In this paper, we propose a framework based on an agreement as a solution to these problems. It contains a privacy model defined in the policy level of the agreement. The framework supports in the negotiation level of the agreement a lifecycle management which is an important deal of a dynamic environment that characterizes Web services. A negotiation protocol is proposed that enable ongoing privacy negotiation to be translated into a new privacy agreement.
Designing privacy policies for adopting RFID in the retail industry	Radio frequency identification (RFID) technologies can potentially improve the productivity of retailers. In this paper, we propose a role-based, enterprise-level, RFID-oriented privacy authorization model for supporting the privacy policies in utilizing RFID in retail industry.
Database as a Service: Challenges and solutions for privacy and security	This paper analyzes the most relevant privacy and security breaches that may arise in the Database as a Service model. Then, it reviews the state of the art in view of the identified privacy and security requirements. The analysis of the state of the art shows that many open problems still remain to be solved.
A Study on the Human Identification Technique for Privacy Protection in Intelligent Video Surveillance System	Recently as the incidences of terrorism and crime increase, the utilization of video surveillance system such as CCTV is increased. The increase of video surveillance system is useful in maintaining the safety of people's living and public order, however, the issue has been brought up about privacy invasion. For this, researches on the masking method to protect the privacy are being carried out. The masking method can protect privacy by eliminating the visual information but reduces the surveillance function. Therefore, the techniques that satisfy the human identification-based privacy protection and surveillance function at the same time have been researched. In this paper, the human identification method that is applicable to the existing privacy protection method and video surveillance system is explained.
More Robust Anonymous Authentication with Link-Layer Privacy	Recently, the problem of protecting privacy at link-layer is of great importance in wireless environments, mainly due to the fact that the wireless link layer is not protected by current technologies used in wireless networks. This leads to many potential threats to security and user privacy. Very recently, Lu et al. proposed an authentication scheme for wireless link-layer privacy which is based on the idea of identity-based encryption from bilinear pairings. The scheme however does not support the security against the type of known-key attack, called key-compromise impersonation. This limits the use of the scheme in that such a security hole can potentially be extended to many additional attacks, causing more serious consequences in practice. In this paper, we demonstrate that how the attack can be launched and also provide an enhanced construction in order to solve the problem. Our scheme has almost the same performance as that of Lu et al. in terms of both computation and communication cost, while it provides much better security results.
An Approach to Privacy-Preserving Alert Correlation and Analysis	Privacy issues are concerned when data holders share their detected security data for correlation and analysis purpose. This paper proposes an approach to correlate and analyze intrusion alerts, while preserve privacy for alert holders. The raw intrusion alerts are protected by improved k-anonymity model, which preserves the alert regulation inside disturbed data records. With this privacy preserving technique, combing the typical FP-tree association rules mining algorithm, the approach provides the capacity of well balancing the alert correlation and the privacy preservation. Experimental results show that this approach works comparatively efficient and reaches a well balance between the alerts correlation and the privacy issues.
Policy Consolidation and Privacy-Vital Information Flow Control in Composite Services	Privacy becomes an increasing concern in modern society because personal information is being collected by more and more online services on the Internet. Although many privacy-aware models and methods were proposed, the protection technology of privacy is underway. This paper aims at addressing privacy-aware access control in composite services. We introduce an automaton-based monitoring solution for privacy-vital information flow for a single execution of a composite service. In addition, this paper also gives a policy consolidation algorithm based on orchestration structures and attribute composition, which can also be used to combine privacy policies.
Value Added Privacy Services for Healthcare Data	The widespread use of digital data, storage and sharing for data mining has given data snoopers a big opportunity to collect and match records from multiple sources for identity theft and other privacy-invasion activities. While most healthcare organizations do a good job in protecting their data in their databases, very few organizations take enough precautions to protect data that is shared with third party organizations. This data is vulnerable to data hackers, snoopers and rouge employees that want to take advantage of the situation. Only recently has the regulatory environment (like HIPAA) tightened the laws to enforce data and privacy protection. The goal of this project was to explore use of value added software services to counter this invasion of privacy problem when data is shared with an external organization for data mining, statistical analysis or other purposes. Specifically, the goal of this service is to protect data without removing sensitive/non-sensitive attributes. Sophisticated data masking algorithms are used in these services to intelligently perturb and swap data fields making it extremely difficult for data snoopers to reveal personal identity, even after linking records with other data sources. Our software service provides value added data analysis with the masked dataset. Dataset-level properties and statistics remain approximately the same after data masking; however, individual record-level values are changed or perturbed to confuse the data snoopers.
Privacy-Preserving Mobile Accesses for Virtual Private Social Media	Online social networking can be accessed by mobile devices, e.g., smartphones which become a platform for social media user interaction. However, although the social media users have the right to turn off and on the application platform, media may be insecurely allowed by followers in many arbitrary situations, and the privacy preserving services are inflexible between followers and followees. This paper proposes a novel technique to generate the flexible and automatic virtual private social media (VPSM) for each follower for every different situation. The VPSM in social media takes into account the location and time information of mobile users. The contribution of this paper includes the location- and time-dependent VPSM which can preserve the privacy of the users and followers while controlling access to media services.
A Threat Free Architecture for Privacy Assurance in Cloud Computing	Cloud Computing is a boon to IT industry that can help its clients to grow with minimal investment in technology. But users deter the adoption of cloud services with apprehensions on data leakage and loss of privacy if their sensitive data is processed in the cloud. The paper aims to provide maximum security and privacy to the data stored on cloud by using Double Authentication and Hybrid Obfuscation Technique with the use of a plug-in for the internet browser as an application software with multiple functionalities. The novelty of this method is to place data and keys separately on different clouds which have no direct communication between them by following the policy of 'Divide and Rule'.
The Evolution of Health Care IT: Are Current U.S. Privacy Policies Ready for the Clouds?	The U.S. healthcare industry has been given anew mandate to expand the use of health information technology to provide better care and to help reduce costs. Equally, cloud computing is poised to become the fifth utility delivering economies of scale and cost benefits that are difficult for businesses to ignore. The utilization of cloud services for the storage and exchange of personal health information is growing with the use of electronic health records and health information exchanges. Yet policies and regulatory mandates are still lagging and the potential for the loss of personal information is expanding exponentially. HIPAA/HITECH currently only provides a baseline of protection for personal health information while various IT security frameworks help to standardize the protection and security of personal information as well as the security of cloud services. As the technology matures further and the healthcare industry embraces data and privacy governance programs, the chance for a successful health IT transformation with the use of the cloud significantly increase.
A Privacy Preserving Selective Authorization Enforcement Approach in Daas	Database as a Service (DaaS) is a practical and useful paradigm, in which the Database Service Provider (DSP) hosts the delegated database generated from the Source DB of Data Owner (DO). Due to the untrusted DSP, most of the proposed approaches were concentrated on using encryption to guarantee the privacy of delegated database and using partition based index to speed up the query. However, few papers were proposed to guarantee the privacy of delegated access control policies. Therefore in order to improve the usability of delegated database and guarantee the privacy of delegated access control policies, a critical problem to be addressed in DaaS is to make the DSP enforce the delegated selective authorization policies correctly, but know nothing about the privacy of users or the privacy of delegated authorization policies. In this paper, we present a privacy preserving selective authorization enforcement approach to resolve the critical problem above. By using selective encryption, Pedersen commitment and access control policy polynomial, the privacy of delegated access control policies and the privacy of users can be efficiently guaranteed. Finally we analyze the security properties of our approach from different aspects.
Improving Web Service Security and Privacy	This paper proposes a scheme that allows the webservice providers to carry out fine-grained access control onthe data hosted by them. Through data tracking, the schemealso automatically detects the data flows that might lead toattacks on online services. Compared with existing schemes,the proposed scheme is more flexible in managing the data onthe service provider. The scheme relieves the programmersfrom enforcing access control and detecting data flow violationin their applications.
A Privacy Assessment Approach for Serviced Oriented Architecture Application	Web services are middle-tier technologies used to access backend applications to perform various operations. Their usage has significantly increased in e-commerce applications since their introduction. Because of their wide usage, security in Web services has become an important point of interest for many. User data provided by users during their transactions with online Web services can be stolen and illegally used. Thus Web service providers have started to strengthen security. This can lead to lack of user privacy. Privacy has received relatively less attention during the growth of information technology. User privacy management needs to be both from the user side and from Web application side. User awareness about information security is the factor for user side privacy management. On the application side, the Web applications must be compliant to privacy policies. In this paper, an approach is designed and implemented for a privacy policy checker engine that automatically verifies and certifies a Web service application based on the levels of overall privacy principle compliance and privacy statement compliance
Modelling and transforming security constraints in privacy-aware business processes	Security and privacy are essential for business processes (BPs). In particular, BPs dealing with personally-identifiable information require mechanisms to give data owners control over their data. Currently, business-process-management systems (BPMSs) lack security features important for BPs in SOA. We propose a language sufficiently broad to formulate security constraints. In addition, we considerably ease how data owners can control their security, privacy and trust preferences at process runtime. The BPMS extensions we have implemented transform security-enhanced BPMN schemas into executable secure processes in a versatile manner.
A collaborative approach for identifying privacy disclosure in Web-based services	Nowadays, abundance of Web applications offers flexible and convenient services for users. Although almost all Web sites have their own privacy policies and declare that they won't disclose users' privacy without their consent, users may still receive spam messages after they register or interact with some sites. Obviously, commercial interests can drive some sites to disclose users' privacy such as email addresses to third parties. In this paper, we propose a collaborative method to identify Web sites that disclose users' privacy by using a privacy disclosure finding protocol inspired from secure multiparty computation (SMC). The advantages of our method are that the method can identify privacy disclosure sites while preserving volunteers' privacy and that the method uses a collaborative approach without relying on a trusted third party which makes it practical in the reality of Web based services.
Towards a base ontology for privacy protection in service-oriented architecture	The service consumer's confidence in the protection of their privacy is an important factor for the success of electronic services (e-services). It may increase if the service provider offers a description of its data practices. This description can be compared to what the consumer defines as appropriate practices. To allow the exchange of privacy-related descriptions and automatically compare them, the parties involved in the interaction should be able to use a common vocabulary. The goal of this paper is to present a base privacy ontology for e-services and a privacy framework for service-oriented architecture (SOA). The ontology offers a base vocabulary that can be extended to create ontologies specific to a given service domain and operating environment. The framework uses ontologies so that it can support service selection considering the consumer's privacy requirements. It extends SOA with provider policies and consumer preferences based on privacy ontologies.
A privacy protection protocol for RFID-enabled supply chain system	Recent years have seen much growing attention on RFID security. However, little work has been performed to address the security issues in the context of supply chain management, which is exactly the major field for RFID applications. In this paper, we take first step toward security and privacy management in such system. We here introduce the formal concept of traceability networks, identify the unique set of privacy and confidentiality requirements in supply chains, highlight the technical challenges involved in sharing data in such a network, how they might be addressed by a practical design of RFID communication protocols.
Electronic identification, personal privacy and security in the services sector	The continued proliferation of services in the economy depends on being able to make co-production secure in the matter of protecting the privacy and security of customer data/information. The increasing prevalence of electronic means of identification, from magnetic stripe cards through touch cards, GSM SIM cards, passive and active radio frequency identification (RFID) tags, to contact and contactless smart cards, has created a great increase in the efficiency of some security and consumer commercial operations, and an at least equal increase in convenience for both the public and administrators of these systems. However, these technologies are being used in ever more sensitive applications, and give rise to serious concerns over personal safety and privacy, identity theft, commercial security, and even to some extent national security.
An approach to measures of privacy in randomized response models for quantitative characteristics	In this paper, we present a new and reasonable measure of privacy protection of randomized response with or without allowing for the auxiliary variable and compare the unrelated question model, the addition model, the multiplication model, the optional randomization model, the generalized multiplicative model and the forced model in the light of the efficiency and protection privacy. This article shows that the results are sometimes in contrast with the authors' assertions regarding the superiority of their methods. This measure is easy to evaluate.
Gateway to the Cloud - Case Study: A Privacy-Aware Environment for Electronic Health Records Research	We describe a study in the domain of health informatics which includes some novel requirements for patient confidentiality in the context of medical health research. We present a prototype which takes health records from a commercial data provider, anonymises them in an innovative way and makes them available within a secure cloud-based Virtual Research Environment (VRE). Data anonymity is tailored as required for individual researchers' needs and ethics committee approval. VREs are dynamically configured to model each researcher's personal research environment while maintaining data integrity, provenance generation and patient confidentiality.
Patronus: Augmented Privacy Protection for Resource Publication in Online Social Networks	On-line social networks are playing an important role in our daily lives in the modern society. It is becoming much more frequent and convenient for individuals to communicate with others by publishing data such as photos and videos over on-line social networks. As plenty of personal information is usually contained in these data, privacy leakage has become a more serious problem. However, current privacy protection mechanism, which is built on the group-based access control model (GBAC), are typically owner-centric. It means that the privacy requirements of data involvers, whose privacy information is also contained in the corresponding resource, are typically overlooked and ignored. In order to provide augmented privacy protection for social data publication, this paper proposes a new data access model named Patronus to provide better privacy protection during social data publication. With Patronus, the privacy requirements of the data owner and its involvers are both taken into considerations. In order to automatically recognize the corresponding involvers and enforce their privacy polices, Patronus provides a simplistic specification based on the format of ``when-where-who-what'' to describe the features of a resource and the privacy preferences of an individual user. We implemented a prototype of Patronus for photo sharing on Android, and demonstrated its feasibility and effectiveness with several case studies.
YI Cloud: Improving user privacy with secret key recovery in cloud storage	Cloud Storage systems provide user a safe and consistent place to save user's valuable data and documents. However, user's files are not encrypted on some open source cloud storage systems, such as Hadoop and Sector. The storage service provider can easily access the user's files. This brings a big concern about user's privacy. This paper describes a cloud storage system named YI Cloud. This system allows the users to encrypt their files in the cloud storage. User's primary encryption key is shared between trusted entities using secret sharing algorithm. The primary key can be recovered when the user loses it. User's privacy is protected because user's files are encrypted in cloud storage. Using secret sharing algorithm, the YI Cloud also decreases the risk that user may lose all his/her encrypted files if he/she loses the encryption key.
A survey of personal privacy protection in public service mashups	Mashups are web application hybrids built from usually independent online services and information sources, commonly for purposes that differ from the original reasons those services were developed in the first place. The intent is usually to make data more useful, often through visualisation, combination, aggregation or the application of distributed expertise. Mashups rely on APIs to leverage content or functionality. APIs come in many varieties and mashup development is often considered an exercise in spaghetti deployment. This means that mashups are not always well-engineered; that they're often brittle; inconsistent; difficult to maintain; and susceptible to unexpected changes at the whim of service and data providers. Mashups are nevertheless important in the light of growing trends in open government and government-community partnership initiatives such as the UK's Big Society, which aim to maximise access to and utilisation of data, functionality and expertise in the community interest. However, these applications have critical privacy requirements. The nature of mashups and the environments within which they are built and maintained mean that they are not naturally well-suited to the protection of privacy. This paper surveys the privacy issues relating to public service mashups as key components of open government and the digital society.
An improved authentication and key agreement protocol preserving user's privacy using smart cards	Recently, a privacy enhanced authentication and key agreement protocol was proposed using elliptic curve cryptograph technology. The scheme is insecure, however, against replay attacks within valid period of certificate and loses users' privacy that should be protected. In this paper we propose an improved authentication and key agreement protocol by employing smart card and random number technology. Replay attacks are thus blocked without the need of time synchronization between computers. Moreover, we develop a secure mechanism to protect users' identity privacy and a convenient password change method without the participation of the server. Our protocol is more secure compared with others at similar computation cost in the authentication period.
Privacy protection for personal data integration and sharing in care coordination services: A case study on wellness cloud	Care coordination services bring together a multitude of providers to deliver continuity of care outside clinical settings. The coordinated services improve wellness management and operational outcomes but pose challenges on privacy when integrating multiple sources of personal health data and providing a data access and sharing mechanism to third party providers. In this paper, we particularly address the privacy challenges associated with data integration and sharing in a multi-tenant cloud environment for healthcare. We present three care coordination use cases and detail the functional requirements across different stages of a personal data service cycle. Additionally, retlecting on technical challenges associated with privacy-preserving data integration and sharing, we introduce a set of common data services to handle these issues, which ultimately lend support to the development of accountable coordinated care services.
Minimally privacy-violative human location sensor by ultrasonic radar embedded on ceiling	A system observing human daily activities that may violate privacy is unacceptable in our society. This paper proposes a minimally privacy-violative system for locating a person using ultrasonic radar embedded in the ceiling of a room. One of the presumable applications is a system for preventing aged people suffering from Alzheimer's disease from accidents. The proposed system can determine the 3D position of a person's head by assuming that the human head is an object that will move at a relatively high vertical position in a living area. The system does not input unnecessarily rich information such as images using a camera so that it can reduce the possibility for violating privacy. The authors constructed an experimental system that consists of 18 ultrasonic transmitters and 32 receivers which are embedded in the ceiling of a room. Experimental results confirmed the feasibility of the proposed system.
EPS: An Efficient and Privacy-Preserving Service Searching Scheme for Smart Community	Smart community leverages information and communications technology to improve the quality of life in terms of education, health care and government services. In smart community, residents manage their home appliances to cooperate on stabilizing renewable power supply, energy saving, and information communications. In this paper, we propose an efficient and privacy-preserving service searching (EPS) scheme for smart community to enable residents to receive some Internet bandwidth from cooperative nearby homes so as to obtain pervasive Internet access at the cheap cost. Specifically, the EPS enables a resident to send a service request to nearby homes, and the latter responds the request with either uploading data via Internet connection or forwarding data to other homes via WiFi. Since the Internet and WiFi bandwidth of homes is limited, the homes assign residents with different priorities and prefer to serve residents with high priorities. The priority is determined by a proximity score between residents and home owners, and the identity information is not disclosed in the calculation process. Moreover, the EPS preserves the location privacy of residents by adopting the multiple pseudonym techniques. Detailed privacy analyses in terms of the identity privacy and the location privacy are provided. In addition, the communication efficiency is validated through extensive simulations.
Preserving Source-Location Privacy in Wireless Sensor Networks	Wireless sensor networks (WSN) have the potential to be widely used in many areas for unattended event monitoring. Mainly due to lack of a protected physical boundary, wireless communications are vulnerable to unauthorized interception and detection. Privacy is becoming one of the major issues that jeopardize the successful deployment of wireless sensor networks. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address the source-location privacy. For WSN, source-location privacy service is further complicated by the fact that the sensor nodes consist of low-cost and low-power radio devices, computationally intensive cryptographic algorithms (such as public-key cryptosystems) and large scale broadcasting-based protocols are not suitable for WSN. In this paper, we propose a scheme to provide both content confidentiality and source-location privacy through routing to a randomly selected intermediate node (RRIN) and a network mixing ring (NMR), where the RRIN provides local source- location privacy and NMR yields network-level (global) source- location privacy. While being able to provide source-location privacy for WSN, our simulation results also demonstrate that the proposed scheme is very efficient and can be used for practical applications.
TACKing Together Efficient Authentication, Revocation, and Privacy in VANETs	Vehicular ad hoc networks (VANETs) require a mechanism to help authenticate messages, identify valid vehicles, and remove malevolent vehicles. A public key infrastructure (PKI) can provide this functionality using certificates and fixed public keys. However, fixed keys allow an eavesdropper to associate a key with a vehicle and a location, violating drivers' privacy. In this work we propose a VANET key management scheme based on temporary anonymous certified keys (TACKs). Our scheme efficiently prevents eavesdroppers from linking a vehicle's different keys and provides timely revocation of misbehaving participants while maintaining the same or less overhead for vehicle-to-vehicle communication as the current IEEE 1609.2 standard for VANET security.
Cross-layer Enhanced Source Location Privacy in Sensor Networks	Source location privacy is an important issue in sensor network monitoring applications. It is difficult to be addressed by traditional security mechanisms, because an external attacker may perform simple traffic analysis to trace back to the event source. Solutions such as flooding or using dummy messages have the drawback of introducing a large amount of message overhead. In this paper, we avoid using network-wide dummy messages by utilizing beacons at the MAC layer. Beacons are sent out regularly, which essentially forms a constant-rate of dummy messages. Using beacons to replace the dummy messages may increase the delivery delay of event information because beacons are only sent out at the predefined beacon interval, but this latency can be controlled. To do this, we propose a cross- layer solution in which the event information is first propagated several hops through a MAC-layer beacon. Then, it is propagated at the routing layer to the destination to avoid further beacon delays. Simulation results show that our cross-layer solutions can maintain low message overhead and high privacy, while controlling delay.
Query privacy in wireless sensor networks	Existing mechanisms for querying wireless sensor networks leak client interests to the servers performing the queries. The leaks are not only in terms of specific regions but also of client access patterns. In this paper we introduce the problem of preserving the privacy of clients querying a wireless sensor network owned by untrusted organizations. We investigate two architectures and their corresponding trust models. For the first model, consisting of multiple, mutually distrusting servers governing the network, we devise an efficient protocol, SPYC, and show that it provides full query privacy. For the second model, where all queries are performed through a single server, we introduce two metrics for quantifying the privacy achieved by a client's query sequence. We propose a suite of practical algorithms, then analyze the privacy and efficiency levels they provide. Our TOSSIM simulations show that the proposed query mechanisms are communication efficient while significantly improving client query privacy levels.
Privacy Preserving Communication in MANETs	Mobile ad hoc networks often support sensitive applications. These applications may require that users' identity, location, and correspondents be kept secret. This is a challenge in a MANET because of the cooperative nature of the network and broadcast nature of the communication media. In this paper, we propose a privacy preserving communication system (PPCS) which provides a comprehensive solution to anonymize communication end- points, keep the location and identifier of a node unlinkable, and mask the existence of communication flows. We present an analysis of the security of PPCS against passive internal attackers, provide a qualitative discussion on its strength against external attackers, and characterize its performance trade-offs. The simulation results demonstrate that PPCS has only 3% lower packet delivery ratio than existing multi-path routing protocols, while effectively providing privacy service in MANETs.
Security and Privacy Issues for Inter-vehicle Communications in VANETs	Vehicular ad hoc network (VANET) is an emerging type of networks to allow vehicles on roads to communicate for driving safety. An vehicle can broadcast messages (e.g. accident information) to other vehicles. These messages may have impact on other vehicles as well as the traffic control system, so all messages must be signed and authenticated. On the other hand, privacy should be enforced while the real identity of the sender should be traceable by authorized party. In this poster, we first discuss the limitations of existing solutions. In particular, we describe an impersonation attack to one of the schemes, highlight the problem of communications overhead, and effectiveness of the message verification procedure. Then, we present the main ideas of our proposed scheme which can be shown to be secure and more effective than existing schemes.
A privacy-preserving social-aware incentive system for word-of-mouth advertisement dissemination on smart mobile devices	The recent penetration of smart mobile devices into the consumer market sets a stage for novel network applications. In particular, we envision a paradigm shift in the commercial advertising model facilitated by the widespread uses of these devices: advertisements circulate in a word-of-mouth fashion among device users and reach potential customers based on the users' knowledge about their contacts. In this paper, we identify two major challenges baffling the deployment of such an application: users' selfishness and their privacy concerns. We address the selfishness issue by proposing an incentive scheme which aligns users' interest with that of advertisers in a way that the users are willing to fully explore their social knowledge for effective advertisement deliveries - the emphasis is not only on users' participation but also on the extent and effectiveness of their contributions. We address the privacy concerns by designing a privacy-preserving evidence-collection mechanism, on which the incentive scheme is based. In addition, our design is 1) appealing to advertisers by guaranteeing effectiveness and controllability of the incentive dispensing and 2) robust against users' misbehaviors. We perceive incentive and enforcement as the keys to unlock the power of users' collective intelligence for effective information dissemination.
Privacy-preserving energy theft detection in smart grids	In the U.S., energy theft causes six billion dollar losses to utility companies (UCs) every year. With the smart grid being proposed to modernize current power grids, energy theft may become an even more serious problem since the ΓÇ£smart metersΓÇ¥ used in smart grids are vulnerable to more types of attacks compared to traditional mechanical meters. Therefore, it is important to develop efficient and reliable methods to identify illegal users who are committing energy theft. Although some schemes have been proposed for the UCs to detect energy theft in power grids, they all require the users to send their private information, e.g., load files or meter readings at certain times, to the UCs which invades users' privacy and raises serious concerns about privacy, safety, etc. As far as we know, we are the first to investigate the energy theft detection problem considering users' privacy issues. In this paper, we propose to solve in a distributed fashion a linear system of equations (LSE) for the users' ΓÇ£honesty coefficientsΓÇ¥, which indicate the users are honest when equal to 1 and are fraudulent when larger than 1. In particular, we develop two distributed privacy-preserving energy theft detection algorithms based on LU decomposition, called LUD and LUPD, respectively, which can identify fraudulent users without invading any user's privacy. Compared to LUD, LUPD requires higher execution time but is stable even in large-size systems. Moreover, the LUD and LUPD algorithms are proposed in the case that users commit energy theft at a constant rate, i.e., with constant honesty coefficients. We also propose adaptive LUD/LUPD algorithms to account for the scenarios where the users have variable honesty coefficients. Extensive simulations are carried out and the results show that the proposed algorithms can efficiently and successfully identify the fraudulent users in the system.
On Bounding Data Stream Privacy in Distributed Cyber-physical Systems	This paper derives fundamental bounds on privacy achievable in future human-centric cyber-physical systems, where time-series sensor data are shared among individuals to compute aggregate information of mutual interest. For example, individual GPS-trajectories may be shared to compute average traffic speed at different locations. An optimal trade-off is explored between individual user privacy, achieved by perturbing data prior to sharing, and the corresponding accuracy of computed aggregate information. The work is motivated by an emergent category of cyber-physical applications that involves large-scale interaction between humans, networked engineered artifacts, and the physical world. These applications are brought about by the proliferation of personal sensing devices of everyday use, leading to unprecedented opportunities for sensory data collection and sharing. The collection of sensory data from large numbers of participants offers privacy as a major new cyber-physical system challenge. In this paper, we propose a novel privacy measure, based on mutual information, and derive a perturbation algorithm, to apply prior to data sharing, that guarantees a least upper bound on the privacy measure. The new algorithm effectively hides individual user data by optimally perturbing the time-series using knowledge of only the mean and the covariance of the original data. We evaluate it using both synthetic data and collected real application data. The results show that the method significantly improves the trade-off between privacy and the accuracy of reconstruction of aggregate information from shared perturbed data.
A Cloaking Algorithm Based on Spatial Networks for Location Privacy	Most of research efforts have elaborated on k-anonymity for location privacy. The general architecture for implementing k-anonymity is that there is one trusted server (referred to as location anonymizer) responsible for cloaking at least k users' locations for protecting location privacy. A location anonymizer will generate cloaked regions in which there are at least k users for query processing. Prior works only explore grid shape cloaked regions. However, grid shape cloaked regions result in a considerable amount of query results, thereby increasing the overhead of filtering unwanted query results. In this paper, we propose a cloaking algorithm in which cloaked regions are generated acording to the features of spatial networks. By exploring the features of spatial networks, the cloaked regions are very efficient for reducing query results and improving cache utilization of mobile devices. Furthermore, an index structure for spatial networks is built and in light of the proposed index structure, we develop a Spatial-Temporal Connective Cloaking algorithm(abbreviated as STCC). A simulator is implemented and extensive experiments are conducted. Experimental results show that our proposed algorithm out-performs prior cloaking algorithms in terms of the candidate query results and the cache utilization.
Semantic Enforcement of Privacy Protection Policies via the Combination of Ontologies and Rules	We propose that the semantic formal model for P3P and EPAL-based privacy protection policies can be enforced and expressed as a variety of ontologies and rules (ontologies+rules) combinations, such as DLP, SWRL, AL-log, DL- log, DL+log, and MKNF, etc. Based on P3P and EPAL's original expressions and their dictionaries, several ontologies+rules semantic enforcement of privacy protection policies will be proposed in this study that can be compared with existing others. Furthermore, we express privacy protection management policies as a set of ontology statements, rules, and facts for both information disclosure and rights delegation using one of the above ontologies+rules combinations for two specific use case scenarios. When verifying P3P/EPAL formal semantics, we exploit which ontologies+rules combination will be a feasible information disclosure control scenario under certain conditions. We hope that this study might shed some light on the study of future general information disclosure and rights delegation controlled on the open Web environment.
Privacy Preserving Classification Algorithm Based Random Diffusion Map	In this paper, a privacy preserving classification algorithm based random diffusion map is presented. We first alter the selection of the parameter dimension d and metaparameter fixed value ├é┬┐ for satisfying the security of privacy-preserving classification. Further the sensitive attributes are embedded into random(even higher) dimension feature space using random diffusion map, thus the sensitive attributes are transformed and protected. Because the transformed space dimension d and the ├é┬┐ are both stochastic, this algorithm is not easily be breached. In addition, diffusion map can keep topology structure of dataset, so the classification precision after encryption are kept well. The experiment shows that the present method can provide sensitive information enough protect without much loss of the classification precision.
Research on Security Architecture and Privacy Policy of Grid Computing System	The wide acceptance of the grid technology has created pressure to add some features that were not part of its original design, such as security, privacy, and quality-of-service support. In this paper, we have proposed the enhanced grid security and privacy (EGSP) system architecture including EGSP system model, identity protection system, onion routing system, and reputation system.
Security and Privacy in Cloud Computing: A Survey	Cloud Computing is becoming a well-known buzzword nowadays. Many companies, such as Amazon, Google, Microsoft and so on, accelerate their paces in developing Cloud Computing systems and enhancing their services to provide for a larger amount of users. However, security and privacy issues present a strong barrier for users to adapt into Cloud Computing systems. In this paper, we investigate several Cloud Computing system providers about their concerns on security and privacy issues. We find those concerns are not adequate and more should be added in terms of five aspects (i.e., availability, confidentiality, data integrity, control, audit) for security. Moreover, released acts on privacy are out of date to protect users' private information in the new environment (i.e., Cloud Computing system environment) since they are no longer applicable to the new relationship between users and providers, which contains three parties (i.e., Cloud service user, Cloud service provider/Cloud user, Cloud provider). Multi located data storage and services (i.e., applications) in the Cloud make privacy issues even worse. Hence, adapting released acts for new scenarios in the Cloud, it will result in more users to step into Cloud. We claim that the prosperity in Cloud Computing literature is to be coming after those security and privacy issues having be resolved.
Enhancing User Privacy in Adaptive Web Sites with Client-Side User Profiles	Web personalization is an elegant and flexible process of making a web site responsive to the unique needs of each individual user. Data that reflects user preferences and likings, comprising therefore a user profile, are gathered to an adaptive web site in a non transparent manner. This situation however raises serious privacy concerns to the end user. When browsing aweb site, users are not aware of several important privacy parameters i.e., which behavior will be monitored and logged, how it will be processed, how long it will be kept, and with whom it will be shared in the long run. In this paper we propose an abstract architecture that enhances user privacy during interaction with adaptive web sites. This architecture enables users to create and update their personal privacy preferences for the adaptive web sites they visit by holding their (user) profiles in the client side instead of the server side. By doing so users will be able to self-confine the personalization experience the adaptive sites offer, thus enhancing privacy.
Distributed Multimedia Information Retrieval Manner Based on the Statistic Information with Privacy	We propose and clarify the manner in which a distributed information retrieval (IR) is conducted using a Peer-to-Peer (P2P) technology that has approximately the same accuracy as a current index-integrated search engine with the statistical information calculated from the contents We need to solve the following problems to develop distributed IR services for distributed objects in peers without indices centralized servers. The first issue is efficient IR strategies that are highly accurate services by using the statistic information for indices using the collaboration among distributed peers (nodes). The second issue is the prevent strategy from flow of object information included personal information and shared information in groups to unknown peers as the result of IR service. We discuss the generating the statistics information and the scalability of service by using simulations and emulations. The dynamic privacy derivation manner of objects is generated based on the information entropy from catchwords. Our proposed strategy is required and suitable for P2P based peer services.
Preserving Privacy in Context-Aware Systems	Recent years have seen a confluence of two major trends -- the increase of mobile devices such as smart phones as the primary access point to networked information and the rise of social media platforms that connect people. Their convergence supports the emergence of a new class of context-aware geosocial networking applications. While existing systems focus mostly on location, our work centers on models for representing and reasoning about a more inclusive and higher-level notion of context, including the user's location and surroundings, the presence of other people and devices, and the inferred activities in which they are engaged. A key element of our work is the use of collaborative information sharing where devices share and integrate knowledge about their context. This introduces the need for privacy and security mechanisms. We present a framework to provide users with appropriate levels of privacy to protect the personal information their mobile devices are collecting, including the inferences that can be drawn from the information. We use Semantic Web technologies to specify high-level, declarative policies that describe user information sharing preferences. We have built a prototype system that aggregates information from a variety of sensors on the phone, online sources, and sources internal to the campus intranet, and infers the dynamic user context. We show how our policy framework can be effectively used to devise better privacy control mechanisms to control information flow between users in such dynamic mobile systems.
Message from the Workshop on Semantics, Security, and Privacy Chairs	
Privacy-Preserving Trust-Based Recommendations on Vertically Distributed Data	Providing recommendations on trusts between entities is receiving increasing attention lately. Customers may prefer different online vendors for shopping. Thus, their preferences about various products might be distributed among multiple parties. To provide more accurate and reliable referrals, such companies might decide to collaborate. Due to privacy, legal, and financial reasons, however, they do not want to work jointly. In this paper, we propose a method for providing trust-based predictions on vertically distributed data while preserving data owners' confidentiality. We analyze our scheme in terms of privacy and performance. We also perform experiments for accuracy analysis. Our analyses show that our scheme is secure and able to provide accurate and reliable predictions efficiently.
An Improved Profile-Based CF Scheme with Privacy	Traditional collaborative filtering (CF) systems widely employing k-nearest neighbor (kNN) algorithms mostly attempt to alleviate the contemporary problem of information overload by generating personalized predictions for items that users might like. Unlike their popularity and extensive usage, they suffer from several problems. First, with increasing number of users and/or items, scalability becomes a challenge. Second, as the number of ratable items increases and number of ratings provided by each individual remains as a tiny fraction, CF systems suffer from sparsity problem. Third, many schemes fail to protect private data referred to as privacy problem. Due to such problems, accuracy and online performance become worse. In this paper, we propose two preprocessing schemes to overcome scalability and sparsity problems. First, we suggest using a novel content-based profiling of users to estimate similarities on a reduced data for better performance. Second, we propose pseudo-prediction protocol to help CF systems surmount sparsity. We finally propose to use randomization methods to preserve individual users' confidential data, where we show that our proposed preprocessing schemes can be applied to perturbed data. We analyze our schemes in terms of privacy. To investigate their effects on accuracy and performance, we perform real databased experiments. Empirical results demonstrate that our preprocessing schemes improve both performance and accuracy.
Privacy and authentication on a portable communications system	Public-key/private-key hybrid key agreements and authentication protocols which maintain privacy of conversation and location information, and deter usage fraud, are presented. These protocols are optimized for low complexity in the portable unit and network infrastructure. The basic cryptographic techniques are described, and some complexity information obtained from these laboratory experiments and from other sources are presented. The three public-key protocols described have differing levels of security and complexity: and the tradeoffs are discussed. Because of the complexity concerns mentioned above, the public-key protocols are compared to a representative private-key approach in the areas of both security and computational complexity
Sage: a strong privacy-preserving scheme against global eavesdropping for ehealth systems	The eHealth system is envisioned as a promising approach to improving health care through information technology, where security and privacy are crucial for its success and largescale deployment. In this paper, we propose a strong privacy-preserving Scheme against Global Eavesdropping, named SAGE, for eHealth systems. The proposed SAGE can achieve not only the content oriented privacy but also the contextual privacy against a strong global adversary. Extensive analysis demonstrates the effectiveness and practicability of the proposed scheme.
Location Privacy in Unattended Wireless Sensor Networks upon the Requirement of Data Survivability	Wireless sensor networks have been used recently to obtain forensic evidence. One of the basic principles of obtaining forensic evidence is to maintain the integrity of the evidence. To increase the probability of retaining data integrity, the data replication strategy was proposed for unattended wireless sensor networks (UWSN), wherein the data integrity was quantified by data survival rate. However, the distribution of multiple data replicas may expose the location information of some critical nodes, thereby resulting in a high possibility of being attacked by the adversary. In this paper, we study the trade-off between the data survival rate and the location privacy of a critical node in an UWSN. Obviously, the increase in the number of data replicas can improve the data survival rate, but could severely degrade the location privacy of a critical node. Based on the captured data replicas, we propose three location estimation algorithms, the coordinate median, average of overlapping area and expectation-maximization approaches. The location estimation performance of the proposed schemes is evaluated and the trade-off between the data survival rate are investigated. According to the simulation results, the location privacy degrades severely with the increase in the number of data replicas.
AMOEBA: Robust Location Privacy Scheme for VANET	Communication messages in vehicular ad hoc networks (VANET) can be used to locate and track vehicles. While tracking can be beneficial for vehicle navigation, it can also lead to threats on location privacy of vehicle user. In this paper, we address the problem of mitigating unauthorized tracking of vehicles based on their broadcast communications, to enhance the user location privacy in VANET. Compared to other mobile networks, VANET exhibits unique characteristics in terms of vehicular mobility constraints, application requirements such as a safety message broadcast period, and vehicular network connectivity. Based on the observed characteristics, we propose a scheme called AMOEBA, that provides location privacy by utilizing the <i>group navigation of vehicles</i>. By simulating vehicular mobility in freeways and streets, the performance of the proposed scheme is evaluated under VANET application constraints and two passive adversary models. We make use of vehicular groups for anonymous access to location based service applications in VANET, for user privacy protection. The robustness of the user privacy provided is considered under various attacks.
Security, payment, and privacy for network commerce	As the Internet is used to a greater extent in business, issues of protection and privacy will have more importance. Users and organizations must have the ability to control reads and writes to network accessible information, they must be assured of the integrity and confidentiality of the information accessed over the net, and they must have a means to determine the security, competence, and honesty of the commercial service providers with which they interact. They must also be able to pay for purchases made on the network, and they should be free from excessive monitoring of their activities. This paper discusses characteristics of the Internet that make it difficult to provide such assurances and surveys some of the techniques that can used to protect users of the network
Privacy-Preserving Location-Based On-Demand Routing in MANETs	Mobile Ad-Hoc Networks (MANETs) are particularly useful and well-suited for critical scenarios, including military, law enforcement as well as emergency rescue and disaster recovery. When operating in hostile or suspicious settings, MANETs require communication security and privacy, especially, in underlying routing protocols. Unlike most networks, where communication is based on long-term identities (addresses), we argue that the location-centric communication paradigm is better-suited for privacy in suspicious MANETs. To this end, we construct an on-demand location-based anonymous MANET routing protocol (PRISM) that achieves privacy and security against both outsider and insider adversaries. We analyze the security, privacy and performance of PRISM and compare it to alternative techniques. Results show that PRISM is more efficient and offers better privacy than prior work.
Distributed Privacy-Preserving Aggregation of Metering Data in Smart Grids	The widespread deployment of Automatic Metering Infrastructures in Smart Grid scenarios rises great concerns about privacy preservation of user-related data, from which detailed information about customer's habits and behaviors can be deduced. Therefore, the users' individual measurements should be aggregated before being provided to External Entities such as utilities, grid managers and third parties. This paper proposes a security architecture for distributed aggregation of additive data, in particular energy consumption metering data, relying on Gateways placed at the customers' premises, which collect the data generated by local Meters and provide communication and cryptographic capabilities. The Gateways communicate with one another and with the External Entities by means of a public data network. We propose a secure communication protocol aimed at preventing Gateways and External Entities from inferring information about individual data, in which privacy-preserving aggregation is performed by means of a cryptographic homomorphic scheme. The routing of information flows can be centralized or it can be performed in a distributed fashion using a protocol inspired by Chord. We compare the performance of both approaches to the optimal solution minimizing the data aggregation delay.
Increasing Smart Meter Privacy Through Energy Harvesting and Storage Devices	Smart meters are key elements for the operation of smart grids. By providing near realtime information on the energy consumption of individual users, smart meters increase the efficiency in generation, distribution and storage of energy in a smart grid. The ability of the utility provider to track users' energy consumption inevitably leads to important threats to privacy. In this paper, privacy in a smart metering system is studied from an information theoretic perspective in the presence of energy harvesting and storage units. It is shown that energy harvesting provides increased privacy by diversifying the energy source, while a storage device can be used to increase both the energy efficiency and the privacy of the user. For given input load and energy harvesting rates, it is shown that there exists a trade-off between the information leakage rate, which is used to measure the privacy of the user, and the wasted energy rate, which is a measure of the energy-efficiency. The impact of the energy harvesting rate and the size of the storage device on this trade-off is also studied.
Privacy-Preserving Profile Matching for Proximity-Based Mobile Social Networking	Proximity-based mobile social networking (PMSN) refers to the social interaction among physically proximate mobile users. The first step toward effective PMSN is for mobile users to choose whom to interact with. Profile matching refers to two users comparing their personal profiles and is promising for user selection in PMSN. It, however, conflicts with users' growing privacy concerns about disclosing their personal profiles to complete strangers. This paper tackles this open challenge by designing novel fine-grained private matching protocols. Our protocols enable two users to perform profile matching without disclosing any information about their profiles beyond the comparison result. In contrast to existing coarse-grained private matching schemes for PMSN, our protocols allow finer differentiation between PMSN users and can support a wide range of matching metrics at different privacy levels. The performance of our protocols is thoroughly analyzed and evaluated via real smartphone experiments.
RFID security and privacy: a research survey	This paper surveys recent technical research on the problems of privacy and security for radio frequency identification (RFID). RFID tags are small, wireless devices that help identify objects and people. Thanks to dropping cost, they are likely to proliferate into the billions in the next several years-and eventually into the trillions. RFID tags track objects in supply chains, and are working their way into the pockets, belongings, and even the bodies of consumers. This survey examines approaches proposed by scientists for privacy protection and integrity assurance in RFID systems, and treats the social and technical context of their work. While geared toward the nonspecialist, the survey may also serve as a reference for specialist readers.
Third International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Cover	The following topics are dealt with: mobile ad hoc network; Internet; wireless sensor network; wireless intrusion detection; secure mobile RFID system and pervasive environment.
Third International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Title	Conference proceedings title page.
Third International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Table of contents	Presents the table of contents of the proceedings.
Secure Mobile RFID system against privacy and security problems	Radio frequency identification (RFID) systems based on EPC (electronic product code) network environment automatically identify tagged objects, using RF signals without direct contact. The RFID system will replace the Bar-code system, because it provides storage ability and contactless property. Recently, researchers introduced the mobile RFID system, which integrates a mobile system with a RFID technique and provides new services to users. However, the feature for obtaining information of objects using RF signals causes personal privacy problems such as information leakage and traceability. In this paper, we propose a privacy protection scheme suitable to mobile RFID systems. Our scheme is secure against threats such as impersonation, information leakage, and traceability.
Third International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Copyright	Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.
Second International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing	The following topics are dealt with: security; privacy; trust; pervasive computing; ubiquitous computing; intrusion detection systems; authentication; and protocols.
Second International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Title	Conference proceedings title page.
Second International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - Copyright	Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.
Second International Workshop on Security, Privacy and Trust in Pervasive and Ubiquitous Computing - TOC	Presents the table of contents of the proceedings.
Enhanced privacy in key-exchange protocols by one-time ID	This paper considers how two parties communicate securely over an adversary-controlled network. We especially focus on the problem of ID protection because of the rapid development of mobile network where any transferred message is easily eavesdropped on. We analyze several existing key exchange protocols and point out their problems: e.g. incompleteness of ID protection and vulnerability to DoS attacks. Then we model the notion of ID protection and construct a protocol with provable security
Privacy friendly applications using citizen cards based on cryptographic smartcards	Citizen Cards are being deployed nowadays. Several applications are being developed using such cards. Different kind of services can be provided with such cards, from services demanded by the administration, to applications from private companies. Unfortunately there is a great amount of applications that are not able nowadays to use the security these cards offer, due to their requirement of keeping the end-user anonymous. This requirement can be forced by the kind of application (e.g. restricted to certain ages), of by data protection laws, where there is no need to access personal data to provide a local service. Authors are proposing in this paper two solutions for this kind of services, benefiting from the already deployed citizen cards, reducing the cost of developing a new card, as well as maintain the card system.
Towards Privacy in Enterprise Directory Services: A User-Centric Approach to Attribute Management	Enterprise directory services (EDS) are commonly used to store attributes related to individual users within a corporation, and provide those attributes to authorized users upon request. These attributes may contain sensitive personal information, such as citizenship or social security numbers. Consequently, access to such information is generally controlled, usually by traditional methods such as access control lists. However, if a user-centric identity management model is considered, in which users control their own information and control access to that information, traditional EDS implementations do not provide complete protection from a user perspective. We propose combining public key infrastructure, user-centric identity management, and EDS to allow users control of the personal information stored within a directory as well as who is allowed to access that information. We demonstrate how a user may employ PKI to encrypt individual attributes, then share decryption information with selected entities. Among other advantages, this solution eliminates the possibility of administrative access to users information, a potential threat that exists within many EDS
Engineering secure software by modelling privacy and security requirements	Requirements are individual statements, usually expressed in a form of natural language, specifying the behaviour and constraints of a proposed system. Due to the intrinsic value of correct requirements, it is therefore essential for the process to be implemented correctly and that the requirements themselves reflect the true needs of the proposed system. The majority of developed systems introduce the concerns of privacy and security, however, traditional requirements engineering techniques have not addressed these issues appropriately. Further, the concepts of privacy, security, and the interrelated concept of trust, have not been accurately defined in terms of requirements engineering. Natural language is shown to be the most prevalent form of knowledge used to represent requirements, however, natural language introduces a number of inherent problems which can lead to ambiguity and specifications open to interpretation. When reasoning with privacy and security concerns the resulting specification should be both clear and concise in the stipulation of requirements. Therefore, before attempting to model privacy and security at the requirements engineering level, it is essential to have an understanding and appreciation of the issues involved. Consideration is given to the various concerns that would effect methodology development and once assessed a possible approach to modelling privacy and security requirements is highlighted.
An efficient anonymous scheme for computer and communication privacy	Due to the rising of on-line C&C (computer and communication) applications, users require an anonymous channel to transfer sensitive or confidential data on the networks. How to hide the sources and their locations during communications becomes an important problem. Although previous schemes such as IPSec can provide data protection for private communications, they require special devices (i.e. security gateways). Recently, researchers focus on applying the ALR (application-level routing) framework to perform private communications on top of IP networks. The Freenet system introduced by Clarke et al. is one of the most famous models. Freenet needs no special device. However, it stores and backwards response data over the entire routing path. Lots of time and resource are wasted. In this paper, we introduce the concept of anonymous-shortcut to improve Freenet's performance. The proposed mechanism permits users to choice different secure levels on their own demands. It provides a high flexibility in adjusting security and performance requirements to obtain the acceptable security and the controllable delay. Our mechanism is easy to implement, and can be combined with other protocols for applying in different problems, such as the "decapitation strike" in the combat zone. It provides anonymous delivery for application-independent and real-time connections.
The real privacy and security implications of the USA Patriot Act	The Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act (USA Patriot Act) of 2001 has aroused the concern of privacy advocates as well as others who question its effectiveness in combating terrorism. The Act amended over 15 important statutes and significantly expands the authority of government to conduct investigations and monitor information transmitted over the Internet. This paper provides an overview of critical portions of the 10 Titles of the Patriot Act that relate to privacy and security and gives an objective assessment of its weakness, strengths, and effects on the lives of US citizens. The analysis will include the topics of "roving wiretaps", secret searches, harboring suspected terrorists, foreign intelligence gathering, money laundering, and tracking of Internet communications. Because the Act affects the US Bill of Rights, the consequences of the Act on the following Constitutional amendments will also be explored: 1) 1st Amendment - Right of Free Access to Ideas, Speech, Assembly, etc.; 2) 4th Amendment - Search and Seizure; 3) 5th Amendment - Self Incrimination, Due Process; and 4) 6th Amendment - Right to Counsel, Unbiased, Speedy Criminal Trial.
Cryptanalysis of a strong proxy signature scheme with proxy signer privacy protection	Shum and Wei proposed an enhancement to the Lee et al.'s strong proxy signature such that the proxy signer's identity is hidden behind an alias. We show that Shum and Wei's enhancement is insecure against the original signer's forgery. In other words, their scheme does not possess the strong unforgeability security requirement.
Adding security and privacy to agents acting in a marketplace: a trust model	A general trust model for secure electronic agent-based marketplaces is described. The trust is presented as a dimensional space covering from physical security to high level trust relationships. A specific scenario has been chosen to show an implementation of the trust model: a secure multi-agent marketplace designed to manage resources in future mobile communications networks (J. Bigham et al., 2000). The multi-agent system is being developed as part of the IST SHUFFLE project (http://www.ist-shuffle.org)
Privacy algorithm for cylindrical holographic weapons surveillance system	A novel personnel surveillance system has been developed to detect and identify threatening objects, which are undetectable by metal detectors, concealed on the human body. This new system can detect threats, which are fabricated with plastic, liquid, metal, or ceramic. It uses millimeter-wave array technology and a cylindrical holographic imaging algorithm to provide full-body, 360-degree coverage of a person in near real-time. This system is ideally suited for mass transportation centers such as airport checkpoints that require high throughput rates and full coverage. Research and development efforts are underway to produce a privacy algorithm that removes the human features from the images while identifying the potential threats. This algorithm locates and segments the threats and places them on a wire-frame humanoid representation. The research areas for this algorithm development include artificial neural networks, image processing, edge detection, and dielectric measurements. This system is operational and results from this test and the privacy algorithm will be discussed in this paper
Communication privacy: a low cost digital approach	Support is demonstrated for an analog/digital system that can be scrambled while in digital form and may or may not transmit the key work for algorithm decoding. Multichannel audio and data communication is considered. In addition to digital audio and pulse code modulation concepts, frequency shift keying, frequency division multiplexing, and quadrature phase modulation are discussed. Both practical and cost aspects are considered. Commercially available integrated parts were used in the empirical work to achieve communication privacy at a low cost
Measuring privacy and security of iris fuzzy commitment	Template protection techniques are important supplements to biometrics, which aim to improve system security and safeguard privacy of users. Their development brings a new challenge of privacy and security assessment especially for real systems. In the paper, we take a close look at fuzzy commitment, which is an efficient and widely used template protection algorithm and demonstrates rigorous assessment of an iris fuzzy commitment scheme using the information-theoretical metrics. For instance, a 56 bit long secret can be derived from iris codes. Instead of iris codes, its hash value is stored. However, due to the dependency of iris codes, the uncertainty of secrets reduces to 11.82 bits given protected templates. It confirms the empirical results that an adversary is able to retrieve the iris features from the protected templates with average number of attempts equal to 2<sup>10.56</sup> as shown in [1]. The poor security and privacy performance is caused by strong correlation of iris feature and unsuitable coding methods used in the algorithm. The quantitative measurement shown in this paper provides a reference guidance on evaluation of template protection in practice. It helps algorithm developers to show the security and privacy of template protection to end-users and to detect the weaknesses of the algorithms.
Home system ΓÇö Biometric privacy and identity management	The term security network intelligence is widely used in the field of communication security network. A number of new and potentially concepts and products based on the concept of security network intelligence have been introduced, including smart flows, intelligent routing, and intelligent web switching. Many intelligent systems focus on a specific security service, function, or device, and do not provide true end-to-end service network intelligence. True security network intelligence requires more than a set of disconnected elements, it requires an interconnecting and functionally coupled architecture that enables the various functional levels to interact and communicate with each other.
A privacy protection architecture in sharing biometric information for NATO applications	In recent years, biometric technologies have been playing more and more important role in the Global War on Terror. As a NATO program, the International Security Assistance Force (ISAF) implemented the US biometric systems as part of ISAF force protection and overall security efforts in Afghanistan in February 2007. Sharing biometric data in combat applications to identify Red Force allows the alliance members to eliminate the terrorist's advantage of anonymity. However, it raises privacy and legal concerns under the current system architecture when the system is used for identifying terrorist suspects and verifying NATO citizens. To address the challenge, a privacy protection architecture is presented that can reduce privacy violations and legal risks in sharing biometric data. The objective is to provide a privacy protection solution for the future development of NATO biometric system.
Measuring Privacy Compliance with Process Specifications	Enforcement relies on the idea that infringements are violations and as such should not be allowed. However, this notion is very restrictive and cannot be applied in unpredictable domains like healthcare. To address this issue, we need conformance metrics for detecting and quantifying infringements of policies and procedures. However, existing metrics usually consider every deviation from specifications equally making them inadequate to measure the severity of infringements. In this paper, we identify a number of factors which can be used to quantify deviations from process specifications. These factors drive the definition of metrics that allow for a more accurate measurement of privacy infringements. We demonstrate how the proposed approach can be adopted to enhance existing conformance metrics through a case study on the provisioning of healthcare treatment.
Privacy Weaknesses in Biometric Sketches	The increasing use of biometrics has given rise to new privacy concerns. Biometric encryption systems have been proposed in order to alleviate such concerns: rather than comparing the biometric data directly, a key is derived from these data and subsequently knowledge of this key is proved. One specific application of biometric encryption is the use of biometric sketches: in this case biometric template data are protected with biometric encryption. We address the question whether one can undermine a user's privacy given access to biometrically encrypted documents, and more in particular, we examine if an attacker can determine whether two documents were encrypted using the same biometric. This is a particular concern for biometric sketches that are deployed in multiple locations: in one scenario the same biometric sketch is deployed everywhere; in a second scenario the same biometric data is protected with two different biometric sketches. We present attacks on template protection schemes that can be described as fuzzy sketches based on error-correcting codes. We demonstrate how to link and reverse protected templates produced by code-offset and bit-permutation sketches.
Towards Practical Privacy for Genomic Computation	Many basic tasks in computational biology involve operations on individual DNA and protein sequences. These sequences, even when anonymized, are vulnerable to re-identification attacks and may reveal highly sensitive information about individuals. We present a relatively efficient, privacy-preserving implementation of fundamental genomic computations such as calculating the edit distance and Smith- Waterman similarity scores between two sequences. Our techniques are crypto graphically secure and significantly more practical than previous solutions. We evaluate our prototype implementation on sequences from the Pfam database of protein families, and demonstrate that its performance is adequate for solving real-world sequence-alignment and related problems in a privacy- preserving manner. Furthermore, our techniques have applications beyond computational biology. They can be used to obtain efficient, privacy-preserving implementations for many dynamic programming algorithms over distributed datasets.
2007 IEEE Symposium on Security and Privacy - Copyright	
2007 IEEE Symposium on Security and Privacy - Table of contents	Presents the table of contents of the proceedings.
2007 IEEE Symposium on Security and Privacy - Title page	The following topics are dealt with: network security; message authentication; data privacy; access control and audit; information flow; host security; hardware and replication; encryption methods.
2007 IEEE Symposium on Security and Privacy - Cover	Presents the front cover or splash screen of the proceedings.
IEEE Symposium on Security and Privacy - Title	Conference proceedings title page.
IEEE Symposium on Security and Privacy - Copyright	Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.
2006 IEEE Symposium on Security and Privacy	The following topics are dealt with: signature generation; intrusion detection; data privacy; formal methods; code analysis; authentication; and security attacks
IEEE Symposium on Security and Privacy - Table of contents	Presents the table of contents of the proceedings.
Privacy and contextual integrity: framework and applications	Contextual integrity is a conceptual framework for understanding privacy expectations and their implications developed in the literature on law, public policy, and political philosophy. We formalize some aspects of contextual integrity in a logical framework for expressing and reasoning about norms of transmission of personal information. In comparison with access control and privacy policy frameworks such as RBAC, EPAL, and P3P, these norms focus on who personal information is about, how it is transmitted, and past and future actions by both the subject and the users of the information. Norms can be positive or negative depending on whether they refer to actions that are allowed or disallowed. Our model is expressive enough to capture naturally many notions of privacy found in legislation, including those found in HIPAA, COPPA, and GLBA. A number of important problems regarding compliance with privacy norms, future requirements associated with specific actions, and relations between policies and legal standards reduce to standard decision procedures for temporal logic
Proceedings. 2005 IEEE Symposium on Security and Privacy	The following topics are dealt with: intrusion detection; sensor networks; access control and authentication; integrity; cryptography and protocols; and worms and network forensics.
Proceedings 2004 IEEE Symposium on Security and Privacy Copyright Page	Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.
Proceedings. 2004 IEEE Symposium on Security and Privacy	
Proceedings 2004 IEEE Symposium on Security and Privacy Table of contents	Presents the table of contents of the proceedings.
Proceedings 2004 IEEE Symposium on Security and Privacy	Presents the title -page of the proceedings record.
Securing OLAP data cubes against privacy breaches	An OLAP (On-line Analytic Processing) system with insufficient security countermeasures may disclose sensitive information and breach an individual's privacy. Both unauthorized accesses and malicious inferences may lead to such inappropriate disclosures. Existing access control models in relational databases are unsuitable for the multi-dimensional data cubes used by OLAP. Inference control methods in statistical databases are expensive and apply to limited situations only. We first devise a flexible framework for specifying authorization objects in data cubes. The framework can partition a data cube both vertically based on dimension hierarchies and horizontally based on slices of data. We then study how to control inferences in data cubes. The proposed method eliminates both unauthorized accesses and malicious inferences. Its effectiveness does not depend on specific types of aggregation functions, external knowledge, or sensitivity criteria. The technique is efficient and readily implementable. Its on-line performance overhead is comparable to that of the minimal security requirement. Its enforcement requires little modification to existing OLAP systems.
Proceedings 2003 Symposium on Security and Privacy	The following topics are dealt with: anonymity; intrusion detection systems (IDS); operating systems (OS) and denial-of-service (DoS) attacks; formal methods; hardware and cryptography; and distributed systems.
Proceedings 2002 IEEE Symposium on Security and Privacy	The following topics are dealt with: security; privacy; intrusion detection; and authentication.
Collaborative filtering with privacy	Server-based collaborative filtering systems have been very successful in e-commerce and in direct recommendation applications. In future, they have many potential applications in ubiquitous computing settings. But today's schemes have problems such as loss of privacy, favoring retail monopolies, and with hampering diffusion of innovations. We propose an alternative model in which users control all of their log data. We describe an algorithm whereby a community of users can compute a public "aggregate" of their data that does not expose individual users' data. The aggregate allows personalized recommendations to be computed by members of the community, or by outsiders. The numerical algorithm is fast, robust and accurate. Our method reduces the collaborative filtering task to an iterative calculation of the aggregate requiring only addition of vectors of user data. Then we use homomorphic encryption to allow sums of encrypted vectors to be computed and decrypted without exposing individual data. We give verification schemes for all parties in the computation. Our system can be implemented with untrusted servers, or with additional infrastructure, as a fully peer-to-peer (P2P) system.
Proceedings 2001 IEEE Symposium on Security and Privacy. S&P 2001	The following topics are covered: security; privacy; tamper resistance; cryptography; information flow; intrusion detection; anomaly detection; and cryptographic protocols
Privacy technology lessons from healthcare	The probability that information will be abused depends both on its value and on the number of people, who have access. The modern trend to ever larger databases increases both of these risk factors at the same time. Compartmented security policies can solve many of the technical issues, and there are applications such as healthcare where they have been developed in some detail. But the big problem isn't technical; it is legal and regulatory. Insurers, employers and governments won't adopt compartmented systems, or will allow them to be adopted only in places such as hospitals which are not where the real threats lie
Proceeding 2000 IEEE Symposium on Security and Privacy. S&P 2000	The following topics are dealt with: computer security and privacy; access control; cryptography applications; protocol analysis and design; intrusion detection; assurance; telecommunications security; and key management
Proceedings of the 1999 IEEE Symposium on Security and Privacy (Cat. No.99CB36344)	The following topics were dealt with: security policy; verification; computer security research; data privacy; authorization; intrusion detection; information flow; authentication and key exchange; and future security
Proceedings. 1998 IEEE Symposium on Security and Privacy (Cat. No.98CB36186)	The following topics were dealt with: access control; Java security; cryptography; trust considerations in PKI-based systems; architectures; database security and biometrics; and formal methods
Proceedings. 1997 IEEE Symposium on Security and Privacy (Cat. No.97CB36097)	The following topics were dealt with: security and privacy; authorisation and authentication; application security; security theory; intrusion detection; innovative operating systems; and system vulnerabilities
Proceedings 1996 IEEE Symposium on Security and Privacy	The following topics were dealt with: data security and privacy; covert channels; computer security education; domain specific security; protocols; databases; biologically based security issues; modelling; and networks
Preserving privacy in a network of mobile computers	Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed. We have developed a replicated memory service which allows users to read from memory without revealing which memory locations they are reading. Unlike previous protocols, our protocol is efficient in its use of computation and bandwidth. We show how this protocol can be used in conjunction with existing privacy preserving protocols to allow a user of a mobile computer to maintain privacy despite active attacks
Proceedings 1995 IEEE Symposium on Security and Privacy	The following topics were dealt with: secure commerce; network security; secure operating systems; formal models for multilevel security; covert channel control; analysis of security vulnerabilities; and protocol analysis
Proceedings 1989 IEEE Symposium on Security and Privacy (Cat. No.89CH2703-7)	The following topics are dealt with: operating systems, database management systems, distributed systems, formal models, authentication, and computer viruses
Proceedings of the 1988 IEEE Symposium on Security and Privacy (Cat. No.88CH2558-5)	The following topics are dealt with: formal security models; security in distributed systems; emerging issues; database security; analysis of secure systems; applying and implementing integrity models; verification; and models of secure distributed systems. Abstracts of individual papers can be found under the relevant classification codes in this or other issues
Privacy in Online Review Sites	The increasing use of online review sites is creating new challenges for user privacy. Although reviews are public, many users inadvertently disclose private information about relationship, location, and temporal attributes to the world. This research protects users of online review sites from the inadvertent disclosure of private information in three ways. First, the types of unstructured and structured information made public by online review sites are characterized and used to grade those sites on their attention to privacy. Second, a privacy-check tool that uses keyword matching and named-entity recognition to annotate potentially sensitive review text is presented. Third, we raise awareness of the privacy threat in online review sites through examples and statistics derived from the privacy-check tool.
IEEE CS Security and Privacy Workshops - SPW 2012 - Table of contents	Presents the table of contents for the 2012 IEEE Symposium on Security and Privacy Workshops proceedings.
Privacy Control in Smart Phones Using Semantically Rich Reasoning and Context Modeling	We present our ongoing work on user data and contextual privacy preservation in mobile devices through semantic reasoning. Recent advances in context modeling, tracking and collaborative localization have led to the emergence of a new class of smart phone applications that can access and share embedded sensor data. Unfortunately, this also means significant amount of user context information is now accessible to applications and potentially others, creating serious privacy and security concerns. Mobile OS frameworks like Android lack mechanisms for dynamic privacy control. We show how data flow among applications can be successfully filtered at a much more granular level using semantic web driven technologies that model device location, surroundings, application roles as well as context-dependent information sharing policies.
Secure computation for data privacy	The Secure Mobile Code is a fragment of code being executed in some unfamiliar and untrusted environment. Protecting integrity and maintaining confidentially of the code execution in unfamiliar environment has been a challenging task. The host environment may try to guess the functionality of the code received. This generates a need to design a scheme that can perform secure computation on encoded data and leaving no clues for the host to guess the functionality and data. In our scheme, the sender will generate the code which is transformed to hide the functionality and she will send it along with encoded data to the host. Subsequently, the host will run the code on the encoded data and send the result to the sender. The functionality is protected by the encoded gates where the truth table is transformed using the Reducible Rank Codes[1]. We also present a detail security analysis and complexity of our scheme. Our scheme finds application where the data computation has been outsourced to other party.
Privacy-preserving authentication with low computational overhead for RFID systems	Providing secure authentication in a resource limited Radio Frequency Identification (RFID) system is a challenging task. To address this problem, we propose a High-Performance RFID authentication protocol, HPA, based on AVL tree which is a highly balanced binary search tree. In the protocol, each tag of a RFID system is associated to a node on an AVL tree. It shares a unique secret key with the database and each key is stored in a node on the tree. Compared with existing RFID schemes, HPA has two salient features: logarithmic complexity of searching a node and identifying a tag; much lower computational overhead and storage cost. Simultaneously, HPA is secure enough to defend against both passive and active attacks.
Proceedings of the third international conference on security and privacy in communication networks	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04550292.png" border="0">
SecureComm 2007 Privacy - Session 3	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04550307.png" border="0">
The CONNECT platform: An architecture for Context-Aware Privacy in pervasive environments	Nowadays, privacy in mobile settings mostly is controlled manually and limited to acknowledging some prefabricated privacy statements offered to the user. However, for Ambient Intelligence scenarios such privacy control falls short for various reasons. The most obvious is that the interaction with a large number of heterogeneous Context-Aware Mobile Services becomes a burdensome task, which eventually might lead to frustration if newly encountered services require the explicit consensus of the user for the disclosure of privacy sensitive data. The IST project CONNECT addresses such issues by defining a common software platform for mediating between users, their privacy needs, privacy management and the context-aware mobile services. It includes not only the core technologies needed, but also easy-to-use interfaces and some self-learning technologies to assist users in the specification of privacy preferences matching their needs. In this paper, we introduce the CONNECT platform and its architecture with a special emphasize on the Context-sensitive Privacy Management middleware and its various functionalities.
First International Conference on Security and Privacy for Emerging Areas in Communications Networks - Cover	Presents the front cover of the proceedings.
Security and Privacy Issues in E-passports	Within the next year, travelers from dozens of nations may be carrying a new form of passport in response to a mandate by the United States government. The e-passport, as it is sometimes called, represents a bold initiative in the deployment of two new technologies: Radio-Frequency Identification (RFID) and biometrics. Important in their own right, e-passports are also the harbinger of a wave of next-generation ID cards: several national governments plan to deploy identity cards integrating RFID and biometrics for domestic use. We explore the privacy and security implications of this impending worldwide experiment in next-generation authentication technology. We describe privacy and security issues that apply to e-passports, then analyze these issues in the context of the International Civil Aviation Organization (ICAO) standard for e-passports.
First International Conference on Security and Privacy for Emerging Areas in Communications Networks - Table of contents	Presents the table of contents of the proceedings.
A Privacy Preserving Reputation System for Mobile Information Dissemination Networks	In a mobile information dissemination network mobile users, equipped with wireless devices, exchange information in a spontaneous manner whenever they come into communication range. Users have to specify what kind of information they are looking for and what kind of information they can offer. A priori there is no relation between users, literally spoken, they don┬Æt know each other and confidence in newly collected information might be low. This work presents two reputation schemes, a simple and an extended version, for mobile information dissemination networks that, based on user ratings, increase a user┬Æs confidence in some information source. As reputation systems collect sensitive personal information and monitor users┬Æ behavior, privacy is an essential requirement ┬ù especially in a mobile scenario ┬ù that is neglected by many existing approaches. Using cryptographic group signatures and the concept of an observer, our extended reputation scheme guarantees high user privacy.
Short Paper: Location Privacy with IP Mobility	Privacy when using IP communication has become an important problem. It is a challenging problem that spans multiple layers in the OSI reference model with various constant identifiers that can be profiled. This leads to user privacy concerns. Location Privacy, on the other hand, is primarily concerned with revealing a user┬Æs identity as a function of mobility. When a user visits a new network and uses a fixed identifier, such as a Mobile IPv6 Home Address for communication, on-lookers can determine that the user has roamed. We address this problem of location privacy and provide a Privacy-Tag for use in place of a fixed identifier to protect user privacy. Our method is readily implementable using the Mobile IPv6 Return Routability [2] protocol and the Binding Update procedure.
Short paper: Random IDs for preserving location privacy	The privacy aspect is often neglected in many electronic systems. With the emergence of ubiquitous systems, privacy will become an even more important aspect than it has been in the past. Location privacy - the information where exactly a node is currently located - is one aspect. This paper classifies several kinds of attacks on location privacy. It examines the results of these attacks on a scheme utilising changing identities to preserve the users┬Æ identities. Simulation results show the influence of the number of nodes and the backoff time between transmissions on the nodes┬Æ location privacy.
Protecting Location Privacy Through Path Confusion	We present a path perturbation algorithm which can maximize users┬Æ location privacy given a quality of service constraint. This work concentrates on a class of applications that continuously collect location samples from a large group of users, where just removing user identifiers from all samples is insufficient because an adversary could use trajectory information to track paths and follow users┬Æ footsteps home. The key idea underlying the perturbation algorithm is to cross paths in areas where at least two users meet. This increases the chances that an adversary would confuse the paths of different users. We first formulate this privacy problem as a constrained optimization problem and then develop heuristics for an efficient privacy algorithm. Using simulations with randomized movement models we verify that the algorithm improves privacy while minimizing the perturbation of location samples.
A Solution for Wireless Privacy and Payments based on E-cash	The IEEE 802.11 Wireless Local Area Network (WLAN) specifications have been the subject of increased attention due to their rapid commercial adaptation and the introduction of new security and privacy concerns. The IEEE 802.1x standard was introduced in order to overcome the initial security shortcomings of the Wired Equivalent Privacy (WEP) protocol. The IEEE 802.1x standard is an extensible standard that couples 802.11 networks with various authentication services through the incorporation of an Extensible Authentication Protocol (EAP) authentication dialog. The existing implementations of EAP dialogs are based on standard cryptographic solutions for authentication and session key generation but do not, however, provide any form of user anonymity or privacy. Anonymity and privacy are currently of pressing interest, especially in the context of WLANs, which are simultaneously the best medium to provide privacy (there is no physical phone number or connection end-point with a predetermined owner) as well as the most threatening medium to user privacy, as they have the potential of disclosing not only the identity of the user, but also their physical location. At the same time, the potential "perfect hiding" capabilities of WLAN users also highlights the need to control anonymity by introducing more flexible authentication mechanisms. Moreover, payment for wireless services is completely decoupled from the above procedures, raising additional efficiency and privacy concerns. In this work we propose a new EAP authentication dialog based on anonymous electronic cash that provides for privacy, anonymity control, payment acceptance and billing, and authentication. Our solution is based on the notion of "public-key embedding e-cash," an e-cash variant we present and formalize in this paper. We present a concrete description of the new EAP authentication dialog in the context of IEEE 802.1x. We also present an effi- cient implementation of a public-key embedding e-cash scheme based on RSA blind signatures and prove its security.
A Privacy Service for Context-aware Mobile Computing	Privacy issues related to the access of context information are becoming increasingly important as we move toward ubiquitous and mobile computing environments. In this article, we describe the design and implementation of a privacy service, called Context Privacy Service (CoPS), to control how, when and to whom disclose a user┬Æs context information. Based on the results of an end-user survey and experience reported by other research groups, we identified the main service requirements and designed CoPS aiming flexibility, generality, simplicity and fine-grained privacy control. CoPS is an optional service of our context-provisioning middleware MoCA and allows users of context- and location-aware applications to define and manage their privacy policies regarding disclosure of their context information. The main features supported by CoPS are group-based access control, pessimistic and optimistic approaches for access control, hierarchical privacy rules, mixed-initiative interaction, and rule specificity analysis.
First International Conference on Security and Privacy for Emerging Areas in Communications Networks - Copyright	Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.
First International Conference on Security and Privacy for Emerging Areas in Communications Networks - Title	The following topics are dealt with: broadband networking applications; wireless networking; security protocols and trust management
Privacy preserving ubiquitous service provisioning based on Bayesian network conversion	Protecting personal privacy is already seen as a crucial requirement in the implementation of service provisioning in the ubiquitous environment. From the view point of preserving personal privacy, the simplest approach would be for users not to reveal any kind of private information at any time while keeping the number of available services unrestricted. Meanwhile, from the service provider's point of view, though this has been not clearly stated so far, their service logics should also be hidden from others because those logics may leak their know-how. This paper presents an ubiquitous service provisioning mechanism that gives more opportunities for users to get available services while preserving the secrecy of users' and providers' sensitive information. The basic idea of this mechanism is to share service execution procedures between the service provider and the user by exchanging converted service logic described in the form of Bayesian decision networks. This paper describes the proposed mechanism and the conversion algorithm for the Bayesian networks, and details the system architecture and implementation.
Sharing computer network logs for security and privacy: a motivation for new methodologies of anonymization	Logs are one of the most fundamental resources to any security professional. It is widely recognized by the government and industry that it is both beneficial and desirable to share logs for the purpose of security research. However, the sharing is not happening or not to the degree or magnitude that is desired. Organizations are reluctant to share logs because of the risk from exposing sensitive information to potential attackers. In this paper we survey current attempts at sharing logs and current log anonymization tools. We further define the problem and describe a roadmap to solve the issues that have to date inhibited large scale log sharing.
Privacy in distributed reputation management	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01588297.png" border="0">
Circuit Structures for Improving Efficiency of Security and Privacy Tools	Several techniques in computer security, including generic protocols for secure computation and symbolic execution, depend on implementing algorithms in static circuits. Despite substantial improvements in recent years, tools built using these techniques remain too slow for most practical uses. They require transforming arbitrary programs into either Boolean logic circuits, constraint sets on Boolean variables, or other equivalent representations, and the costs of using these tools scale directly with the size of the input circuit. Hence, techniques for more efficient circuit constructions have benefits across these tools. We show efficient circuit constructions for various simple but commonly used data structures including stacks, queues, and associative maps. While current practice requires effectively copying the entire structure for each operation, our techniques take advantage of locality and batching to provide amortized costs that scale polylogarithmically in the size of the structure. We demonstrate how many common array usage patterns can be significantly improved with the help of these circuit structures. We report on experiments using our circuit structures for both generic secure computation using garbled circuits and automated test input generation using symbolic execution, and demonstrate order of magnitude improvements for both applications.
Privacy-Preserving Ridge Regression on Hundreds of Millions of Records	Ridge regression is an algorithm that takes as input a large number of data points and finds the best-fit linear curve through these points. The algorithm is a building block for many machine-learning operations. We present a system for privacy-preserving ridge regression. The system outputs the best-fit curve in the clear, but exposes no other information about the input data. Our approach combines both homomorphic encryption and Yao garbled circuits, where each is used in a different part of the algorithm to obtain the best performance. We implement the complete system and experiment with it on real data-sets, and show that it significantly outperforms pure implementations based only on homomorphic encryption or Yao circuits.
A Scanner Darkly: Protecting User Privacy from Perceptual Applications	Perceptual, "context-aware" applications that observe their environment and interact with users via cameras and other sensors are becoming ubiquitous on personal computers, mobile phones, gaming platforms, household robots, and augmented-reality devices. This raises new privacy risks. We describe the design and implementation of DARKLY, a practical privacy protection system for the increasingly common scenario where an untrusted, third-party perceptual application is running on a trusted device. DARKLY is integrated with OpenCV, a popular computer vision library used by such applications to access visual inputs. It deploys multiple privacy protection mechanisms, including access control, algorithmic privacy transforms, and user audit. We evaluate DARKLY on 20 perceptual applications that perform diverse tasks such as image recognition, object tracking, security surveillance, and face detection. These applications run on DARKLY unmodified or with very few modifications and minimal performance overheads vs. native OpenCV. In most cases, privacy enforcement does not reduce the applications' functionality or accuracy. For the rest, we quantify the tradeoff between privacy and utility and demonstrate that utility remains acceptable even with strong privacy protection.
LAP: Lightweight Anonymity and Privacy	Popular anonymous communication systems often require sending packets through a sequence of relays on dilated paths for strong anonymity protection. As a result, increased end-to-end latency renders such systems inadequate for the majority of Internet users who seek an intermediate level of anonymity protection while using latency-sensitive applications, such as Web applications. This paper serves to bridge the gap between communication systems that provide strong anonymity protection but with intolerable latency and non-anonymous communication systems by considering a new design space for the setting. More specifically, we explore how to achieve near-optimal latency while achieving an intermediate level of anonymity with a weaker yet practical adversary model (i.e., protecting an end-host's identity and location from servers) such that users can choose between the level of anonymity and usability. We propose Lightweight Anonymity and Privacy (LAP), an efficient network-based solution featuring lightweight path establishment and stateless communication, by concealing an end-host's topological location to enhance anonymity against remote tracking. To show practicality, we demonstrate that LAP can work on top of the current Internet and proposed future Internet architectures.
Hummingbird: Privacy at the Time of Twitter	In the last several years, micro-blogging Online Social Networks (OSNs), such as Twitter, have taken the world by storm, now boasting over 100 million subscribers. As an unparalleled stage for an enormous audience, they offer fast and reliable centralized diffusion of pithy tweets to great multitudes of information-hungry and always-connected followers. At the same time, this information gathering and dissemination paradigm prompts some important privacy concerns about relationships between tweeters, followers and interests of the latter. In this paper, we assess privacy in today's Twitter-like OSNs and describe an architecture and a trial implementation of a privacy-preserving service called Hummingbird. It is essentially a variant of Twitter that protects tweet contents, hash tags and follower interests from the (potentially) prying eyes of the centralized server. We argue that, although inherently limited by Twitter's mission of scalable information-sharing, this degree of privacy is valuable. We demonstrate, via a working prototype, that Hummingbird's additional costs are tolerably low. We also sketch out some viable enhancements that might offer better privacy in the long term.
2012 IEEE Symposium on Security and Privacy - S&P 2012: Table of contents	Presentrs the table of contents of the proceedings of the 2012 IEEE Symposium on Security and Privacy.
Proceedings: 2012 IEEE Symposium on Security and Privacy - S&P 2012 [Title page i]	Presents the title page of the proceedings of the 2012 IEEE Symposium on Security and Privacy - S&P 2012.
Proceedings: 2012 IEEE Symposium on Security and Privacy - S&P 2012 [Title page iii]	Presents the title page of the proceedings of the 2012 IEEE Symposium on Security and Privacy - S&P 2012.
Formalizing and Enforcing Purpose Restrictions in Privacy Policies	Privacy policies often place restrictions on the purposes for which a governed entity may use personal information. For example, regulations, such as the Health Insurance Portability and Accountability Act (HIPAA), require that hospital employees use medical information for only certain purposes, such as treatment, but not for others, such as gossip. Thus, using formal or automated methods for enforcing privacy policies requires a semantics of purpose restrictions to determine whether an action is for a purpose or not. We provide such a semantics using a formalism based on planning. We model planning using a modified version of Markov Decision Processes (MDPs), which exclude redundant actions for a formal definition of redundant. We argue that an action is for a purpose if and only if the action is part of a plan for optimizing the satisfaction of that purpose under the MDP model. We use this formalization to define when a sequence of actions is only for or not for a purpose. This semantics enables us to create and implement an algorithm for automating auditing, and to describe formally and compare rigorously previous enforcement methods. To validate our semantics, we conduct a survey to compare our semantics to how people commonly understand the word "purpose".
Verifiability, Privacy, and Coercion-Resistance: New Insights from a Case Study	In this paper, we present new insights into central properties of voting systems, namely verifiability, privacy, and coercion-resistance. We demonstrate that the combination of the two forms of verifiability considered in the literature -- individual and universal verifiability -- are, unlike commonly believed, insufficient to guarantee overall verifiability. We also demonstrate that the relationship between coercion-resistance and privacy is more subtle than suggested in the literature. Our findings are partly based on a case study of prominent voting systems, Three Ballot and VAV, for which, among others, we show that, unlike commonly believed, they do not provide any reasonable level of verifiability, even though they satisfy individual and universal verifiability. Also, we show that the original variants of Three Ballot and VAV provide a better level of coercion-resistance than of privacy.
Quantifying Location Privacy	It is a well-known fact that the progress of personal communication devices leads to serious concerns about privacy in general, and location privacy in particular. As a response to these issues, a number of Location-Privacy Protection Mechanisms (LPPMs) have been proposed during the last decade. However, their assessment and comparison remains problematic because of the absence of a systematic method to quantify them. In particular, the assumptions about the attacker's model tend to be incomplete, with the risk of a possibly wrong estimation of the users' location privacy. In this paper, we address these issues by providing a formal framework for the analysis of LPPMs, it captures, in particular, the prior information that might be available to the attacker, and various attacks that he can perform. The privacy of users and the success of the adversary in his location-inference attacks are two sides of the same coin. We revise location privacy by giving a simple, yet comprehensive, model to formulate all types of location-information disclosure attacks. Thus, by formalizing the adversary's performance, we propose and justify the right metric to quantify location privacy. We clarify the difference between three aspects of the adversary's inference attacks, namely their accuracy, certainty, and correctness. We show that correctness determines the privacy of users. In other words, the expected estimation error of the adversary is the metric of users' location privacy. We rely on well-established statistical methods to formalize and implement the attacks in a tool: the Location-Privacy Meter that measures the location privacy of mobile users, given various LPPMs. In addition to evaluating some example LPPMs, by using our tool, we assess the appropriateness of some popular metrics for location privacy: entropy and k-anonymity. The results show a lack of satisfactory correlation between these two metrics and the success of the adversary in inferring the users' actual- - locations.
RePriv: Re-imagining Content Personalization and In-browser Privacy	We present RePriv, a system that combines the goals of privacy and content personalization in the browser. RePriv discovers user interests and shares them with third parties, but only with an explicit permission of the user. We demonstrate how always-on user interest mining can effectively infer user interests in a real browser. We go on to discuss an extension framework that allows third-party code to extract and disseminate more detailed information, as well as language-based techniques for verifying the absence of privacy leaks in this untrusted code. To demonstrate the effectiveness of our model, we present RePriv extensions that perform personalization for Netflix, Twitter, Bing, and Get Glue. This paper evaluates important aspects of RePriv in realistic scenarios. We show that RePriv's default in-browser mining can be done with no noticeable overhead to normal browsing, and that the results it produces converge quickly. We demonstrate that RePriv personalization yields higher quality results than those that maybe obtained about the user from public sources. We then go onto show similar results for each of our case studies: that RePrivenables high-quality personalization, as shown by cases studies in news and search result personalization we evaluated on thousands of instances, and that the performance impact each case has on the browser is minimal. We conclude that personalized content and individual privacy on the web are not mutually exclusive.
"You Might Also Like:" Privacy Risks of Collaborative Filtering	Many commercial websites use recommender systems to help customers locate products and content. Modern recommenders are based on collaborative filtering: they use patterns learned from users' behavior to make recommendations, usually in the form of related-items lists. The scale and complexity of these systems, along with the fact that their outputs reveal only relationships between items (as opposed to information about users), may suggest that they pose no meaningful privacy risk. In this paper, we develop algorithms which take a moderate amount of auxiliary information about a customer and infer this customer's transactions from temporal changes in the public outputs of a recommender system. Our inference attacks are passive and can be carried out by any Internet user. We evaluate their feasibility using public data from popular websites Hunch, Last. fm, Library Thing, and Amazon.
Reflections on the 30th Anniversary of the IEEE Symposium on Security and Privacy	This article is a retrospective of concepts and people who have contributed significantly to the IEEE Symposium on Security and Privacy over the past 30 years. The authors identify many individuals who have contributed to SSP as program chairs, general chairs, and heads of the overseeing IEEE technical committee. They recognize SSP participants who have provided significant leadership in creating and funding opportunities for research and development in security and privacy. Some contributions to advances in security are also discussed in following articles by Carl Landwehr and Douglas Maughan, both of whom have been major instigators of R&D programs at multiple US government agencies. The authors also highlight some influential SSP papers from three decades, and also efforts that have had significant impact in providing or stimulating effective technology transfer, as well as authors and educators whose work provided major contributions to academic curricula, all helping instill trustworthiness into computercommunication security. Finally, they identify some of the anniversary event honorees.
Anonymous social stamps: Authenticating anonymous statements to friends with privacy	Numerous online services and applications for smart devices exist today on the internet which claim almost similar functionalities. This inevitably leads to the problem of being able to choose the right one which is mostly done today by trial-and-error. However this gets tricky if it involves sharing privacy sensitive information with the service e.g. in the case of health and well-ness services. A customer's trust in a new online service is known to increase based on testimonials (or observable behavior) of people within a social distance (friends, friends-of-friends etc). Linking testimonials to users requires releasing one's social network information which by itself is privacy invasive. The paper presents the concept of an anonymous social stamp which can be assigned to anonymous statements and help prove that the statement was made by a particular member of an external social networking site. Trust can then be derived based on the social distance between the persons concerned: the person who made the statement and the person verifying the statement. A possible implementation of the concept is shown with the existing infrastructure of RSA keys already in use by social networking sites. The concept is applicable for the new services that can create confidence in new users by revealing anonymous data sharing configurations of other users with the service.
Privacy protection for user authentication	The paper deals with Internet user privacy. We focus on the protection of user identity during an Internet service use. We start with an overview of systems for the anonymous channel creation. Such channels are necessary as any solution for the identity protection will have to work with the TCP/IP protocols used in the Internet. In the second part of the paper we argue about the need for an anonymous authentication introduction. Such a service is almost missing in the current Internet. We show how the concept of anonymous authentication could improve privacy and identity protection. Finally we introduce our concept for anonymous authentication with the feature of a malicious user detection.
Data and application security and privacy	
Anonymous services: Enhancing end-user privacy exploiting anonymous networks	The large number of online services poses serious problems to users' privacy. The sole confidentiality of data exchanged is not enough for complete privacy because an external observer may learn sensitive information simply by observing the communication channel, even if it is not possible to access the actual data transmitted. In this position paper, we propose a solution where user privacy is guaranteed by providing anonymous access to the services. Our solution is based on a service gateway, an anonymous credential system, an authentication protocol and an anonymous network. We designed the solution to be cost-effective and scalable; moreover, we employ existing standard protocols whenever possible to facilitate development and deployment.
EnCoRe: Towards a holistic approach to privacy	We make the case for an integrated approach to privacy management within organisations. Current approaches to privacy management are either too high-level, enforcing privacy of personal data using legal compliance, risk and impact assessments, or too low-level, focusing only on the technical implementation of access controls to personal data held by an enterprise. High-level approaches tend to address privacy as an afterthought in ordinary business practice, and involve ad hoc enforcement practices; low-level approaches often leave out important legal and business considerations. As part of the EnCoRe project we are developing a methodology which tries to bridge the gap between privacy risk and impact assessment with the technical management of privacy policies. We are working to define a conceptual model as a means of expressing policy requirements as well as users' privacy preferences and as a way to bridge the gap described above. We aim to show the value of this approach in collaborative case studies (including corporate personnel management, biobanks and assisted living) in the context of the EnCoRe project.
Unlinking database entries: Implementation issues in privacy preserving secure logging	This paper discusses implementation issues related to using relational databases as storage when implementing privacy preserving secure logs. In these types of logs it is important to keep the unlinkability properties of log entries intact when the entries are stored. We briefly describe the concept of privacy preserving secure logging and give the rational for it. The problems of using relational database systems as storage is discussed and we suggest three solutions to the problem. Two of the solutions are analyzed and compared and we show that at least one of the solutions is feasible in a real live setting and that the added overhead of the solution is very small.
A Transatlantic Convergence on Privacy?	Both the European Union and US recently released major reports on privacy. These significant and long-awaited government reports provide new insights into how regulators on both sides of the Atlantic view privacy challenges. They also reveal the extent to which those views are converging.
Nudging Privacy: The Behavioral Economics of Personal Information	Privacy decisions often involve balancing competing interests. As such, they're a natural field of study for economics. But traditional economic models have made overly restrictive assumptions about the stability and nature of individual privacy preferences. Approaches drawing on existing research in behavioral economics and psychology can offer complementary tools for understanding privacy decision making.
Privacy Law Resource for Students and Professionals	A review of Daniel J. Solove and Marc Rotenberg's book, Information Privacy Law.
Complementary Perspectives on Privacy and Security: Economics	Economics and behavioral economics offer different but complementary approaches to understanding privacy and security. This article explains briefly their differences and similarities, and why they matter in our thinking about security and privacy.
Security, Privacy, and Policy Roundup	Our news briefs cover the latest in security, privacy, and policy.
Privacy and Identity Management	Creating and managing individual identities is a central challenge of the digital age. As identity management systems defined here as programs or frameworks that administer the collection, authentication, or use of identity and information linked to identity are implemented in both the public and private sectors, individuals are required to identify themselves with increasing frequency. Traditional identity management systems are run by organizations that control all mechanisms for authentication (establishing confidence in an identity claim's truth) and authorization (deciding what an individual should be allowed to do), as well as any behind-the-scenes profiling or scoring of individuals. Recent work has looked toward more user-centric models that attempt to put individuals in charge of when, where, how, and to whom they disclose their personal information.
Privacy Interests in Prescription Data, Part I: Prescriber Privacy	For several years, concern has been growing about privacy implications that arise from using and disclosing prescription data. Some patterns or practices provide pharmaceutical companies with the historical trends they need to better target their marketing efforts aimed at individual physicians through more intense, precise, and unique detailing strategies. In the first of a two part-article, the authors focus the privacy implications arising from the sale or transfer of prescription data, in respect to prescribers in Canada and the US.
Scrubbing Stubborn Data: An Evaluation of Counter-Forensic Privacy Tools	An evaluation of six privacy tools highlights significant shortfalls in their methods and implementations. It also raises a question: how much privacy protection we can realistically expect given ever-changing environments and the tremendous resources required to test for both known and unknown threats?
IEEE Security & Privacy Table of contents	Presents the table of contents for this issue of this magazine.
Security, Privacy, Policy, and Dependability Roundup	Our news briefs cover the latest in security, privacy, policy, and dependability.
IEEE Security & Privacy masthead	
Privacy, Ethics, and Analytics	When using the analytics process, companies should consider the risks it poses to individuals' information privacy as well as develop responsible measures to accompany its use. This set of ethical standards calls on companies to adopt accountable approaches that reflect the specific risks in a given use of the analytics process.
IEEE Security & Privacy masthead	
The Puzzle of Privacy	A number of recent news stories have made me wonder more about privacy. It's not just that the threats to privacy are increasing; rather, the problem is that the countervailing forces are becoming very much stronger. Was Scott McNealy right when he told us that we had no privacy and that we should just "get over it"?
Privacy-Enabled Global Threat Monitoring	Could the future of Internet-scale collaborative security frameworks ultimately open a new era of fast-reaction Internet defenses, or are these systems destined to provide limited deployment and detection power for unclear liability risks? We think the former is unlikely without significant progress in rich-content extraction that addresses the fundamental vulnerabilities inherent in collaborative data sharing. Cyber-TA brings together an established group of researchers across a broad spectrum to search for practical solutions and enable new ways of threat detection.
RFID privacy: an overview of problems and proposed solutions	As organizations aggressively deploy radio frequency identification systems, activists are increasingly concerned about RFID's potential to invade user privacy. This overview highlights potential threats and how they might be addressed using both technology and public policy.
Inside JetBlue's privacy policy violations	JetBlue Airways (JetBlue) gave five million customers' travel records to a USA Department of Defense contractor. The authors' analysis reveals that JetBlue's privacy policy might pose additional significant threats to customer privacy and that the USA Department of Homeland Security anti-terrorism exercise has adversely affected personal privacy.
Privacy Enhancing Technologies	The sixth annual Workshop on Privacy Enhancing Technologies (PET) was held in Cambridge, England, from 28-30 June 2006.
Security and Privacy Challenges in Cloud Computing Environments	Cloud computing is an evolving paradigm with tremendous momentum, but its unique aspects exacerbate security and privacy challenges. This article explores the roadblocks and solutions to providing a trustworthy cloud computing environment.
International participation. The continuing march toward security and privacy	To create a future with improved prospects for dealing with security and privacy, nations will have to reach agreement on many issues, including Banking and financial services; privacy laws related to sensitive data such as healthcare information; intellectual property (IP) rights, their reasonable protection, and the significant challenge of achieving international agreement on an enforceable set of common standards; cybercrime laws and penalties for breaking them and new networking technologies that adversely impact privacy, the subtleties of which might not be fully appreciated until a product is well entrenched. Many of these issues have been around since the onset of literacy, but the challenge of dealing with them has grown enormously in the information age owing to the speed, storage capacity, intelligence, and ubiquity of modern IT (and its inherent vulnerabilities).
Managing information privacy: developing a context for security and privacy standards convergence	Information privacy is much broader than data security. It's about the collection, processing, use, and protection of personal information. Essentially, business processes, IT systems, and compliance controls must support the full set of requirements embodied in these principles and expressed in relevant laws and policies. Implementation choices, including automation level and security control selection, become business and business-risk decisions. To institute such principles, businesses should understand the critical need for policy-driven security and privacy compliance in developing the right business processes and overall technical architecture
Patient privacy in electronic prescription transfer	In paper-based prescribing in the United Kingdom's National Health Service (NHS), patients are responsible for protecting the privacy of their prescription information while it is in transit from the prescriber to the dispenser. The UK government has introduced a plan for future NHS reform that includes a change from paper-based prescribing to a national electronic transfer of prescriptions (ETP) system. This brings with it concerns for patient data privacy and questions about the burden of trust placed on professionals in the ETP system. As recently seen in the Emilio Calatayud case in the United States, systems that contain an aggregation of identifiable personal information can be abused. A similar case could result from malpractice in an ETP system. We have developed and implemented an ETP system for the UK NHS. We present our system for protecting the privacy of patient data, describe how we implemented it in Java, and discuss how others can use our system for other applications both inside and outside the healthcare sector.
Identity Management, Privacy, and Price Discrimination	In economics, privacy is usually discussed in the context of consumer preferences and price discrimination. But what forms of personal data privacy are compatible with merchants' interests in knowing more about their consumers, and how can identity management systems protect information privacy while enabling personalization and price discrimination?
The security and privacy of smart vehicles	Road safety, traffic management, and driver convenience continue to improve, in large part thanks to appropriate usage of information technology. But this evolution has deep implications for security and privacy, which the research community has overlooked so far.
Exploring privacy issues in Web services discovery/agencies	The increasing discussions concerning Web services privacy often neglect a key building block of the Web services architecture: discovery agencies. This overview of discovery agency privacy issues highlights the various challenges and proposes different technical approaches for addressing them.
Identity as Privacy	The class structure of the future is based not on money but on privacy.
Privacy and rationality in individual decision making	Traditional theory suggests consumers should be able to manage their privacy. Yet, empirical and theoretical research suggests that consumers often lack enough information to make privacy-sensitive decisions and, even with sufficient information, are likely to trade off long-term privacy for short-term benefits
"All the better to see you with, my dear": Facial recognition and privacy in online social networks	Focusing primarily on popular online social networks like Facebook, this article provides an overview of the main social and legal challenges attending the use of facial-recognition technologies on these platforms and explores ways of governing the associated privacy implications, specifically from a European data protection perspective. The authors discuss potential legal, technological, and business model responses to these developments.
Privacy: Front and Center	In the 10 years since IEEE Security &#x0026; Privacy's initial launch, privacy has moved from being a side story occasionally covered in the newspaper to a central issue of our times. With the Internet, through the rise of online social networks, tracking technologies such as cookies and Web beacons, and the sharing of data with third parties, and the government's increasing use of surveillance mechanisms such as closed-circuit television, wiretapping, and location tracking, almost everyone experiences far less privacy than they did just a decade ago. But at the same time, governments and industry are taking much more of an interest in privacy protection than they did when IEEE Security &#x0026; Privacy first appeared, particularly because consumers adopt personalized services in large numbers. In this roundtable, five privacy leaders discuss some recent concerns: Ann Cavoukian, Ontario's privacy commissioner, Alan Davidson, a recent head of Google's US public policy office, Ed Felten, who recently served a term as chief technologist at the US Federal Trade Commission, Marit Hansen, deputy privacy and information commissioner of Land Schleswig-Holstein, Germany, and Anna Slomovic, chief privacy officer at Equifax.
Security & Privacy masthead	
P3P: making privacy policies more useful	The World Wide Web Consortium's Platform for Privacy Preferences (P3P) lets Web sites convey their privacy policies in a computer-readable format. Although not yet widely adopted, P3P promises to make Web site privacy policies more accessible to users.
Privacy is the issue	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01253559.png" border="0">
IEEE Security & Privacy Society Staff	
IEEE Security & Privacy masthead	
Privacy-preserving data mining: why, how, and when	Data mining is under attack from privacy advocates because of a misunderstanding about what it actually is and a valid concern about how it is generally done. This article shows how technology from the security community can change data mining for the better, providing all its benefits while still maintaining privacy.
Valuating privacy	In several experimental auctions, participants put a dollar value on private information before revealing it to a group. An analysis of results show that a trait's desirability in relation to the group played a key role in the amount people demanded to publicize private information. Because people can easily obtain, aggregate, and disperse personal data electronically, privacy is a central concern in the information age. This concern is clear in relation to financial data and genetic information, both of which can lead to identity abuse and discrimination. However, other relatively harmless information can also be abused, including a person's gender, salary, age, marital status, or shopping preferences. What's unclear is whether it's the fear of such abuse that actually causes people's stated hesitance to reveal their data. Our hypothesis - and the motivation for our study - is that people reveal information when they feel that they're somewhat typical or positively atypical compared to the target group. To test this hypothesis, we conducted experiments that elicit the value people place on their private data. We found, with great significance (more than 95 percent statistical confidence) that a linear relationship exists between an individual's belief about a trait and the value he or she places on it. That is, the less desirable the trait, the greater the price a person demands for releasing the information. Furthermore, we found that small deviations in a socially positive direction are associated with a lower asking price.
IEEE Security & Privacy - Front cover	
The NRC Takes on Data Mining, Behavioral Surveillance, and Privacy	In mid 2000, The Wall Street Journal reported that the US Federal Bureau of Investigation (FBI) was developing a tool for wiretapping at an Internet service provider (ISP). Carnivore, later renamed DCS 1000, was built to capture communications content - email,pages, and so forth - or the transactional information in the communications of targeted suspects.
Preserving Privacy Based on Semantic Policy Tools	Different organizations are constantly collecting, analyzing, and storing individuals' private data: shopping sites want to provide better service and recommendations, hospitals to improve healthcare, and government agencies to enable national defense and law enforcement. Sharing data lets these organizations discover important knowledge and draw useful conclusions but raises concerns about information privacy and trust. Until recently, the focus was on restricting access to data on a "need-to-know" basis, but since the 9/11 Commission, the paradigm has shifted to a "need to share." The authors explore the use of semantic privacy policies, justifications for data requests, and automated auditing to encourage sharing of sensitive data between organizations. They describe an architecture based on policy tools that evaluate incoming queries against semantic policies and domain knowledge and provide a justification for each query-why they're permitted, denied, or inapplicable. Using a semantic policy language gives policies explicit semantics that allow all participants to unambiguously understand their meaning. The justifications generated by checking incoming requests against these policies help requesters formulate privacy-aware queries. Reasoning over event logs and justifications allows data owners to verify that their privacy policies are being correctly enforced.
Privacy-Enabled Global Threat Monitoring	The history of intrusion detection research gives a nice example of a community in a perpetual race to stay relevant. While we once focused on detecting user account misuse in mainframes, we then moved on to local area network abuse, and then to address the scalability problems in enterprise-wide detection. With the rise of e-commerce in the late 1990s, we intrusion detection developers have had to react to the emergence of script kiddies and Web defacements. Distributed denial-of-service attacks and wide-scale virus propagation soon followed, as did a new term, malware research, to address the growing concern about viruses and self-replicating worms spreading across the Internet at alarming speeds. More recently, we've had to consider the problem of botnets, which can organize and maintain illicit control of thousands of machines for months at a time to spread spam, conduct phishing attacks, or steal data or computing resources. Over the past decade, intrusion detection research has rarely been boring
Security and Privacy Landscape in Emerging Technologies	Recent events spawned a need for better communications of security systems, including industrial control systems and emergency management systems. This work is in initial phases and the author reports it here. In this final column for emerging standards and technologies, she also discusses the privacy and security challenges of Web 2.0 and globalization.
Logical Methods in Security and Privacy	Computer security and privacy is concerned with the design, implementation, and analysis of mechanisms intended to guarantee that desired policies (or properties) hold in the presence of malicious adversaries. In this article some logical methods for reasoning about system security and for enforcing security and privacy policies are discussed.
Technology and web user data privacy - a survey of risks and countermeasures	The author examines privacy risks to user data in a Web environment and explores the characteristics and roles of technical countermeasures, including mechanized privacy policy representations, pseudonym facilities, access-control methods, and technical methods for constraining data use
IEEE Security & Privacy masthead	
Privacy Concerns	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01193206.png" border="0">
Everything You Wanted to Know about Privacy (But Were Afraid to Ask)	A review of the book, "Privacy: What Developers and IT Professionals Should Know," by J.C. Cannon.
Considering New Privacy Laws in Australia	Like many nations, Australia is currently weighing numerous options regarding privacy legislation. The Australian Law Reform Commission (ALRC) has released a 2,000-page review of Australian privacy law, in which it proposes several changes that would significantly shift the balance between freedom of speech and privacy in Australia because they would extend to the media and private individuals as well as governments and businesses - especially important because Australia has no express right of free speech.
IEEE Security & Privacy masthead	
IEEE Security & Privacy call for papers	Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.
Does the common criteria paradigm have a future? [security and privacy]	In IEEE Security & Privacy's July/August 2003 issue, the author discussed the then upcoming 4th International Common Criteria Conference, which was held in Stockholm in September. Reviewing the CD of the presentations, however, he is left with the strong impression that, while a good idea when promulgated five years ago (after five years' effort by the six founding nations), the CC enterprise might have run out of gas. The proceedings' record and the author's own sampling of discussions on the CC Forum suggest the management structure and process need considerable revamping if the CC is to have a future.
Speech privacy technophobes need not apply	Anyone can download Speak Freely, enable its essentially unbreakable encryption, and then talk telephone-style via the Internet with any other person in the world with a similar installation. The conversation will enjoy complete privacy because every utterance is encrypted on-the-fly before being transmitted. The software costs nothing, and because it is installed locally, it does not go through any vendor's servers (as is the case with much commercial software that offers voice-over-IP, or VoIP, services), which could act as convenient interception points. Users can select the encryption algorithm they like (Blowfish, 128-bit IDEA, DES, or even a concatenation of two or more of these) as well as their encryption keys for each conversation; they could even change encryption during the course of the conversation. Less user-friendly, though comparably effective for voice encryption over the Internet, are other free software packages such as Nautilus (which offers triple DES, IDEA, and Blowfish encryption) and Pretty-Good Privacy (PGP) Voice, both of which are downloadable from numerous sources.
Is privacy really constraining security or is this a red herring?	On the surface, the argument at the heart of the "security vs. privacy" debate is seductively simple: "to prevent terrorism we must empower police to monitor all online activities." However, this claim suffers two fatal logical flaws: it presumes that the proposed fix will solve the problem, and it ignores the proposal's potential for creating even more serious problems than the one it professes to fix. The article considers these aspects.
IEEE Security & Privacy call for papers	Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.
Financial privacy policies and the need for standardization	The authors analyze 40 online privacy policy documents from nine financial institutions to examine their clarity and readability. Their findings show that compliance with the existing legislation and standards is, at best, questionable.
IEEE Security & Privacy	
IEEE Security & Privacy masthead	
IEEE Security and Privacy masthead	
HIPAA's Effect on Web Site Privacy Policies	Healthcare institutions typically post their privacy practices online as privacy policy documents. We conducted a longitudinal study that examines the effects of HIPAA's enactment on a collection of privacy policy documents for a fixed set of organizations over a four-year period. We present our analysis of 24 healthcare privacy policy documents from nine healthcare Web sites, analyzed using goal mining, a content-analysis method that supports extraction of useful information about institutions' privacy practices from documents. We compare our results to our pre-HIPAA study of these same institutions' online privacy practices and evaluate their evolution in the presence of privacy laws
Are You Sure You Had a Privacy Incident?	Whether it's lost laptops, misplaced backup tapes, or data posted to Web sites, data spills have become a fact of life. In the US, state governments and federal agencies have responded with a series of notification rules, which require companies to inform the affected individuals after security incidents. Yet, to determine whether an incident affects individuals' privacy and thus requires notice, organizations must uncover a fairly in-depth set of facts.
The IEEE Symposium on Security and Privacy Is Moving to San Francisco	The authors discuss the IEEE Symposium on Security and Privacy, which because of its growing popularity, is moving to a larger venue this year.
Deconstructing the Privacy Experience	The public dialogue around digital privacy lacks critical focus on elements of user interface design. With the rise of the social Web, attention to user interface design has become even more important in setting expectations of privacy online. This essay suggests designing proactively for the privacy experience.
IEEE Security & Privacy masthead	
The thoughts are free [security and privacy]	Security and privacy are twin social goods that exist in perpetual tension: our society has debated the trade-offs between them ever since the first days of social organization. Over the ages, the border between security and privacy has moved back and forth as first one side and then the other made bold steps forward impelled by events in ideas, economics, technology, and warfare. At present, privacy appears to be in retreat under the threat of terrorism; it seems at times as if we ourselves are destroying the very freedom that terrorists find so threatening. This paper looks at some radical views of privacy's future through the eyes of several influential science-fiction (SF) writers. In The Light of Other Days and The Transparent Society, we see two radical visions of a world in which privacy as we know it has entirely ceased to be. Unlike George Orwell's 1984, in which despotism armed with two-way television eradicates privacy, these books describe privacy falling victim to technological innovation.
Security, Privacy, and Policy Roundup	IEEE Security & Privacy news briefs cover the latest in security, privacy, and policy.
Privacy Interests in Prescription Data, Part 2: Patient Privacy	For several years, concern has been mounting about the privacy implications of using and disclosing prescription data. Several transactions forming part of a growing chain of valuable health information have come under scrutiny, including 1) the sale or transfer of prescription data from pharmacies to commercial data brokers;2) processing of the data to analyze physicians' prescribing patterns; 3)the subsequent sale of these prescribing patterns to pharmaceutical companies, among others, that use this information to customize their marketing strategies aimed at physicians. In part one of this two-part series, we discussed privacy concerns with respect to prescribers. In this second installment, we examine the privacy risks to patients from Canadian and US perspectives.
Biometric recognition: security and privacy concerns	Biometrics offers greater security and convenience than traditional methods of personal recognition. In some applications, biometrics can replace or supplement the existing technology. In others, it is the only viable approach. But how secure is biometrics? And what are the privacy implications?.
Security, Privacy, and Policy Roundup	IEEE Security &amp; Privacy news briefs cover the latest in security, privacy, and policy.
Critical RFID Privacy-Enhancing Technologies	RFID technology can help automatically and remotely identify objects, which raises many security concerns. The authors review and categorize several RFID security and privacy solutions, and conclude that the most promising and low-cost approach currently attracts little academic attention.
Architecture of Privacy	The natural tendencies of the Internet make privacy harder. Technology is the friend of intrusive tools. Digital sensors become smaller and more plentiful. More data is collected and stored every year. Privacy isn't something that occurs naturally online, it must be deliberately architected.
IEEE Security & Privacy masthead	
New strategies for employment? internet skills and online privacy practices during people's job search	How does online know-how relate to people's tendencies to manage their privacy? A survey of a diverse group of young adults' online skills and privacy practices reveals patterns of online privacy management, specifically with job search in mind. Findings suggest that women, Whites, and those with higher Internet privacy skills are more likely to manage their online profiles actively.
Enabling video privacy through computer vision	Closed-circuit television cameras used today for surveillance sometimes enable privacy intrusion. The authors' privacy console manages operator access to different versions of video-derived data according to access-control lists. Additionally, their PrivacyCam is a smart camera that produces a video stream with privacy-intrusive information already removed.
IEEE Security & Privacy masthead	
Privacy vs. information technology	Modern information technology is facilitating the steady disappearance of individual privacy - even under normal circumstances. Add a real or hyped threat to the common good, and the erosion of individual privacy is further accelerated.
Protecting client privacy with trusted computing at the server	Current trusted-computing initiatives usually involve large organizations putting physically secure hardware on user machines, potentially violating user privacy. Yet, it's possible to exploit robust server-side secure hardware to enhance user privacy Two case studies demonstrate using secure coprocessors at the server.
Building Privacy into Software Products and Services	In the marketplace, customer trust is paramount. As consumers increasingly rely on the Internet for shopping, banking, and other daily activities, privacy is both a major public concern and a barrier to e-commerce growth: fear of data breaches and identity theft threaten to erode trust in the Internet. Once the core privacy team (CPT) is built, it can begin to define the program, deploy its processes, and enforce the rules.
Security, Privacy, and the Role of Law	US President Barack Obama promised a "new comprehensive approach" to cybersecurity and guaranteed to preserve "personal privacy and civil liberties," but the administration has stopped short of committing to the legal changes necessary to protect either information infrastructure or privacy. This tendency to undervalue law as a tool for enhancing both security and individual privacy is shared with other governments. Sound cybersecurity policy requires better incentives to secure data and systems, and those incentives will emerge, at least in part, from legal requirements. Similarly, serious efforts to protect against cyberthreats will compromise privacy and other civil rights unless those rights are protected by law.
IEEE Security & Privacy masthead	
IEEE Security and Privacy masthead	
IEEE Security & Privacy masthead	
Privacy-Preserving Sharing of Sensitive Information	Privacy-preserving sharing of sensitive information (PPSSI) is motivated by the increasing need for entities (organizations or individuals) that don't fully trust each other to share sensitive information. Many types of entities need to collect, analyze, and disseminate data rapidly and accurately, without exposing sensitive information to unauthorized or untrusted parties. Although statistical methods have been used to protect data for decades, they aren't foolproof and generally involve a trusted third party. Recently, the security research community has studiedΓÇöand, in a few cases, deployedΓÇötechniques using secure, multiparty function evaluation, encrypted keywords, and private information retrieval. However, few practical tools and technologies provide data privacy, especially when entities have certain common goals and require (or are mandated) some sharing of sensitive information. To this end, PPSSI technology aims to enable sharing information, without exposing more than the minimum necessary to complete a common task.
Setting Boundaries at Borders: Reconciling Laptop Searches and Privacy	If you've traveled internationally on business, the odds are that you've taken your laptop with you. Like most business travelers, you need these ubiquitous devices to do work, make presentations, and communicate with coworkers, family, and friends via the Internet. In a previous department, we explored the notion that laptops deserve special consideration because of the increasingly blurred line between home and office, the entrusting of intimate, private information to storage on laptops, and the resulting need to rethink the rules surrounding reasons-able expectations of privacy. This time, we examine the nexus between laptops, a government's search and seizure powers, and a traveler's transit through an international border checkpoint where customs officials have enhanced powers to search travelers and their belongings
Privacy debate centers on radio frequency identification	The emergence of radio frequency identification (RFID) has brought with it a plethora of privacy concerns and experts are questioning whether the hoopla surrounding RFID is justified. Using RFID should trigger the same privacy concerns as other commonly used technology such as credit cards, cell phones, and the Internet. RFID's potential to revolutionize the retail industry by maximizing suppliers' ability to control inventory and reduce theft is widely recognized. In fact, some technology forecasters predict that RFID tags will eventually replace bar codes on almost all product packaging. The privacy debate centers around RFID tags themselves, which function like tiny radios, wirelessly transmitting information to network receivers. If RFID tags were to remain active even after consumers complete their purchases and exit stores, their wireless technology would let the stores track consumers' movement and behavior; or so goes the argument.
Engineering or sloganeering? the counterattack on privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01193219.png" border="0">
Countering Terrorism through Information and Privacy Protection Technologies	This article describes a vision for countering terrorism through information and privacy-protection technologies. This vision was initially imagined as part of a research and development (R&D) agenda sponsored by DARPA in 2002 in the form of the information awareness office (IAO) and the total information awareness (TIA) program. It includes a critical focus and commitment to delicately balancing national security objectives with privacy and civil liberties. We strongly believe that the two don't conflict and that the ultimate solution lies in utilizing information technologies for counterterrorism along with privacy-protection technologies to safeguard civil liberties, and twining them together with coordinated policies that bind them to their intended use
IEEE Security & Privacy masthead	
RFID privacy workshop	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01281245.png" border="0">
IEEE Security & Privacy masthead	
Two tales of privacy in online social networks	Privacy is one of the friction points that emerge when communications are mediated in online social networks (OSNs). Different communities of computer science researchers have framed the OSN privacy problem as one of surveillance, institutional privacy, or social privacy. In tackling these problems, researchers have also treated them as if they were independent. In this article, the authors argue that the different privacy problems are entangled and that OSN privacy research would benefit from a more holistic approach.
"Oakland" 2012 in San Francisco! [IEEE Symposium on Security and Privacy Symposium and Workshops]	Provides notice of upcoming conference events of interest to practitioners and researchers.
The delicate balance: security and privacy	The article examines the USA Patriot Act; a new push by law enforcement to wiretap voice-over-IP (VoIP) communications; and the need to prevent abuses of technology at the international level. Although the Patriot Act might be good for overall security, it raises serious privacy concerns. It is very one-sided in favoring law enforcement's ability to get information about people, without giving them the opportunity to attempt to protect that information. The act permits using wiretaps without requiring authorities to specify who is being tapped or where the tapping occurs. The Patriot Act likewise opens the door to potential technology abuses, such as providing funding for government database improvements, while offering no protections in terms of how those databases will be used. The article also examines the worldwide state of security by looking at concerns about the dumping and testing of surveillance technologies in countries where civil rights and civil liberties are not an issue.
Are You Sure You Had a Privacy Incident?	Stories about security breach are in the news. Some stories concern "leaks" of companies' sensitive information, the urgency of finding the source (or sources), and the efforts to interdict them or "plug" the leaks. But most published stories involve the loss of control over personal information stored in electronically saved records; they therefore often include whether there has been a privacy compromise. Whether its lost laptops, misplaced backup tapes, or data posted to Web sites, data spills have become a fact of life for all of us. In the US, state governments and federal agencies have responded with a series of notification rules, which require companies to inform the affected individuals after security incidents
Security, Privacy, Policy, and Dependability Roundup	Our news briefs cover the latest in security, privacy, policy, and dependability.
IEEE Security & Privacy masthead	
IEEE Security & Privacy subscribe advertisement	
IEEE Security & Privacy masthead	
Developing a Culture of Privacy: A Case Study	In building a culture of privacy, an organization must clearly articulate privacy as an organizational priority; communicate key privacy and security messages; educate across the organization; raise awareness of the importance of registering privacy incidents and breaches; build privacy into the fabric of the organization's activities; and make privacy information and guidance readily accessible. Accomplishing these objectives provides a framework to create or reinforce a privacy culture. In 2003, the province of Ontario, Canada, created the smart systems for health agency (SSHA) to connect healthcare professionals across the province.
Mobile Devices and Location Privacy: Where Do We Go from Here?	The eruption of concern over mobile device tracking has led to important public debate over location privacy. These cases demonstrate a lack of transparency in mobile systems, with users in the dark about how companies collect and use their location information.
Security and Privacy: Enemies or Allies?	We show ID cards at every juncture. Is this necessary? Is it helpful? Or is it actually harmful, not just to our privacy but to security as well?
Security, Privacy, Policy, and Dependability Roundup	Our news briefs cover the latest in security, privacy, policy, and dependability.
Data Retention and Privacy in Electronic Communications	The retention of communication data by network providers, often mandated by legislation, raises social and technical security concerns. A generic model combining technical, procedural, and legal controls can help secure retained data and minimize privacy threats against users.
Security, privacy, policy, and dependability roundup	These news briefs cover the latest in security, privacy, policy, and dependability.
IEEE Security & Privacy masthead	
IEEE Security & Privacy masthead	
How internet users' privacy concerns have evolved since 2002	Internet privacy was the topic in this paper. A 2008 survey revealed that US Internet users' top three privacy concerns haven't changed since 2002, but privacy-related events might have influenced their level of concern within certain categories. The authors describe their results as well as the differences in privacy concerns between US and international respondents. They also mentioned that individuals have become more concerned about personalization in customized browsing experiences, monitored purchasing patterns, and targeted marketing and research.
The ChoicePoint Dilemma: How Data Brokers Should Handle the Privacy of Personal Information	Before 2005, data broker ChoicePoint suffered fraudulent access to its databases that exposed thousands of customers' personal information. We examine Choice-Point's data breach, explore what went wrong from the perspective of consumers, executives, policy, and IT systems, and offer recommendations for the future.
IEEE Symposium on Security and Privacy House Advertisement	IEEE Symposium on Security and Privacy House Advertisement
Security, Privacy, and Policy Roundup	These news briefs cover the latest in security, privacy, and policy.
What Anyone Can Know: The Privacy Risks of Social Networking Sites	For the Net generation, social networking sites have become the preferred forum for social interactions, from posturing and role playing to simply sounding off. However, because such forums are relatively easy to access, posted content can be reviewed by anyone with an interest in the users' personal information.
Speaking of Privacy	When Plato, quoting Socrates, said "the unexamined life is not worth living," he was talking about self-examination. Today, it seems every life is examined, but more frequently by others than by ourselves.
Security and Privacy Challenges in the Smart Grid	Global electrical grids are verging on the largest technological transformation since the introduction of electricity into the home. The antiquated infrastructure that delivers power to our homes and businesses is being replaced with a collection of digital systems called the smart grid. This grid is the modernization of the existing electrical system that enhances customers' and utilities' ability to monitor, control, and predict energy use.
Society cannot function without privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01203230.png" border="0">
Privacy and the System Life Cycle	Engineering long-lived systems is hard, and adding privacy considerations to such systems makes the work harder.The system life cycle and privacy implications of user-created code are beyond the current state of the art and merit significant attention in their own right. But experienced software engineers know very well that test datasets are generally way too clean and don't exercise the worst of the system.
Countering Terrorism through Information and Privacy Protection Technologies	Security and privacy aren't dichotomous or conflicting concerns--the solution lies in developing and integrating advanced information technologies for counterterrorism along with privacy-protection technologies to safeguard civil liberties. Coordinated policies can help bind the two to their intended use.
IEEE Security & Privacy masthead	
A Shortage of Privacy Engineers	Companies have an urgent need for trained privacy engineers who can hit the ground running. New courses and degree programs are needed to train students for these privacy engineering jobs.
IEEE Security & Privacy 2006 Annual Index, Volume 4	
IEEE Security &amp; Privacy 2006 Editorial Calendar	Provides a listing of upcoming events of interest to practitioners and researchers.
IEEE Security & Privacy 2006 Annual Index, Volume 4	Index of authors of papers and participants in discussions and titles of papers and topics discussed.
Security, Privacy, and Policy Roundup	Our news briefs cover the latest in security, privacy, and policy.
What engineers should know about US security and privacy law	As new technology challenges our assumptions about security and privacy, lawmakers respond by attempting to curb and avoid the most egregious risks to the public. In this article, the authors examine how emerging US security and privacy laws create new requirements that constrain software development affecting business owners and developers who want to design security and privacy into IT systems.
2007 Security & Privacy Annual Index, Volume 5	Index of authors of papers and participants in discussions and titles of papers and topics discussed.
Privacy on the Web: facts, challenges, and solutions	Despite important regulatory and technical efforts aimed at tackling aspects of the problem, privacy violation incidents on the Web continue to hit the headlines. The authors outline the salient issues and proposed solutions, focusing on generic Web user's Web privacy.
Must social networking conflict with privacy?	Online social networks have serious privacy drawbacks, some of which stem from the business model. Must this be? Is the current OSN business model the only viable one? Or can we construct alternatives that are technically and economically feasible?
Privacy and online social networks: can colorless green ideas sleep furiously?	One definition of privacy is the selective revelation of information about oneself. With billions of people using social media, it's increasingly difficult for users to control what they're disclosing and to whom. Current privacy protection measures block leakages via privacy settings that are syntactic in nature, but existing solutions don't attempt to cover all the entities who might end up receiving the data, ensure the need for or use of the data collected, determine the duration of data retention, or reveal if the data is merged with external information to reveal the user's full identity. The title of the article is from linguist Noam Chomsky, who used it to distinguish between syntax and semantics. Virtually all privacy solutions thus far handle issues relating only to the first hop of the personal data flow from a user. The gap can only be filled by examining the semantics behind the multihop flow of user data over time. This article surveys the state of the art and presents some potential directions in moving from a syntactic approach to a more holistic semantics-based approach.
The Price of Privacy	Simply declaring privacy to be a legal right doesn't provide any resources to enforce it. If privacy was an economic transaction, meaning that people pay for it, then their payments would provide resources to protect it. Would we have better privacy if people were paying for it directly rather than trying to get it via political campaigns?
Protecting Personal Privacy: Hauling Down the Jolly Roger	Internet piracy is a growing threat to organizations as their customers become increasingly unwilling to place their personal private information (PPI) at risk for the convenience of electronic transactions. Although this threat isn't severe enough to significantly reduce e-commerce and Internet usage, the threat to PPI does portend a future in which individuals shy away from performing online transactions.
Balancing Privacy and Risk in the E-Messaging World	Messaging within an enterprise used to be like the local water department; as long as the email flowed, no one paid any attention to it and all was good. Things are different now - messaging has become the center of a legal and regulatory maelstrom. It's the confluence of security, privacy, and opportunity within an organization. Email and instant messaging reduce the cost of delivering products, increase responsiveness to customers, enfranchise distance expertise, and evenly balance employee work/home responsibilities. Yet, these very same technologies open the door to intellectual property loss, malware intrusions, employee harassment, and compliance violations.
2006 IAPP Privacy Academy Information	
IEEE Security & Privacy masthead	
Protecting privacy, in continuous location-tracking applications	Although some users might willingly subscribe to location-tracking services, few would be comfortable having their location known in all situations. The authors investigate disclosure-control algorithms that hide users' positions in sensitive areas and withhold path information that indicates which areas they have visited.
Subscription Information for IEEE Security &amp; Privacy	
Privacy recovery with disposable email addresses	Disposable e-mail address (DEA) services are a privacy recovery mechanism for the growing spam problem. However, this problem is clearly more complex than simply closing DEA; as the rolling e-mail address protocols (REAP) system demonstrates, recovery approaches must accommodate different normal states.
Politics, love, and death in a world of no privacy	Is privacy possible in a state in which everyone's interests are visible via their postings&amp;amp;#x2014;and those of their friends&amp;amp;#x2014;on online social networks?
Moving 2 Mishap: M2M's Impact on Privacy and Safety	The rapidly evolving technology of embedded cellular devices has led to weaknesses that attackers could exploit to compromise our privacy and safety.
Sociotechnical architecture for online privacy	Users' concerns regarding privacy issues are lowering their trust in e-services and, thus, affecting the widespread adoption of online services. To increase users' perceived control over their privacy, the authors propose a novel e-privacy architecture.
Privacy-Aware Role-Based Access Control	A privacy-aware role-based access control model extends RBAC to express highly complex privacy-related policies, including consideration of such features as conditions and obligations. Because it's based on the RBAC model, the full-fledged P-RBAC solution is easy to deploy in systems already adopting RBAC, thus allowing seamless integration of access control and privacy policies.
Dialing Privacy and Utility: A Proposed Data-Sharing Framework to Advance Internet Research	The current reluctance to share systems and network data derives from gaps in the law, commercial pressures, and evolving considerations of threat models and ethical behavior. Internet research stakeholders have an opportunity to tip the risk scales in favor of more protected data sharing by proactively implementing appropriate privacy risk management. The privacy-sensitive sharing (PS2) framework integrates privacy-enhancing technologies with a policy framework. The authors evaluate this framework along two primary criteria: how well the policies and techniques address privacy risks, and how well policies and techniques achieve utility objectives. A case study applies the framework to enable network operational data sharing for cybersecurity RD.
Enhancing Privacy Preservation of Anonymous Location Sampling Techniques in Traffic Monitoring Systems	Automotive traffic monitoring belongs to a class of applications that collect aggregate statistics from the location traces of a large number of users. A widely-accepted belief is that anonymization of individual records can address the privacy problem which such aggregate statistics might pose. However, in this paper, we show that data mining techniques, such as clustering, can reconstruct private information from such anonymous traces. To meet this new challenge, we propose enhanced privacy-preserving algorithm to control the release of location traces near origins/destinations and evaluate it using real-world GPS location traces
A Customizable Reputation-based Privacy Assurance System using Active Feedback	People are often required to disclose personal identifying information (PII) in order to achieve their goals, e.g. when accessing services, obtaining information and goods, etc. Being able to say with absolute certainty that another party can be trusted to properly handle personal data with today's technology is probably unrealistic. Feedback solutions based on reputation mechanisms can address aspects of trust and assurance in relation to how personal data is managed by an enterprise. However they usually rely on subjective feedback which is based on empirical experiences, and typically they do not allow individuals to systematically track and manage their specific experience. In this paper we propose an approach that enables people to monitor the status of their personal data which they have previously shared with an enterprise, service provider or other organization - under specific conditions previously negotiated - and actively gather information on how adequately the management of these data meets their personal expectations. Ongoing monitoring and notification, and the ability of the client to form a simple record of past interaction, provides the client with greater confidence and assurance in situations where they need to share personal sensitive information with organizations they would otherwise not be able to claim they trust. This feedback process is based on conditions that are specific to the process of sharing PII and provides the client with assurance that an enterprise is a) capable and b) actually fulfilling PII processing preferences that are agreed at the time the data is disclosed, and which ultimately enables the client to form an opinion about the service provided. We present the principles of our approach and architectural components that support a practical implementation. This is work in progress and the research is on-going, carried out in the context of PRIME
An Identity-based Ring Signature Scheme with Enhanced Privacy	There are many applications in which it is necessary to transmit authenticatable messages while achieving certain privacy goals such as signer ambiguity. The emerging area of vehicular ad-hoc network is a good example application domain with this requirement The ring signature technique that uses an ad-hoc group of signer identities is a widely used method for generating this type of privacy preserving digital signatures. The identity-based cryptographic techniques do not require certificates. The construction of ring signatures using identity-based cryptography allow for privacy preserving digital signatures to be created in application when certificates are not readily available or desirable such as in vehicle area networks. We propose a new designated verifier identity-based ring signature scheme that is secure against full key exposure attacks even for a small group size. This is a general purpose primitive that can be used in many application domains such as ubiquitous computing where signer ambiguity is required in small groups. We consider the usefulness of identity-based cryptographic primitives in vehicular ad-hoc networks and use a specific example application to illustrate the use of identity-based ring signatures as a tool to create privacy preserving authenticatable messages
Implementation of the Privacy Protection in Video Surveillance System	Due to increased terrors and crimes, the use of the video surveillance camera system is increasing. It has been operated for public interest such as prevention of crimes and fly-tipping by the police and local government, but private information such as faces or behavior patterns can be recorded in CCTV. When the recorded video data is exposed, it may cause an invasion to privacy and crimes. This paper analyses conventional methods of privacy protection in surveillance camera systems and applied scrambling and RFID system to existing surveillance systems to prevent privacy exposure in monitoring simultaneously for both privacy protection and surveillance. The proposed system adjusts the intensities of privacy according to access levels to reduce invasion of privacy by people who are not concerned.
Packet Cloaking: Protecting Receiver Privacy Against Traffic Analysis	With widespread use of the Internet, there is an increase in concern over users' privacy. In particular, an adversary may identify the receiver involved in a communication session by observing the packet traffic. We propose a new routing mechanism, which we call packet cloaking, to protect the privacy of a receiver. The main idea of packet cloaking is to transmit multiple copies of a sent packet to a selected group of k receivers, so that an adversary may only identify the true receiver with a probability of j. We present the system design to support packet cloaking. We also propose two metrics that measure the receiver privacy, based on evaluating the similarity between the sender/receiver traffic patterns. We have performed experimental evaluations to verify the effectiveness of our approach.
PEUC-WiN: Privacy Enhancement by User Cooperation in Wireless Networks	Location awareness capabilities of today's wireless networks provide position tailored services but, at the same time, impose serious privacy implications for the wireless users. Interface identifiers allow an adversary to trace a user's movement and location over time in a wireless environment. This causes a significant privacy threat to users, since an adversary could learn a lot of information about them from their locations. Current proposed location privacy mechanisms suffer from a high rate of network disruption and degraded throughput. In this paper, we introduce a new scheme to improve the location privacy of wireless users while minimizing network disruption. The proposed scheme achieves its goals by exploiting the collaboration among users in the same coverage area of an access point in a wireless system.
APRAP: Another privacy preserving RFID authentication protocol	Privacy preserving RFID (Radio Frequency Identification) authentication has been an active research area in recent years. Both forward security and backward security are required to maintain the privacy of a tag, i.e., exposure of a tag's secret key should not reveal the past or future secret keys of the tag. We envisage the need for a formal model for backward security for RFID protocol designs in shared key settings, since the RFID tags are too resource-constrained to support public key settings. However, there has not been much research on backward security for shared key environment since Serge Vaudenay in his Asiacrypt 2007 paper showed that perfect backward security is impossible to achieve without public key settings. We propose a Privacy Preserving RFID Authentication Protocol for shared key environment, APRAP, which minimizes the damage caused by secret key exposure using insulated keys. Even if a tag's secret key is exposed during an authentication session, forward security and 'restricted' backward security of the tag are preserved under our assumptions. The notion of 'restricted' backward security is that the adversary misses the protocol transcripts which are needed to update the compromised secret key. Although our definition does not capture perfect backward security, it is still suitable for effective implementation as the tags are highly mobile in practice. We also provide a formal security model of APRAP. Our scheme is more efficient than previous proposals from the viewpoint of computational requirements.
A Disc-based Approach to Data Summarization and Privacy Preservation	Data summarization has been recognized as a fundamental operation in database systems and data mining with important applications such as data compression and privacy preservation. While the existing methods such as CF-values and DataBubbles may perform reasonably well, they cannot provide any guarantees on the quality of their results. In this paper, we introduce a summarization approach for numerical data based on discs formalizing the notion of quality. Our objective is to find a minimal set of discs, i.e. spheres satisfying a radius and a significance constraint, covering the given dataset. Since the proposed problem is NP-complete, we design two different approximation algorithms. These algorithms have a quality guarantee, but they do not scale well to large databases. However, the machinery from approximation algorithms allows a precise characterization of a further, heuristic algorithm. This heuristic, efficient algorithm exploits multi-dimensional index structures and can be well-integrated with database systems. The experiments show that our heuristic algorithm generates summaries that outperform the state-of-the-art data bubbles in terms of internal measures as well as in terms of external measures when using the data summaries as input for clustering methods
Ensuring document security and privacy in transpromo printing	Transactional printing and fulfillment is an area of the graphic communications industry that requires highly advanced informational assurance and security, not only on a digital level, but also once the information is printed. Financial institutions and other service providers exchange confidential information about individuals and business accounts directly with the printer. If this information were to be compromised, the consequences could be dire. The security issues surrounding transactional printing are even more relevant with the advent of trans-promotional printing, where statement information is combined with variable data promotional materials on printed account statements.Another area of the graphic communications industry that requires a high degree of security is the manufacturing of specialty products such as prepaid phone cards, where the card number and PIN (personal identification number) of the card must be matched and sorted in a database, and then combined on the card with no way of workers duplicating or otherwise pilfering this information. During the prepress process, sensitive information or documents may be transmitted electronically back and forth in a number of forms including raw database files, text information, page layout files, and as proofs. In the case of transactional printing and specialty phone card printing, post-printing security measures are also required. Sophisticated equipment is used to ensure the right statements go to the right people, or that phone cards are sorted and delivered to the right businesses. One security technology that offers the right ratio of security and flexibility to meet the challenges of transpromo printing security is Internet Protocol Security (IPSec). Using IPSec, transpromo printers can effectively protect sensitive client information as it is merged with advertising information prior to the physical printing of the transpromo documents, effectively protecting sensitive client information during - - the initial data merging process. As transpromo process continue to evolve, more research will have to be done to ensure the integrity of data security as transpromo marketing enters the realm of targeted digital distribution.
Addressing privacy constraints for efficient monitoring of network traffic for illicit images	The sexual exploitation of children remains a very serious problem and is rapidly increasing globally through the use of the Internet. This paper focuses on the privacy issues involved in design and implementation of a system capable of image classification at the network layer. In this paper, we examined two learning algorithms, namely the Maximum Likelihood Estimator (MLE), and the Stochastic Learning Weak Estimator (SLWE) as well as six distance measures including the Euclidian Distance (ED), the Weighted Euclidian Distance (WED), and the Cosine Distance (CosD). Our experiments indicate that the SLWE algorithm has slightly better classification accuracy than MLE and as a result the SLWE algorithm combined with a Linear Classifier can be used to actively filter illicit pornographic images as they are transmitted over the network layer.
Identity, privacy and security challenges with Ontario's enhanced driver's licence	This paper examines the development in Ontario of the `enhanced driver's licence' as a passport substitute for entering the US, including the public discussion surrounding it. We discuss the significant security, privacy, and identity risks that outweigh the benefits claimed, and call for more effective public participation in decision making over future ID schemes.
Towards protecting consumer's privacy in Service-Oriented Architecture	There is a tendency to use electronic networks for delivering services. These electronic services can provide several benefits to service consumers, mainly by enabling service providers to offer high quality services. However, they also create many risks to privacy protection as consumers' data may be electronically collected, stored and processed. These risks are related to the possibility of service providers using these data in a manner unacceptable by consumers. The goals of this paper are to identify requirements for a privacy framework for Service-Oriented Architecture and propose a framework, which offers mechanisms that enable service consumers to control how their private data are manipulated and service providers to obtain consumers' acceptance on how their data are going to be handled.
Privacy and security in environmental monitoring systems	There is today an increasing interest in environmental monitoring for a variety of specific applications, with great impact especially on natural resource management and preservation, economy, and people's life and health. Typical uses encompass, for example, Earth observation, meteorology, natural resource monitoring, agricultural and forest monitoring, pollution control, natural disaster observation and prediction, and critical infrastructure monitoring. While on one hand these systems play an important role in our society, on the other hand their adoption can raise a number of security and privacy concerns, representing a possible obstacle for the development of future environmental applications. In this paper, we analyze the security and privacy issues characterizing both the environmental monitoring infrastructures and the data collected and processed by them. We also provide an overview of possible countermeasures for diminishing the effects of these issues.
Enabling fair and privacy-preserving applications using reconciliation protocols on ordered sets	Fair and privacy-preserving reconciliation protocols on ordered sets have been introduced recently. Despite the fact that these protocols promise to have a great impact in a variety of applications, so far their practical use has been explored to a limited extent only. This paper addresses this gap. As main contributions, this paper identifies e-voting, auctions, event scheduling, and policy reconciliation as four far-reaching areas of application and shows how fair and privacy-preserving reconciliation protocols can be used effectively in these contexts.
A location privacy metric for V2X communication systems	The emerging vehicle-to-vehicle/vehicle-to-infrastructure (V2X) communication systems enable a new way of collaboration among the vehicles, the operators of transportation systems, and the service providers. However, many functionalities of V2X systems rely on detailed location information. This raises concerns on location privacy of the users of such systems. Although privacy protection mechanisms have been developed, existing privacy metrics are inappropriate or insufficient to reflect the true underlying privacy values in such systems. Without a proper metric, preserving location privacy in V2X communication systems becomes difficult due to the lack of a benchmark to evaluate any given protection mechanisms. In this paper, we develop a quantitative metric to measure and quantify location privacy in V2X systems. To do so, we introduce the concept of snapshots, which capture the information related to a user in a given space and time. Then the level of location privacy is quantified as the uncertainty of the information related to that user. Our analyses show that the metric provides the users, the system designers, and other stakeholders a valuable tool to evaluate the risk and measure the level of location privacy in V2X communication systems.
Qualitative analysis of differential privacy applied over graph structures	The increase in popularity of online services has generated interest in developing new algorithms to better protect user privacy. Some services defend individual user records by only releasing statistics like the number of users that match certain criteria. If an attacker has access to side information, releasing such summaries can lead to privacy breaches where the records of a certain user are revealed. Differential privacy is a new technique which protects individual user records by altering the released statistics. Many services organize their data as a graph with the edge weights representing statistics. If such services are interested in releasing the information, they must do so in a privacy-preserving manner. We analyze how differential privacy can be used to protect such graph structures. We assess the quality of the released data in relation to the Dijkstra shortest path algorithm. Finally, we propose research directions to improve the performance of the released data.
Session 1: Network security and privacy (NS)	
The trusted driver approach to privacy in TDP road pricing schemes	A collection of slides from author's conference presentation is given. Road congestion is a growing problem. It could be relieved by "time, distance, place" (TDP) road pricing across the entire road network. Concern about driver privacy is a significant issue for public acceptance. UK Department for Transport Demonstrations Project trial the TDP. Technology Strategy Board funds a parallel "innovation platform" program to develop key technologies.
Issues of privacy and electronic personhood in robotics	The sector of robotics develops rapidly at the moment. Law is not already prepared for the aspects coming with this new technology. This regards not only to research and development but also to application and use of this systems. Some legal areas like liability or admission are already debated at the moment. In this paper other crucial problems like privacy or legal status will be discussed. Issues of privacy regarding legal sources, basic principles and privacy in research and development will be focused on. Moreover, the use and application of robots will be analyzed. Additionally it concentrates on the status of robots and electronic personhood. Actions of software agents will be evaluated legally and the concept of electronic personhood will be introduced.
Towards a robust privacy and anonymity preserving architecture for ubiquitous computing	Anonymous authentication is a means of authorizing a user without revealing his/her identification. Mobile technologies such as radiofrequency identification (RFID) tags, PDAs and mobile phone systems are increasingly being deployed in pervasive computing. These mobile devices have raised public concern regarding violation of privacy, anonymity and information confidentiality. Considering these concerns, there is a growing need to discover and develop techniques and methods to overcome the threats described above. In this paper we propose an architecture which enhances the privacy and anonymity of users in ubiquitous computing and yet preserves the security requirements of the system. Our proposed architecture is based on elliptic curve techniques, on MaptoCurve or MapToPoint function, on Weil pairing techniques and finally on elliptic curve based Okamoto identification scheme. In addition, we present a formal validation of our protocol by using the AVISPA tool. The main comparative study of our proposed architecture is to provide privacy and anonymity for mobile users. Our proposed architecture achieves many of desirable security requirements.
Managing and accessing data in the cloud: Privacy risks and approaches	Ensuring proper privacy and protection of the information stored, communicated, processed, and disseminated in the cloud as well as of the users accessing such an information is one of the grand challenges of our modern society. As a matter of fact, the advancements in the Information Technology and the diffusion of novel paradigms such as data outsourcing and cloud computing, while allowing users and companies to easily access high quality applications and services, introduce novel privacy risks of improper information disclosure and dissemination. In this paper, we will characterize different aspects of the privacy problem in emerging scenarios. We will illustrate risks, solutions, and open problems related to ensuring privacy of users accessing services or resources in the cloud, sensitive information stored at external parties, and accesses to such an information.
Privacy-by-design based on quantitative threat modeling	While the general concept of ΓÇ£Privacy-by-Design (PbD)ΓÇ¥ is increasingly a popular one, there is considerable paucity of either rigorous or quantitative underpinnings supporting PbD. Drawing upon privacy-aware modeling techniques, this paper proposes a quantitative threat modeling methodology (QTMM) that can be used to draw objective conclusions about different privacy-related attacks that might compromise a service. The proposed QTMM has been empirically validated in the context of the EU project ABC4Trust, where the end-users actually elicited security and privacy requirements of the so-called privacy-Attribute Based Credentials (privacy-ABCs) in a real-world scenario. Our overall objective, is to provide architects of privacy-respecting systems with a set of quantitative and automated tools to help decide across functional system requirements and the corresponding trade-offs (security, privacy and economic), that should be taken into account before the actual deployment of their services.
Security of privacy-preserving RFID systems	In this paper, we study systems where a reader wants to authenticate and identify legitimate RFID tags. Such system needs thus to be correct (legitimate tags are accepted) and sound (fake tags are rejected). Moreover, an RFID tag in a privacy-preserving system should be anonymous and untraceable, except for the legitimate reader. We here present the first security model for RFID authentication/identification privacy-preserving systems which is at the same time complete and easy to use. Our correctness property permits to take into account active adversaries. Our soundness property incorporates the case of adversaries realizing relay attacks. Finally, our privacy model includes adversaries with no restrictions on their interactions with the system and moreover takes into account the case of "future correlations".
RFID EPC-Gen2 for postal applications: A security and privacy survey	Security and privacy on low-cost RFID deployments is focusing the attention of researchers due to the progressive adoption by retailers, making the RFID a real ubiquitous technology. Besides the retail sector, other logistics industries are starting to improve their processes with this technology like the postal companies, supposed to be one of the largest RFID sector. This paper is focused on the postal model of EPC RFID technology, and its security and privacy implications. We define a postal RFID threat context and propose measures to improve security and privacy in current RFID deployments.
Random modulation privacy for RFID channels	These instructions give you guidelines for preparing papers for IEEE conferences Use this document as a template if you are using Microsoft Word 6.0 or later. Otherwise, use this document as an instruction set. Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a "template" to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website. Do not delete the blank line immediately above the abstract; it sets the footnote at the bottom of this column.
A cross layer approach to preserve privacy in RFID ISO/IEC 15693 systems	This paper presents an implementation of a cross layer approach to preserve privacy in the ΓÇ£Internet of ThingsΓÇ¥ based on RFID and especially ISO/IEC 15693 standard, preventing from threats like eavesdropping, skimming or tracking of tags. We merge a solution at physical layer with a noisy reader which secures the communication from tag to reader, with a simple challenge-response protocol implemented with a lightweight symmetric block cipher PRESENT requiring only 1570 gates. The use of unique identifier has been safeguarded to ensure backward compatibility and a simple ownership transfer giving back to the user a full control on his tags. Backward and forward privacy are always preserved whereas after sale services and electronic warranties remain possible.
MedAssist - A privacy preserving application using RFID tags	Privacy is an important aspect in the Internet of Things (IoT). We see the provision of privacy preserving mechanisms as one enabler for this technology (above all because of the public acceptance). Privacy means, that a user has control over the access to its data. In this work we want to present a medical application which uses passive RFID tags on pharmaceuticals to provide special services for the user. We consider this information as sensible and developed a system where the user has the full control over the access to this data. For our protocol we use standardized cryptographic primitives which are suitable for passive RFID technology. Our protocol provides data privacy as well as transfer of ownership.
Privacy protection for RFID-based tracking systems	RFID technology is increasingly being deployed in ubiquitous computing environments for object tracking and localization. Existing tracking architecture usually assumes the use of a trusted server which is invulnerable to compromise by internal and external adversaries. However, maintaining such a trusted server is unlikely in the real world. In this paper, we consider the problem of adding privacy protection to object tracking systems built upon passive RFID tags, without relying on a trusted server assumption. Our protocol continues to protect user privacy in the event of partial compromise of a server.
Privacy-preserving clone detection for RFID-enabled supply chains	Counterfeit products cause financial losses and represent a health risk. Within RFID-enabled supply chains, where products are equipped with RFID tags, clone detection mechanisms based on tag traces can help in detecting counterfeits. These mechanisms assume that supply chain partners share (private) information to run trace analysis, and may suffer from supply chain dynamics, tag misreads, product recalls, and misdeliveries. In this work, we present a novel, effective, privacy-preserving clone detection mechanism for RFID-enabled supply chains. Our mechanism does not rely on global knowledge of supply chain structures or products flow, it is robust to recalls and misdeliveries, and considers tag misreads while evaluating the presence of counterfeits. We propose privacy-preserving implementations of our mechanism that show better performance when compared to similar implementations based on existing secure multi-party computation frameworks.
Preserving RFID data privacy	Radio frequency identification (RFID), a technology for automatic object identification, has wide applications in many areas including manufacturing, healthcare, and transportation. Yet, the uniquely identifiable objects pose a privacy threat to individuals carrying the objects. Most previous work on privacy-preserving RFID technology, such as EPC re-encryption and killing tags, focused on the threats caused by the physical RFID tags in the data collection phase, but these techniques cannot address the privacy threats in the data publishing phase, when a large volume of RFID data is released to a third party. In this paper, we study the privacy threats caused by publishing RFID data. Even if the explicit identifying information, such as name and social security number, has been removed from the published RFID data, an adversary may identify a target victim's record or infer her sensitive value by matching a priori known visited locations and timestamps. RFID data by default is high-dimensional, so applying traditional anonymity model to RFID data suffers from the curse of high dimensionality, and would result in poor data usefulness. We define a new privacy model, develop an anonymization algorithm to address the special challenges on RFID data, and evaluate its performance in terms of data quality and efficiency.
An Efficient and Flexible Way to Protect Privacy in RFID Environment with Licenses	To release the tension between the convenience and the privacy risk brought by RFID systems, organizations are requested to disclose their policies about RFID activities, to obtain a customer's consent, and to adopt appropriate mechanisms to enforce the policies. However, current researches on RFID typically focus on the enforcement part - to protect personal data stored in RFID tags and to prevent organizations from tracking a person through the information emitted by specified RFID tags. There is a missing piece for customers to achieve agreements with organizations efficiently and to limit organizations' RFID activities flexibly. This paper proposes a new technical and legal approach for responding to concerns about the privacy of personal data in RFID systems by extending the framework of online personal data licensing (OPDL) and applying the framework to RFID environment. In our proposed approach, organizations must obtain licenses before collecting a person's data via RFID technologies. The digitalized and standard licenses can further be checked automatically to ensure that the collection and use of a person's data is strictly under the person's consent. While individuals can control who have licenses and the content of the licenses easily, the framework can hopefully provide an efficient and flexible way to overcome the deficiency of current privacy protection technologies for RFID system.
Embedded RFID and Everyday Things: A Case Study of the Security and Privacy Risks of the U.S. e-Passport	New applications for Radio Frequency Identification (RFID) technology include embedding transponders in everyday things used by individuals, such as books, payment cards, and personal identification. While RFID technology has existed for decades, these new applications carry with them substantial new privacy and security risks for individuals. These risks arise due to a combination of aspects involved in these applications: (1) The transponders are permanently embedded in objects individuals commonly carry with them (2) Static data linkable to an individual is stored on these transponders (3) The objects these transponders are embedded in are used in public places where individuals have limited control over who can access data on the transponder. In 2002, the U.S. Department of State proposed the adoption of an "electronic passport," which embedded RFID transponders into U.S. passports for identification and document security purposes. In this paper, we use the U.S. Government's adoption process for the electronic passport as a case study for identifying the privacy and security risks that arise by embedding RFID technology in "everyday things." We discuss the reasons why the Department of State did not adequately identify and address these privacy and security risks, even after the government's process mandated a privacy impact assessment. We conclude with recommendations to assist government as well as industry in early identification and resolution of relevant risks posed by RFID technology embedded in everyday things.
RFID and Privacy	There is a lot of discussion about RFID and its possible influence on privacy. Many publications concerning this subject only concerned about the technical aspects and consequently see possible solutions in encryption techniques or physical limitations of the air interface. Others see legal restrictions as final solution. It seems necessary to come to a more general approach that includes and structures all human related aspects of this new technology and its possible applications. Beside technical and legal aspects also ethical, political, cultural and economic aspects are considered within this essay.
Data-on-Tag: An Approach to Privacy friendly Usage of RFID Technologies	The proliferation of RFID technology in many application areas has caused serious concerns regarding threats to consumer privacy. To a large extent, this is due to the widespread approach of storing RFID-based data via a global network (Data-on- Network), enabling its linkage and analysis. Based on a description of existing privacy threats and a presentation of the two general storage approaches, we argue that privacy concerns can be narrowed down by exclusively storing data on RFID tags (Data-on-Tag). We support this assumption by presenting advantages for consumers as well as for companies and describe some novel application areas emerging from tag-centric approaches
RFID Usage in Retail beyond the Point of Sale - Temporary Deactivation as a Solution for Challenges in Privacy and Security	For a couple of years, major retailers across the world have been integrating RFID applications in their supply chain. The anticipated benefits of RFID usage in retail, however, range much further - beyond the point of sale and into the customer├é┬┐s home. Frequently-cited visions picture fully-automated homes where the microwave oven picks the correct power level by itself and the washing machine autonomously detects the program best suited for the laundry it contains. So far, there are no deployments on a grand scale of RFID technologies beyond the point of sale, primarily due to the cost of transponders. As long as a single RFID tag costs 5├é┬ó and more, attaching one to each item in a retail store does not pay off. Improved production processes and the general trend of decreasing prices for integrated circuits might soon render such scenarios economically feasible, though.
Standards, Security & Privacy Issues about Radio Frequency Identification (RFID)	There is no doubt that managing the flow of goods depends on monitoring the real flow in the physical world meanwhile in the digital world. Today automatic identification (auto-ID) technologies are used to close the gap between these two different environments by online updating of databases as the materials flow in the chain. From this point of view, it can be said that auto-ID technologies are core components of automated inventory control systems on all echelons of supply chain. As being a novel subcomponent of auto-ID, RFID innovates important features. Due to the fact that RFID is a recently developed technology, there exist some deficiencies, like the lack of standardization and the lack of legislation regulations that cause questions about privacy and security in society. In this study, we reviewed the standardization studies of related organizations like EPC global and ISO and compare these regulations. We also classify the risks that threaten the privacy of individuals and organizations. Finally, regarding the standardization studies and existing risks towards the privacy of individuals and organizations, security proposals and policy suggestions are introduced.
Smart grid security resiliency and privacy	Start of the above-titled section of the conference proceedings record.
Privacy preserving association rule mining	The current trend in the application space towards systems of loosely coupled and dynamically bound components that enables just-in-time integration jeopardizes the security of information that is shared between the broker, the requester, and the provider at runtime. In particular, new advances in data mining and knowledge discovery that allow for the extraction of hidden knowledge in an enormous amount of data, impose new threats on the seamless integration of information. We consider the problem of building privacy preserving algorithms for one category of data mining techniques, association rule mining. We introduce new metrics in order to demonstrate how security issues can be taken into consideration in the general framework of association rule mining, and we show that the complexity of the new heuristics is similar to that of the original algorithms
Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy	The following topics were dealt with: security and privacy research; formal modelling of cryptographic protocols; information flow; secure systems composition; secure DBMS; cryptographic engineering; distributed systems security; and access control
Proceedings of IEEE Symposium on Research in Security and Privacy	The following topics are dealt with: viruses and intrusion detection; causality and integrity; authentication protocols; timing channels; information flow, database security; cryptographic protocols; distributed systems; covert channels; security models; and concurrency control
Proceedings. 1992 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.92CH3157-5)	Presents the front cover from the Proceedings, 1992 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.92CH3157-5).
Proceedings. 1991 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.91CH2986-8)	The following topics are dealt with: covert channels; models; distributed systems; protocol verification; security policy; authentication; database security; intrusion detection; and information theory
Proceedings. 1990 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.90CH2884-5)	The following topics were dealt with: secure systems; database systems; information flow; access control and integrity; authentication; auditing and intrusion detection; verification; and facing the challenges of the 1990s
Information privacy issues for the 1990s	Information privacy deals with protecting individuals against potential violations of their rights due to collection, storage, and use of personal information by the government and private sector organizations. The privacy protection laws enacted in the 1970s are inadequate and limited in scope. New applications of computer-communications technology involving personal information are now emerging for the decade of the 1990s and create new potentials for privacy violations. The basics of privacy protection, examples of the new technologies, and the need for new privacy laws are discussed
A decision tree based quasi-identifier perturbation technique for preserving privacy in data mining	Classification is an important issue in data mining, and decision tree is one of the most popular techniques for classification analysis. Some data sources contain private personal information that people are unwilling to reveal. The disclosure of person-specific data is possible to endanger thousands of people, and therefore the dataset should be protected before it is released for mining. However, techniques to hide private information usually modify the original dataset without considering influences on the prediction accuracy of a classification model. In this paper, we propose an algorithm to protect personal privacy for classification model based on decision tree. Our goal is to hide all person-specific information with minimized data perturbation. Furthermore, the prediction capability of the decision tree classifier can be maintained. As demonstrated in the experiments, the proposed algorithm can successfully hide private information with fewer disturbances of the classifier.
Privacy models for protecting personal medical information: A preliminary study	Information privacy is regarded as the most important subject matter, especially in a paperless-based environment for hospitals which have adopted the Hospital Information System (HIS). A comprehensive model on securing the information privacy is therefore needed as a guideline for internal system designers and developers in order to ensure the efficiency and the effectiveness of the system. Several useful models were suggested from previous studies but still need to be evaluated by relevant experts. This paper proposes a set of model which focuses in protecting personal medical information stored in an electronic medical record system. A preliminary study has been conducted by interviewing selective experts in related field. Hence, the findings shall enlist several useful models that are necessary for the development of a personal medical information system that is capable in preserving individual's privacy.
Privacy measures awareness, privacy setting use and information privacy concern with Social Networking Sites	Using cross-sectional survey approach, this research investigated privacy measures awareness, privacy setting use and information privacy concern with Social Networking Sites (SNS). The targeted respondents were International Islamic University Malaysia (IIUM) undergraduate students. A total of 413 questionnaires were distributed. A total number of 345 respondents returned the questionnaires and 340 were used for analysis. There is evidence to suggest that those who are aware of the existence of privacy measures in SNS will use them to protect their privacy. Further, there is a significant difference in information privacy concern between those who use privacy setting measures in SNS and those who do not.
Analyzing Website privacy requirements using a privacy goal taxonomy	Privacy has recently become a prominent issue in the context of electronic commerce websites. Increasingly, Privacy policies posted on such websites are receiving considerable attention from the government and consumers. We have used goal-mining, to extract pre-requirements goals from post-requirements text artifacts, as a technique for analyzing privacy policies. The identified goals are useful for analyzing implicit internal conflicts within privacy policies and conflicts with the corresponding websites and their manner of operation. These goals can be used to reconstruct the implicit requirements met by the privacy policies. This paper interrelates privacy policy and requirements for websites; it introduces a privacy goal taxonomy and reports the analysis of 23 Internet privacy policies for companies in three health care industries: pharmaceutical, health insurance and online drugstores. The evaluated taxonomy provides a valuable framework for requirements engineering practitioners, policy makers and regulatory bodies, and also benefits website users.
The hidden meta-requirements of security and privacy	When collecting requirements for software, designers may learn of needs for specific forms of protection to be present. These needs may be translated into requirements for encryption or authentication, but what about the non-obvious aspects of security - including privacy, auditability and assurance - that are usually overlooked in the requirements capture process? When we overlook these issues, we get software that doesn't deserve our trust. In this paper, I discuss some of the aspects of security that are regularly overlooked by designers and suggest some standard questions that should be addressed in every design
The role of policy and stakeholder privacy values in requirements engineering	Diverse uses of information technology (IT) in organizations affect privacy. Developers of electronic commerce, database management, security mechanisms, telecommunication and collaborative systems should be aware of these effects and acknowledge the need for early privacy planning during the requirements definition activity. Public concerns about the collection of personal information by consumer-based Web sites have led most organizations running such sites to establish and publish privacy policies. However, these policies often fail to align with prevalent societal values on one hand and the operational functioning of Web-based applications on the other. Assuming that such misalignments stem from imperfect appreciation of consequences and not an intent to deceive, we discuss concepts, tools and techniques to help requirements engineers and IT policy makers bring policies and system requirements into better alignment. Our objective is to encourage RE researchers and practitioners to adopt a more holistic view of application and system specification, in which a system or application is seen as an engine of policy enforcement and values attainment
Security and privacy requirements analysis within a social setting	Security issues for software systems ultimately concern relationships among social actors stakeholders, system users, potential attackers - and the software acting on their behalf. We propose a methodological framework for dealing with security and privacy requirements based on i*, an agent-oriented requirements modeling language. The framework supports a set of analysis techniques. In particular, attacker analysis helps identify potential system abusers and their malicious intents. Dependency vulnerability analysis helps detect vulnerabilities in terms of organizational relationships among stakeholders. Countermeasure analysis supports the dynamic decision-making process of defensive system players in addressing vulnerabilities and threats. Finally, access control analysis bridges the gap between security requirement models and security implementation models. The framework is illustrated with an example involving security and privacy concerns in the design of agent-based health information systems. In addition, we discuss model evaluation techniques, including qualitative goal model analysis and property verification techniques based on model checking.
Privacy arguments: Analysing selective disclosure requirements for mobile applications	Privacy requirements for mobile applications offer a distinct set of challenges for requirements engineering. First, they are highly dynamic, changing over time and locations, and across the different roles of agents involved and the kinds of information that may be disclosed. Second, although some general privacy requirements can be elicited a priori, users often refine them at runtime as they interact with the system and its environment. Selectively disclosing information to appropriate agents is therefore a key privacy management challenge, requiring carefully formulated privacy requirements amenable to systematic reasoning. In this paper, we introduce privacy arguments as a means of analysing privacy requirements in general and selective disclosure requirements (that are both content- and context-sensitive) in particular. Privacy arguments allow individual users to express personal preferences, which are then used to reason about privacy for each user under different contexts. At runtime, these arguments provide a way to reason about requirements satisfaction and diagnosis. Our proposed approach is demonstrated and evaluated using the privacy requirements of BuddyTracker, a mobile application we developed as part of our overall research programme.
A Requirements-based Comparison of Privacy Taxonomies	Understanding the nature of privacy regulation is a challenge that requirements engineers face when building software systems in financial, healthcare, government, or other sensitive industries. Requirements engineers have begun to model privacy requirements based on taxonomic classifications of privacy. Independently, legal research has modeled privacy harms in a taxonomic fashion. In this paper, we compare a requirements engineering taxonomy of privacy protections and vulnerabilities to a legal taxonomy of privacy harms. We seek to determine the extent to which the concepts and terminology are consistent between the two taxonomies. A consistent, standard vocabulary for privacy concepts for both requirements engineers and lawyers will improve the common understanding of privacy concepts, legal traceability and compliance auditing. We conclude that the taxonomies we analyzed are reasonably compatible. We believe this compatibility indicates that a taxonomic understanding of privacy is a promising area of research for requirements engineers.
Assessing identification of compliance requirements from privacy policies	In the United States, organizations can be held liable by the Federal Trade Commission for the statements they make in their privacy policies. Thus, organizations must include their privacy policies as a source of requirements in order to build systems that are policy-compliant. In this paper, we describe an empirical user study in which we measure the ability of requirements engineers to effectively extract compliance requirements from a privacy policy using one of three analysis approaches-CPR (commitment, privilege, and right) analysis, goal-based analysis, and non-method-assisted (control) analysis. The results of these three approaches were then compared to an expert-produced set of expected compliance requirements. The requirements extracted by the CPR subjects reflected a higher percentage of requirements that were expected compliance requirements as well as a higher percentage of the total expected compliance requirements. In contrast, the goal-based and control subjects produced a higher number of synthesized requirements, or requirements not directly derived from the policy than the CPR subjects. This larger number of synthesized requirements may be attributed to the fact that these two subject groups employed more inquiry-driven approaches than the CPR subjects who relied primarily on focused and direct extraction of compliance requirements.
Privacy Risk Assessment in Privacy Requirements Engineering	In spite of the overlap between privacy requirements engineering and security requirements engineering, each addresses a different set of problems. As a result, security risk assessment techniques used in security requirements engineering may be unsuitable to assess privacy risks. This paper proposes considering security risk assessment along with privacy impact and risk assessment approaches using the Security Quality Requirements Engineering (SQUARE) method. The study focuses on PIA and HIPAA as privacy risk assessment techniques.
An Entity-Centric Approach for Privacy and Identity Management in Cloud Computing	Entities (e.g., users, services) have to authenticate themselves to service providers (SPs) in order to use their services. An entity provides personally identifiable information (PII) that uniquely identifies it to an SP. In the traditional application-centric Identity Management (IDM) model, each application keeps trace of identities of the entities that use it. In cloud computing, entities may have multiple accounts associated with different SPs, or one SP. Sharing PIIs of the same entity across services along with associated attributes can lead to mapping of PIIs to the entity. We propose an entity-centric approach for IDM in the cloud. The approach is based on: (1) active bundles-each including a payload of PII, privacy policies and a virtual machine that enforces the policies and uses a set of protection mechanisms to protect themselves, (2) anonymous identification to mediate interactions between the entity and cloud services using entity's privacy policies. The main characteristics of the approach are: it is independent of third party, gives minimum information to the SP and provides ability to use identity data on untrusted hosts.
PrEServD - Privacy Ensured Service Discovery in Mobile Peer-to-Peer Networks	In mobile peer-to-peer networks, proposed service discovery protocols disregard the exposure of the participating peers' privacy details (privileged information). In these methods, the participating peers must provide their identities during the service discovery process to be authorized to utilize services. However, a peer may not be willing to reveal its privileged information until it identifies the service providing peer. So these peers face a problem, should the service requesting or the service providing peer reveal the identity first. The protocol presented in solves this problem to some extent and discover the services available in the service requester's vicinity in a single-hop time sync peers only. In this paper, we propose a privacy-preserving model based on challenged/response idea to discover the services available in the mobile peer-to-peer network even when the moving service requester and the service provider are at a multi-hop distance away. The performance studies shows that our protocol does preserve the privacy in a communication efficient way with reduced false positives in comparison to one other recently proposed protocol.
PEQ: A Privacy-Preserving Scheme for Exact Query Evaluation in Distributed Sensor Data Networks	Evaluating queries in distributed sensor networks while preserving privacy of data is a challenging problem. In this paper, we propose a new scheme for evaluating almost all types of queries, including sum, min/max, mean, median and histogram, accurately while, at the same time, preserving privacy of individual data. Our scheme does not require sensor nodes to share secret keys with each other. Further, it does not use encryption and secure hashing, both of which can be expensive operations.
Privacy and Data Protection	This chapter contains sections titled: Public Policy Objectives, Types of Code Regulation, Institutional Political Economy, Outcomes
An efficient approach for data privacy in distributed environment using Nearest Neighbor Search Anonymization	Data mining is a technique for identifying patterns and trends from large collection of data. The collected data may contain personal information which may violate the privacy of individuals, which makes data mining a critical issue. Techniques available on hand in the field of privacy preserving data mining work well for relational data with fixed-schema, and low dimensionality. In this paper, an anonymization method for sparse high-dimensional transactional data is proposed. An anonymized group formation strategy is used which relies on efficient Nearest-Neighbor (NN) Search in high dimensional spaces. The problem of high dimensionality is addressed by anonymizing each group of transaction according to relevant Quasi Identifiers (QID). The privacy requirement is fulfilled by partitioning the transactional dataset into disjoint sets of transactions, referred as anonymized groups. These groups contain QIDs and the frequencies of sensitive items. The proposed NN search algorithm maximizes the quality of each individual group and can be used for sparse high-dimensional data. On the other hand, the number of groups formed is proportional to number of sensitive item, which paves way for inference attack. Hence to overcome this problem, anonymization can be integrated with anatomization, where the same data can be published as two distinct tables, the quasi identifier table and the sensitive table. This enhancement would prevent inference attack, which is the major drawback of NN search algorithm.
Cloud intelligent track - Risk analysis and privacy data management in the cloud computing	Cloud computing is a computing platform with the backbone of internet to store, access the data and application which is in the cloud, not in the computer. The biggest issue which should be addressed in cloud computing are security and privacy. Outsourcing data to other companies worries internet clients to think about the privacy data. Most Enterprise executives hesitate to use cloud computing system due to their sensitive enterprise information. This paper provides data integrity and user privacy through cloud intelligent track system. This paper discuss about the previous experiment done on the privacy and data management. The work proposes the Architecture or system which provides intelligent track in Privacy Manager and Risk Manager to address privacy issues which rules the cloud environment.
Secured Identity Based Routing and privacy preservation in Wireless Mesh Networks	Wireless Mesh Networks (WMNs) have been expected to be the ultimate solution for the next decade wireless networking. The attractions of WMNs include easy set-up on the fly, off-the-shelf cost, flexible interoperability with other networks, and highly reliable connectivity. One main challenge in the design of these networks is their vulnerability to security attacks. The attacker will possibly be able to identify an ongoing communication session between any two network users by analyzing the network traffic pattern without knowing the user's identity information. To address these security risks, we propose a Secured Identity Based Routing (SIBR) scheme in which every node is assigned with the security cards for efficient authentication. The major goal of the proposed system is to reduce the number of levels at which an attack can take place by providing anonymity in routing. Our implementation results show that the proposed scheme increases the overall performance of the network substantially. Such a routing scheme enhances the privacy preservation of the end users. Our approach also protects against performance degradation even in the presence of malicious behavior.
Secure privacy and distributed group authentication for VANET	Vehicular Ad Hoc Network (VANET) has evolved to complement Intelligent Transportation System (ITS) for communicating safety messages while driving on the road and it faces challenges such as certificate management and privacy preservation. In this paper, a distributed authentication scheme called as Group Authentication Protocol (GAP) is proposed to resolve the most conflicting security requirements such as group authentication and conditional privacy. GAP uses session based pseudonym to support anonymous communication. The proposed batch verification scheme as a part of the protocol poses a significant reduction in the message delay. Furthermore, it enables the vehicles to verify a large number of messages in the case of high vehicular density and also improves message loss ratio. Trusted third party called Trusted Authority has the complete control of tracing the vehicles both benign and misbehaving vehicles.
A hybrid data anonymization integrated with suppression for preserving privacy in mining multi party data	In recent years of data mining applications, an effective technique to preserve privacy is to anonymize the dataset that include private information before being released for mining. Inorder to anonymize the dataset, manipulate its content so that the records adhere to k-anonymity. Two common manipulation techniques used to achieve k-anonymity of a dataset are generalization and suppression. However, generalization presents a major drawback as it requires a manually generated domain hierarchy taxonomy for every quasi identifier in the dataset on which k-anonymity has to be performed. In this paper, new method for achieving k-anonymity (based on suppression) called `kactus' is proposed. In this method, efficient multi-dimensional suppression is performed, i.e., values are suppressed only on certain records depending on other attribute values, without the need for manually-produced domain hierarchy trees. Thus, this method identify attributes that have less influence on the classification of the data records and suppress them if needed in order to comply with k-anonymity. The method was evaluated on several datasets to evaluate its accuracy as compared to other k-anonymity based methods. Anonymisation can be integrated with perturbation for privacy preservation in a multiparty environment.
Unconditional security based privacy protected user communication in Wireless Mesh Networks	Wireless communication has become prominent due to its ubiquitous computing. Addressing privacy enhanced security mechanism in Wireless Mesh Networks (WMNs) is a challenging task. Classical solution to address the foresaid issue offers conditional security, which does not guarantee secure routing mechanism as it can be broken by quantum computing. In this paper, a new method is proposed which integrates quantum principles in wireless communication. Quantum Key Distribution Protocols (QKDPs) like BB84 and B92 are employed in order to establish secret key among network users, which affords unconditional security. Better security and anonymity is ensured with the use of quantum digital signatures together with pseudonym. Hence proposed protocol achieves secure privacy enhanced quantum wireless communications and also it is feasible with current technology.
TelosCAM: Identifying Burglar through Networked Sensor-Camera Mates with Privacy Protection	We present TelosCAM, a networking system that integrates wireless module nodes (such as TelosB nodes) with legacy surveillance cameras to provide storage-efficient and privacy-aware services of accurate, real time tracking and identifying of the burglar who stole the property. In our system, a property owner will have a wireless module node (called secondary module) attached to the property that s/he wants to protect. The secondary wireless module node will not store any personal information about the owner, nor any specific information about the property to be protected. Each user of the system will also have a unique wireless module node (called primary module) that contains some security information about the user, thus should be privately held by the user and be kept to the user always. Once a tracking process is triggered in privacy preserving manner, the secondary module will start sending out the alarm signal periodically. The alarm signal will be captured by some surveillance wireless module, integrated with existing surveillance cameras. Using the trajectory information provided by the secondary wireless module node, and the videos captured by the surveillance cameras, our system will then automatically pinpoint a burglar (e.g., a person or a car) that is more likely to carry the stolen property. Our extensive evaluation of the system shows that we can find the burglars with surprisingly high accuracy under various experiment settings, with significantly reduced storage-requirement of the legacy video surveillance system. It also can help the police to catch the burglars more efficiently by providing critical images or videos containing the burglars.
Efficient Proxy-Based Internet Media Distribution Control and Privacy Protection Infrastructure	Massive Internet media distribution demands pro longed continuous consumption of networking and disk band widths in large capacity. Many proxy-based Internet media distribution algorithms and systems have been proposed, implemented, and evaluated to address the scalability issue. However, few of them have been used in practice, since two important issues are not satisfactorily addressed. First, existing proxy-based media distribution architectures lack an efficient media distribution control mechanism. Without protection on the Internet, content providers are hesitant to use existing fast distribution techniques. Second, little has been done to protect client privacy during client accesses. Straightforward solutions to address these two issues independently lead to conflicts. For example, to enforce distribution control, only legitimate users should be granted access rights. However, this normally discloses more information (such as which object the client is accessing) other than the client identity, which conflicts with the client's desire for privacy protection. In this paper, we propose a unified proxy-based media distribution protocol to effectively address these two problems simultaneously. We further design a set of new algorithms for cooperative proxies where our proposed scheme works practically. Simulation results show that our proposed strategy is efficient
Evaluation of visual privacy filters impact on video surveillance intelligibility	Since privacy issues are becoming important with growth of the video surveillance, many tools are proposed for protection of personal privacy in the video. However, little is understood regarding the effectiveness of such tools and their effect on the underlying surveillance tasks. In this paper, we propose a subjective evaluation methodology that compares several popular privacy protection techniques applied to typical indoor surveillance video. We identify and analyze the tradeoff between the privacy preservation of these tools and the intelligibility of activities in the resulted surveillance video.
Privacy-preserving SVM classification on arbitrarily partitioned data	With the development of information science and modern technology, it becomes more important about how to protect privacy information. In this paper, a novel privacy-preserving support vector machine (SVM) classifier is put forward for arbitrarily partitioned data. The proposed SVM classifier, which is public but does not reveal the privately-held data, has accuracy comparable to that of an ordinary SVM classifier based on the original data. We prove the feasibility of our algorithms by using matrix factorization theory and show the security.
A privacy-preserving alert correlation model	Data holders need to share the alerts data that they detected for correlation and analysis purpose. In such cases, privacy issues turn out to be a major concern. This paper proposes a model to correlate and analyze intrusion alerts with privacy-preserving capability. The raw intrusion alerts are protected by improved k-anonymity method, which preserves the alert regulation inside disturbed data records. Combining this privacy preserving method with typical FP-tree frequent pattern mining approach and WINEPI sequence pattern mining algorithm, an alert correlation model is set up to well balance the alert correlation and the privacy protection. Experimental results show that this model reaches close similarity of correlation and analysis result comparing with original FP-tree and WINEPI algorithm, while sensitive attributes are well preserved.
ΓÇ£Who's reading my e-mail?ΓÇ¥: a study of professionals' e-mail usage and privacy perceptions in the workplace	E-mail privacy in the workplace has emerged as one of the most complex ethical and legal issues confronting corporate communication in the electronic age. The paper discusses the array of legal and ethical concerns of e-mail privacy in the workplace. Building on the existing body of knowledge on the topic, the results of a research study are presented which explore the similarities and differences in e-mail usage and privacy perceptions among management level and administrative level employees. The survey, which polled 337 working professionals, confirmed the popular belief that companies are not effectively communicating their e-mail monitoring policies to their employees. Finally, recommendations are made to corporate communicators on how best to forge an e-mail communications policy that can reduce the risk of disputes, incidents, and lawsuits regarding e-mail privacy issues
Information Ethics: Privacy and Intellectual Property	
Safe harbor and privacy protection: a looming issue for IT professionals	The 25 European Union (EU) Member States require that their residents' personal information not be transferred to countries that do not protect that information adequately. In 2000, the EU ruled that the United States (US), through its voluntary Safe Harbor program, met that requirement. Since that time, however, the EU has charged that many US companies that claim to be in compliance with Safe Harbor policies are not. In this article, I report on a study of the privacy-policy statements of 20 randomly selected US companies that claim to be in compliance. Of the 20, 19 are not in compliance. This study argues that as EU Member States begin to examine Safe Harbor carefully, they are likely to force US companies to adhere to more stringent privacy policies. The burden of this adherence will be borne by US IT professionals.
Privacy, e-mail, and information policy: where ethics meets reality	Although the use of e-mail is prevalent, few articles address the legal and ethical implications of e-mail monitoring. The paper argues that managerial monitoring of e-mail is ethically questionable because of its potential to violate privacy rights. After examining the legal guidelines related to e-mail monitoring, the article explores the ethical considerations surrounding this type of monitoring. Privacy issues and implications for management are addressed. The paper also offers suggestions for organizations that choose to monitor employees' e-mail
Historical perspectives on technology, ethics, and privacy	The critical issues of technological change involve people, before profits. However, the authors consider how technology and profits drive most organizations. Responsible managers understand how people reacted to change in the past to prepare them for future changes. They ask how change shifts the values and responsibilities within their own organizations. Learning from history, managers break from the past and lead people who use technology to further the interests of all
Internet and Online Information Privacy: An Exploratory Study of Preteens and Early Teens	Information security and privacy on the internet are critical issues in our society. In this research, we examine factors that influence Internet users' private-information-sharing behavior. Based on a survey of 285 preteens and early teens, who are among the most vulnerable groups on the Web, this study provides a research framework that explains an internet user's information privacy protection behavior. According to our study results, internet users' information privacy behaviors are affected by two significant factors: (1) users' perceived importance of information privacy and (2) information privacy self-efficacy. The study also found that users believe in the value of online information privacy and that information privacy protection behavior varies by gender. Our findings indicate that educational opportunities regarding internet privacy and computer security as well as concerns from other reference groups (e.g., peer, teacher, and parents) play an important role in positively affecting the Internet users' protective behavior regarding online privacy.
Multinational data-privacy laws: an introduction for IT managers	Information-technology managers at United States companies are likely to be affected by recent legislation in the European Union and in Canada that restricts the transfer of citizens' personal information to countries that do not protect that information adequately. We argue that, from both ethical and pragmatic perspectives, USA businesses should reject the voluntary, self-certifying approach to data protection currently in favor in the United States. USA businesses should advocate instead for a European approach that mandates stronger data protection and establishes a government agency charged with enforcing it. If the USA adopted a European approach to data privacy, USA businesses would attract more customers and avoid the legal problems that are likely to result when European and Canadian data-privacy authorities begin to enforce their new laws vigorously.
Information export in the electronic environment: an overview of the EU data privacy directive and the U.S. response	The European Union has recently implemented its Data Directive on Privacy, a legal measure stating that certain ΓÇ£personalΓÇ¥ information (e.g., an individual's race, sexual orientation, or medical records) cannot leave the EU unless it is going to a nation with privacy laws similar to those of the EU Directive. As the United States is not a member of the EU and as it has no official national data privacy legislation paralleling that of the EU, it cannot legally receive any form of ΓÇ£personalΓÇ¥ information from any of the EU's 15 member states unless it first receives the consent of the individual. The United States responses with the ΓÇ£Safe Harbor PrinciplesΓÇ¥ which shift the burden of meeting EU privacy standards away from the national governments and to individual companies. The Safe Harbor Principles, however, have not been well received by either the EU or the American companies they were designed to help. To date, response to the EU Data Privacy Directive remains mixed, but one thing is certain-it will forever alter the way in which we view and we use the online environment
Prolog To Biometrics: Privacy's Foe Or Privacy's Friend?	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00628722.png" border="0">
Prolog to the Section on Privacy and Cybersecurity	
Privacy-Aware Design Principles for Information Networks	Privacy has become a critical topic in the engineering of networked systems. Electronic surveillance, both covert and overt, has a negative impact on both the individual and society, and the public's perception of engineered systems that forsake the privacy issue is increasingly negative. Engineers and computer scientists thus have a moral obligation to avoid design choices that are unnecessarily privacy invasive. To fully illustrate this point, we provide an overview of the philosophical, legal, moral, and epistemological literature on the subject of privacy and related implications of its invasion. We then introduce a series of privacy-aware design principles that lead to less invasive information technologies. We develop a smart grid/demand response case study to illustrate the impact of the proposed design rules that protect individual privacy and promote understanding of ethical issues underlying the need for privacy for individuals and society.
Security and Privacy for Distributed Multimedia Sensor Networks	There is a critical need to provide privacy and security assurances for distributed multimedia sensor networking in applications including military surveillance and healthcare monitoring. Such guarantees enable the widespread adoption of such information systems, leading to large-scale societal benefit. To effectively address protection and reliability issues, secure communications and processing must be considered from system inception. Due to the emerging nature of broadband sensor systems, this provides fertile research ground for proposing more paradigm-shifting approaches. This paper discusses issues in designing for security and privacy in distributed multimedia sensor networks. We introduce the heterogeneous lightweight sensornets for trusted visual computing framework for distributed multimedia sensor networks. Protection issues within this architecture are analyzed, leading to the development of open research problems including secure routing in emerging free-space optical sensor networks and distributed privacy for vision-rich sensor networking. Proposed solutions to these problems are presented, demonstrating the necessary interaction among signal processing, networking, and cryptography.
Privacy and Cybersecurity: The Next 100 Years	The past and the future of privacy and cybersecurity are addressed from four perspectives, by different authors: theory and algorithms, technology, policy, and economics. Each author considers the role of the threat from the corresponding perspective, and each adopts an individual tone, ranging from a relatively serious look at the prospects for improvement in underlying theory and algorithms to more lighthearted considerations of the unpredictable futures of policy and economics.
The politics of privacy: Planning for personal data systems as powerful technologies	
Smart Cameras and the Right to Privacy	This essay provides a matrix for use by researchers and system designers as a heuristic device to assess the likely legality of the deployment of a surveillance camera system. After presenting the matrix the essay considers examples in which smart camera technology might enhance the venues for deployment of surveillance cameras. Lastly, the article speculates about legal risks that may confront smart camera technology as it becomes more sophisticated.
Prolog to "Privacy-Aware Design Principles for Information Networks"	This article talks about privacy in the context of modern technology, which may be defined as a zone of exclusion in which individuals retain the right to control access to personal information.
Privacy and authentication: An introduction to cryptography	This paper presents a tutorial introduction to contemporary cryptography. The basic information theoretic and computational properties of classical and modern cryptographic systems are presented, followed by cryptanalytic examination of several important systems and an examination of the application of cryptography to the security of timesharing systems and computer networks. The paper concludes with a guide to the cryptographic literature.
Biometrics: privacy's foe or privacy's friend?	From the INS to ATM's, both the public and private sectors are making extensive use of biometrics for human recognition. As this technology becomes more economically viable and technically perfected, and thus more commonplace, the field of biometrics will spark legal and policy concerns. Critics inevitably compare biometrics to Big Brother and the loss of individual privacy. The probiometric lobby generally stresses the greater security and improved service that the technology provides. Is biometrics privacy's friend or privacy's foe? This paper explores the various arguments for and against biometrics and contends that while biometrics may pose legitimate privacy concerns, these issues can be adequately addressed. In the final analysis, biometrics emerges as privacy's friend
Security and Privacy in Distributed Smart Cameras	Distributed smart camera systems are becoming increasingly important in a wide range of applications. As they are often deployed in public space and/or our personal environment, they increasingly access and manipulate sensitive or private information. Their architectures need to address security and privacy issues appropriately, considering them from the inception of the overall system structure. In this paper, we present security and privacy issues of distributed smart camera systems. We describe security requirements, possible attacks, and common risks, analyzing issues at the node and at the network level and presenting available solutions. Although security issues of distributed smart cameras are analogous to networked embedded systems and sensor networks, emphasis is given to special requirements of smart camera networks, including privacy and continuous real-time operation.
Protecting Privacy of Sensitive Data Dissemination Using Active Bundles	The solution for protecting data privacy proposed in this paper-called Active Bundles-protects sensitive data from their disclosure to unauthorized parties and from unauthorized dissemination (even if started by an authorized party). The Active Bundles solution protects private or sensitive data throughout their entire lifecycle, from creation through dissemination to partial or total destruction (such as evaporation or apoptosis defined in the paper). In addition, it protects identity of entities exchanging private data. The core of the solution are active bundles themselves, which are containers with a payload of sensitive data, metadata, and a virtual machine specific to the active bundle. Metadata control access to private data and dissemination of active bundles. The main virtual machine roles are: validating integrity of its active bundle; and enforcing access control policies and dissemination policies for data of the active bundle. The Active Bundles solution also includes the active bundle exchange protocol for transmitting the bundles between hosts. The protocol uses buddies to provide anonymity to senders and receivers. The performance of the Active Bundles solution for data dissemination is evaluated analytically and by a simulation. The results indicate that: (i) the percentage of sensitive data that reaches unauthorized hosts during dissemination can be high, (ii) the apoptosis mechanism protects sensitive data from dissemination to unauthorized hosts, (Hi) the Active Bundles solution provides a level of anonymity to hosts while it does not decrease significantly the throughput of buddies.
Electronic Personal Health Record Systems: A Brief Review of Privacy, Security, and Architectural Issues	Electronic personal health records (PHRs) are beginning to receive widespread attention as a tool for consumers. Such systems may be used by individuals to input data and to access information from a variety of sources (e.g. family physicians), thus improving their understanding of the state of their health and helping to manage their own healthcare better. The main source of information for PHRs is normally the patient's physician, supplemented by patient input and other sources of information such as prescriptions and lab test results, as well as institutional inputs from hospitals and other facilities. The architecture of such a system must be such that patients can access all the useful information that is relevant to their medical history in a form that is understandable to them, while at the same time protecting against unauthorized access. This paper addresses design and architectural issues of PHR systems, and focuses on privacy and security issues which must be addressed carefully if PHRs are to become generally acceptable to consumers.
Why Privacy Matters in Health Care Delivery: A Value Proposition	Privacy is important in health care delivery. Effective and efficient health care delivery is about exploiting information - accurate information, complete information. Without privacy, patient trust is diminished, information flow may be compromised and, so too, patient care. When patient care is compromised, inefficiencies emerge and there are verifiable costs to the individual, to the provider and to the health care system as a whole. Privacy, therefore, should be seen as a cornerstone of successful business operations in health care not an afterthought driven by compliance issues.
Research Data in Google Earth: How Do We Protect Privacy and Meet Ethical Obligations?	In 2005, Google released Google Earth (a free virtual globe, map and geographic information program) allowing anyone with location coordinates (postal codes, GPS data) to create and share accurate spatial-location maps. It has since become a powerful tool for researchers and scientists in the growing discipline of visual data analysis. In 2008, Fleet and Williamson demonstrated analytic and communication benefits by mapping the survey data of 400 small and medium businesses in Atlantic Canada. Yet, our (research) ethical obligation is to ensure the confidentiality of identification information received from respondents, and the postal code data entered into geo-analytic tools such as Google Earth allow the viewer to see identification pins marking individual buildings or rooftops. This paper will summarize the Canadian requirements on privacy, confidentiality and identification issues and requirements for Canadian researchers (as defined by the Canadian Tri-Council Policy Statement). It will conclude with a series of proposals and discussion points (both technical and non-technical) for how to address these concerns.
A Gap in Perceived Importance of Privacy Policies between Individuals and Companies	Although several studies have examined individuals' privacy concerns and companies' privacy policy disclosures, only a few studies examined whether customers' privacy concerns are adequately addressed in companies' privacy policy disclosures. This study investigates companies' privacy policy statements and important privacy policies that individuals want to know. We examine the privacy policy statements of 136 companies from the U.S. and Canada and relate them to the results of a Web-based user survey of 210 respondents. Our findings reveal a difference in companies' privacy policies between the U.S. and Canada and a gap between what privacy policies individuals value and what companies emphasize in their privacy policy statements.
Privacy-Preserving Techniques and System for Streaming Databases	Streaming databases and other distributed, event-based systems are very useful tools for business and security applications. When event sources and event processing are distributed across multiple distinct domains, confidentiality and privacy issues emerge. These can be addressed by a number of cryptographic techniques. In this paper we consider high-performance symmetric encryption techniques. We build a system for privacy-preserving event correlation and evaluate the performance of the its techniques. We demonstrate efficient privacy-preserving event correlation using equality tests, greater-than comparisons and range queries. The results indicate that in comparable settings, it is therefore recommended to employ these techniques to address pertinent security and privacy concerns.
Towards a Modeling and Analysis Framework for Privacy-Aware Systems	Nowadays, almost any software application deals with private information. However, effective tools that support the specification and implementation of privacy-aware systems are still missing. This work makes a step to address this issue. In this paper we present MAPaS, a model based framework for the modeling and analysis of privacy-aware systems. MAPaS provides a modeling language for the privacy domain and a rich set of functionalities that allow users to easily analyze privacy-preserving characteristics of a system at the early stages of its development. In this paper, besides presenting the main modules of MaPaS, we show how it can effectively help in the development of privacy-aware systems.
Privacy Threats Related to User Profiling in Online Social Networks	The popularity of Online Social Networks (OSNs) has increased the visibility of users profiles and interactions performed between users. In this paper we structure different privacy threats related to OSNs and describe six different types of privacy threats. One of these threats, named public information harvesting, is previously not documented so we therefore present it in further detail by also presenting the results from a proof-of-concept implementation of that threat. The basis of the attack is gathering of user interactions from various open groups on Facebook which then is transformed into a social interaction graph. Since the data gathered from the OSN originates from open groups it could be executed by any third-party connected to the Internet independently of the users' privacy settings. In addition to presenting the different privacy threats we also we propose a range of different protection techniques.
Workshop on Security and Privacy in Social Networks (SPSN 2012) Committees	Provides a listing of current committee members.
Non-linear Dimensionality Reduction for Privacy-Preserving Data Classification	Many techniques have been proposed to protect the privacy of data outsourced for analysis by external parties. However, most of these techniques distort the underlying data properties, and therefore, hinder data mining algorithms from discovering patterns. The aim of Privacy-Preserving Data Mining (PPDM) is to generate a data-friendly transformation that maintains both the privacy and the utility of the data. We have proposed a novel privacy-preserving framework based on non-linear dimensionality reduction (i.e. non-metric multidimensional scaling) to perturb the original data. The perturbed data exhibited good utility in terms of distance-preservation between objects. This was tested on a clustering task with good results. In this paper, we test our novel PPDM approach on a classification task using a k-Nearest Neighbour (k-NN) classification algorithm. We compare the classification results obtained from both the original and the perturbed data and find them to be much same particularly for the few lower dimensions. We show that, for distance-based classification, our approach preserves the utility of the data while hiding the private details.
Legislation and Privacy across Borders	This paper explores the influences of cultural values and government structure on technology-based privacy legislation. The following geographic areas are analyzed to better understand this relationship: the United States (U.S.), the European Union (EU), China, and India. Using three primary cultural dimensions from the extensive studies of Geert Hofstede, the findings reveal a significant connection between the strength of certain cultural traits and whether the government is reactive or proactive to technology-based privacy breaches.
Privacy in the Age of Mobility and Smart Devices in Smart Homes	Privacy concerns arise in a wide range of context. One of such context is in smart devices used within smart environment. Adaptors of such developments are generating an ever-increasing amount of data, this is often done without their consent or been fully aware of the implications of sharing and using such devices. This paper identifies the implications and challenges of privacy to smart devices in smart homes. The paper begins with a background and motivation. Subsequently, current privacy and security issues are discussed and analysed. Framework for privacy and security in smart homes is proposed and discussed in the subsequent section, while also presenting early simulation results.
Vegas -- A Secure and Privacy-Preserving Peer-to-Peer Online Social Network	Although Social Network Service (SNS) providers like Facebook and Google attempt to mitigate security and privacy-related concerns of their users, abuses and misuses of personal data still make the headlines. As centralized storage of personal data is a decisive factor for unintended information disclosure, several architectures for decentralized Online Social Networks (OSNs) have been proposed. System designs range from solutions based on a decentralized client server architecture like Diaspora to P2P systems like PeerSoN. Despite all efforts to accomplish strong decentralization, most proposals cannot achieve sufficient informational self-determination, i.e., users do not have full control over storage and dissemination of their personal data and published content. In this paper we follow a contrary approach and present Vegas, a secure and privacy-preserving P2P OSN which restricts the possibility to browse the social graph to the ego network. We show how Vegas achieves a maximum degree of security and privacy through encryption and decentralization. We present our mobile Vegas prototype and its context-dependent communication channel decision model. Finally we show how Vegas can be extended to support services like social-search and directory services in a secure and privacy-preserving way.
Towards an Identity-Based Data Model for an Automotive Privacy Process	Information technology has attracted considerable attention in modern automobiles for their promise of value-added services. Based on increasing connectivity and seamless integration of advanced functionality into vehicles, a new challenge is the development of holistic and standardized privacy approaches. So far, privacy has often been considered as a singular task, neglecting the impact of a holistic viewpoint on automotive data. In this paper we provide an identity-based data model, a way to define a structured and flexible view to the acquired vehicular data, i.e., identifying information. We develop the data model as a graph, provide a formal notation and demonstrate its application with an example. The proposed scheme of the model is of multiple uses and the formal notation shows to serve additional privacy features to our model, e.g., privacy risk assessment.
Differential Privacy through Knowledge Refinement	We introduce a novel mechanism to attain differential privacy. Contrary to the common mechanism based on the addition of a noise whose magnitude is proportional to the sensitivity of the query function, our proposal is based on the refinement of the user's prior knowledge about the response. We show that our mechanism has several advantages over noise addition: it does not require complex computations, and thus it can be easily automated, it lets the user exploit her prior knowledge about the response to achieve better data quality, and it is independent of the sensitivity of the query function (although this can be a disadvantage if the sensitivity is small). We also show some compounding properties of our mechanism for the case of multiple queries.
Mining Privacy Settings to Find Optimal Privacy-Utility Tradeoffs for Social Network Services	Privacy has been a big concern for users of social network services (SNS). On recent criticism about privacy protection, most SNS now provide fine privacy controls, allowing users to set visibility levels for almost every profile item. However, this also creates a number of difficulties for users. First, SNS providers often set most items by default to the highest visibility to improve the utility of social network, which may conflict with users' intention. It is often formidable for a user to fine-tune tens of privacy settings towards the user desired settings. Second, tuning privacy settings involves an intricate tradeoff between privacy and utility. When you turn off the visibility of one item to protect your privacy, the social utility of that item is turned off as well. It is challenging for users to make a tradeoff between privacy and utility for each privacy setting. We propose a framework for users to conveniently tune the privacy settings towards the user desired privacy level and social utilities. It mines the privacy settings of a large number of users in a SNS, e.g., Facebook, to generate latent trait models for the level of privacy concern and the level of utility preference. A tradeoff algorithm is developed for helping users find the optimal privacy settings for a specified level of privacy concern and a personalized utility preference. We crawl a large number of Facebook accounts and derive the privacy settings with a novel method. These privacy setting data are used to validate and showcase the proposed approach.
Factors that Influence the Choice of Privacy Settings on Facebook: Freshmen's View at a South African University	A contradiction between the reported privacy concerns and observed privacy behaviour of users of social networking sites has been reported. To understand this contradiction this paper examines factors that influence privacy behaviour of users on social networking sites. Participants in this study were freshmen studying IT recruited from Nelson Mandela Metropolitan University during the academic year of 2011. A questionnaire was used to study the reported privacy concerns of the participants, followed by observations on the public Facebook profiles of the participants to shed light on their actual behaviour. Interviews exposed factors that negatively influence privacy behaviour, while another questionnaire explored factors that positively influence privacy behaviour. This study shows that the contradiction between privacy concerns and observed privacy behaviour varies according to the type of information in question. Based on the findings, we developed a model that identifies factors that users consider when choosing privacy settings on Facebook.
Identifying Critical Factors of Community Privacy	Just as an individual is rightly concerned about the privacy of their personally identifying information, so also is a group of people, a community, concerned about the privacy of sensitive information entrusted to their care. Our research seeks to better understand the factors contributing to the sensitivity of community information, the privacy threats that are recognized by the community, and the means by which the community attempts to fulfill their privacy responsibilities. We are also interested in seeing how the elements of a community privacy model which we developed are related to the findings from the studies of actual communities. This paper presents results from three focus group interviews conducted with participants from two information technology companies and one group from our university. In this paper we report how the studied communities acted to confine sensitive information. These studies capture the character and complexity of community privacy and expose breakdowns in current approaches. We also find significant relationship between these results and the key elements of our community privacy model.
PESAP: A Privacy Enhanced Social Application Platform	Nowadays, social networking sites provide third party application developers with means to access their social graph, by providing a social application platform. Through their users, these developers acquire a significant set of personal information from the social graph. The current protection mechanisms, such as privacy policies and access control mechanisms fall short on protecting the privacy of the users. In this paper we present a framework for a privacy enhanced social application platform, called PESAP, that technically enforces the protection of the personal information of a user, when interacting with social applications. The framework is based on two pillars: anonymization of the social graph and secure information flow inside the browser. PESAP is targeted to be as compatible as possible with the current state-of-the-art design of social application platforms, while technically enforcing the protection of user privacy. We evaluate this compliance, based on a classification of applications in different categories.
Privacy Preserving Maximum-Flow Computation in Distributed Graphs	The maximum-flow problem arises in a wide variety of applications such as financial transactions and logistics collaboration networks, where the data can be modeled as a directed graph. In many such applications, the graph data is actually distributed across several organizations where each owns a portion of the overall graph. Due to privacy concerns, the parties may not wish to disclose their local graphs. However, the computation of maximum-flow over the overall graph brings great benefits to concerned stakeholders. In this paper, we address the privacy preserving maximum-flow computation problem in distributed graphs. We propose a two-stage approach that achieves privacy protection while ensuring the correct maximum flow computation. In the first stage, a novel probabilistic edge expansion process is used to obfuscate the graph structure and prevent node re-identification while preserving the maximum flow, the second stage securely integrates local graphs into a global whole such that any third party can then compute the maximum flow. We provide a thorough correctness and privacy analysis and experimentally evaluate the proposed approach.
Sharing and Privacy-Aware RBAC in Online Social Networks	Online social networks have gained enormous popularity in the last decade. Users share their private information online with other users, which is becoming a serious privacy issue at the social and technical level. In a society, everyone is a member of many collaborative groups (social circles), for example, colleagues, class fellows. There are many collaborative relationships among group members. Current social networks mostly use friend as a relationship, which in our social life, is not practical. In a society, we have different levels of collaborative relationships with others and even some relationship with non-friends. We use collaborative groups and relationships that facilitate users in controlling the privacy and sharing level of their information in social networks. We present a sharing and privacy-aware SP-RBAC model by extending the well-known RBAC model. Our model increases the collaborative community of a user, and hence increases sharing of information, minimizing the privacy threats using simple user management.
Do the Privacy Policies Reflect the Privacy Controls on Social Networks?	An increasing number of people are sharing ever-greater amounts of private information, making social networking sites a "personal data ecosystem". Such networks publish lengthy privacy policies explaining their data practices and provide users with extensive privacy controls to manage what they share and with whom. Despite this, privacy concerns over social networks are on the rise. It is not clear whether the published privacy policies are effectively reflected in privacy controls of the sites. In this paper we describe an exploratory approach that examines whether a clear mapping can be established between the privacy policies of social networking sites and the privacy controls. Our preliminary results show a significant disconnect between the two dichotomies.
A Privacy-Aware Bayesian Approach for Combining Classifier and Cluster Ensembles	This paper introduces a privacy-aware Bayesian approach that combines ensembles of classifiers and clusterers to perform semi-supervised and transductive learning. We consider scenarios where instances and their classification/clustering results are distributed across different data sites and have sharing restrictions. As a special case, the privacy aware computation of the model when instances of the target data are distributed across different data sites, is also discussed. Experimental results show that the proposed approach can provide good classification accuracies while adhering to the data/model sharing constraints.
Privacy and Information Markets: Controlling Information Flows in Decentralized Social Networking	The contribution motivates a substantial conceptual overlap between privacy control and potential information markets in decentralized contextual Social Networking and suggests substituting appropriate means for controlling outgoing and incoming information flows as the key problem of both points of view. An XACML-based approach for information flow control is suggested based on social conventions and involving traceable signed speech acts and sticky policies based on long- and short term social contexts, spatio-temporal regions and digital IDs as basic building blocks. An analysis of the basic micro-economics of information markets based on such a flow control approach shows how price building mechanisms and other characteristics of these markets may contribute to privacy and information quality.
Personal Social Screen--A Dynamic Privacy Assignment System for Social Sharing in Complex Social Object Networks	Online social networks allow millions of individuals to create online profiles and share information with vast networks of friends, and often, unknown strangers. Privacy within social networking sites is often undefined, which might render potential privacy risks. In this paper, we present a dynamic trust-based privacy assignment system to help people select the privacy preference on-the-fly to the piece of content he/she is sharing, where trust information is derived from social network structure and user interactions. Our proposed system, Personal Social Screen (PerCial), first automatically detects a two-level topic sensitive community hierarchy using the available resources, and then assigns privacy preference for users based on their personalized trust networks. Preliminary results on a social object network dataset collected from Flickr demonstrate the efficacy and effectiveness of our proposed system.
Supportive, Comprehensive and Improved Privacy Protection for Web Browsing	Protecting users privacy on the Web is becoming increasingly complicated because of the silent actions of third party sites that spy, collect data, aggregate information and build profiles, transparently to end users, to provide targeted advertising. On the Web, users are loudly concerned about the large amount of information left in many locations during their navigation and claim more protection to safely conduct their online activities. We present, in this paper, a supportive, comprehensive and improved approach for privacy protection to allow users to be aware of the risks of their navigation and to give them full control on effective actions to address online privacy threats. Our approach is validated by a Mozilla Fire fox extension, No Trace, that provides the feasibility of the techniques, and whose efficiency is thoroughly tested on an extensive data set for effectiveness, impact on users experience and performances.
Analyzing Privacy in Social Networks--An Interdisciplinary Approach	The rise of the social web has traditionally been accompanied by privacy concerns. Research on social web privacy has been conducted from various directions including law, social and computer sciences contributing to the body of literature. In this paper, we argue for an interdisciplinary approach to capture the multidimensional concept of privacy. For this purpose, we propose a three-layered framework to systematically analyze the privacy impact of various research directions. Subsequently, we conduct an interdisciplinary literature analysis, highlighting areas for improvement as well dependencies between different research directions.
A Decentralized Group Privacy Protocol for Vehicular Networks	Vehicular Networks by means of Car-to-X (C2X) communication aims to enhance road safety and traffic efficiency by exchanging foresighted traffic information. For successfully establishing this technology on the market, C2X messages have to be secured and the driver's privacy must not be violated. However, currently applied pseudonymization strategies provide only basic protection against profiling and are entirely ineffective towards a powerful global adversary. We present a novel group privacy protocol, which creates dynamic cryptographic 'Mix Zones' in a decentralized and cooperative way. The proposed protocol obfuscates pseudonym changes and thus reduces trace ability of vehicles significantly. While geographical cells are used to establish a secret group key among all members, the group is maintained even when travelling along the road. Using the group key, a vehicle is able to send secure authenticated messages, though its anonymity is preserved. We simulate the proposed protocol by means of a dedicated C2X simulator and evaluate the achieved privacy enhancements with respect to a global passive adversary.
Information Integration and Analysis: A Semantic Approach to Privacy	The balance between privacy and security concerns is a hotly debated topic, especially as government (and private) entities are able to gather and analyze data from several disparate sources with ease. This ability to do large scale analytics of publicly accessible data leads to significant privacy concerns. In particular, for the government, there is the fear of a fishing expedition against individuals. The model in this paper describes a way to address these concerns in a multi-user and multi-database owner environment. The model provides an assurance system where database owners are able to test and audit the assurances given by users thereby increasing the trust in the system. The concept of segregating data used for processing from data needed for final end use and providing different levels of access to them through a mediator machine has been used. The audit component consisting of a justification mechanism increases the trust in the system.
Practical Privacy-Preserving Multiparty Linear Programming Based on Problem Transformation	Cryptographic solutions to privacy-preserving multiparty linear programming are slow. This makes them unsuitable for many economically important applications, such as supply chain optimization, whose size exceeds their practically feasible input range. In this paper we present a privacy-preserving transformation that allows secure outsourcing of the linear program computation in an efficient manner. We evaluate security by quantifying the leakage about the input after the transformation and present implementation results. Using this transformation, we can mostly replace the costly cryptographic operations and securely solve problems several orders of magnitude larger.
TISS-loc: Towards User Control of Privacy in Location Disclosure	The rise in popularity of location disclosure brings privacy concerns to the forefront. Mechanisms are needed that empower users to personalize the balance between the benefits of location awareness and privacy. This paper presents TISS-loc, which leverages trust management foundations to enhance control of location disclosure. TISS-loc supports location obfuscation to balance privacy and the benefits of disclosure, it uses stereotyping to promote openness and scalability on the number of requestors, it supports automatic update of disclosure policies based on requestor behavior, and it supports multilateral and multi-level decision making. The paper also describes an Android-based implementation of TISS-loc and a user study that investigates whether end users can understand and use TISS-loc.
PrivacyJudge: Effective Privacy Controls for Online Published Information	With the rise of online social networks, sharing of personal information online has become the rule for many people rather than the exception. However, users have only limited abilities to effectively control privacy of their posted information. Even gaining an overview of posted information is already a difficult task. We propose a privacy control system for personal information online. Privacy Judge allows fine-grained access control to posted information and provides a comprehensive overview of previously posted data. Thereby, Privacy Judge does not require cooperation of service providers, instead operation remains transparent to them. Thus effectively providing privacy protection against other users and service providers alike. Privacy Judge follows a hybrid approach combining cryptographic enforcement with social signaling to achieve privacy protection beyond technical enforcement boundaries by leveraging system trust as well as social trust mechanisms.
Towards Privacy in a Context-Aware Social Network Based Recommendation System	Previous work has reported on `Instant Knowledge', a context-aware social networking based recommendation system for enterprise. This paper outlines a hierarchical privacy architecture, to provide anonymity, unlink ability, unobservability and pseudonymity to IK users. Users are grouped according to `proportional distance reservation', which indicates how likely users are willing to share private information. The protection of private information is stronger when queries are made by `distant' users, and weaker for fellow group members.
Achieving Full Security in Privacy-Preserving Data Mining	In privacy-preserving data mining, a number of parties would like to jointly learn a function of their private data sets in a way that no information about their inputs, beyond the output itself, is revealed as a result of such computation. Yang et al. 2010 showed that several popular data mining algorithms can be reduced to three basic operations, secure implementation of which -- termed Secure Product of Summations (SPoS), Secure Ratios of Summations (SRoS), and Secure Comparison of Summations (SCoS) -- would lead to privacy-preserving data mining solutions. The authors showed that prior privacy-preserving data mining solutions are unsatisfactory in presence of participants' collusion and they gave new implementation of these operations that were designed to sustain the collusion. In this work, we show that unfortunately the protocols of Yang et al. leak a significant amount of private information and are not secure even if no collusion takes place. We then show how these operations can be securely and efficiently realized in the same and stronger security models, which leads to fully secure solutions for many data mining algorithms.
Practice Makes Perfect: Motivating Confident Privacy Protection Practices	The study presented in this paper shows that service users can have low confidence in a service provider's ability to protect their personal information even if those service users trust the overall brand. Today, on-line services are not specifically designed to promote a service user's confidence building. As a result, service users have to depend on off-line techniques to build confidence in their information practices. One implication of not having effective support for confidence building designed into the on-line service is that, despite costly investment in trust marks, security technologies and brand development, service users will continue to give false information, limit the extent of their engagement in on-line services and avoid registration with on-line services. In the era of on-line public services delivery, this pattern of privacy protection practice potentially has devastating consequences for public service delivery and the ability of the most vulnerable to receive the public service support that they need. The study also indicates that providing interaction possibilities through social computing as part of the service design is one way to help build service user confidence. This paper concludes with examples of social computing used for this purpose.
Decoupled Data for Privacy Preserving Record Linkage with Error Management	Data from social networks are an excellent source of information for studying human behaviors and interactions. Typically, when analyzing such data, the default mode of access is de-identified data, which provides a level of privacy protection. However, due to its inability to link to other data, de-identified data has limitations with regard to answering broad and critically important questions about our complex society. In this paper, we (1) investigate the properties of information related to privacy, and (2) present a novel model of data access, decoupled data access, for studying personal data using these properties. Decoupling refers to separating out the identifying information from the sensitive data that needs protection. We assert that decoupled data access can provide flexible record linkage with error management while still providing the same level of privacy protection as de-identified data.
Modeling and Analyzing User Behavior of Privacy Management on Online Social Network: Research in Progress	There are diversified threats to privacy in the area of online social network. Unlike traditional e-commerce situation, privacy on online social networks can be threatened by published communication open to untargeted audience and public disclosure of personally identifiable information. Moreover, users of online social network encounter greater threats to their privacy since management of privacy depends on both service vendors and users themselves. In order to better understand the mechanism of privacy on online social network, this paper explores a model of privacy related issues in regards to user behavior on online social networks, based on frequently used theories and research constructs.
An Approach to Community-Oriented Email Privacy	This paper describes how members of a community can collaboratively protect the privacy of the information they share via email. An extension of email tagging is used to represent communities and establish privacy protection boundaries. The approach is illustrated informally by scenarios and the key concepts are defined formally. The contributions of this paper are: (1) extending the idea of boundary regulation to a community, (2) empowering a community to manage its membership through group consensus and providing awareness of the actions of its members via notifications, and (3) capturing the semantics of this approach in a state-transition system and proving that email sharing is privacy-preserving.
Privacy Goals and Settings Mediator Model for PHRs	Personal Health Record (PHR) platforms support an extensible ecosystem of third party applications that share health data. Still, support for self-management of privacy in PHR platforms remains primitive and insufficient. Privacy experts can offer users advice to help configure their privacy settings, but there is a lack of tools to support this activity. Our research proposes a model (and the associated tooling) that fills the gap between the end-user privacy intentions and what PHR systems offer as privacy features. We develop a privacy goals and settings mediator model based on an existing agent and goal-oriented modeling approach. Our proposed model is capable of encoding the accumulated privacy knowledge of the privacy experts during design-time, and offers privacy setting options that best match the users' intentions during run-time. We demonstrate the effectiveness of the model through an example scenario. We also report on qualitative evidence of the acceptance of the model by practitioners, based on interviews with health care privacy experts.
From Privacy Concern to Uses of Social Network Sites: A Cultural Comparison via User Survey	Individuals from different regions normally bear different cultural norms and values, and these variations would in turn affect their behavior and attitude with the computing system. However, though the cross-cultural study has been performed in other areas (e.g., e-commerce websites), few have identified its influence on users' behavior in social network sites (SNS). With the increasing popularity of SNS (e.g., Face book) worldwide, especially in Asian region, we are interested in revealing the effect of culture variables on users' privacy concern and trust in SNS, and furthermore their influence on users' usage motivation, actual uses, overall attitudes and future behavior intentions. This paper presents the in-depth analysis of results from an online survey, which indicates the significant differences between Hong Kong and French SNS users, in respect of various measures. Moreover, it shows that for predicting a user's usage pattern, her/his culture value should be considered since the predictors are different between the two cultural groups.
Privacy and Security in Multi-modal User Interface Modeling for Social Media	This paper addresses privacy and security issues regarding the modeling of multi-modal user interfaces for social media applications. The proposed approach describes how privacy and security concerns are modeled from the user interface perspective, and how this model is related to a four layer conceptual framework for developing multi-modal and multi platform user interfaces. The approach also explains how to adapt these models to the development of social media applications. Finally, we use this proposal to model the Social TV case of study as an example of a social media application to show its feasibility.
An Ontological Study of Data Purpose for Privacy Policy Enforcement	Data purpose is a central concept in modeling privacy requirements. Existing purpose-based approaches for privacy protection have mainly focused on access control. The problem of ensuring the consistency between data purpose and data usage has been under-addressed. In an attempt to bridge this research gap, we develop a grounded understanding of data purpose and relevant key concepts that is fundamental to address the problem. We propose a Minimum Action Permission Principle as a basic guideline to establish a path to solutions to the consistency problem for privacy management.
Relationship Privacy Preservation in Publishing Online Social Networks	The third-party enterprises, such as sociologists and commercial companies, are mining data published from online social network (OSN) websites (e.g., Face book, Twitter) to serve their diverse purposes. This process leads to critical user concerns over their privacy, especially sensitive relationship with others on OSNs. Existing anonymization techniques in publishing online social data are focused on user identities, as users' relationship privacy will be automatically protected in general, if their identities are hidden. However, in reality, some users can still be identified from an identity-anonymized OSN by an attacker, as an individual user may publish his personal information to the public, through blog for example, which can be exploited by the attacker to re-identify the user from the published data. Therefore, we intend to preserve relationship privacy between two users one of whom can even be identified in the released OSN data. We define the Γäô-diversity anonymization model to preserve users' relationship privacy. Additionally, we devise two algorithms to achieve the Γäô-diversity anonymization - one only removes edges while the other only inserts vertices/edges for maintaining as many topological properties of the original social networks as possible, thus retaining the utility of the published data for the third-parties. Extensive experiments are conducted on both synthetic and real-world social network data sets to demonstrate that except from the achievement of privacy preservation, the utility loss caused by our proposed graph manipulation based techniques is acceptable. Besides, we analyze the influence of social network topology (e.g., average degree, network scalability) on the performance of our algorithms.
Privacy: Gone with the Typing! Identifying Web Users by Their Typing Patterns	The lack of privacy protection for Internet users has been identified as a major problem in modern web browsers. While authenticating web users by their typing patterns has been well studied and successfully applied in practice, the related privacy risk of identification by typing patterns has received little attention in both the research and general community. In this paper we present a simple but effective statistical detection model for constructing users' identity from their typing patterns. Extensive experiments are conducted to justify the accuracy of our model. Using this model, online adversaries could uncover the identity of Web users even if they are using anonym zing services. Our goal is to raise awareness of this privacy risk to general Internet users and encourage countermeasures in future implementations of anonymous browsing techniques.
BM (Break-Merge): An Elegant Approach for Privacy Preserving Data Publishing	Publishing of person specific data has elevated much concern on the individual privacy. Many frameworks and privacy principles were proposed to protect the privacy of the published data. However, techniques must be investigated onattacker's background knowledge. This paper proposes a new approach, Break-Merge (BM) to reduce the associations between quasi-identifiers and sensitive attributes in an anonymized data. On the fly our approach reduces the attacker's inferring nature on sensitive data drastically by decomposing the anonymizedtable into Quasi-identifier table (QIT) and Sensitive attribute tables (ST's).
Privacy-Preserving Tabu Search for Distributed Graph Coloring	Combinatorial optimization is a fundamental problem found in many fields. In many real life situations, the constraints and the objective function forming the optimization problem are naturally distributed amongst different sites in some fashion. The typical approach is to collect all of this information together and centrally solve the problem. However, this requires all parties to completely share their information, which may lead to serious privacy issues. Privacy-preserving techniques need to be developed to enable distributed optimization with limited information disclosure. A further complicating factor is that combinatorial optimization problems are typically NP-hard, requiring approximation algorithms or heuristics to provide a practical solution. In this paper, we focus on a very well known hard problem - the distributed graph coloring problem, which has been utilized to model many practical problems in scheduling and resource allocation. We propose an efficient protocol that securely solves this problem based on the tabu search metaheuristic. Specifically, our solution uses a distributed local search algorithm to find a good solution. We analyze the security of our approach and experimentally demonstrate the effectiveness of our approach.
Confidence-Compensating Privacy Protection	The particularly acute problem in privacy protection is to provide such a protection beyond the original disclosure of personal information. There, the need for privacy is strongly related to the confidence in the goodwill of the party that receives such information. In the absence of such a confidence, the disclosure should be limited. However, putting excessive constrains on the disclosure itself can have a damaging effect on the relationship. In order to minimize the potential damage, limitations to the extent of a disclosure should be deployed sparsely, with its strength and direction adjusted to the extent of actual lack of confidence. This paper proposes the flexible strategy for privacy protection that takes into account the lack of perceived confidence. The strategy determines three orthogonal dimensions that can be used to classify various privacy-enhancing tools and links those dimensions with individualpsilas structure of beliefs regarding confidence. This allows to provide the simple decision-making tools that allows to determine the best minimum privacy protection for a given case.
IT Security and Privacy Issues in Global Financial Services Institutions: Do Socio-Economic and Cultural Factors Matter?	Financial services institutions (FSIs) around the globe know they must proactively work toward protecting customer data and thwarting emerging security threats. Deloitte Touche Tohmatsu (DTT), an international firm that provides audit, consulting, and financial advisory services has used its networks and reach to investigate security and privacy issues in FSIs around the world. DTTpsilas first survey appeared in 2003 and four others have followed since then. This present article draws from last survey. Given that the literature has shown that socio-economic and cultural factors are important considerations for organizations when accepting innovations and new practices. This study was designed to provide a layer of understanding not seen in the DTTpsilas study by examining whether socio-economic and cultural indicators matter in how IT security and privacy issues are being perceived in global FSIs. Two relevant hypotheses were developed to test our assertions. The main finding of the study was that such contextual factors may not be sufficient in differentiating how global FISs view or respond to key IT security and privacy issues. However, our study found one item related to security awareness training for FISspsila employees to vary significantly across the surveyed regions when the gross domestic product (GDP per capita) variable was used in the analysis. It is hoped that our studypsilas findings and conclusion will be beneficial to practitioners and researchers.
Towards Privacy Taxonomy-Based Attack Tree Analysis for the Protection of Consumer Information Privacy	There is a strong legal and ethical imperative for organisations to protect consumer information privacy. In this paper we present a method called privacy taxonomy-based attack tree analysis (PTATA). PTATA involves the combination of privacy violation taxonomies and attack trees. It assists organisations in protecting information privacy by providing a means to analyze weaknesses in their protective measures. We define privacy violation taxonomies, as well as review attack trees, and illustrate the practical implementation of PTATA through example scenarios. The advantages and drawbacks to our method are also discussed. The paper ends with future research which may build on this work.
Incorporating Privacy Outcomes: Teaching an Old Dog New Tricks	Canadian government bodies are subject to a number of requirements, including legislation, regulations,directives and policies, that speaks to informational privacy. These have come to be considered synonymous with the completion of a Privacy Impact Assessment. Some go so far as to specifically require an assessment, but few speak to specific technical content. Nor are there process requirements for sustaining privacy standards once the assessment document is submitted. At best, recommendations are identified to enhance the privacy posture of a program area's information management practices, but there is no mechanism to ensure that they are implemented. We propose the PIA process be adapted to mandate privacy outcomes in terms of specific actions that must betaken once the assessment is complete. Starting with the established PIA document, the program area can identify how to best marry the privacy requirements with the established business processes supporting the service delivery line. The result would incorporate privacy outcomes as ongoing activities and include not only consideration of agency requirements for personal information management, but also the impact to an individual's informational privacy.
Limiting data collection in application forms: A real-case application of a founding privacy principle	Application forms are often used by companies and administrations to collect personal data about applicants and tailor services to their specific situation. For example, taxes rates, social care, or personal loans, are usually calibrated based on a set of personal data collected through application forms. In the eyes of privacy laws and directives, the set of personal data collected to achieve a service must be restricted to the minimum necessary. This reduces the impact of data breaches both in the interest of service providers and applicants. In this article, we study the problem of limiting data collection in those application forms, used to collect data and subsequently feed decision making processes. In practice, the set of data collected is far excessive because application forms are filled in without any means to know what data will really impact the decision. To overcome this problem, we propose a reverse approach, where the set of strictly required data items to fill in the application form can be computed on the user's side. We formalize the underlying NP Hard optimization problem, propose algorithms to compute a solution, and validate them with experiments. Our proposal leads to a significant reduction of the quantity of personal data filled in application forms while still reaching the same decision.
Privacy-preserving resource evaluation in social networks	In new generation social networks, we expect that the demand of tools allowing the user to effectively control privacy, without relying on the provider trustworthiness, will be more and more increasing. A lot of precious information is currently released by users with no privacy control whenever they evaluate resources, which, for example, is done in Facebook through the ΓÇ£Like ButtonΓÇ¥. A mechanism allowing the user to express her preferences fully preserving her privacy is thus desired, especially if it is able to protect user privacy also in case of untrustworthy social network provider. In this paper, we propose a solution to this problem, based on a DHT-based P2P social network and on a cryptographic protocol relying on partially blind digital signatures. The protocol is shown to be a solution to the trade-off between feasibility and security, since it guarantees the needed security requirements without including the complex features of existing e-voting systems.
Aggregation and privacy in multi-relational databases	The aim of privacy-preserving data mining is to construct highly accurate predictive models while not disclosing privacy information. Aggregation functions, such as sum and count are often used to pre-process the data prior to applying data mining techniques to relational databases. Often, it is implicitly assumed that the aggregated (or summarized) data are less likely to lead to privacy violations during data mining. This paper investigates this claim, within the relational database domain. We introduce the PBIRD (Privacy Breach Investigation in Relational Databases) methodology. Our experimental results show that aggregation potentially introduces new privacy violations. That is, potentially harmful attributes obtained with aggregation are often different from the ones obtained from non-aggregated databases. This indicates that, even when privacy is enforced on non-aggregated data, it is not automatically enforced on the corresponding aggregated data. Consequently, special care should be taken during model building in order to fully enforce privacy when the data are aggregated.
Privacy invasion in business environments	It is not uncommon for business managers to use recent innovations in information and communications technology to monitor employees and job candidates. These methods not only rely on heavy surveillance during working hours of employees but can also be applied outside their professional environment, to impinge on their personal lives. Surveillance techniques encompass such traditional means like recording cameras to more recent methods including analyzing social networks pages, performing extensive web searches and dealing with online data brokers. While monitoring initiatives set up by employers can have benefits for companies, the threat to privacy they entail can deteriorate the mental and physical health of employees and have a negative impact on the quality of relationship between colleagues. Businesses have a social responsibility and need to ensure that their behavior does not infringe upon their employee's rights to privacy. In this non-technical paper, we discuss some online approaches adopted by companies regarding employee surveillance. We elaborate on various methods employed by managers to monitor their employees and gain as much information as possible on job candidates. Then, these techniques are further discussed from the standpoint of their moral and legal perspectives with regards to privacy rights.
Towards privacy-preserving access control with hidden policies, hidden credentials and hidden decisions	The growing adoption of cloud technology in sensitive application domains, such as medicine, gives rise to new problems in maintaining the privacy of the involved parties during authorisation. In such domains, an honest but curious service provider can derive sensitive information purely from the authorisation process. In this paper, we present a detailed discussion of this rising problem including a concrete example and argue the need for the combination of hidden credentials, hidden policies and hidden decisions. We then show that mechanisms explored in previous work only cover individual aspects of this problem, but do not achieve a comprehensive solution without making restrictive assumptions on the resources, policies or subjects to be protected. As a first step towards solving this problem, we introduce an abstract foundation for using homomorphic cryptography to provide the required combination of privacy as a wrapper for other access control (AC) mechanisms. We achieve hidden policies, hidden credentials and even hidden access control decisions, so that the subject of an AC request only learns whether or not access was granted. Meanwhile, the provider of a resource learns nothing at the policy decision point and only access frequencies for individual resources at the policy enforcement point. We postulate that this is the maximum achievable level of protection in the authorisation process, without making restrictive assumptions on the resources, policies or subjects to be protected. Once homomorphic cryptography achieves satisfactory performance, our model can be used to transparently add this protection to other access control models.
SIPPA-2.0 - Secure information processing with privacy assurance (version 2.0)	We present a two-party secure information processing protocol referred to as SIPPA-2.0 - targeted towards privacy preserving biometric data comparison and reconstruction. The original intention of SIPPA as reported previously is to enable private data comparison and reconstruction between a client and a server when (a) the client possesses some data that are ΓÇ£sufficiently similarΓÇ¥ to that of the server, and (b) the server provides a scalar helper data to facilitate private data reconstruction by the client. In SIPPA-2.0, private data comparison and reconstruction are based on new theoretical results and a novel secure computation protocol referred to as SLSSP. These new results allow us to design and develop the much improved SIPPA and SLSSP protocols guaranteeing (a) security under semi-malicious model rather than just semi-honest model, and (b) privacy assurance with arbitrary reconstruction accuracy controllable by the server. Security analysis proving SLSSP secure under the semi-honest and semi-malicious models is presented. SIPPA-2.0 is applied to enable privacy preserving fingerprint comparison; where two parties can compare their fingerprint samples and can obtain a similarity score without revealing their raw fingerprint to each other. Experimental results on the accuracy of fingerprint matching and the run-time performance are also reported.
Platform for privacy preferences (P3P): Current status and future directions	Web sites usually express their privacy practices in natural language text that is often complex, informal and possibly confusing. The platform for Privacy Preference (P3P) has been proposed by W3C as a technology for expressing privacy practices of web sites in precise, machine readable language. This paper provides an account of the current status of research on P3P and proposes directions for future research, together with some possible solutions. Cloud computing (SaaS), anti-phishing, and mobile applications are some of the aspects that we consider. We claim that P3P and P3P-based techniques have considerable potential to be developed beyond their current status. The challenge is to design formalized privacy policy languages that can enable computers to process the privacy practices of web sites. In this way, many privacy issues, such as filtering web sites, combining their policies, etc., will be able to be dealt with automatically by privacy agents.
An implementation of secure two-party computation for smartphones with application to privacy-preserving interest-cast	In this paper, we present an implementation of the FairPlay framework for secure two-party function computation on Android smartphones, which we call MobileFairPlay. Mobile-FairPlay allows high-level programming of several secure two-party protocols, including protocols for the Millionaire problem, set intersection, computation of Jaccard similarity coefficient, etc. All these functions are useful in the context of mobile social networks and opportunistic networks, where parties are often requested to exchange sensitive information (list of contacts, interest profiles, etc.) to optimize network operation. To demonstrate the feasibility of MobileFairPlay, we present an application to privacy-preserving interest-casting in opportunistic networks, implementing a recently proposed protocol. We tested running times of the implemented protocol on several Android phones, obtaining very reasonable (up to 5sec) running times. These results clearly promote MobileFairPlay as a feasible security framework for mobile environments.
A Diffie-Hellman based privacy protocol for Car-to-X communication	For Car-to-X (C2X) communication, group signature based protocols can provide privacy and authentication for vehicles that are members of the respective group. Current group approaches all rely on a centralized group key generation and distribution. We propose a novel decentralized approach based on n-party Diffie-Hellman key establishment. The proposed protocol implies a low latency for key establishment and a high robustness towards possible failures of single nodes. Simulations have been carried out to evaluate privacy enhancements of the proposed protocol in presence of a global passive adversary.
Privacy challenges of open APIs: Case location based services	Location coordinates provide interesting context data for various purposes. In the early days location data was mainly connected to emergency services, but nowadays several social and commercial applications can benefit from users' position information. Smartphones may reveal location data directly to application developers, but due to the latest developments any mobile can be traced using operators' infrastructure. However, there are several technology, business, usability and privacy challenges to be solved before successful and widespread location based services (LBS) can be offered. This paper focuses on the usability and privacy challenges, utilizing both operator and internet location services. The LBS challenges are evaluated and then followed by a definition of a location broker model. The implementation of the corresponding proof of concept is described in detail. Finally the conclusions with future research proposals are presented.
Beyond privacy policies - assessing inherent privacy risks of consumer health services	There is a rapidly growing market for direct-to-consumer health services offered through the Internet and other information and communication technologies (ICT). Personal health information is one of the most sensitive types of data;while consumer health services have many potential health benefits, privacy advocates have warned consumers about the privacy risks associated with the indiscriminate use of direct-to-consumer services. Some tools and methods have been developed to aid consumers in assessing the privacy risk of ICT-based consumer health services. Most of these methods focus on the privacy policies published by the service provider, and are limited to a particular class of service offerings, e.g., Personal Health Records. While these methods have proven useful in gauging the apparent risk associated with certain types of services, they fall short of addressing the inherent risks of an entire spectrum of different service types. Moreover, privacy policy based risk assessment falls short of catching some of the more subtle privacy threats, such as indirect information disclosure due to targeted advertisements and social computing. This paper attempts to fill this gap by proposing a complementary tool to aid consumers in gauging the inherent privacy risks associated with consumer health services. The tool was developed based on a systematic review of the types of services and their associated privacy risks.
Safe realization of the Generalization privacy mechanism	An increasing number of surveys and articles high-light the failure of database servers to keep confidential data really private. Even without considering their vulnerability against external or internal attacks, mere negligences often lead to privacy disasters. The advent of powerful smart portable tokens, combining the security of smart card microcontrollers with the storage capacity of NAND Flash chips, introduces today credible alternatives to the systematic centralization of personal data on servers. Individuals can now store their personal data (e.g., their medical folder) in their own smart tokens, kept under their control, and never disclose in clear their private data to the outside untrusted world. However, this new opportunity of managing and protecting personal data conflicts with the objective of implementing knowledge-based decision making tools on top of centralized data. This paper precisely addresses this issue and proposes to adapt the traditional Generalization privacy mechanism to an environment composed of a large set of tamper-resistant smart portable tokens seldom connected to a highly available but untrusted infrastructure. This conjunction of hypothesis makes the problem fundamentally different from any previously studied privacy-preserving data publishing problem we are aware of.
Privacy-preserving matchmaking For mobile social networking secure against malicious users	The success of online social networking and of mobile phone services has resulted in increased attention to mobile social networking. Matchmaking is a key component of mobile social networking. It notifies users of nearby people who fulfil some criteria, such as having shared interests, and who are therefore good candidates for being added to a user's social network. Unfortunately, the existing matchmaking approaches are troublesome from a privacy point of view. One approach has users' smartphones broadcast their owners' personal information to nearby devices. This approach reveals more personal information than necessary. The other approach requires a trusted server that participates in each matchmaking operation. Namely, the server knows the interests and current location of each user and performs matchmaking based on this information. This approach allows the server to track users. This paper proposes a privacy-preserving matchmaking protocol for mobile social networking that lets a potentially malicious user learn only the interests (or some other traits) that he has in common with a nearby user, but no other interests. In addition, the protocol is distributed and does not require a trusted server that can track users or that needs to be involved in each matchmaking operation. We present an implementation and evaluation of our protocol on Nexus One smartphones and demonstrate that the protocol is practical.
The ultimate invasion of privacy: Identity theft	Identity theft has become one of the fastest growing crimes. Most people are unaware of the amount of data they disclose over all the Internet services proposed by search engines, social networking sites, e-commerce web sites, free online tools, etc. They are also unaware that this data can be easily aggregated, data-mined and linked together, which may lead to a potential identity theft should it fall into the wrong hands. If one adds up all of his online searching, communicating, shopping, browsing, blogging, chatting, reading and news sharing, one would realize that one revealed a complete picture of oneself and perhaps some information about his relatives, friends, colleagues, employer, etc. The potential value of this data is considerable for criminals. This paper deals with identity theft and all the issues raised by this type of computer crime. More precisely, it illustrates the variety of information that hackers may want to sift through, the attacks that they may perform and the locations where they can find the information.
Online information privacy: Agent-mediated payoff	With the rapid development of applications in open distributed environments such as eCommerce, privacy of information is becoming a critical issue. Information about the preferences, activities, and demographic attributes of people using online shopping is very valuable to online businesses. Beyond the general anxieties with sharing personal information, people may more specifically have concerns about becoming increasingly identifiable; as increasing amounts of personal data are acquired. Not only that, but also it is widely known that information about consumers is often sold to online marketing and advertising companies, generally without the knowledge of consumers [4, 16]. In this paper, we introduce a model where people can opt out to share personal information for a payoff value that balances out the costs of privacy. Our model is based on agents working on behalf of consumers to maximize their benefit. The analysis of the model and a proof of concept implementation are presented in this paper.
Delegation of access rights in a privacy preserving access control model	Delegation is a process of sharing access rights by users of an access control model. It facilitates the distribution of authorities in the model. It is also useful in collaborative environments. Despite the advantages, delegation may have an impact on the access control model's security. Allowing users to share access rights without the control of an administrator can be used by malicious users to exploit the model. Delegation may also result in privacy violations if it allows accessing data without the data provider's consent. Even though the consent is taken, the privacy can still be violated if the data is used differently than the data provider agreed. Our work investigates data privacy in delegation. As a contribution, a privacy model is introduced that allows a data provider setting privacy policies that state how their data should be used by different organizations or parties who are interested in their data. Based on this setting, a delegation model is designed to consider the privacy policies in taking delegation decisions and also, to set the data usage criteria for the access right receivers. In addition to privacy policies, several delegation policies and constraint have been used to control delegation operations. Delegation is studied within a party and between two parties.
Privacy Data Envelope: Concept and implementation	In this paper, we present a privacy control mechanism called PDE (Privacy Data Envelope) allowing users to protect their privacy sensitive content travelling over social and communication networks. Our solution is based on privacy policies expressed by the user and associated with his content. This approach makes use of a decentralized architecture carried out through a PDE feature that has to be added to the existing application access tools like email clients and web browsers. A prototype has been developed to embody the PDE paradigm and to illustrate a scenario where such envelopes cross the boundaries of enterprise social networks and other communications tools. Preliminary performance evaluations were done helping the understanding of the PDE plug-in behaviors and computation overhead.
Efficient privacy preserving reputation protocols inspired by secure sum	The secure sum protocol is a well-known protocol for computing the sum of private inputs from distributed entities such that the inputs remain private. In this paper we present protocols for computing reputation in a privacy preserving manner that are inspired by the secure sum protocol. We provide a protocol that is secure under the semi-honest adversarial model as well as one that is secure under the stronger non-disruptive malicious model. Although the protocols are inspired by secure sum, they do not suffer from the issues that plague secure sum. Our protocols are resilient against colluding entities, which secure sum is not. The protocols that we develop are also efficient. We require an exchange of O(n) messages under the semi-honest model, where n is the number of feedback providers in the protocol. This is the same complexity offered by secure sum. Our protocol for the non-disruptive malicious model exchanges O(N log n) messages, where N is the number of entities in the system.
A new perspective of privacy protection: Unique distinct l-SR diversity	More and more public data sets which contain information about individuals are published in recent years. The urgency to reduce the risk of privacy disclosure from such data sets makes the approaches of privacy protection for data publishing widely employed. There are two popular models for privacy protection: k-anonymity and l-diversity. k-anonymity focuses on reducing the probability of identifying a particular person, which requires that each equivalence class (a set of records with the same identifier attributes) contains at least k records. l-diversity concentrates on reducing the inference from released sensitive attributes. It requires that each equivalence class has at least l ΓÇ£well-representedΓÇ¥ sensitive attribute values. In this study, we view the privacy protection problem in a brand new perspective. We proposed a new model, Unique Distinct l-SR diversity based on the sensitivity of private information. Also, we presented two performance measures to evaluate how much sensitive information can be inferred from an equivalence class. l-SR diversity algorithm was implemented to achieve Unique Distinct l-SR diversity. We tested l-SR diversity on one benchmark data set and two synthetic data sets, and compared it with other l-diversity algorithms. The results show that our algorithm achieved better performance on minimizing inference of sensitive information and reached the comparable generalization data quality compared with other data publishing algorithms.
Towards a privacy preserving policy based infrastructure for social data access to enable scientific research	In this paper, we present a policy based infrastructure for social data access with the goal of enabling scientific research, while preserving privacy. We describe motivating application scenarios that could be enabled with the growing number of user datasets such as social networks and medical datasets. These datasets contain sensitive user information and sufficient caution must be exercised while sharing them with third parties to prevent privacy leaks. One of the goals of our framework is to allow users to control how their data is used, while at the same time enable researchers to use the aggregate data for scientific research. We extend existing access control languages to explicitly model user intent in data sharing as well as supporting additional access modes viz. Complete Access, Abstract Access and Statistical Access that go beyond the traditional allow/deny binary semantics of access control. We then describe our policy infrastructure and show how it can be used to enable the above scenarios while still guaranteeing individual privacy. We then present our initial implementation of the framework extending the SecPAL authorization language to account for new roles and operations.
Secure Information Processing with Privacy Assurance - standard based design and development for biometric applications	This paper presents the design and development of a technique referred to as SIPPA - Secure Information Processing with Privacy Assurance - for biometric data reconstruction. SIPPA enables a client/server model with the following two properties: (1) the client party can compare the similarity between his/her sample data with the source data on the server side - without each party revealing his/her data to another, nor to a third party. If the sample data is ΓÇ£sufficiently similarΓÇ¥ to the source data, the client can reconstruct the source data by using only the sample data and some helper data with negligible overhead provided by the server. The main contributions of this paper are: (1) algorithmic steps of SIPPA and its relationship to privacy homomorphism, (2) a parallel SIPPA architecture, and (3) the realization of parallel SIPPA as a service component for BioAPI 2.0 framework using Java RMI technology. To demonstrate its potential application, we apply SIPPA to the reconstruction of biometric data, and more specifically, biometric face images represented in terms of linearized vectors.
Vampire bats: Trust in Privacy	Trust and privacy are ancient social concepts. Work on formalizing trust dates back to the mid-nineties, while work on formalizing privacy is in its infancy. The two concepts have a number of similarities including considerations of information type and sensitivity to inform actions, relationship between the communicating parties, and the context or purpose for communication. There are some key differences. Privacy, unlike trust, is legislated. In Canada, there are also a number of regulations, directives and policies that come along with the legislation. Trust, on the other hand, is the Wild West; almost anything goes. Early attempts at formalizing privacy have been largely restricted to P3P initiatives and other policy developments. Not only have they been largely ignored by the user community, but also because of the limited scope in application seem to fail to actually enable privacy protection. On the other hand, early trust models have taken a different approach. Instead, using a natural science approach and artificial agents, trust is circumscribed, simple and most importantly - repeatable. In the context of failed attempts at formalizing privacy through policy, learnings from trust can be utilized to advance the computational notion of privacy protection. This paper takes the work on formalizing privacy in a much needed new direction by examining the potential of an appropriate and applicable framework for privacy based on extant trust formalizations. It proposes a formalization for privacy can be based on trust, and would outline the types of privacy, examine privacy based decision-making, and explore the applicability of the agents as appropriate representations of people in the computational environment.
Analysis of Privacy Impact Assessments within Major jurisdictions	In this paper we define and analyse the notion of a Privacy Impact Assessment (PIA), with reference to various examples that have been carried out in different countries. We compare and contrast such approaches and examine current trends, including the potential role - and limitations - of technology in future assessments.
Social networks for health care: Addressing regulatory gaps with privacy-by-design	Social computing is a relatively new approach to systems design that emphasizes the importance of facilitating collaboration and communication between users. Although social networking is now part of mainstream culture, the use of these applications in the health care space is still in its infancy in Canada. As major vendors are preparing to enter the marketplace, it is important for a wide variety of stakeholders to discern the ramifications of this next wave of technological innovation. This paper discusses social networking applications for health care, and the challenges of dealing with this new type of information management system under current Canadian law. While regulatory authorities have considered the privacy and security implications of social networking in the course of investigating complaints, this paper contains the first explicit analysis of the legal difficulties surrounding the use of social networking for health care applications in Canada. Those risks not covered by the current regulatory framework are assessed from the standpoint of privacy-by-design, as we discuss how software developers can build privacy protection into social networking applications.
Privacy: Protections and Threats	This chapter contains sections titled: The Dimensions of Privacy, Privacy Protection in the United States, Privacy Threatened, Privacy Lost, Why Privacy?
A user-centric privacy manager for future energy systems	The integration of modern information and communication technologies with the energy infrastructure as incarnated by the Smart Grid vision raises new threats in term of information and identity theft, privacy breaches and failure to ensure data privacy compliance. In this paper, we discuss the need to for strong user-centric privacy protection in a Smart Grid context and propose a privacy manager to allow users (individual and non-individual energy consumers) to be involved in the management of their privacy. The privacy manger is designed as a software component running on Smart Energy Gateway (SEG) deployed at users' premises. In essence, we recommend and employ trusted computing technologies to ensure data minimization i.e., reduce the amount and type of user's personal data which is disclosed to other smart grid stakeholders, including those running applications on the same SEG. The privacy manager also provides users with the ability to specify their privacy preferences with respect to the handling of their privacy sensitive data. We also describe how the SEG security infrastructure built on a hardware security anchor would help to reliably enforced user-specified privacy policies. Moreover the paper discusses privacy manager functions such as the support for pseudonimity, secure storage and data masking techniques. The development of the user-centric privacy manager for SEG is an integrated part of our ongoing effort towards developing a privacy-preserving advanced metering infrastructure.
Adapting the Pretty Good Privacy Security Style to Power System Distributed Network Protocol	Power system modernization with increasing operation automation and integration results in growing computer network access. This facilitates cyber-attackers' capabilities to assume control over power system operations that could cause serious blackouts. Security therefore becomes a critical issue for DNP3, a commonly used protocol for power system communications. This paper proposes cyber-security based on Pretty Good Privacy (PGP) for DNP3 to strengthen computer network security. This PGP-based cyber-security provides authentication capabilities using public key cryptography, with enhanced performance using symmetric keys for most of the encryption. This paper provides a symmetric cipher key exchange mechanism using PGP-based cyber-security to further enhance the power system security. The proposed PGP-based cyber-security is implemented as a pseudo-layer below the DNP3 data-link layer to minimize any impact on the DNP3 specifications and the operations of original DNP3 devices. This PGP-based cyber-security provides confidentiality, identity authentication, transmission content authentication, and nonrepudiation
Smart grid security, privacy, and resilient architectures: Opportunities and challenges	Any complex dynamic infrastructure network typically has many layers, decision-making units and is vulnerable to various types of disturbances. Cyber connectivity has increased the complexity of the control systems and facilities it is intended to safely and reliably control. Thus, in order to defend electric infrastructure against the impacts of cyber-physical attacks, significant challenges must be overcome before extensive deployment and implementation of smart grid technologies can begin. Cyber security and interoperability are two of the key challenges of the smart grid transformation. As for security, it must be built-in as part of its design and NOT glued on as afterthought. Regarding recent cyber threat reports, it is fundamental to separate hype from the truth. What is most concerning about such reports is mainly one piece from an early article: The response to the alert was mixed. An audit of 30 utility companies that received the alert showed that only seven were in full compliance, although all of the audited companies had taken some precautions. This is the reality that needs to be addressed. A key challenge is to enable secure and very high-confidence sensing, communications, and control of a heterogeneous, widely dispersed, yet globally interconnected system. It is even more complex and difficult to control it for optimal efficiency and maximum benefit to the ultimate consumers while still allowing all its business components to compete fairly and freely. In the electric power industry and other critical infrastructures, new ways are being sought to improve network efficiency by eliminating congestion problems without seriously diminishing reliability and security. Effective, intelligent, hierarchically distributed control is required within a layered defense architecture that would enable parts of the networks to remain operational and even automatically reconfigure in the event of local failures or threats of failure. Sensing, communication and con- rol systems are needed across broad temporal, geographical, and industry scalesfrom devices to power-system-wide, from fuel sources to consumers, from utility pricing to demand response, and so on. With increased deployment of feedback and communication, opportunities arise for reducing consumption, for better exploiting renewable sources, and for increasing the reliability and performance of the transmission and distribution networks. At the same time, however, closing loops where they have never been closed before, across multiple temporal and spatial scales, creates control challenges as well. Societal and governmental visions for the smart grid will require the engagement of the controls community for their realization. Feedback, optimization, estimation, dynamics, stability... these and other control system concepts are core to smart grid technology. In many ways, the smart grid is a control problem! Another major strategic goal is to enable real-time demand management and responseto make is possible for customers to modify consumption in reaction to hourly changes in electricity prices and availability. We see inexpensive but advanced two-way secure wireless communications as essential: Dynamic modeling of energy flows, their optimization and control depend on the availability of trustworthy data streams from sensors and monitors distributed throughout the electricity delivery system, for example on power lines and local distribution transformers. Drawing on those inputs and the even more ubiquitous data transmitted securely and wirelessly from substations, operations engineers will be able to spot potential problems and make adjustments before problems arise. As these systems are put in place, they will provide the opportunity to investigate the whole range of issues that arise in connection with the smart grid, from hybrid vehicle integration and electricity market design to system automation and security. If the smart grid is to fulfill its promise, it nee
Privacy and confidentiality in Cyber-Physical Power Systems	Cyber-Physical Power Systems consist of significant cyber components that mange the physical electric power infrastructure under distributed control of power electronics devices. This represents a departure from more centralized SCADA-type control. NERC Critical Infrastructure Protection standards emphasize the need to protect the power infrastructure from both cyber and physical attacks and recent NIST documents also emphasize the need for privacy and confidentiality in both the AMI smart grid. The physical flow of power, the flow of sensor readings through network traffic, and the cyber computation all contain information. The combination of these information flows presents new challenges in securing cyber-physical power systems. These challenges and potential solutions are outlined in this paper.
A private matter [privacy in society]	Discusses the gradual erosion of privacy in society and the ways in which individuals are being monitored. The constitutional right to privacy is mentioned based on provisions within the Bill of Rights and amendments. The relationship between globalization and privacy is finally considered
BlueStar, a privacy centric location aware system	This paper provides the research background and system approach for project BlueStar. Our aim is to develop a system using a flexible in/outdoor location management scheme that allows for only the end-user to be aware of their location, while still enabling them to access location-relevant information from a centralised source. In such a system the user can choose the level of granularity with which they provide or publish their location details in contrast to systems in which a fixed network is used to track the user. BlueStar addresses the need for a scalable user-centric end-to-end solution in which end-user privacy is protected. As we show in this paper many existing indoor tracking systems rely on special purpose receivers (badges) and transmitters in conjunction with a costly site radio survey, neither of which is necessary in the BlueStar model. Finally, this paper describes one possible location-aware peer-to-peer application, using location sniffing, namely an "ad-hocracy".
Enhancing User Privacy - Location Based Search Using MEMD	Aim of this paper is to discuss about detection of mobile (cell phone) misplaced in vibration mode. This equipment will be able to detect the mobile phone and produce a beep sound and show the direction in which the phone is present. To detect the mobile device, Incoming mobile signal is used and signal is processed to produce the required output. This device has the capability to shows the direction and aid the user in finding the lost mobile phone. The architecture is flexible to connect and detect the Mobile from Internet by using J2EE technology.
Or Best Offer: A Privacy Policy Negotiation Protocol	Privacy policy languages, such as P3P, allow websites to publish their privacy practices and policies in machine readable form. Software agents designed to protect users' privacy follow a "take it or leave it" approach that is inflexible and gives the server ultimate control. Privacy policy negotiation is one approach to leveling the playing field by allowing a client to negotiate with a server to determine how that server collects and uses the client's data. We present a privacy policy negotiation protocol, "or best offer", that includes a formal model for specifying privacy preferences and reasoning about privacy policies. The protocol is guaranteed to terminate within three rounds of negotiation while producing policies that are Pareto-optimal, and thus fair to both the client and the server.
Automatic Compliance of Privacy Policies in Federated Digital Identity Management	Privacy [4] in the digital world is an important problem which is becoming even more pressing as new collaborative applications are developed. The lack of privacy preserving mechanisms is particularly problematic in federated identity management contexts. In such a context, users can seamlessly interact with a variety of federated web services, through the use of single-sign-on mechanisms and the capability of sharing personal data among these web services. We argue that comprehensive privacy policies should be stated by federated service providers and proactively checked by these providers, before disclosing users' data to federated partners. To address such requirements, we introduce mechanisms and algorithms for policy compliance checking between federated service providers, based on an innovative policy subsumption approach. We formally introduce and analyze our approach.
Privacy in the Semantic Web: What Policy Languages Have to Offer	Uncontrolled disclosure of sensitive information during electronic transactions may expose users to threats like loss of privacy and identity theft. The means envisioned for addressing protection of security and privacy in the context of the Semantic Web are policy languages for trust establishment and management. Although a number of policy languages have been proposed, it is unclear how well each language can address users' privacy concerns. The contribution of this work is an independent, scenario-based comparison of six prominent policy languages, namely Protune, Rei, Ponder, Trust-X, KeyNote and P3P-APPEL, with respect to the needs that users have in protecting their personal, sensitive data. We present how each language addresses access control for objects, such as user credentials and sensitive policies. We evaluate how each language defines or imports hierarchies of resources, whether the language supports protection of user information after it has been released, whether the language supports the principle of least privilege and more. The evaluation is not only an analytical literature study but also rich in actual implementations in all six languages.
Towards Privacy-Aware Handling of Authorizations	Privacy issues have hindered centralised authentication approaches from being adopted by a wide range of users. This also applies to authorizations which suffer from privacy problems when stored and processed centrally. We present first steps towards a framework of privacy-aware handling of authorizations. We split up the storage and the processing of access control policies in a user-centric approach. We illustrate our approach at the example of a security infrastructure scenario.
Performance Evaluation of Privacy-Preserving Policy Reconciliation Protocols	The process of policy reconciliation allows multiple parties with possibly different policies to resolve differences in order to reach an agreement on an acceptable policy. Previous solutions for policy reconciliation required the participants to reveal their entire security policy in order to reach an agreement. It was not until recently that new protocols were developed which take into account the privacy concerns of reconciliating parties. In this paper we present a performance evaluation of these privacy-preserving reconciliation protocols with a focus on quantifying the added cost due to the privacy guarantees.
On Parametric Obligation Policies: Enabling Privacy-Aware Information Lifecycle Management in Enterprises	Enterprises that collect and process personal data must deal with related privacy management issues. It is not just a matter of privacy-aware access control: privacy obligation policies, dictating duties and expectations on how personal data has to be handled, must be considered too. The management of obligation policies is a promising area but it is still underestimated. Enterprises require solutions that enable automation and can leverage their current identity management solutions. HP Labs have been working on this topic in the last few years, also in the context of the EU PRIME project. In this paper we present our recent work on parametric obligation policies and a related obligation management framework to deal with a scalable management of these policies on large amounts of data, stored in distributed data repositories.
Towards Learning Privacy Policies	With the proliferation of personal computing devices users are creating a variety of digitized personal information, from personal contact databases and multimedia content to context data such as location, activity and mood. Preventing unintended disclosure of such information is a key motivator for developing privacy management frameworks. It is equally critical that protecting privacy does not prevent users from completing essential tasks. Current efforts in privacy management have focussed on notations for privacy policy specification and on user interaction design for privacy management. However, little has been done to support automated analysis and learning of privacy policies. We advocate an approach based on inductive logic programming (ILP) for automatic learning of privacy policies. ILP is preferred over statistical learning techniques because it produces rules (privacy policies) which are comprehensible to the user and amenable to automated analysis.
Confidentiality, Privacy and Trust Policy Enforcement for the Semantic Web	In this position paper we describe aspects of securing the semantic Web. In particular, we discuss ways of enforcing confidentiality privacy and trust polices. We also discuss our research on secure geospatial semantic Web. Our application of secure semantic Web technologies for assured information sharing is also discussed.
Enhancing Web privacy protection through declarative policies	The platform for privacy preferences (P3P) is a W3C framework for Web privacy management. It provides a standard vocabulary that Websites can use to describe their privacy practices. The presence of Web site published P3P policies enable users to configure Web browsers to allow, block or warn users during access and data exchange with Websites. It's a good idea that unfortunately is rarely used. We identify three primary reasons: (i) the languages available to describe user privacy preferences are not sufficiently expressive, (ii) P3P policies published by Web sites are not trusted by users and (iii) P3P framework does not provide a coherent view of available privacy protection mechanisms to the user towards addressing these issues; we present enhancements to the P3P framework. We use a more expressive policy language based on deontic concepts to describe user privacy-related policies, constraints and preferences. We introduce a new trust model for Websites and describe its use in user privacy preferences. Finally, we present sample policies to demonstrate the relevance of our work and offer it as an effective starting point towards enhancing Web privacy management.
Deriving semantic models from privacy policies	Natural language policies describe interactions between and across organizations, third-parties and individuals. However, current policy languages are limited in their ability to collectively describe interactions across these parties. Goals from requirements engineering are useful for distilling natural language policy statements into structured descriptions of these interactions; however, they are limited in that they are not easy to compare with one another despite sharing common semantic features. In this paper, we propose a process called semantic parameterization that in conjunction with goal analysis supports the derivation of semantic models from privacy policy documents. We present example semantic models that enable comparing policy statements and discuss corresponding limitations identified in existing policy languages. The semantic models are described by a context-free grammar (CFG) that has been validated within the context of the most frequently expressed goals in over 100 Website privacy policy documents. The CFG is supported by a qualitative and quantitative policy analysis tool.
Privacy protection of enterprise information through inference analysis	Ensuring that disclosure of information to outside entities is in conformance with the enterprise privacy policies is of utmost concern for all enterprises dealing with consumer information. The existing protection measures proposed for meeting this goal are inadequate. In this paper we present an approach in which the privacy label taxonomy is developed to classify information types in an enterprise by their privacy labels. Inference analysis is performed on the information types using a disjunctive logic programming technique to detect violations of privacy labeling semantics in various information types. The analysis also provides the technique to deal with such violations so as to achieve a violation-free privacy labeling scheme.
Unification in privacy policy evaluation - translating EPAL into Prolog	Privacy policy evaluation engines enable queries whether a specific user is allowed to access specific data for a specific purpose. While tools for authoring, maintaining, and auditing privacy policies already exist, no tool exists yet to deal with unification within such policies, e.g., to enable queries if data might be modified by some user, or how many user entries satisfy a certain constraint. We show how this can be achieved by embedding enterprise privacy policies into Prolog. We show this concretely for IBM's Enterprise Privacy Authorization Language (EPAL). Based on the unification mechanisms of Prolog, our work enables general queries for privacy policies as well as quantitative measurements.
Translating privacy practices into privacy promises - how to promise what you can keep	Enterprises advertise privacy promises using the W3C Platform for Privacy Preferences (P3P). These privacy promises define what recipients can obtain what collected data for what purpose. Internally, enterprises can use fine-grained privacy practices such as defined by the Platform for Enterprise Privacy Practices (E-P3P) to enforce privacy. These internal privacy policies should guarantee and enforce the promises made to the customers. Since privacy practices reflect business internals, they can change frequently. As a consequence, it can be challenging to keep the promises up-to-date with the actual practices. To enable up-to-date privacy promises, we describe a methodology for enterprises to promise what they can keep. This is done by automatically transforming E-P3P privacy practices into corresponding P3P privacy promises that reflect the actual enterprise-internal behavior. These P3P promises can then be published on a regular basis. Whenever the internal policies change, the P3P promises can easily be updated as well.
Content Analysis of Privacy Policies for Health Social Networks	The Web is an important resource for health information. Pew's Internet and American Life Project found 62% of adult Web users looking for health-related information on health social networks. However, the National Survey on Identity and Privacy in Social Media by The Ponemon Institute reported that about 56% of adult users were anxious about the privacy of their personal information on social networks. This paper examines the privacy policies of 35 online health social networks selected based on the U.S. users' traffic. The objectives of this research are to determine the extent to which privacy policies of online health social networks comply with the principles of Fair Information Practice (FIP) and to evaluate the readability and accessibility of policies. To measure the readability of the policy statements, the Flesch Reading Ease Score and Flesch Kincaid Grade Level score metrics are used. The findings indicate that 9% of the websites in the sample had no privacy policy posted, and only about 26% of the websites in the sample fully complied with the FIP. Our findings show that compliance with the FIP principles is poor, and confirm that most policies require a reading skill higher than the Internet population's average literacy level.
Information Flow Control for Static Enforcement of User-Defined Privacy Policies	Information flow control (IFC) allows software programmers and auditors to detect and prevent the sharing of information between different parts of a program which, as a matter of policy, should be kept logically separate. However, the lack of widespread use of IFC suggests technology and usability barriers to adoption. The programming language JIF provides IFC on top of Java. To assess pragmatic issues and systematic limitations of using JIF for commercial privacy-preserving Web applications, we deliver the first Web-based case-study with customer-negotiated restrictions on data recipients and usage. On a practical level, from our experience of programming in JIF, we assess its suitability for preventing accidental misuse of personal information and deduce recommendations for future implementations. On a theoretical level, we explore the compatibility between static analysis and privacy policies configured at runtime.
A Multi-environment Application of Privacy Data Envelopes	This demonstration illustrates the concept of Privacy Data Envelopes (PDE) where each piece of information identified by the user as privacy-sensitive is embodied (or "enveloped") into a data structure that in addition to the initial raw data carries privacy-related properties and policies. We show a scenario where such envelopes cross the boundaries of enterprise social networks and other communications tools.
PrimAndroid: Privacy Policy Modelling and Analysis for Android Applications	The rapid growth of mobile applications has imposed new threats to privacy: users often find it challenging to ensure that their privacy policies are consistent with the requirements of a diverse range of of mobile applications that access personal information under different contexts. This problem exacerbates when applications depend on each other and therefore share permissions to access resources in ways that are opaque to an end-user. To meet the needs of representing privacy requirements and of resolving dependencies issues in privacy policies, we pro-pose an extension to the P-RBAC model for reasoning about plausible scenarios that can exploit such weaknesses of mobile systems. This work has been evaluated using the case studies on several Android mobile applications.
PPL: PrimeLife Privacy Policy Engine	Web 2.0 introduces new breaches in the privacy protection of personal data. Most of the users of such Internet media are not aware about the risks of publishing personal information. These threats can lead to identity thefts, scams, and cyber criminal attacks. In this paper we propose a framework, based on a privacy policy language called PPL (Primelife Policy Language), in which every user can control his personal information by imposing access and usage control restrictions. Sticky policies are used in order to keep the trace ability of these privacy constrains when the data is travelling from a domain to another. In this paper we detail the demo that shows how the user can express his privacy preferences, how the servers will comply with the privacy constraints stated in the sticky policies and how the data is shared with third parties according to the user's whishes.
A Policy Based Infrastructure for Social Data Access with Privacy Guarantees	We present a policy based infrastructure for social data access with the goal of enabling scientific research, while preserving privacy. We describe motivating application scenarios that could be enabled with the growing number of user datasets such as social networks, medical datasets etc. These datasets contain sensitive user information and sufficient caution must be exercised while sharing them with third parties to prevent privacy leaks. One of the goals of our framework is to allow users to control how their data is used, while at the same time enabling the aggregate data to be used for scientific research. We extend existing access control languages to explicitly model user intent in data sharing as well as supporting additional access modes that go beyond the traditional allow/deny binary semantics of access control. We describe our policy infrastructure and show how it can be used to enable the above scenarios while still guaranteeing individual privacy and present a prototype implementation of the framework extending the SecPAL authorization language to account for new roles and operations.
Collaborative Privacy Policy Authoring in a Social Networking Context	Recent years have seen a significant increase in the popularity of social networking services. These online services enable users to construct groups of contacts, referred to as friends, with which they can share digital content and communicate. This sharing is actively encouraged by the social networking services, with users' privacy often seen as a secondary concern. In this paper we first propose a privacy-aware social networking service and then introduce a collaborative approach to authoring privacy policies for the service. In addressing user privacy, our approach takes into account the needs of all parties affected by the disclosure of information and digital content.
Enhanced privacy in broadcast passive optical networks through the use of spectral slicing in waveguide grating routers	We have measured the ability of a third party to intercept upstream messages in both passive splitter-based and waveguide-grating router-based broadcast passive optical networks. Bit-error-rate (BER) measurements at 150 Mb/s indicate that privacy is enhanced by at least 14 dB in the router-based network, and will improve further with router developments.
Analyze a Privacy-Preserving Vehicular Communication Protocol and Propose a New One	Though security and privacy are two important issues in vehicular networks, limited works are done on the design of communication protocol until recently. Several proposals tackle these issues in the cryptographic way, such as using group signature to construct vehicular communication protocol. The proprieties of anonymity and traceability make group signature to the purpose to be used in designing secure and privacy-preserving vehicular communication protocol. We would point out that a current communication protocol for vehicular networks is not privacy-preserved, for its basis, a group signature, is unsatisfied with anonymity. In the end, we propose a new one which is based on one current efficient group signature.
Effectively Changing Pseudonyms for Privacy Protection in VANETs	As a technology to improve safety, efficiency and convenience in transportation, vehicular ad hoc networks(VANETs) attract more and more attentions of researchers. VANETs will achieve a series of applications by periodically broadcasting beacons containing vehicular status information such as position, velocity and direction. However, some attackers might also utilize the information to track users' whereabouts. Therefore, the lack of privacy protection might impede the further success of VANETs in the future. Frequently changing pseudonyms are commonly accepted as a solution to protect privacy in VANETs, but most pseudonym change algorithms are ineffective. This paper proposes a pseudonym change algorithm, called synchronous pseudonym change algorithm, where both simultaneity of changing pseudonyms and vehicular status information are taken into consideration. Simulation results show that the algorithm can improve the effectiveness of changing pseudonyms to protect privacy in VANETs.
A Novel Time-Obfuscated Algorithm for Trajectory Privacy	Location-based services (LBS) which bring so much convenience to our daily life have been intensively studied over the years. Generally, an LBS query processing can be categorized into snapshot and continuous queries which search on user location information and reply search results to the users. An LBS has full control to the location information, causing a user privacy concern. If an LBS has a malicious intention to infer the user privacy by tracking the user's routes to their destinations, it incurs a serious problem. In this paper, we propose a comprehensive trajectory privacy technique and combined ambient conditions to cloak location information based on the user privacy profile. We first propose a r-anonymity concept which preprocesses a set of similar trajectories R to blur the actual trajectory of a user. We then combine k-anonymity with s road segments to protect the user privacy. We introduce a novel time-obfuscated technique which breaks the sequence of the query issuing time for a user to confuse the LBS from knowing the user trajectory by sending a query randomly from a set of locations residing at the trajectories R. Despite the randomness incurring from the obfuscation process for providing a strong trajectory privacy protection, the experimental results showed that our trajectory privacy technique maintained the correctness of the query results at a competitive computational cost.
Privacy-Aware Service Integration	Privacy mechanisms exist for monolithic systems. However, pervasive environments that gather user data to support advanced services provide little control over the data an individual releases. This is a strong inhibitor for the development of pervasive systems, since most users do not accept that their personal information is sent out to the wild, and potentially passed over to third party systems. We therefore propose a framework to support user control over the data made available to service providers in the context of an OSGi based Extensible Service Systems. A formal privacy model is defined and service and policy descriptions are deduced. Technical system requirements to support these policies are identified. Since guaranteeing privacy inside the system is of little help if any malicious entity can break into it, a security architecture for OSGi based Extensible Service Systems is also defined.
A Trust-Based Approach to Control Privacy Exposure in Ubiquitous Computing Environments	In ubiquitous computing environments, service servers play a central role of actively providing information about a person to help people determine whether he is available for contact or not. A tradeoff exists in these systems: the more sources of data and the higher fidelity in those sources which can improve people's decision, the more privacy reduction. Alternatively, there is generally no a priori trust relationship among entities interacting in pervasive computing environments which makes it essential to establish trust from scratch. This task becomes extremely challenging when it is simultaneously necessary to protect the privacy of the users involved. In this paper, we first show how trust evaluation process of the user's system can be based on previous interactions and peer recommendations. A solution then relied on trust to control privacy disclosure is proposed that depends on pre-defined privacy policy. Several tuning parameters and options are suggested so that end-users can customize to meet the security and privacy requirement of a ubiquitous system.
Concealed Data Aggregation in Heterogeneous Sensor Networks using Privacy Homomorphism	Data aggregation is implemented in wireless sensor networks to reduce data redundancy and to summarize relevant and necessary information without requiring all pieces of the data. The benefit of data aggregation can be maximized by implementing it at every data aggregator on the path to the base station. However, data confidentiality requires sensor nodes to encrypt their data prior to transmission. Moreover, once data is encrypted by a sensor node, it should be decrypted at the base station to maintain end-to-end security. This makes the implementation of data aggregation very difficult because data aggregation algorithms require encrypted data to be decrypted. Consequently, data aggregation and secure communication have conflicts in their implementation. To achieve data aggregation and secure communication together, this paper employs privacy homomorphism which offers end-to-end concealment of data and ability to operate on ciphertexts. In the proposed protocol, the computational overhead imposed by the privacy homomorphic encryption functions is tolerated by employing a set of powerful nodes, called AGGNODEs.
Privacy-Aware Modelling and Distribution of Context Information in Pervasive Service Provision	Context awareness is an essential cornerstone in future pervasive computing systems. It has the potential to greatly reduce the user attention and interaction bottlenecks, to give humans the impression that services fade into the background, and to support intelligent personalization features. Nevertheless, in order to create such an environment, a growing amount of personal information has to be provided to the system, either manually or automatically. Hence the digital trace and representation users have in the system is getting dangerously detailed, thus stressing the need for privacy protection. DAIDALOS (Satyanarayanan, 2001) is a European research project in the area of 3G and beyond, which aims to combine heterogeneous networks in a transparent and seamless way, and develop on top of this a pervasive environment for applications and end-users. This paper describes the main models and mechanisms that have been established to provide federated context-aware services and protect the privacy of their users
Privacy-preserving location-dependent query processing	A mobile portable device will often make queries, to a remote database, that depend on its location: It may ask for the nearest coffee shop, restaurant, pharmacy, etc. For privacy reasons, the mobile unit may not wish to disclose its precise location to the remote database - while it is unavoidable that the cell phone company already knows the rough location of the customer ("somewhere in Lafayette "), it is quite another matter if the customer's precise location can be tracked over tune through his pattern of location-dependent queries to the remote database. This work describes an efficient protocol, between the client and database, through which a client can learn the answer to its location-dependent query without revealing to the remote database anything about his location, other than what the database can infer from the answer it gives to the query (which is unavoidable). We also analyze the performance of some other, simpler solutions, that do not require the database to run a protocol with the client, but that can reveal more information about the private location and also introduce inaccuracies in the answer - we quantify how much error these simpler schemes introduce in the answer.
Privacy-Preserving Location-Dependent Query Processing	A mobile portable device will often make queries, to a remote database, that depend on its location: It may ask for the nearest coffee shop, restaurant, pharmacy, etc. For privacy reasons, the mobile unit may not wish to disclose its precise location to the remote database - while it is unavoidable that the cell phone company already knows the rough location of the customer ("somewhere in Lafayette"), it is quite another matter if the customer's precise location can be tracked over time through his pattern of location-dependent queries to the remote database. This paper describes an efficient protocol, between the client and database, through which a client can learn the answer to its location-dependent query without revealing to the remote database anything about his location, other than what the database can infer from the answer it gives to the query (which is unavoidable). We also analyze the performance of some other, simpler solutions, that do not require the database to run a protocol with the client, but that can reveal more information about the private location and also introduce inaccuracies in the answer - we quantify how much error these simpler schemes introduce in the answer.
Privacy Preserving Trust Negotiation for Pervasive Healthcare	Healthcare systems are being extended to monitor patients with body sensors wirelessly linked to a mobile phone that interacts with remote healthcare services and staff. As such systems become more widespread, with multiple healthcare providers and security domains, the establishment of trust between users, providers and medical staff will become important. In this paper we implement the ETTG privacy-preserving trust negotiation protocol and show how it can be used to automatically establish mutual trust between interacting parties in compliance with access-control and disclosure policies. The protocol is implemented in Java and can be run on J2ME platforms. The trust negotiation steps are logged and the resulting trust graphs can be visualised to show how policy compliance was achieved. We also develop a new easier-to-understand syntax for ETTG and use it to define access-control and disclosure policies for a small pervasive healthcare scenario
Privacy in Mobile Web Services eHealth	There are many advantages to deploying mobile devices in eHealth systems. However; security is still an issue: in particular authentication and user privacy. In this paper we propose a novel architecture that integrates 3GPP UMTS mobile technology with Web services. This will help address authentication and privacy concern within eHealth environment. The architecture makes use of the generic authentication architecture from the 3GPP and the single sign-on system to authenticate mobile users to a health authentication server to give access to various eHealth service providers. The platform for Privacy Preferences Project is thus used to manage privacy in the system
Security and privacy in a wireless remote medical system for home healthcare purpose	The study investigates, assesses and evaluates data security and patients' privacy in a real-time wireless telemedicine system utilising GSM/GPRS, BLUETOOTH protocol, and a cellular phone. Fifteen non-risky heart patients, aged (49plusmn14) years (9 females, 6 male) were recruited. The ECGs were continuously monitored (72 h) and transferred anonymously; assigning each patient an identification number and monitoring start time and date, while the patients were performing their every day's indoors and outdoors activities. The data were collected and processed by a modem server at hospital. The server was assigned user-name and password, which were known only by the in charge health care personnel, and the ECGs were identified only by patients' id-number. Authentication, confidentiality and integrity of the data were tested for the risk of insertion attacks, client-to-client attacks and Misconfiguration. Results indicate that no access by unauthorised person was possible to neither mobile phone, nor the Bluetooth module which controls connection establishment and termination, data flow and dial-up communication. No access was possible for unauthorised person at server side and nor the ECG could be personalised. It is conluded that in the present setup, which clinical application is implemented in a small scale, the ECG data is secured and patients' privacy is achieved
Guest Editors' Introduction: Security & Privacy	Security and privacy concerns touch on all aspects of pervasive computing, including hardware, operating systems, networks, databases, user interfaces, and applications. The seven articles selected for this special issue draw on ideas from many of these fields and provide a flavor of the kinds of security and privacy challenges and opportunities in pervasive computing. This article is part of a special issue on security and privacy.
Location privacy in pervasive computing	As location-aware applications begin to track our movements in the name of convenience, how can we protect our privacy? This article introduces the mix zone-a new construction inspired by anonymous communication techniques-together with metrics for assessing user anonymity. It is based on frequently changing pseudonyms.
Introduction security and privacy	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01186721.png" border="0">
Security and Privacy for Implantable Medical Devices	Protecting implantable medical devices against attack without compromising patient health requires balancing security and privacy goals with traditional goals such as safety and utility. Implantable medical devices monitor and treat physiological conditions within the body. These devices - including pacemakers, implantable cardiac defibrillators (ICDs), drug delivery systems, and neurostimulators - can help manage a broad range of ailments, such as cardiac arrhythmia, diabetes, and Parkinson's disease. IMDs' pervasiveness continues to swell, with upward of 25 million US citizens currently reliant on them for life-critical functions. Growth is spurred by geriatric care of the aging baby-boomer generation, and new therapies continually emerge for chronic conditions ranging from pediatric type 1 diabetes to anorgasmia and other sexual dysfunctions. Moreover, the latest IMDs support delivery of telemetry for remote monitoring over long-range, high-bandwidth wireless links, and emerging devices will communicate with other interoperating IMDs.
Privacy in Location-Aware Computing Environments	This study explores how privacy preferences vary with place and social context. These findings are useful for designing privacy policies and user interfaces for pervasive computing.
Modeling privacy control in context-aware systems	Significant complexity issues challenge designers of context-aware systems with privacy control. Information spaces provide a way to organize information, resources, and services around important privacy-relevant contextual factors. In this article, we describe a theoretical model for privacy control in context-aware systems based on a core abstraction of information spaces. We have previously focused on deriving socially based privacy objectives in pervasive computing environments. Building on Ravi Sandhu's four-layer OM-AM (objectives, models, architectures, and mechanisms) idea, we aim to use information spaces to construct a model for privacy control that supports our socially based privacy objectives. We also discuss how we can introduce decentralization, a desirable property for many pervasive computing systems, into our information space model, using unified privacy tagging.
OpenTag: Privacy Protection for RFID	Radio frequency identification's use in retail is good for pervasive computing, but raises considerable privacy issues. OpenTag programmable tags address privacy issues while remaining fully compatible with the supply-chain RFID standard.
Security and Privacy in Pervasive Computing	In this issue's Works in Progress department, we have six projects. The first two projects address an individual's privacy concerns and preferences. The next entry discusses a project on data protection for electronic passports. The remaining three projects are investigating various types of privacy protection mechanisms for data collected in pervasive computing environments, by attestation services, and by voice recording systems.
A Framework for Assessing RFID System Security and Privacy Risks	This framework for evaluating security and privacy risks in RFID systems focuses on key application domains, assessing risk levels for each on the basis of RFID-specific criteria.
Privacy &amp;#x2013; The Irony of Automation in Social Media	Classic research on human factors has found that automation never fully eliminates the human operator from the loop. Instead, it shifts the operator&amp;#x2019;s responsibilities to the machine and changes the operator&amp;#x2019;s control demands, sometimes with adverse consequences, called the &amp;#x201C;ironies of automation.&amp;#x201D; In this paper, we revisit the problem of automation in the era of social media, focusing on privacy concerns. Present-day social media automatically disclose information such as users&amp;#x2019; whereabouts, likings, and undertakings. Our review of empirical studies exposes three recurring privacy-related issues in automated disclosure: 1) insensitivity to situational demands, 2) inadequate control of nuance and veracity, and 3) inability to control disclosure with service providers and third parties. We claim that the &amp;#x201C;all-or-nothing&amp;#x201D; type of automation has proven problematic and that social network services should design their user controls with all stages of the disclosure process in mind.
Enhancing Security and Privacy in Traffic-Monitoring Systems	Intelligent transportation systems increasingly depend on probe vehicles to monitor traffic: they can automatically report position, travel time, traffic incidents, and road surface problems to a telematics service provider. This kind of traffic-monitoring system could provide good coverage and timely information on many more roadways than is possible with a fixed infrastructure such as cameras and loop detectors. This approach also promises significant reductions in infrastructure cost because the system can exploit the sensing, computing, and communications devices already installed in many modern vehicles. This architecture separates data from identities by splitting communication from data analysis. Data suppression techniques can help prevent data mining algorithms from reconstructing private information from anonymous database samples
Aging, Privacy, and Home-Based Computing: Developing a Design Framework	Applications for "aging in place" focus on supporting elders and informing the caregiver but often at the risk of abrogating privacy. The authors developed and tested various prototypes to create a privacy framework for designing home-based computing for seniors.
Privacy By Design [From the Editor in Chief]	Nigel Davies and Marc Langheinrich explore one of the greatest challenges in ubiquitous systems&#x2014;how to provide smart, context-aware systems that can realize Weiser's vision while protecting users' privacy.
Security, privacy, and health	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01186730.png" border="0">
A framework for comparing perspectives on privacy and pervasive technologies	Pervasive computing research has evolved, investigating mechanisms for supporting some predefined notion of privacy, typically favoring individual rights over the rights of the community. We offer a framework to consider individual and group rights so that technology developers can more effectively reason about concerns for existing technology as well as generate new technologies that respect a well-defined set of social norms. We outline a framework designed to help developers understand the conflict between privacy and pervasive computing technologies, particularly those technologies that deal with sensing and storage. Pervasive computing technologies, especially those that can automate perception of human activity and then store that information, can provide tremendous benefits. We offer an analytic method to assist developers in asking questions about the systems and applications they are creating. We believe this framework will help developers minimize the gap between design goals and actual effects on privacy.
Designing for ubiquity: the perception of privacy	Ubicomp researchers have long argued that privacy is a design issue, and it goes without saying that successful design requires that we understand the desires, concerns, and awareness of the technology's users. Yet, because ubicomp systems are relatively unusual, too little empirical research exists to inform designers about potential users. Complicating design further is the fact that ubicomp systems are typically embedded or invisible, making it difficult for users to know when invisible devices are present and functioning. As early as 1993, ubicomp researchers recognized that embedded technology's unobtrusiveness both belies and contributes to its potential for supporting potentially invasive applications. Not surprisingly, users' inability to see a technology makes it difficult for them to understand how it might affect their privacy. Unobtrusiveness, nevertheless, is a reasonable goal because such systems must minimize the demands on users. To investigate these issues further, I conducted an ethnographic study of what I believe is the first US eldercare facility to use a sensor-rich environment. Our subjects were normal civilians (rather than ubicomp researchers) who lived or worked in a ubiquitous computing environment. We interviewed residents, their family members, and the facility's caregivers and managers. Our questions focused on how people understood both the ubiquitous technology and its effect on their privacy. Although the embedded technology played a central role in how people viewed the environment, they had a limited understanding of the technology, thus raising several privacy, design, and safety issues.
Preserving privacy in environments with location-based applications	The increase in location-based applications makes protecting personal location information a major challenge. Addressing this challenge requires a mechanism that lets users automate control of their location information, thereby minimizing the extent to which the system intrudes on their lives.
Privacy enforcement for distributed healthcare queries	In the healthcare industry and others, sensitive private information must be stored and shared between various organizations in the course of running their business. We have developed an architecture in which distributed data can be queried as if it resided in a single centralized database, while revealing minimal information beyond the answer to the query. In this paper we review the architecture and show how queries can be filtered to enforce user-specified privacy policies.We present a system for tracking information flow that is flexible enough to permit revealing sensitive data to those who have a need to know, while limiting the amount of useful information that can be obtained by a less-than-honest participant.
Privacy-aware access to Patient-controlled Personal Health Records in emergency situations	Patient-controlled Personal Health Record (PHR) systems may facilitate a patient not only to share her health records with healthcare professionals but also to control her health privacy, in a convenient and easy way. Governed by privacy protection laws, explicit consent/permission of the respective patient is a prerequisite for sharing personal health records. However, in emergency situations, when the patient becomes unable to give consent on her PHRs, healthcare professionals of emergency care units may need to access her health history for better and safer care. In this paper, we have introduced a novel privacy-aware protocol for handling access to patient-controlled PHR by healthcare professionals in emergency situations. The protocol is for the Privacy-aware Patient-controlled Personal Health Record (P<sup>3</sup>HR) system. It uses strong authentication using health IC cards, authorizes healthcare professionals and embeds emergency access report into the patients health IC card by which we achieve non-repudiation. Use of a dynamic access token in the authorization process protects replay attack. Intuitive privacy analysis shows that the proposed solution can preserve patients privacy from unauthorized parties while granting traceable access to personal health records by authorized healthcare professionals in emergency situations.
Multi-domain and privacy-aware role based access control in eHealth	Information Technology-supported Heathcare (eHealth) is crucial in order to reduce healthcare costs, and improve quality of care and patient safety. Among technologies in eHealth, Electronic Medical/Health Records (EMR/EHR) enabling communication of patient data between different healthcare professionals (e.g. specialists, pharmacy), is the most important and sensitive. There are three crucial requirements when accessing EMRs: such access must be both secure and privacy preserving; such access must be allowed to individuals from different organizations; such access should be confined based on meta information about the EMRs. In this paper, we propose a multi-domain privacy-aware role based access control meeting these requirements.
Security and privacy issues in middleware for emergency and rescue applications	Mobile ad-hoc networks (MANETs) are a natural candidate for communication and information exchange in emergency and rescue operations. The personnelpsilas movements, network disruptions and other system dynamics make it hard to implement robust applications for such environments. The MIDAS project aims at creating a middleware platform to simplify the task of developing and deploying mobile and robust services for events in which the network might be set-up at short notice. MANETs may be used because infrastructure is non-existing, and the number of users might be very high. One of the application domains addressed by MIDAS are emergency and rescue operations. To get a broad acceptance of the MIDAS solutions, security and privacy issues need also to be addressed. In this paper, we analyze the security threats and present a two-way approach to securing the MIDAS architecture. In the bottom-up approach, we use an efficient key management protocol to establish trust, and in the top-down approach we use dynamic role based access control to secure the system and provide privacy.
PatientΓÇÖs privacy protection with anonymous access to medical services	The Internet and mobile networks have penetrated the healthcare sector due to their increased functionality, low cost, high reliability and easy-to-use nature. However, in such healthcare environment the privacy and security of the transmitted information must be preserved. When dealing with health sensitive information at times it is vital to protect the patientpsilas identity and their health sensitive information from third parties. In this paper we present a protocol that will authenticate and authorize patients to healthcare services without providing the patientpsilas identification. The protocol protects patientpsilas privacy with a secure anonymous authentication to healthcare services, where the patient has access to a complete set of healthcare services.
PervasiveHealth 2008 Session chair: Rajarajan Muttukrishnan ΓÇö pervasive healthcare for health professionals & privacy & trust issues	
End-User perception towards pervasive cardiac healthcare services: Benefits, acceptance, adoption, risks, security, privacy and trust	This study examined patient and caregiver's perception regarding pervasive healthcare technology using five focus groups and a 31-item questionnaire. To further develop an understanding of the benefits and functionalities that prospective patients deem as either desirable, undesirable, inadequate or in need of further development the study was categorized under 7 main headings: Personal Profile; Benefits; Adoption; Acceptance; Risks; Security, Privacy and Trust; (use of) Cell Phone. This study was completed as part of the European Union BRAVEHEALTH project, aimed at the support of cardiac patients in everyday life using in vivo monitoring and diagnosis, thereby enabling the patient to be more proactive in heath management. Most participants felt that there is a great future for this technology and showed positive response in regards to the potential benefits but are (at present) not willing to adopt the system due to concerns over reliability, like security, privacy and trust.
Perception of privacy and security for acceptance of E-health technologies: Exploratory analysis for diverse user groups	The present study explores perceived relevance of security and privacy aspects in different user groups and assesses the predictive power of these attributes on acceptance of medical assistive technologies. Based on previously conducted focus groups a questionnaire was developed and quantitative data from N = 104 persons were analyzed. In a descriptive manner opinions of adults in all stages of life (age groups from young, middle-aged to older people) as well as gender - and health-related are presented and discussed with regard to those characteristics, and differences between the groups are disclosed. In multivariate regressions follows the analysis of most predictive security and privacy attributes for the acceptance (i.e. perceived usefulness) of E-health technologies. Results show that both security and privacy aspects play an important role for acceptance and usage of medical assistive technologies.
Privacy Protection in Ubiquitous Computing	Even though it is hard to define privacy in ubiquitous computing formally, study of privacy protection is now a spotlight of research to accelerate the emergency of ubiquitous computing age. In this paper, IDs assigned by the authority of end user are picked out from sensitive information such as location, time, likings. Service procedure assert, unless under juristic directive, other ID should be used instead. It is ideal to let end users of ubiquitous computing environment decide the level of their privacies required by services, so standardizing schema which depicts services and data requests is the base for end users offer information needed to get expected services with reducing the possibility of exposing who they are. Besides of any progress in preserving sensitive information, clarifying and using potential sensitive information separately from privacy information will do advantage to make services privacy preserving services.
Privacy-preserving event detection in pervasive spaces	In this paper, we consider privacy challenges in event-driven pervasive spaces where multimedia streams captured by sensors embedded in the infrastructure are used to detect a variety of application-specific media events. In particular, we develop techniques to detect events without disclosing any identifying information unless necessary. We characterize the nature of inference channels that arise and model privacy preserving event detection as an optimization problem that attempts to balance disclosure with performance. We design and test efficient communication protocols that realize this tradeoff.
An automatic user study demo in indoor environments and its privacy implications	User studies usually involve much organization and manual labor. Even when performed correctly, a common problem of the studies is user bias. This occurs when participating users' knowledge of the study influences their actions. Another problem is the willingness of the users to participate at all. Finally, participants will always have privacy concerns. We have developed a framework to help with anonymized user studies, trying to solve the aforementioned problems. We have prepared a demo to show the effectiveness of our system.
Towards privacy-sensitive participatory sensing	The ubiquity of mobile devices has brought forth the concept of participatory sensing, whereby ordinary citizens can now contribute and share information from the urban environment. However, such applications introduce a key research challenge: preserving the location privacy of the individuals contributing data. In this paper, we propose the use of microaggregation, a concept used for protecting privacy in databases, as a solution to this problem. We compare microaggregation with tessellation, the current state-of-the-art, and demonstrate that each technique has its advantage in certain mutually exclusive situations. We propose a hybrid scheme called, Hybrid Variable-Size Maximum Distance to Average Vector (V-MDAV), which combines the positive aspects of both these techniques. Our evaluations based on real-world data traces show that hybrid V-MDAV improves the percentage of positive identifications made by the application server by up to 100% and decreases the information loss by about 40%. Furthermore, our studies show that perturbing user locations with random Gaussian noise can provide users with an extra layer of protection with very little impact on the system performance.
A distributed k-anonymity protocol for location privacy	To benefit from a location-based service, a person must reveal her location to the service. However, knowing the person's location might allow the service to re-identify the person. Location privacy based on k-anonymity addresses this threat by cloaking the person's location such that there are at least k - 1 other people within the cloaked area and by revealing only the cloaked area to a location-based service. Previous research has explored two ways of cloaking: First, have a central server that knows everybody's location determine the cloaked area. However, this server needs to be trusted by all users and is a single point of failure. Second, have users jointly determine the cloaked area. However, this approach requires that all users trust each other, which will likely not hold in practice. We propose a distributed approach that does not have these drawbacks. Our approach assumes that there are multiple servers, each deployed by a different organization. A user's location is known to only one of the servers (e.g., to her cellphone provider), so there is no single entity that knows everybody's location. With the help of cryptography, the servers and a user jointly determine whether the k-anonymity property holds for the user's area, without the servers learning any additional information, not even whether the property holds. A user learns whether the k-anonymity property is satisfied and no other information. The evaluation of our sample implementation shows that our distributed k-anonymity protocol is sufficiently fast to be practical. Moreover, our protocol integrates well with existing infrastructures for location-based services, as opposed to the previous research.
Providing Security and Privacy in RFID Systems Using Triggered Hash Chains	RFID technology shall increase security, e.g. by helping to prevent counterfeiting. But the technology also causes privacy issues. In this paper, after highlighting goals and problems, an approach called "triggered hash chains" is proposed to address the problems. The approach combines concepts of two very different, widely known RFID protocols, i.e. the "hash-based ID variation" approach and the "Hash chain" approach. The resulting proposal joins the advantages of both protocols. The approach is evaluated using a variety of criteria that are relevant in practice.
Composition and Generalization of Context Data for Privacy Preservation	This paper presents preliminary results on anonymization and obfuscation techniques to preserve users' privacy in context-aware service provisioning. The techniques are based on generalizing request parameters as well as the context data provided to the application. Local context semantic aggregation is used to improve the quality of service that can be achieved while preserving privacy. The paper also shows how the software architecture of the CARE middleware can be extended to implement the proposed techniques.
Enforcing Patient Privacy in Healthcare WSNs Using ECC Implemented on 802.15.4 Beacon Enabled Clusters	We consider healthcare wireless sensor networks implemented using 802.15.4 beacon enabled technology, in which security processors are implemented with low power microcontrollers. In this setting, we propose to use elliptic curve cryptography for key distribution, in order to decrease energy consumption compared to the better known RSA algorithm.
GP^2S: Generic Privacy-Preservation Solutions for Approximate Aggregation of Sensor Data (concise contribution)	Protecting privacy in sensor networks poses new challenges because of the potential incompatibilities between new privacy-preserving mechanisms and mechanisms already implemented in sensor networks (such as in-network data aggregation). To address this problem, we propose in this paper a set of new privacy-preservation data aggregation schemes. Different from past research, our solutions have the following features: supporting data aggregation for a variety of queries; providing privacy protection for both individual data and aggregate data; being resilient to any number of node collusion; being highly efficient.
Physically Unclonable Function-Based Security and Privacy in RFID Systems	Radio frequency identification (RFID) is an increasingly popular technology that uses radio signals for object identification. Tracking and authentication in RFID tags have raised many privacy and security concerns. On the other hand, known privacy and security cryptographic defenses are too hardware-expensive to incorporate into low-cost RFID tags. In this paper, we propose hardware-based approaches to RFID security that rely on physically unclonable functions (PUFs). These functions exploit the inherent variability of wire delays and parasitic gate delays in manufactured circuits, and may be implemented with an order-of-magnitude reduction in gate count as compared with traditional cryptographic functions. We describe protocols for privacy-preserving tag identification and secure message authentication codes. We compare PUFs to digital cryptographic functions, address other uses of PUFs to enhance RFID security and suggest interesting directions for future research. The proposed solutions are efficient, practical, and appropriate for low-cost RFID systems
Dynamic Key-Updating: Privacy-Preserving Authentication for RFID Systems	The objective of private authentication for radio frequency identification (RFID) systems is to allow valid readers to explicitly authenticate their dominated tags without leaking tags' private information. To achieve this goal, RFID tags issue encrypted authentication messages to the RFID reader, and the reader searches the key space to locate the tags. Due to the lack of efficient key updating algorithms, previous schemes are vulnerable to many active attacks, especially the compromising attack. In this paper, we propose a strong and lightweight RFID private authentication protocol, SPA. By designing a novel key updating method, we achieve the forward secrecy in SPA with an efficient key search algorithm. We also show that, compared with existing designs, SPA is able to effectively defend against both passive and active attacks, including compromising attacks. Through prototype implementation, we observe that SPA is practical and scalable in current RFID infrastructures
Avoiding privacy violations caused by context-sensitive services	The increasing availability of information about people's context makes it possible to deploy context-sensitive services, where access to resources provided or managed by a service is limited depending on a person's context. For example, a location-based service can require an individual to be at a particular location in order to let the individual use a printer or learn her friends' location. However, constraining access to a resource based on confidential information about a person's context could result in privacy violations. For instance, if access is constrained based on a person's location, granting or rejecting access will provide information about this person's location and could violate the person's privacy. We introduce an access-control algorithm that avoids privacy violations caused by context-sensitive services. Our algorithm exploits the concepts of access-rights graphs, which represent all the information that needs to be collected in order to make a context-sensitive access decision. Moreover, we introduce hidden constraints, which keep some of this information secret and thus allow for more flexible access control. We present a distributed, certificate-based access-control architecture for context-sensitive services that avoids privacy violations, a sample implementation, and a performance evaluation
A high performance privacy-oriented location system	Many mobile applications can be greatly enhanced when provided with the locations of people and devices. Ultrasonic location systems have been shown to supply location information with centimeter accuracy at high update rates. Such high-performance systems, however, have relied upon a centralized or coordinated architecture, preventing the user from being in control of how their location information is handled and thus giving rise to privacy concerns. In this paper we present a privacy-oriented location system allowing users with mobile ultrasonic receivers to ascertain their position autonomously. We formulate a method of operation for the system, detail its implementation in a small office, and characterize the performance of the system. The utilization of broadband ultrasound makes it possible for the privacy-oriented location system to have competitive accuracy and high update rates, while allowing the user to be in direct control of their location information.
Context-Derived Pseudonyms for Protection of Privacy in Transport Middleware and Applications	This paper outlines why context-aware transport applications necessarily record information about people and describes how we can use anonymity techniques to minimise the resulting invasion of privacy. In particular we: (i) describe how to generate unlinkable personal pseudonyms; (ii) describe a method of creating group pseudonyms (an opaque pseudonym representing several individuals); and (iii) describe how to store these pseudonyms safely in a database. We go on to present two sample transport applications which utilise our technique and suggest areas for future work
RIPP-FS: An RFID Identification, Privacy Preserving Protocol with Forward Secrecy.	This paper presents a new RFID identification protocol: RIPP-FS. The proposed protocol is based on hash chains and it enforces privacy and forward secrecy. Further, unlike other protocols based on hash chains, our proposal is resilient to a specific DoS attack, in which the attacker attempts to exhaust the hash chain the tag is programmed to spend. The computations required on the tag side are very limited, just three hash functions; on the reader side RIPP-FS allows to leverage pre-computations, in such a way that tag identification resolves to a lookup in pre-computed tables, speeding up the identification process. To the best of our knowledge this is the first protocol providing all these features at once
Defining Strong Privacy for RFID	In this work, we consider privacy in radio frequency identification (RFID) systems. Our contribution is twofold: (1) we propose a simple, formal definition of strong privacy useful for basic analysis of RFID systems, as well as a different (weaker) definition applicable to multi-verifier systems; and (2) we apply our definition to reveal vulnerabilities in proposed privacy-enhancing RFID protocols. This paper is a highly abbreviated version of Juels, A et al, (2005)
Privacy Protection in Dynamic Systems Based on RFID Tags	We propose a solution for privacy problems regarding use of electronic identification tags such as RFID's. In our scheme the ID tag changes at random driven by its internal circuitry during each activation. The changes are small enough so that the legitimate system can recognize the tag and register the modified ID for the next activation. On the other hand, after a certain number of activations the new ID cannot be linked with the original one. We provide a rigid mathematical analysis of security of this unlinkability property
Lightweight Asymmetric Privacy-Preserving Authentication Protocols Secure against Active Attack	As pervasive computing technologies develop fast, the privacy protection becomes a crucial issue and needs to be coped with very carefully. Typically, it is difficult to efficiently identify and manage plenty of the low-cost pervasive devices like radio frequency identification devices (RFID), without leaking any privacy information. In particular, the adversary may not only eavesdrop the communication in a passive way, but also mount an active attack to ask queries adaptively, which is obviously more dangerous. Towards settling this problem, in this paper, we propose lightweight authentication protocols which are privacy-preserving against active attack. The protocols are based on a fast asymmetric encryption with novel simplification, which consequently can assign an easy work to pervasive devices. Besides, unlike the usual management of the identities, our approach does not require any synchronization nor exhaustive search in the database, which enjoys great convenience in case of a large-scale system
A Privacy-Enhancing Radio Frequency Identification Tag: Implementation of the Clipped Tag	The use of RFID tags for the tagging of individual consumer items is a distinct possibility The "clipped tag" has been suggested for individual items in order to enhance consumer privacy. The clipped tag allows the consumer to tear off a portion of the tag in order to transform a tag that may be read at a range of 10 meters to one than can only be read at a few cm. The use of these tags puts privacy protection in the hands of the consumer, provides a visual indication that the tag has been modified, but makes it possible for the tag to be used later for returns, recalls, or recycling. This paper describes an implementation of the clipped tag as a garment hang tag
Evidence-based nursing care support enhanced by minimally privacy invasive and pervasive sensing technology	This paper introduces a system for nursing homes, where daily activities of elderly persons are monitored by pervasive sensors. In this system, the sensors detect and save position of an elderly person as his life log and these logs are analyzed for obtaining the evidence of his activities of daily living. The collected evidence enables caregivers to provide effective support for the elderly. In our experiment, the system accumulated position data for a month and a half and we analyzed them to obtain his daily activities models, such as the relation between the time of day and the probability of visiting the lavatory. This paper presents the concept and the overview of the system and explains further some experimental results
Extending context models for privacy in pervasive computing environments	Privacy is widely recognised as a significant obstacle inhibiting the adoption of context-aware applications. In order to remove this obstacle, advances are required in many areas of context-awareness research. In this paper, we address the incorporation of privacy support into context models. In particular, we present extensions to our context modelling approach that address the challenges of assigning ownership to context information and enabling users to express privacy preferences for their own information.
A privacy enhanced service architecture for mobile users	Location, presence and messaging services provide the essential ingredients for emerging information and communications services. Nevertheless, the users are concerned about revealing their actualized location, presence or contact address information, especially to non-trusted third party applications. In this paper we propose a privacy architecture to achieve unlinkability between services related to a certain user and the user identity itself. The architecture is based on a privacy service which is integrated in the telecom service architecture Parlay-X, currently being standardized by the Parlay Group, and a chained hash technique called PRIVES, well suited to run in small mobile devices.
A capability-based privacy-preserving scheme for pervasive computing environments	In a pervasive computing environment, users interact with many smart devices or service providers (SPs) to obtain some useful services from them. These SPs can be either genuine or malicious. As a result, users privacy is at a greater risk, as they are prone to revealing their location, identity and transactions information to such SPs. On the other hand, user authentication is also required for SPs to provide service access control to only authorized users. In order to protect users privacy, they must be allowed to have anonymous interactions with SPs. But, authenticating and authorizing an anonymous user becomes a challenging task. In this paper, we propose a simple and efficient scheme that allows users to anonymously interact with SPs and the SPs can effectively authenticate and authorize the users based on the anonymous information submitted by the users.
Privacy and anonymity in personal networks	Personal networks (PN) is a new concept related to pervasive computing with a strong user focus. Unlike present personal area networks that have a limited coverage, PNs have an unrestricted geographical span and incorporate devices into the personal environment regardless of their location. PNs are configured in an ad-hoc fashion to support personal applications as the opportunity and demand arise. This paper proposes an architecture for PNs and discusses the related privacy and security issues and requirements.
Untraceable secret credentials: trust establishment with privacy	There is generally no a priori trust relationship among entities interacting in pervasive computing environments which makes it necessary to establish trust from scratch. This task becomes extremely challenging when it is simultaneously necessary to protect the privacy of the actors involved. We show how trust can be based on previous interactions yet remain unlinkable to any previous event or any specific entity. A solution based on group blind signatures is proposed that relies on credentials both secret, meaning that they contain an encrypted description of previous interactions, and untraceable, meaning that they cannot be recognized when presented to their issuer.
Mix zones: user privacy in location-aware services	Privacy of personal location information is becoming an increasingly important issue. We refine a method, called the mix zone, developed to enhance user privacy in location-based services. We improve the mathematical model, examine and minimise computational complexity and develop a method of providing feedback to users.
Hash-based enhancement of location privacy for radio-frequency identification devices using varying identifiers	Radio-frequency identification devices (RFID) may emerge as one of the most pervasive computing technologies in history. On the one hand, with tags affixed to consumer items as well as letters, packets or vehicles costs in the supply chain can be greatly reduced and new applications introduced. On the other hand, unique means of identification in each tag like serial numbers enable effortless traceability of persons and goods. But data protection and privacy are worthwhile civil liberties. We introduce a simple scheme relying on one way hash-functions that greatly enhances location privacy by changing traceable identifiers on every read getting by with only a single, unreliable message exchange. Thereby the scheme is safe from many threats like eavesdropping, message interception, spoofing, and replay attacks.
Privacy policies change management for smartphones	The ever increasing popularity of apps stems from their ability to provide highly customized services for the user. The flip side is that to provide such customized services, apps need access to very sensitive personal user information. This has led to a lot of rogue apps that e.g. pass personal information to 3<sup>rd</sup> party Ad servers in the background. Studies have shown that current app vetting processes which are mainly restricted to install time verification mechanisms are incapable of detecting and preventing such attacks. We argue that the missing fundamental aspect here is the inability to capture and control runtime characteristics of apps, e.g. we need to know not only the list of sensors that need to be accessed by an app but also their frequency of access. This leads to the need for an expressive policy language that in addition to the list of sensors, also allows specifying when, where and how frequently can they be accessed. An expressive policy language has the disadvantage of making the task of an average user more difficult in setting and analyzing the consequences of his privacy settings. Further, privacy polices evolve over time. Over time, users are likely to change their privacy settings, as a response to a recently discovered vulnerability, or to be able to install that ΓÇ£much desiredΓÇ¥ app, etc. Such a policy change affects both already installed (may no longer be compliant) and previously rejected apps (may be compliant now). In this paper, we propose an integrated privacy add-on that (i) compares the apps profiles vs. user's privacy settings, outlining the points of conflict as well as the different ways in which they can be resolved. And (ii) provides efficient change management with respect to any changes in user privacy settings.
A study of privacy settings errors in an online social network	Access control policies are notoriously difficult to configure correctly, even people who are professionally trained system administrators experience difficulty with the task. With the increasing popularity of online social networks (OSN) users of all levels are sharing an unprecedented amount of personal information on the Internet. Most OSNs give users the ability to specify what they share with whom, but the difficulty of the task raises the question of whether users' privacy settings match their sharing intentions. We present the results of a study that measures sharing intentions to identify potential violations in users' real Facebook privacy settings. Our results indicate a serious mismatch between intentions and reality: every one of the 65 participants in our study had at least one confirmed sharing violation. In other words, OSN users' are unable to correctly manage their privacy settings. Furthermore, a majority of users cannot or will not fix such errors.
Enhancing location privacy in Mobile IPv6 by using redundant home agents	Mobile IP allows mobile nodes (MN) to keep reachability from correspondent nodes (CN) while moving around in the Internet. Every MN has a fixed home address (HoA) maintained by the node called home agent (HA.) The HA acts as a proxy of the MN, and forwards all packets sent to the HoA. In order to continue communication, the MN tells its location to the HA by sending binding updates (BU) every time it moves. Since the source and destination addresses of BUs are clear to nodes between the MN and the HA, the movements of the MN may be traced by the third person who links BUs with their destination addresses. In this paper, we propose an extension to Mobile IPv6 to protect location privacy. By employing multiple HAs, MNs can permutate destination addresses of BUs and make it hard to link BUs. We have implemented a prototype system by extending the UMIP (USAGI-patched Mobile IPv6 for Linux), and conducted some experiments. The results show that only communication delays for traversing the additional path are observed.
Towards a trustworthy privacy in pervasive video surveillance systems	The consideration of security and privacy is a linchpin of the social acceptance of pervasive technology. This paper paves the way to the development of trustworthy pervasive video surveillance systems, by emphasizing the need to properly combine different aspects that current systems do not manage. In particular, in this paper we propose the combination of the following issues into a common framework: proper people identification mainly based on computer vision techniques, content protection not only by using convenient cryptographic techniques, but also law enforcement and user cooperation in order to get feedback with regard to the whole video surveillance system. Furthermore, an analysis focused on the current computer vision techniques used for people identification is presented. Finally, a score to measure the trust offered by video surveillance systems is proposed.
The devil is in the metadata ΓÇö New privacy challenges in Decentralised Online Social Networks	Decentralised Online Social Networks (DOSN) are evolving as a promising approach to mitigate design-inherent privacy flaws of logically centralised services such as Facebook, Google+ or Twitter. A common approach to build a DOSN is to use a peer-to-peer architecture. While the absence of a single point of data aggregation strikes the most powerful attacker from the list of adversaries, the decentralisation also removes some privacy protection afforded by the central party's intermediation of all communication. As content storage, access right management, retrieval and other administrative tasks of the service become the obligation of the users, it is non-trivial to hide the metadata of objects and information flows, even when the content itself is encrypted. Such metadata is, deliberately or as a side effect, hidden by the provider in a centralised system. In this work, we aim to identify the dangers arising or made more severe from decentralisation, and show how inferences from metadata might invade users' privacy. Furthermore, we discuss general techniques to mitigate or solve the identified issues.
Understanding the privacy implications of using context-based awareness cues in social networks	Information from the physical world is increasingly being digitalized and shared in social networks. We share our locations, tag photos and add different kinds of informal awareness cues about the physical world to our online communities. In this paper, we investigate the privacy implications of shared context cues in social networking services. We present an experimental mobile application, which allows users to add different descriptions of context information to their Facebook and Twitter status updates. The application was used by 12 persons during a two-week user trial using their own devices and Facebook accounts. The results indicate that user-defined abstractions of context items were often preferred over more accurate indicators due to privacy concerns or discomfort in sharing. We also found out that using shared context from friends in vicinity needs careful design to overcome the extended privacy implications.
Location privacy via actively secure private proximity testing	We present a solution which improves the level of privacy possible in location based services (LBS). A core component of LBS is proximity testing of users. Alice wants to know if she is near to Bob (or generally some location). The presented solution support private proximity testing and is actively secure meaning it prevents a number of attacks possible in existing protocols for private proximity testing. We demonstrate that the improved security provided only implies a factor of two penalty on execution time compared to an existing passively secure protocol. We also provide a security analysis and discuss the relevance of secure multiparty computation for location based services.
Towards context adaptive privacy decisions in ubiquitous computing	In ubiquitous systems control of privacy settings will be increasingly difficult due to the pervasive nature of sensing and communication capabilities. We identify challenges for privacy decisions in ubiquitous systems and propose a system for in situ privacy decision support. When context changes occur, the system adapts a user's privacy preferences to the new situation. As a consequence, recommendations can be offered to the user or sharing behavior can be automatically adjusted to help the user maintain a desired level of privacy. The system learns from user interaction and behavior to improve decision accuracy. In this paper, we outline the main components of our system and illustrate its operation with an ambient assisted living use case.
DECENT: A decentralized architecture for enforcing privacy in online social networks	A multitude of privacy breaches, both accidental and malicious, have prompted users to distrust centralized providers of online social networks (OSNs) and investigate decentralized solutions. We examine the design of a fully decentralized (peer-to-peer) OSN, with a special focus on privacy and security. In particular, we wish to protect the confidentiality, integrity, and availability of user content and the privacy of user relationships. We propose DECENT, an architecture for OSNs that uses a distributed hash table to store user data, and features cryptographic protections for confidentiality and integrity, as well as support for flexible attribute policies and fast revocation. DECENT ensures that neither data nor social relationships are visible to unauthorized users and provides availability through replication and authentication of updates. We evaluate DECENT through simulation and experiments on the PlanetLab network and show that DECENT is able to replicate the main functionality of current centralized OSNs with manageable overhead.
Detecting social cliques for automated privacy control in online social networks	As a result of the increasing popularity of online social networking sites, millions of people spend a considerable portion of their social life on the Internet. The information exchanged in this context has obvious privacy risks. Interestingly, concerns of social network users about these risks are related not only to adversarial activities but also to users they are directly connected to (friends). In particular, many users want to occasionally hide portions of their information from certain groups of their friends. To satisfy their users' needs, social networking sites have introduced privacy mechanisms (such as Facebook's friend lists) that enable users to expose a particular piece of their information only to a subset of their friends. Unfortunately, friend lists need to be specified manually. As a result, users frequently do not use these mechanisms, either due to a lack of concern about privacy, but more often due to the large amount of time required for the necessary setup and management. In this paper, we propose a privacy control approach that addresses this problem by automatically detecting social cliques among the friends of a user. In our context, a social clique is a group of people whose members share a significant level of social connections, possibly due to common interests (hobbies) or a common location. To find cliques, we present an algorithm that, given a small number of friends (seed), uses the structure of the social graph to generate an approximate clique that contains this seed. The cliques found by the algorithm can be transformed directly into friend lists, making sure that a piece of sensitive data is exposed only to the members of a particular clique. Our evaluation on the Facebook platform shows that our method delivers good results, and the cliques that our algorithm identifies typically cover a large fraction of the actual social cliques.
Keynote: Google and privacy	Cyrill Osterwalder has been the privacy engineering lead at Google since 2010. His responsibilities at Google include ensuring that effective privacy controls are built into products and internal practices. Before Google, Cyrill was Vice President of the web application security division at Phion. Phion acquired the Web application security company Visonys in 2008 which Cyrill co-founded. Cyrill has a master's degree in computer science from ETH Zurich with a focus on information security and cryptography, as well as a minor degree in business administration.
Demystifying privacy in sensory data: A QoI based approach	There is a growing consensus regarding the emergence of privacy concerns as a major deterrent towards the widespread adoption of emerging technologies such as mobile healthcare, participatory sensing and other social network based applications. In this paper, we motivate the need for privacy awareness, present a taxonomy of the privacy problems, and the various existing solutions. We highlight the tension that exists between quality of service at the receiver and the privacy requirement at the source and present a linear program formalization to model the tradeoff between the two objectives. We further present the design and architecture of SensorSafe, a framework which allows privacy-aware sharing of sensory information.
Towards preserving privacy in participatory sensing	With the abundance and ubiquity of mobile devices, a new class of applications is emerging, called participatory sensing (PS), where people can contribute data (e.g., images, video) collected by their mobile devices to central data servers. However, privacy concerns are becoming a major impediment in the success of many participatory sensing systems. While several privacy preserving techniques exist in the context of conventional location-based services, they are not directly applicable to the PS systems because of the extra information that the PS systems can collect from their participants. In this paper, we formally define the problem of privacy in PS systems and identify its unique challenges assuming an un-trusted central data server model. We propose PiRi, a privacy-aware framework for PS systems, which enables participation of the users without compromising their privacy.
Privacy settings from contextual attributes: A case study using Google Buzz	Social networks provide users with privacy settings to control what information is shared with connections and other users. In this paper, we analyze factors influencing changes in privacy-related settings in the Google Buzz social network. Specifically, we show statistics on contextual data related to privacy settings that are derived from crawled datasets and analyze the characteristics of users who changed their privacy settings. We also investigate potential neighboring effects among such users.
On preserving location privacy in mobile environments	With the proliferation of mobile devices and advances in positioning technologies, the location-based services (LBSs) have emerged as one of the killer applications for mobile users. Preserving user location privacy is one of the most crucial issues for LBSs. In this paper, we propose a new concept of k-anonymity to preserve users' location privacy. We devise a novel cloaking algorithm, called split cloaking, to generate a set of distributed cloaking regions. These distributed cloaking regions achieve higher k-anonymity for mobile users, leading to better privacy protection. In addition, the split cloaking algorithm addresses the problem that the number of querying users is too small to achieve k-anonymity. The experimental results show that the split cloaking algorithm is effective in user location privacy preservation.
Privacy preservation schemes for querying wireless sensor networks	In this work we study the problem of query privacy in large scale sensor networks. Motivated by a novel trust model in which clients query networks owned by trusted entities but operated by potentially untrusted adversaries, we consider several proposals for protecting the identities of the queried sensors. Our schemes do not rely on the use of public key cryptography nor do they make any assumptions on the topology of the network. Inspired by the data-centric communication model and the collaborative nature of sensor networks, our proposals distribute the data in random locations to be later retrieved by random direction queries, using only local computations and total absence of coordination. It is perhaps of interest to note that query privacy is achieved using only lightweight, symmetric cryptographic primitives. Extensive analytical and experimental results confirm that the proposed protocols can achieve their goals using only minimal communication and storage overhead.
Privacy-preserving admission to mobile peer-to-peer groups	Mobile peer-to-peer groups, which do not require any pre-deployed infrastructure or trusted centralized authority are valuable for a variety of collaborative applications. This work is focused on how to securely admit new users to such groups. Existing mechanisms based on threshold cryptography require that prospective members collect sufficient number of individual votes from the group prior to obtaining a membership credential. However, this approach does not consider the desirable anonymity of group members towards the admitted or declined users. This paper presents an admission control mechanism in which group members decide collectively and notify prospective members on the outcome of their decision without revealing their identities to prospective members.
Privacy-enhanced social network routing in opportunistic networks	Opportunistic networking-forwarding messages in a disconnected mobile ad hoc network via any encountered nodes-offers a new mechanism for exploiting the mobile devices that many users already carry. Forwarding messages in such a network often involves the use of social network routing-sending messages via nodes in the sender or recipient's social network. Simple social network routing, however, may broadcast these social networks, which introduces privacy concerns. This paper introduces two methods for enhancing privacy in social network routing by obfuscating the social network graphs used to inform routing decisions. We evaluate these methods using two real-world datasets, and find that it is possible to obfuscate the social network information without leading to a significant decrease in routing performance.
Adding privacy and currency to social networking	Social networking and e-commerce sites have many mechanisms with which they encourage generation of user content, represent user trust and reputation relationships, and control access to desirable digital resources. Using anonymous electronic cash (or scrip), the proposed system RepScrip provides the preceding three features and adds optional (to the user) anonymity and a certain level of commodification and interoperability with similarly-configured sites. With an electronic cash protocol like that described by Chaum, we show how online services can issue scrip to users as a representation of positive value in their dealings with those users. Like cash in a bank account, this currency may be withdrawn and exchanged with a third party. By holding the currency of that issuer, this third party (who may not have had any previous contact with the issuer) may now access resources with whichever privileges are afforded to those holding the issuer's scrip.
Privacy assurance in mobile sensing networks: Go beyond trusted servers	Mobile devices are becoming the largest sensor network around the world. They could be used to collect a large amount of data with little effort and cost which is leading to a promising future for participatory sensing networks or urban sensing. However, privacy concerns of the mobile users are the major inhibitors hindering massive participation. This paper proposes a solution to user privacy preserving problem in a participatory sensing network. Each user is considered as a node in a social network and users are connected through friendship links which are represented as edges on the network. Typically, each user contributes to the participatory system by uploading his/her acquired data to a server. Instead of uploading data to the server directly, we devised a Hot-Potato-Privacy-Protection Algorithm (H P<sup>3</sup>) in which data is sent to one of the friends of the user and the friend will choose another friend to deliver the data to the next hop. Hopping goes on until some user-defined threshold is reached, then the last user uploads the data to the server. Friend selection is random and the number of hops is also random and independent. H P<sup>3</sup> ensures that the probability that the server can make a successful attack on the data owner is no better than 1/n where n is the number of mobile users in the system. Therefore, H P<sup>3</sup> protects location privacy as well as data ownership privacy of mobile users. We simulate our approach on some large scale social networks and report some findings in the paper. Experiments show that our system achieves privacy protection for each user against the server with tolerable communication overhead.
Privacy Butler: A personal privacy rights manager for online presence	The online presence projected by a person is comprised of all the information about them available on the Internet. In online communities and social networking services, it is often possible for third-parties to modify this content by, for example, commenting on existing content or uploading new content. This has the potential to negatively impact the privacy of a presence owner (the person referred to by the on-line content) by disclosing information about them without consent. In this paper we propose a Privacy Butler, an automated service that can monitor a person's online presence and attempt to make corrections based on policies specified by the owner of the online presence.
Impenetrable obscurity vs. informed decisions: privacy solutions for Participatory Sensing	By harnessing sensors embedded in personal end devices, Participatory Sensing enables novel applications, but also raises severe privacy concerns. Instead of using existing centralized privacy mechanisms that remain obscure to the participants, we propose to involve the participants themselves into the process to protect privacy by interacting directly with others users using their available sensors. Furthermore, our decentralized solution helps in limiting the dissemination of sensitive data, which eliminates some threats to privacy.
Integrating people-centric sensing with social networks: A privacy research agenda	During the last few years there has been an increasing number of people-centric sensing projects, which combine location information with other sensors available on mobile devices, such as the camera, the microphone or the accelerometer, giving birth to a different dimension in sensing our environment compared to the existing wireless sensor networks approach. In this paper, we envision a new scenario, where users develop their own participatory urban sensing projects at a large scale through the use of social networks. Consequently, users can participate in campaigns created by other users, according to their sensitivities and interests, exploiting the existing enormous social interconnections offered by existing social networking tools. We place our primary concern to protecting user privacy and address the need for new solutions in location anonymity and access control under this new complex and dynamic communication paradigm.
Privacy preservation for participatory sensing data	Over the recent years, the proliferation of mobile networking and the increasing capabilities of smartphone devices have led to the development of ΓÇ£Participatory SensingΓÇ¥ applications, where users actively participate in data collection and sharing in a wide range of application domains from entertainment, to transportation, to environmental monitoring. One important challenge in these settings is privacy preservation for participatory sensing data, such as user trajectories. This paper develops a participatory sensing system for Android smartphones and proposes an efficient approach for privacy preservation which enables users to disclose their trajectory information without compromising their privacy. Existing approaches for privacy-aware data sharing operate under the assumption that user data is maintained in a centralized database. In our work we assume that user data is generated and stored locally on the individual smartphone devices. Our technique is distributed and low cost. We present detailed experimental results to illustrate that our approach is practical, efficient and with low overhead.
Providing privacy-aware incentives for mobile sensing	Mobile sensing exploits data contributed by mobile users (e.g., via their smart phones) to make sophisticated inferences about people and their surrounding and thus can be applied to environmental monitoring, traffic monitoring and healthcare. However, the large-scale deployment of mobile sensing applications is hindered by the lack of incentives for users to participate and the concerns on possible privacy leakage. Although incentive and privacy have been addressed separately in mobile sensing, it is still an open problem to address them simultaneously. In this paper, we propose two privacy-aware incentive schemes for mobile sensing to promote user participation. These schemes allow each mobile user to earn credits by contributing data without leaking which data it has contributed, and at the same time ensure that dishonest users cannot abuse the system to earn unlimited amount of credits. The first scheme considers scenarios where a trusted third party (TTP) is available. It relies on the TTP to protect user privacy, and thus has very low computation and storage cost at each mobile user. The second scheme removes the assumption of TTP and applies blind signature and commitment techniques to protect user privacy.
PShare: Position sharing for location privacy based on multi-secret sharing	Location-based applications such as Facebook Places, Foursquare, or Loopt attract millions of users by implementing point of interest finders, friend finders, geosocial networking, etc. Typically, these applications act as clients to a location service such as Google Latitude or Yahoo Fire Eagle, which manage mobile object positions and ensure the scalability to provide various clients with mobile object positions. However, exposing precise user positions raises user privacy concerns, especially if location service providers are not fully trusted, and private position information could be ΓÇ£lostΓÇ¥, leaked, stolen, etc. To enable the secure management of private user positions on non-trusted location servers (LSs), we present novel position sharing approaches based on the concept of multi-secret sharing. Our approaches split up a precise user position into position shares, which are distributed to different LSs of different providers such that a compromised provider only reveals user positions with degraded precision. On the other hand, clients can combine several shares queried from different LSs to increase their provided precision without the need to store precise information at a single LS. We propose two position sharing approaches: PShare-SLM is the first position sharing approach presented so far for symbolic location models. For geometric location models, we present PShare-GLM, which improves existing geometric position sharing approaches [1] by considering continuous position updates and by increasing the robustness against various attacks.
Enhancing privacy in participatory sensing applications with multidimensional data	Participatory sensing applications rely on individuals to share local and personal data with others to produce aggregated models and knowledge. In this setting, privacy is an important consideration, and lack of privacy could discourage widespread adoption of many exciting applications. We present a privacy-preserving participatory sensing scheme for multidimensional data which uses negative surveys. Multidimensional data, such as vectors of attributes that include location and environment fields, are challenging for privacy protection and are common in participatory sensing applications. When reporting data in a negative survey, an individual participant randomly selects a value from the set complement of the sensed data value, once for each dimension, and returns the negative values to a central collection server. Using algorithms described in this paper, the server can reconstruct the probability density functions of the original distributions of sensed values, without knowing the participants' actual data. Our algorithms avoid computationally expensive encryption and key management schemes, conserving energy. We study trade-offs between accuracy and privacy, and their relationships to the number of dimensions, categories, and participants. We introduce dimensional adjustment, a method that reduces the magnification of error associated with earlier work. Two simulation scenarios illustrate how the approach can protect the privacy of a participant's multidimensional data while allowing useful aggregate information to be collected.
P<sup>3</sup>-coupon: A probabilistic system for Prompt and Privacy-preserving electronic coupon distribution	In this paper, we propose P<sup>3</sup>-coupon, a Prompt and Privacy-preserving electronic coupon distribution system based on a Probabilistic one-ownership forwarding algorithm. In this algorithm, only one hop of forwarder (coupon owner) information instead of the complete forwarder list is recorded to keep the coupon short and privacy-preserving. Such information is updated probabilistically following two ownership flipping models, namely, One-Flip and Always-Flip models. We also use a Bluetooth Service Discovery Protocol (SDP) toolkit to enable fast, configuration-free coupon exchange. We have implemented the system in Java ME. Our experiments on real world mobile phones, such as Nokia and Samsung phones, and large scale simulations show that our system is efficient in peer to peer coupon distribution and capable of massive deployment. We believe our key methodology can serve as a general framework for facilitating information propagation on mobile phones, which requires promptness and privacy protection.
Position sharing for location privacy in non-trusted systems	Many novel location-based services (LBS) such as a friend finder service require knowledge about the positions of mobile users. Usually, location services are used to manage these positions, and for providing basic functionality like spatial range queries or spatial events to the LBS. Managing and using the positions of mobile users raises privacy issues, in particular, if the providers of LBS and location services are only partially trusted. Many different approaches for preserving a user's privacy have been proposed in the literature, e.g. location obfuscation and the k-anonymity concept. However, most of them are not suitable if both LBS and location service providers are non-trusted. In contrast to these approaches, we present a novel approach for the secure management of private position information in partially trusted system environments. The main contribution in this paper is a position sharing concept which allows for the distribution of position information (shares) of strictly limited accuracy onto several location servers of different providers. With this approach, a compromised server will only reveal information of limited accuracy. Moreover, we will show how position shares of coarse granularity from multiple location servers can be fused into information of higher precision to satisfy the accuracy requirements of different LBS.
Reclaiming privacy for smartphone applications	The scope of mobile phones has skyrocketed in recent years to such an extent that smartphone sales are expected to surpass those of PCs by the end of 2011. Equipped with relatively powerful processors and fairly large memory and storage capabilities, smartphones can accommodate increasingly complex interactive applications. As a result, the growing amount of sensitive information shared by smartphone users raises serious privacy concerns and motivates the need for appropriate privacy-preserving mechanisms. In this paper, we present a novel architecture geared for privacy-sensitive applications where personal information is shared among users and decisions are made based on given optimization criteria. Specifically, we focus on two application scenarios: (i) privacy-preserving interest sharing, i.e., discovering shared interests without leaking users' private information, and (ii) private scheduling, i.e., determining common availabilities and location preferences that minimize associate costs, without exposing any sensitive information. We propose efficient yet provably-private solutions, and conduct an extensive experimental analysis that attests to the practicality of the attained privacy features.
Privacy protection protocol in pervasive computing	In order to preserve the privacy of users, an improved secure protocol in pervasive computing is presented in this paper. With this privacy protection protocol, it allows the users to accomplish the tasks by communicating with service discoverers, instead of with service providers directly. By the security analysis of the proposed protocol, it validated that this protocol can availably protect the privacy of the users and prevent them being tracked, and significantly reduce the computational complexity compared with the existing protocol. Based on the analysis result, this improved protocol is able to protect the users' privacy and to resist replay attack more effectively.
Designs of privacy protection in location-aware mobile social networking applications	The emergence of location-aware mobile social networking applications (SNAs) has gained considerable prominence in ubiquitous computing. However, the weak designs of privacy protection result in more potential risks that users have to face. This paper presents a deep insight into the designs of privacy protection, especially from the perspective of location privacy. Three main potential risks and some necessary privacy-related functionality in current applications are analyzed and summarized. And with respect to the risks and weak protection methods, we propose the designs of privacy protection in LaMOC which is a location-aware mobile cooperation system developed by us. The designs include both the policy-based mechanisms and computational approaches to protect users' location privacy. Policy-based mechanisms enable users to fully control their locations disclosure while computational approaches can protect users' real locations from malicious attackers. The designs provide a reasonable level of privacy protection in location-aware mobile SNAs to some extent.
An exploration of RFID information security and privacy	The application of RFID after years of development, there are many cases of the industries applied, and Tag is considered to be the next generation of Barcode. However, the RFID is via transmission of radio frequency manner, so hacker could obtain information through the analysis way of frequency signal. The personal privacy will be violated if used in the user's privacy information and transmission without any protective measures to protect. RFID data transmission and storage with hardware ways to achieve the security of information is the best way, but this had been in the problem of Tag costs and capacity. The study taking from the applications ways is to achieve RFID information security and privacy, and do the information securities between the low-cost Tag and the Reader. The study submitted an EPC specification and combined with XOR logical applications to achieve privacy by the way of discussion currently.
Spontaneous privacy-aware location sharing	We propose a privacy conserving protocol to share location information with groups of trusted agents (e.g. friends) using a mobile device. All information published by the user is cryptographically secured and authenticated. Furthermore, we employ methods to make it hard for third parties to derive a user's relationships from communication patterns. Users can create multicast groups spontaneously and maintain these efficiently. In contrast to previous solutions, our approach does not rely on any dedicated or trusted network infrastructure for coordination or communication. For our prototype implementation messages are pushed to the listening group members with low overhead, by using existing publicly available and accessible communication infrastructure (IRC). Finally, we present a cost and privacy analysis of the proposed protocol.
Privacy-enhanced personalisation in ambient environments	In ambient environments both quantity and quality of context-aware, personalizable information will continuously increase. Acceptance and benefit will depend on personalization technologies which enable end-users to protect their privacy. However, starting from the experience how users, service providers and network operators nowadays take advantage of personalised services the authors deplore inadequate and intransparent control mechanisms for end-users in current platforms and implementations. The introduction of a structured approach in this paper to privacy requirements engineering helps analysing and identifying threats and challenges in future ambient scenarios. The paper promotes privacy-enhancing technologies, such as user empowerment, user-centric identity management, as well as pseudonyms and client-side personalization and gives an overview on legal requirements.
Towards Privacy-Preserving Network Monitoring: Issues and Challenges	Passive network monitoring is required for the operation and maintenance of communication networks as well as to detect frauds and attacks. Typically, raw packet-level traffic traces are collected using suitable traffic probe devices and fed to monitoring applications (IDSs, antivirus, etc.) for analysis, with potential risks for the legitimate privacy rights of the customers. This paper aims to discuss the technical feasibility and the underlying research challenges of a two-tiered privacy-preserving network monitoring system, where carefully designed data protection mechanisms can coexist with suitably adapted monitoring applications.
Privacy Threats of Data Retention in Internet Communications	Data retention refers to the legal obligation of Internet service providers (ISPs) to retain the communication data of their subscribers for a certain period, in order to enable the legal investigation of possible crimes. However, the retention of communication data increases the security threats against the privacy of theirs subscribers. In this paper we explore the privacy issues of data retention in Internet communications. We also describe possible security mechanisms which may thwart these threats and minimize the risks against user privacy.
Enhancing Security and Privacy in 3GPP E-UTRAN Radio Interface	We focus the security and privacy threats in radio interface between evolved node B (eNB, "base station") and user equipment (UE). We identify new threats including several user tracking attacks by various information in MAC and RRC signalling messages, and an active attack with false buffer status reports. Finally, we propose a solution including confidentiality of RRC layer messages, periodic C-RNTI reallocation on one cell; discontinuous sequence number in RRC message, and one time access token for MAC buffer status report.
Technical Enforcement of Privacy Legislation	The potential invasion of individuals' privacy constitutes the flip side of the advanced services' provision, boosted by the recent advances in mobile communications, location and sensing technologies and data processing. Being situated in the realms of legal and social studies, the notion of privacy is mainly left, concerning its protection, to legislation and service providers' self-regulation by means of privacy policies. However, all laws and codes of conduct are useless without enforcement. Based on this concept, this paper presents a framework that formally models the privacy principles that regulate the services' provision and incorporates them into a privacy enhancing middleware system. The mediation of the considered architecture between the users and the service providers, guarantees the enforcement of a privacy policy that is defined by the technical translation of the privacy principles and regulations and overrides the service providers' ones.
A Federated Privacy-Enhancing Identity Management System (FPE-IMS)	Privacy and identity management should not been treated as generic problems providing generic solutions and architectures. A systematic approach is required against the problems of conducting identity management effortlessly, conveniently and smoothly solving interoperability problems that impede the communication and creation of unified infrastructures and produce an interoperable solution for identity management. This paper aims to contribute towards the proposal of a federated privacy-enhancing identity management system providing all the main tools and services in order address the major privacy requirements, required for the achievement of privacy aware e/m-transactions. This system can be embedded to each reconfigurable framework, enhancing privacy issues on existing web services based platforms, which delivers privacy-aware e/m-organizational services.
Privacy requirements for embedded sensor devices	This paper analyses data privacy issues as they arise from different deployment scenarios for networks that use embedded sensor devices. Maintaining data privacy in pervasive environments requires the management and implementation of privacy protection measures close to the data source. We propose a set of atomic privacy parameters that is generic enough to form specific privacy classes and might be applied directly at the embedded sensor device
Improving user privacy with firewall techniques on the wireless LAN access point	Wireless local area networks (WLANs) for public access need to provide privacy between users and also ensure correct charging where access is based on payment. However, by design, conventional LANs and WLANs provide directs unmediated communications between networked devices at the link layer. The paper presents a method to allow networked client devices to communicate with a network comprising routers and other servers while preventing unmediated communication between the clients on the wireless network. An advantage of the method is that it can be implemented entirely within the WLAN access point as a configurable forwarding policy database. No changes are needed to the WLAN client software or the routers and servers and the communication remains completely within the scope of existing industry standards.
Wireless security & privacy	Internet enabled wireless devices continue to proliferate and are expected to surpass traditional Internet clients in the near future. This has opened up new exciting opportunities in the mobile e-commerce market. Data security and privacy is the major concern in the current generation of "wireless Web" offerings. The physical security of wireless devices, Bluetooth security, WAP security, higher-level security protocols like SSL are known. In this article, the WEP algorithm is discussed. The IEEE 802.11 standard defines WEP i.e., wired equivalent privacy. WEP is designed to provide data privacy to the level of a wired network. 802.11 designed WEP is not able to achieve this goal. But WEP could achieve this by migrating from 40 bit to 104 or 128 bit RC4 keys. Privacy cannot be obtained with WEP encapsulation just by increasing key size. Even if key size is 1 into 1000 bit it does not affect the security of WEP encapsulation or if any other stream cipher which replaces RC4.
Security and privacy issues in wireless and mobile computing	Implementing security in wireless systems is a difficult and challenging task owing to the mobility of users and network components and the fact that the wireless medium is susceptible to eavesdropping, espionage and fraud. We study the security issues in wireless systems in this paper. Specifically, we discuss the security problems in wireless systems and the proposed solutions and security measures implemented in several wireless systems
Preserving privacy in mobile communications: a hybrid method	We propose three security protocols for mobile communications, which enable mutual authentication and establish a shared secret key between mobile users. They also provide a certain degree of anonymity of the communicating users to other system users. Our protocols are based on a hybrid scheme involving a combination of public key and symmetric key based systems
Privacy and authentication for wireless local area networks	Wireless networks are being driven by the need for providing network access to mobile or nomadic computing devices. Although the need for wireless access to a network is evident, new problems are inherent in the wireless medium itself. Specifically, the wireless medium introduces new opportunities for eavesdropping on wireless data communications. Anyone with an appropriate wireless receiver can eavesdrop, and this kind of eavesdropping is virtually undetectable. Furthermore, since the wireless medium cannot be contained by the usual physical constraints of walls and doors, active intrusions through the wireless medium are also made easier. In order to prevent this unauthorized access to the network, the authors present the design of a secure communication protocol that provides for both the privacy of wireless data communications and the authenticity of communicating parties. The placement of the protocol in the overall protocol stack and issues relevant to wireless links and mobile computing devices are discussed. They also present proof of the security of the protocol using the logic of authentication formalism developed by Burrows, Abadi, and Needham (1990).<<ETX>>
Techniques for privacy and authentication in personal communication systems	Describes progress in the development of authentication and key agreement (AKA) processes for personal communication systems (PCS). A conceptual framework is first established; this is a three-part general model that characterizes all AKA techniques. Then three proposed AKA methods are compared using this model. These methods are the so-called secret key method of GSM, the secret key method of United States Digital Cellular (IS-54, IS-95), and a public key/secret key method. Finally, a summary is presented that indicates the AKA method of preference for some proposed PCS air interfaces that are under development by standards bodies
Privacy and authentication needs of PCS	To provide the proper privacy and authentication for a PCS phone, some cryptographic system will be necessary. The article defines requirements that a cryptographic system used for PCS would need to meet. It does not attempt to define the cryptographic system. It does provide a template for examining cryptographic systems to choose between cryptographic alternatives. Some of the cryptographic requirements are in the air interface between the PCS phone and the radio port. Other requirements are on databases stored in the network and on information shared between systems in the process of handovers or giving service for roaming units. The paper first discusses four levels of privacy (including defining two new levels). Then, requirements are identified and discussed in the areas of privacy, theft resistance, radio system performance, system lifetime, physical requirements as implemented in portable/mobile PCS phones, and law enforcement needs
Privacy and authentication protocols for PCS	This article describes the message flow due to authentication, voice privacy, and signaling message encryption expected to be incorporated in the EIA/TIA's cellular industry Interim Standard IS 41 Revision C. The algorithm for authentication and generation of voice privacy mask and signalling message encryption keys employed by the standard is based on private key cryptographic techniques that use a secret key (also known as shared secret data, or SSD) for authentication. Two schemes have been proposed in the standard. In the first one, the SSD is shared only between the handset and the authentication center. In the second, the SSD is also shared with the visited system. Compared to the first scheme, the second scheme requires a considerably reduced rate of accesses to network databases for authentication during call origination determination, thereby reducing call setup time. However, during registration, the second scheme requires additional database accesses compared to the first due to the need to get an up-to-date call history count from the previous visited system. We compare the two schemes with the use of a simple mobility model for users and study their impact on the traffic to network databases. Defining the user mobility rule as the number of registrations per hour per user, we show that as the user mobility rate increases from roughly 0.5 to 15, the effectiveness of the second scheme compared to the first varies from about a 66 percent improvement to about a 30 percent degradation, clearly implying that the mobility characteristics of the user population dictate the choice of the authentication scheme
Towards a Collusion-Resistant Algebraic Multi-Party Protocol for Privacy-Preserving Association Rule Mining in Vertically Partitioned Data	Privacy-preserving data mining has recently become an attractive research area, mainly due to its numerous applications. Within this area, privacy-preserving association rule mining has received considerable attention, and most algorithms proposed in the literature have focused on the case when the database to be mined is distributed, usually horizontally or vertically. In this paper, we focus on the case when the database is distributed vertically, and propose an efficient multi-party protocol for evaluating item-sets that preserves the privacy of the individual parties. The proposed protocol is algebraic and recursive in nature, and is based on a recently proposed two-party protocol for the same problem. It is not only shown to be much faster than similar protocols, but also more secure. We also present a variant of the protocol that is resistant to collusion among parties.
Support for Security and Privacy in SenSearch	This paper describes the design, implementation and performance of a security and privacy framework for SenSearch, which is a sensor-based search and rescue system for people in emergency situation in wilderness areas. A key obstacle in a wide deployment of search and rescue systems such as SenSearch is vulnerability to users' security and privacy. Support for security and privacy for SenSearch has been carefully built by employing a combination of both symmetric and asymmetric key cryptography to meet the constraints of resource-limited devices and short time intervals during which most security operations have to be performed.
LBSs privacy preserving for continuous query based on semi-honest third parties	Location based systems are becoming prevalent in recent years, many Location Based Services (LBSs) require users providing exact location information, due to the privacy concerns, the link between queries and users should not be disclosed. In this paper, we present a distributed query privacy preserving scheme involving multiple semi-honest servers, based on which, a novel query privacy preservation algorithm considering the moving status and trend is proposed. The service quality is taken into account to improve the clients' service experience. To improve the efficiency and practicality, the algorithm only employs the query issuing clients to generate cloaked regions at one time for several clients. Due to the privacy concerns caused by clients' dynamics, a location predicting mechanism is introduced. Finally, the evaluation metrics including privacy guarantee, quality of service, and system performance are presented. The simulation results show that our algorithm can preserve mobile user's privacy as well as provide high Quality of Service (QoS).
Improving location privacy in mix-zones for VANETs	Providing location privacy to users is one of the important issues that must be addressed in Vehicular Ad-Hoc Networks. Recent solutions address it by using cryptographic ΓÇ£mix-zonesΓÇ¥, which are anonymizing regions where nodes change their temporary identities (pseudonym) without being tracked. However, existing solutions are vulnerable to internal attackers since within a mix-zone messages are encrypted using a group secret key. In this paper we improve location privacy of mix-zones via extensions to the CMIX protocol. By carrying out extensive simulations, we investigate and compare the effective location privacy provided by the proposed approach.
The cost of location privacy in locator/identifier-split architectures	The locator/identifier separation paradigm is widely considered to be a feasible solution to the problematic issues of today's Internet architecture. This approach, however, introduces a novel problem by revealing a node's location information to all of its peers. Thus, each node becomes trackable. To overcome this problem, a solution is required which is able to hide location information while not limiting connectivity at the same time. So far, few proposals have been made to address this problem. In this paper, the concepts are analyzed and evaluated based on the costs introduced to the network due to overhead. The paper shows the overall costs for a privacy solution and the importance to implement mechanisms to limit additional required transit traffic.
From nowhere to somewhere: Protecting end-to-end location privacy in wireless sensor networks	Wireless sensor networks (WSNs) are often deployed in hostile environments for specific applications from mobile objects monitoring to data collecting. By eavesdropping the sensor nodes' transmissions and tracing the packets' trajectories in the WSNs, an adversary can capture the location of a source or sink eventually. Thus, the location privacy of both source and sink becomes a significant issue in WSNs. Previous research only focuses on the location privacy of the source or sink independently. In this paper, we address the importance of location privacy of both source and sink and propose four schemes to protect them simultaneously. Simulation results illustrate the effectiveness of our proposed schemes.
A local distributed peer-to-peer algorithm using multi-party optimization based privacy preservation for data mining primitive computation	This paper proposes a scalable, local privacy-preserving algorithm for distributed peer-to-peer (P2P) data aggregation useful for many advanced data mining/analysis tasks such as average/sum computation, decision tree induction, feature selection, and more. Unlike most multi-party privacy-preserving data mining algorithms, this approach works in an asynchronous manner through local interactions and therefore, is highly scalable. It particularly deals with the distributed computation of the sum of a set of numbers stored at different peers in a P2P network in the context of a P2P Web mining application. The proposed optimization-based privacy-preserving technique for computing the sum allows different peers to specify different privacy requirements without having to adhere to a global set of parameters for the chosen privacy model. Since distributed sum computation is a frequently used primitive, the proposed approach is likely to have significant impact on many data mining tasks such as multi-party privacy-preserving clustering, frequent itemset mining, and statistical aggregate computation.
An Information-Theoretic Framework for Analyzing Leak of Privacy in Distributed Hash Tables	An important security issue in DHT-based structured overlay networks is to provide anonymity to the storage nodes. Compromised routing tables in those DHTs leak information about other nodes in the system and therefore compromise privacy. In this paper, we use information theory to build a model to quantify the information leak from compromised routing tables for a given DHT with certain routing geometry and route table size. Based on this model, we have analyzed and compared how existing DHTs perform in face of anonymity attacks. We found that ring-based routing geometry (Chord) performs the best among the studied DHTs with the same routing complexity when no routing optimizations are used. The analysis of the interaction between routing geometries and recipient anonymity will help improve the design of future DHTs which can achieve a balance between routing efficiency and robustness against information leak.
On the Privacy of Peer-Assisted Distribution of Security Patches	When a host discovers that it has a software vulnerability that is susceptible to an attack, the host needs to obtain and install a patch. Because centralized distribution of patches may not scale well, peer-to-peer (P2P) approaches have recently been suggested. There is, however, a serious privacy problem with peer-assisted patch distribution: when a peer A requests a patch from another peer B, it announces to B its vulnerability, which B can exploit instead of providing the patch. Through analytical modeling and simulation, we show that a large majority of vulnerable hosts will typically become compromised with a basic design for peer- assisted patch distribution. We then study the effectiveness of two different approaches in countering this privacy problem. The first approach utilizes special-purpose peer nodes, referred to as honeypots, that discover and blacklist malicious peers listening for patch requests from susceptible hosts. In the second approach, the patches are requested through an anonymizing network, hiding the identities of susceptible hosts from malicious peers. Using analytical models and simulation, we show that, honeypots do not completely solve the privacy problem; in contrast, an anonymizing network turns out to be more suitable for security patch distribution.
Towards Plugging Privacy Leaks in the Domain Name System	Privacy leaks are an unfortunate and an integral part of the current Internet domain name resolution. Each DNS query generated by a user reveals -- to one or more DNS servers -- the origin and the target of that query. Over time, users' communication (e.g., browsing) patterns might become exposed to entities with little or no trust. Current DNS privacy leaks stem from fundamental features of DNS and are not easily fixable by simple patches. Moreover, privacy issues have been overlooked by DNS security efforts (such as DNSSEC) and are thus likely to propagate into future versions of DNS. In order to mitigate privacy issues in DNS, this paper proposes a Privacy-Preserving DNS (PPDNS), that offers privacy during domain name resolution. PPDNS is based on distributed hash tables (DHTs), an alternative naming infrastructure, and computational private information retrieval (cPIR), an advanced cryptographic construct. PPDNS takes advantage of the DHT index structure to provide name resolution query privacy, while leveraging cPIR to reduce communication overhead for bandwidth-sensitive clients. Our analysis shows that PPDNS is a viable approach for obtaining a reasonably high level of privacy for name resolution queries. PPDNS also serves as a demonstration of blending advanced systems techniques with their cryptographic counterparts.
Distributed Access Enforcement in P2P Networks: When Privacy Comes into Play	In open environments such as peer-to-peer networks, the decision to collaborate with multiple users (e.g., by granting access to a resource) is hard to achieve in practice due to extreme decentralization. The literature contains a plethora of examples where a scalable solution for access control is basic to spur their adoption.Motivated by this need, we introduce a novel protocol to enforce access control in a distributed but also privacy-preserving manner - i.e., so as to minimize the disclosure of privileges and of access policies. Privacy is rather scarce in peer-to-peer systems, for which we believe that our protocol is a valuable contribution. Using extensive simulations on top of real Internet topologies, we illustrate the applicability of our protocol, which is efficient both in terms of communication and rounds of interaction.
Detection of sensitive items in market basket database using association rule mining for privacy preserving	Data mining is an essential technology to extract patterns or knowledge from large repositories of data. Association rules in market basket database represent the shopping behavior of customers. The association information may reveal trade secrets. It must be hidden before publishing. Association rule hiding in privacy preserving data mining hides sensitive rules containing sensitive items. In this paper, a new method is proposed to detect the sensitive items for hiding sensitive association rules. This proposed method finds the frequent item sets and generates the association rules. It employs the concept of representative association rules to detect sensitive items.
Anonymization technique through record elimination to preserve privacy of published data	The term Data Privacy is associated with data collection and dissemination of data. Privacy issues arise in various area such as health care, intellectual property, biological data etc. It is one of the challenging issues when sharing or publishing the data between one to many sources for research purpose and data analysis. Sensitive information of data owners must be protected. There are two kinds of major attacks against privacy namely record linkage and attribute linkage attacks Earlier, researchers have proposed new methods namely k-anonymity, l-dlverslty, t-closeness for data privacy. K-anonymity method preserves the privacy against record linkage attack alone. It fails to address attribute linkage attack. l-diversity method overcomes the drawback of k-anonymity method. But it fails to address identity disclosure attack and attribute disclosure attack in some exceptional cases. t-closeness method preserves the privacy against attribute linkage attack but not identity disclosure attack. But it computational complexity is large. In this paper, the authors propose a new method to preserve the privacy of individuals' sensitive data from record and attribute linkage attacks. In the proposed method, privacy preservation is achieved through generalization of quasi identifier by setting range values and record elimination. The proposed method is implemented and tested with various data sets.
Context aware privacy in visual surveillance	In this paper we present preliminary work implementing dynamic privacy in public surveillance. The aim is to maximise the privacy of those under surveillance, while giving an observer access to sufficient information to perform their duties. As these aspects are in conflict, a dynamic approach to privacy is required to balance the systempsilas purpose with the systempsilas privacy. Dynamic privacy is achieved by accounting for the situation, or context, within the environment. The context is determined by a number of visual features that are combined and then used to determine an appropriate level of privacy.
Biomapping: Privacy trustworthy biometrics using noninvertible and discriminable constructions	Biometric authentication and privacy protection are conflicting issues in a practical system. Since biometrics cannot be revoked or canceled if compromised duo to the permanent association with the user, privacy-preserving biometric recognition is desired. However, the recently proposed template protection schemes are not yet sufficiently mature. Specially, the popular noninvertible transform approach will result in an obvious decrease of GAR for a fixed FAR. In this paper, we put forward a novel anonymous fingerprint recognition scheme, Biomapping, as the first approach to integrate the feature extraction, noninvertible transform, and anonymous query as a whole. Biomapping extracts the fingerprint feature utilizing a minutiae-centered region encoding, then performs anonymous enrollment and verification using the noninvertible and discriminable constructions. Experiments on the public domain database show Biomapping can provide better recognition accuracy along with the ability to protect the biometric template, thus becomes a promising solution for privacy trustworthy biometric applications.
Stealth vision for protecting privacy	We propose an anonymous video capturing system, called "stealth vision", which protects the privacy of objects by fading out their appearance. In order to avoid difficulty in detecting the region of human faces (privacy-protected regions) in an image captured with a mobile camera, the fade-out areas are determined in 3D (three-dimensional) space instead of 2D image space. The 3D position of the captured object is estimated with a simple algorithm, which projects the foreground region in the overhead image onto several horizontal 3D planes and extracts the 3D position while merging the projecting results. By projecting the 3D information onto an image plane of mobile camera, the region to use for the anonymizing process is determined. Experimental results show that our system successfully protects the privacy of target objects.
Digital privacy: Replacing pedestrians from Google Street View images	Given the lack of modern techniques to ensure the digital privacy of individuals, we want to pave the way for a new approach to make pedestrians in cityscape images anonymous. To address these concerns, we propose an automated method to replace any unknown pedestrian with another one which is extracted from a controlled and authorized dataset. The techniques used up to now to make people anonymous are based mainly on the blurring of people's faces, but even so it is possible to trace the identity of the subject starting from his clothing, personal items, hairstyle, the place and time where the photo was taken. The proposed method aims to make the pedestrians completely anonymous, and consists of four phases: firstly we identify the area where the pedestrian is located, we separate the pedestrian from the background, we select the most similar pedestrian from a controlled dataset and subsequently we substitute it. Our case study is Google Street View because it is one of the online services which suffers most from this kind of privacy issues. The experimental results show how this technique can overcome the problems of digital privacy with promising results.
Video privacy filters with tolerance to segmentation errors for video conferencing and surveillance	It is sometimes desired to obscure background of a person on a video conference or foreground people in a surveillance video. Background subtraction (or foreground detection) methods can help separate desired from undesired planes, however current methods often have errors - holes in foreground or background - especially after lighting changes. We describe a unified approach to video privacy that capitalizes on the realization that private information is often in the image detail, which have edges, rather than in the uniform intensity regions. So a gradient based method for foreground detection can offer both error tolerance and privacy. We show results of error tolerance to lighting change, and degree of privacy gained by foreground and background privacy filters.
Privacy Protection in Context Transfer Protocol	In the future 4G wireless networks will span across different administrative domains. In order to provide secure seamless handovers in such an environment the context transfer protocol is an attractive solution. However, the aforementioned protocol arises some privacy issues concerning the location and movement of users roaming between administrative domains. The purpose of this paper is to present and analyze these privacy issues and propose two privacy enhanced context transfer schemes that alleviate these problems. In the first scheme the Mobile Node (MN) is responsible for the transmission of the context to the new domain. In the second scheme the Home Domain (HD) of the user forwards the context acting as a proxy between the old and the new domain. While the second scheme is expected to be more useful towards realizing seamless handovers, the first one poses less signaling load to the HD. In addition, assuming that the most appropriate form of user identity for the context is the Network Access Identifier (NAI), we show how the employment of temporary NAIs can further increase the privacy of our schemes.
Privacy Violation Classification of Snort Ruleset	It is important to analyse the privacy impact of Intrusion Detection System (IDS) rules, in order to understand and quantify the privacy-invasiveness of network monitoring services. The objective in this paper is to classify Snort rules according to the risk of privacy violations in the form of leaking sensitive or confidential material. The classification is based on a ruleset that formerly has been manually categorised according to our PRIvacy LEakage (PRILE) methodology. Such information can be useful both for privacy impact assessments and automated tests for detecting privacy violations. Information about potentially privacy violating rules can subsequently be used to tune the IDS rule sets, with the objective to minimise the expected amount of data privacy violations during normal operation. The paper suggests some classification tasks that can be useful both to improve the PRILE methodology and for privacy violation evaluation tools. Finally, two selected classification tasks are analysed by using a Nai├é┬┐ve Bayes classifier.
Improving fairness and privacy of Zhou-Gollmann's fair non-repudiation protocol	We deal with two claws of Zhou-Gollmann's fair non-repudiation protocol. Firstly, their protocol divides a message into 2 parts, i.e., a key K and a ciphertext C. Then, C is delivered to the recipient, while K is submitted to TTP (Trusted Third Party). If the originator doesn't submit K to TTP, then the protocol appears to have no dispute between the originator and the recipient. However the protocol depends on his action on whether the originator really submits K to TTP or not. We show that the originator can make the protocol unfair by using his advantageous position, and present how to improve the fairness of the protocol. Secondly, the protocol doesn't provide the message privacy. This means that additional protocols are required to transfer an important message in private. We propose an improved version of the protocol to guarantee the message privacy
Privacy Preserving OLAP over Distributed XML Documents	We introduce a novel Privacy Preserving Distributed Data Mining routine over collections of XML documents stored in distributed environments, called secure distributed OLAP aggregation, which plays a critical role in next-generation distributed Business Intelligence (BI) scenarios. In order to effectively and efficiently support secure distributed OLAP aggregation routines in such scenarios, a privacy preserving distributed OLAP framework that embeds several points of innovation in the context of privacy preserving OLAP research is hence proposed and deeply investigated in this paper.
Privacy Leakage in Access Mode: Revisiting Private RFID Authentication Protocols	Existing RFID Privacy-Preserving Authentication (PPA) solutions mainly focus on the design of crypto based interactive protocols between readers and tags. Although the cryptographic mechanisms enable randomization and enhance protocol-level privacy, the access mode in RFID systems is less random and may leak private information. We introduce anew attack based on such privacy leakage in access mode, where we show that the mainstream RFID PPA protocols, including the linear, tree-based, and synchronization-based solutions, are not private. We also show that this new attack is easy to conduct, e.g., we can track tags that employ typical tree-based PPA protocols without the need of compromising tags. We discuss the applicability of the attack. Moreover, we provide useful recommendations to strengthen existing PPA protocols in defending against such attacks. The simulation results demonstrate the practicability and effectiveness of this attack.
Assignment of SW using statistical based data model in SW-SDF based personal privacy with QIDB-anonymization method	Privacy preserving data publishing is an important direction in privacy preserving data mining which focuses on ensuring privacy of individual data when it is released for mining. SW-SDF personalized privacy preservation uses two flags SW & SDF to improve data utilization and privacy. This method also gives more privacy to record values which are actually sensitive as compared to algorithms where privacy is applied for all the records. In SW-SDF system SW is manually applied which has been improved by using statistical inference and thereby improving the system. Experimental results show that the overhead of implementing this approach is minimal and can be incorporated.
Privacy-preserving Naive Bayes classification using trusted third party and different offset computation over distributed databases	Privacy-preservation in distributed databases is an important area of research in recent years. In a typical scenario, multiple parties may be wish to collaborate to extract interesting global information such as class labels without revealing their respective data to each other. This may be particularly useful in applications such as car selling units, medical research etc. In the proposed work, we aim to develop a global classification model based on the Nai╠êve Bayes classification scheme. The Nai╠êve Bayes classification has been used because of its applicability in case of car-evaluation dataset. For privacy-preservation of the data, the concept of trusted third party with different offset has been used. The data is first anonymized at local party end and then the aggregation and global classification is done at the trusted third party. We have proposed algorithms and tested dataset for different distributed database scenarios such as horizontal, vertical and arbitrary partitions.
Secure multiparty privacy preserving data aggregation by modular arithmetic	The increasing ability to track and collect large amounts of data with the use of current hardware and software technology has lead to immense challenge and consequent interest in the development of data mining algorithms which preserve user security and privacy in a large distributed system. Secure data aggregation with privacy preserving feature is a demanding task. Privacy preservation is becoming a necessity for data generated for individual purpose as well as for organizational purpose. In this paper, we develop a scheme for secure multiparty data aggregation with the help of modular arithmetic concept. Specifically, we consider a scenario in which two or more parties owning confidential data need to share only for aggregation purpose to a third party, without revealing any unnecessary information. More generally, data aggregation needs to take place by the server or aggregator without acquiring the content of the individual data. Our work is motivated by the need to both protect privileged information and confidentiality. We have shown through simulation results the efficacy of our scheme and compare the result with one of the established scheme.
Privacy Preserving Mobility Control Protocols in Wireless Sensor Networks	With the development of technology, wireless sensor networks (WSNs) performing sensing and communication tasks will be widely deployed in the near future because they greatly extend our ability to monitor and control the physical environment and improve the accuracy of information gathering. Since the sensors are usually deployed in hostile environments and cannot get recharged frequently, the power in sensors is the scarcest resource. Recently many mobility control protocols have been put forward as an effective mechanism to minimize energy consumption. However, security issues in all these protocols have not been discussed so far. In this paper, we will address these issues and point out a new privacy issue (the sink location privacy). A privacy preserving scheme is proposed to protect the sink. Analysis of the scheme shows its effectiveness in sink protection. This scheme can be well integrated into most mobility control protocols to enhance their security.
An Efficient Algorithm for Privacy Preserving Maximal Frequent Itemsets Mining	This paper addressed the insecurity and the inefficiency of privacy preserving association rule mining in vertically partitioned data. We presented a privacy preserving maximal frequent itemsets mining algorithm in vertically partitioned data. The algorithm adopted a more secure vector dot protocol which used an inverse matrix to hide the original input vector, and without any site revealing privacy vector. The mining strategy was based on depth-first search for the maximal frequent itemsets. Performance analysis and experimental analysis showed that the algorithm possessed higher security and efficiency.
Distributed auction servers resolving winner and winning bid without revealing privacy of bids	We have developed an electronic auction system with a set of distributed servers that collaborate to resolve a winning bid without revealing the secrecy of bids. This paper describes the system architecture and shows the performance in terms of the round complexity and the bandwidth consumption for a message. Based on the actual measurements, the upper bound of number of bidding prices is identified. In addition, by adding some steps to the basic auction protocol in Kikuchi, Harkavy, and Tygar, 1998, we improve the security of protocol so that the second highest bid must not be known even by the winner
Privacy enhanced access control by SPKI	In Internet and electronic commerce applications, a user may want to access servers as anonymous with an authorized certificate. In this paper, such privacy-enhanced service scheme is presented by using Simple Public Key Infrastructure (SPKI). A certificate of SPKI carries as few information on clients as possible compared to a certificate of PKIX (Public Key Infrastructure with X.509). After obtaining a certificate issued by an authorized server, a client submits the certificate to the service provider (server) in order to take services associated with the certificate. Then, the provider verifies the submitted certificate and gives permission to the client if verified. A client can delegate a certificate to a third party, so that he/she can access the server instead of the original certificate recipient. The implementation of the proposed certificate-based access control consists of authorized server, issuing agent, client. These are based on SPKI certificate issuer, certificate verifier, access control list management, and delegate mechanism. These subsystems are coded on the basis of SPKI library written in Java
Security Analysis of a Privacy-Preserving Decentralized Key-Policy Attribute-Based Encryption Scheme	In a decentralized attribute-based encryption (ABE) system, any party can act as an authority by creating a public key and issuing private keys to different users that reflect their attributes without any collaboration. Such an ABE scheme can eliminate the burden of heavy communication and collaborative computation in the setup phase of multi-authority ABE schemes, thus is considered more preferable. Recently in IEEE Trans. Parallel Distrib. Syst., Han et al. proposed an interesting privacy-preserving decentralized key-policy ABE scheme, which was claimed to achieve better privacy for users and to be provably secure in the standard model. However, after carefully revisiting the scheme, we conclude that their scheme cannot resist the collusion attacks, hence fails to meet the basic security definitions of the ABE system.
Privacy-Conscious Location-Based Queries in Mobile Environments	In location-based services, users with location-aware mobile devices are able to make queries about their surroundings anywhere and at any time. While this ubiquitous computing paradigm brings great convenience for information access, it also raises concerns over potential intrusion into user location privacy. To protect location privacy, one typical approach is to cloak user locations into spatial regions based on user-specified privacy requirements, and to transform location-based queries into region-based queries. In this paper, we identify and address three new issues concerning this location cloaking approach. First, we study the representation of cloaking regions and show that a circular region generally leads to a small result size for region-based queries. Second, we develop a mobility-aware location cloaking technique to resist trace analysis attacks. Two cloaking algorithms, namely MaxAccu_Cloak and MinComm_Cloak, are designed based on different performance objectives. Finally, we develop an efficient polynomial algorithm for evaluating circular-region-based kNN queries. Two query processing modes, namely bulk and progressive, are presented to return query results either all at once or in an incremental manner. Experimental results show that our proposed mobility-aware cloaking algorithms significantly improve the quality of location cloaking in terms of an entropy measure without compromising much on query latency or communication cost. Moreover, the progressive query processing mode achieves a shorter response time than the bulk mode by parallelizing the query evaluation and result transmission.
Incentive-Driven and Privacy-Preserving Message Dissemination in Large Scale Mobile Networks	In this paper, we propose a new type of incentive-driven and privacy-preserving systems for large scale message dissemination in mobile networks. To distribute incentives which encourage forwarding behaviors, such as monetary rewards, we want to keep track of the forwarder list. In our algorithms, we rely on a robabilistic one-ownership forwarding algorithms to record the list, so that the exchanged messages can be kept short and privacy-preserving. More specifically, only one hop of forwarder information, instead of the complete list, is recorded, and the information is updated probabilistically following two ownership flipping models, namely, One-Flip and Always-Flip models. We also use a Bluetooth Service Discovery Protocol (SDP) toolkit to enable fast, configuration-free message exchange. Throughout the paper, we use coupon as a typical type of message to illustrate the core ideas. We have implemented the coupon dissemination system in Java ME. Our experiments on real world mobile phones, such as Nokia and Samsung phones, and large scale simulations show that our system is efficient in peer to peer message distribution and capable of massive deployment. We believe our key methodology can serve as a general framework for facilitating information propagation on mobile phones, where incentives and privacy protection are both essential.
PEACE: A Novel Privacy-Enhanced Yet Accountable Security Framework for Metropolitan Wireless Mesh Networks	Recently, multihop wireless mesh networks (WMNs) have attracted increasing attention and deployment as a low-cost approach to provide broadband Internet access at metropolitan scale. Security and privacy issues are of most concern in pushing the success of WMNs for their wide deployment and for supporting service-oriented applications. Despite the necessity, limited security research has been conducted toward privacy preservation in WMNs. This motivates us to develop PEACE, a novel Privacy-Enhanced yet Accountable seCurity framEwork, tailored for WMNs. On one hand, PEACE enforces strict user access control to cope with both free riders and malicious users. On the other hand, PEACE offers sophisticated user privacy protection against both adversaries and various other network entities. PEACE is presented as a suite of authentication and key agreement protocols built upon our proposed short group signature variation. Our analysis shows that PEACE is resilient to a number of security and privacy related attacks. Additional techniques were also discussed to further enhance scheme efficiency.
Privacy Preserving Collaborative Enforcement of Firewall Policies in Virtual Private Networks	The widely deployed Virtual Private Network (VPN) technology allows roaming users to build an encrypted tunnel to a VPN server, which, henceforth, allows roaming users to access some resources as if that computer were residing on their home organization's network. Although VPN technology is very useful, it imposes security threats on the remote network because its firewall does not know what traffic is flowing inside the VPN tunnel. To address this issue, we propose VGuard, a framework that allows a policy owner and a request owner to collaboratively determine whether the request satisfies the policy without the policy owner knowing the request and the request owner knowing the policy. We first present an efficient protocol, called Xhash, for oblivious comparison, which allows two parties, where each party has a number, to compare whether they have the same number, without disclosing their numbers to each other. Then, we present the VGuard framework that uses Xhash as the basic building block. The basic idea of VGuard is to first convert a firewall policy to nonoverlapping numerical rules and then use Xhash to check whether a request matches a rule. Comparing with the Cross-Domain Cooperative Firewall (CDCF) framework, which represents the state-of-the-art, VGuard is not only more secure but also orders of magnitude more efficient. On real-life firewall policies, for processing packets, our experimental results show that VGuard is three to four orders of magnitude faster than CDCF.
A Privacy Leakage Upper Bound Constraint-Based Approach for Cost-Effective Privacy Preserving of Intermediate Data Sets in Cloud	Cloud computing provides massive computation power and storage capacity which enable users to deploy computation and data-intensive applications without infrastructure investment. Along the processing of such applications, a large volume of intermediate data sets will be generated, and often stored to save the cost of recomputing them. However, preserving the privacy of intermediate data sets becomes a challenging problem because adversaries may recover privacy-sensitive information by analyzing multiple intermediate data sets. Encrypting ALL data sets in cloud is widely adopted in existing approaches to address this challenge. But we argue that encrypting all intermediate data sets are neither efficient nor cost-effective because it is very time consuming and costly for data-intensive applications to en/decrypt data sets frequently while performing any operation on them. In this paper, we propose a novel upper bound privacy leakage constraint-based approach to identify which intermediate data sets need to be encrypted and which do not, so that privacy-preserving cost can be saved while the privacy requirements of data holders can still be satisfied. Evaluation results demonstrate that the privacy-preserving cost of intermediate data sets can be significantly reduced with our approach over existing ones where all data sets are encrypted.
Privacy-Preserving Decentralized Key-Policy Attribute-Based Encryption	Decentralized attribute-based encryption (ABE) is a variant of a multiauthority ABE scheme where each authority can issue secret keys to the user independently without any cooperation and a central authority. This is in contrast to the previous constructions, where multiple authorities must be online and setup the system interactively, which is impractical. Hence, it is clear that a decentralized ABE scheme eliminates the heavy communication cost and the need for collaborative computation in the setup stage. Furthermore, every authority can join or leave the system freely without the necessity of reinitializing the system. In contemporary multiauthority ABE schemes, a user's secret keys from different authorities must be tied to his global identifier (GID) to resist the collusion attack. However, this will compromise the user's privacy. Multiple authorities can collaborate to trace the user by his GID, collect his attributes, then impersonate him. Therefore, constructing a decentralized ABE scheme with privacy-preserving remains a challenging research problem. In this paper, we propose a privacy-preserving decentralized key-policy ABE scheme where each authority can issue secret keys to a user independently without knowing anything about his GID. Therefore, even if multiple authorities are corrupted, they cannot collect the user's attributes by tracing his GID. Notably, our scheme only requires standard complexity assumptions (e.g., decisional bilinear Diffie-Hellman) and does not require any cooperation between the multiple authorities, in contrast to the previous comparable scheme that requires nonstandard complexity assumptions (e.g., q-decisional Diffie-Hellman inversion) and interactions among multiple authorities. To the best of our knowledge, it is the first decentralized ABE scheme with privacy-preserving based on standard complexity assumptions.
Exploiting Service Similarity for Privacy in Location Based Search Queries	Location-based applications utilize the positioning capabilities of a mobile device to determine the current location of a user, and customize query results to include neighboring points of interests. However, location knowledge is often perceived as personal information. One of the immediate issues hindering the wide acceptance of location-based applications is the lack of appropriate methodologies that offer fine grain privacy controls to a user without vastly affecting the usability of the service. While a number of privacy-preserving models and algorithms have taken shape in the past few years, there is an almost universal need to specify one's privacy requirement without understanding its implications on the service quality. In this paper, we propose a user-centric location-based service architecture where a user can observe the impact of location inaccuracy on the service accuracy before deciding the geo-coordinates to use in a query. We construct a local search application based on this architecture and demonstrate how meaningful information can be exchanged between the user and the service provider to allow the inference of contours depicting the change in query results across a geographic area. Results indicate the possibility of large default privacy regions (areas of no change in result set) in such applications.
Privacy-Aware Collaborative Spam Filtering	While the concept of collaboration provides a natural defense against massive spam e-mails directed at large numbers of recipients, designing effective collaborative anti-spam systems raises several important research challenges. First and foremost, since e-mails may contain confidential information, any collaborative anti-spam approach has to guarantee strong privacy protection to the participating entities. Second, the continuously evolving nature of spam demands the collaborative techniques to be resilient to various kinds of camouflage attacks. Third, the collaboration has to be lightweight, efficient, and scalable. Toward addressing these challenges, this paper presents ALPACAS-a privacy-aware framework for collaborative spam filtering. In designing the ALPACAS framework, we make two unique contributions. The first is a feature-preserving message transformation technique that is highly resilient against the latest kinds of spam attacks. The second is a privacy-preserving protocol that provides enhanced privacy guarantees to the participating entities. Our experimental results conducted on a real e-mail data set shows that the proposed framework provides a 10 fold improvement in the false negative rate over the Bayesian-based Bogofilter when faced with one of the recent kinds of spam attacks. Further, the privacy breaches are extremely rare. This demonstrates the strong privacy protection provided by the ALPACAS system.
Privacy in VoIP Networks: Flow Analysis Attacks and Defense	(A short version of this paper appears in IEEE INFOCOM 2009: http://www.research.ibm.com/people/i/iyengar/INFOCOM2009-kanon.pdf.) Peer-to-peer VoIP (voice over IP) networks, exemplified by Skype, are becoming increasingly popular due to their significant cost advantage and richer call forwarding features than traditional public switched telephone networks. One of the most important features of a VoIP network is privacy (for VoIP clients). Unfortunately, most peer-to-peer VoIP networks neither provide personalization nor guarantee a quantifiable privacy level. In this paper, we propose novel flow analysis attacks that demonstrate the vulnerabilities of peer-to-peer VoIP networks to privacy attacks. We then address two important challenges in designing privacy-aware VoIP networks: Can we provide personalized privacy guarantees for VoIP clients that allow them to select privacy requirements on a per-call basis? How to design VoIP protocols to support customizable privacy guarantee? This paper proposes practical solutions to address these challenges using a quantifiable k-anonymity metric and a privacy-aware VoIP route setup and route maintenance protocols. We present detailed experimental evaluation that demonstrates the performance and scalability of our protocol, while meeting customizable privacy guarantees.
Distributed Privacy-Preserving Access Control in Sensor Networks	The owner and users of a sensor network may be different, which necessitates privacy-preserving access control. On the one hand, the network owner need enforce strict access control so that the sensed data are only accessible to users willing to pay. On the other hand, users wish to protect their respective data access patterns whose disclosure may be used against their interests. This paper presents DP<sup>2</sup>AC, a Distributed Privacy-Preserving Access Control scheme for sensor networks, which is the first work of its kind. Users in DP<sup>2</sup>AC purchase tokens from the network owner whereby to query data from sensor nodes which will reply only after validating the tokens. The use of blind signatures in token generation ensures that tokens are publicly verifiable yet unlinkable to user identities, so privacy-preserving access control is achieved. A central component in DP<sup>2</sup>AC is to prevent malicious users from reusing tokens, for which we propose a suite of distributed token reuse detection (DTRD) schemes without involving the base station. These schemes share the essential idea that a sensor node checks with some other nodes (called witnesses) whether a token has been used, but they differ in how the witnesses are chosen. We thoroughly compare their performance with regard to TRD capability, communication overhead, storage overhead, and attack resilience. The efficacy and efficiency of DP<sup>2</sup>AC are confirmed by detailed performance evaluations.
SPOC: A Secure and Privacy-Preserving Opportunistic Computing Framework for Mobile-Healthcare Emergency	With the pervasiveness of smart phones and the advance of wireless body sensor networks (BSNs), mobile Healthcare (m-Healthcare), which extends the operation of Healthcare provider into a pervasive environment for better health monitoring, has attracted considerable interest recently. However, the flourish of m-Healthcare still faces many challenges including information security and privacy preservation. In this paper, we propose a secure and privacy-preserving opportunistic computing framework, called SPOC, for m-Healthcare emergency. With SPOC, smart phone resources including computing power and energy can be opportunistically gathered to process the computing-intensive personal health information (PHI) during m-Healthcare emergency with minimal privacy disclosure. In specific, to leverage the PHI privacy disclosure and the high reliability of PHI process and transmission in m-Healthcare emergency, we introduce an efficient user-centric privacy access control in SPOC framework, which is based on an attribute-based access control and a new privacy-preserving scalar product computation (PPSPC) technique, and allows a medical user to decide who can participate in the opportunistic computing to assist in processing his overwhelming PHI data. Detailed security analysis shows that the proposed SPOC framework can efficiently achieve user-centric privacy access control in m-Healthcare emergency. In addition, performance evaluations via extensive simulations demonstrate the SPOC's effectiveness in term of providing high-reliable-PHI process and transmission while minimizing the privacy disclosure during m-Healthcare emergency.
Call for Papers: Special Issue on Trust, Security, and Privacy in Parallel and Distributed Systems	"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers."
A Cloud-Based Scheme for Protecting Source-Location Privacy against Hotspot-Locating Attack in Wireless Sensor Networks	In wireless sensor networks, adversaries can make use of the traffic information to locate the monitored objects, e.g., to hunt endangered animals or kill soldiers. In this paper, we first define a hotspot phenomenon that causes an obvious inconsistency in the network traffic pattern due to the large volume of packets originating from a small area. Second, we develop a realistic adversary model, assuming that the adversary can monitor the network traffic in multiple areas, rather than the entire network or only one area. Using this model, we introduce a novel attack called Hotspot-Locating where the adversary uses traffic analysis techniques to locate hotspots. Finally, we propose a cloud-based scheme for efficiently protecting source nodes' location privacy against Hotspot-Locating attack by creating a cloud with an irregular shape of fake traffic, to counteract the inconsistency in the traffic pattern and camouflage the source node in the nodes forming the cloud. To reduce the energy cost, clouds are active only during data transmission and the intersection of clouds creates a larger merged cloud, to reduce the number of fake packets and also boost privacy preservation. Simulation and analytical results demonstrate that our scheme can provide stronger privacy protection than routing-based schemes and requires much less energy than global-adversary-based schemes.
A Generic Framework for Three-Factor Authentication: Preserving Security and Privacy in Distributed Systems	As part of the security within distributed systems, various services and resources need protection from unauthorized use. Remote authentication is the most commonly used method to determine the identity of a remote client. This paper investigates a systematic approach for authenticating clients by three factors, namely password, smart card, and biometrics. A generic and secure framework is proposed to upgrade two-factor authentication to three-factor authentication. The conversion not only significantly improves the information assurance at low cost but also protects client privacy in distributed systems. In addition, our framework retains several practice-friendly properties of the underlying two-factor authentication, which we believe is of independent interest.
Hop-by-Hop Message Authentication and Source Privacy in Wireless Sensor Networks	Message authentication is one of the most effective ways to thwart unauthorized and corrupted messages from being forwarded in wireless sensor networks (WSNs). For this reason, many message authentication schemes have been developed, based on either a symmetric-key cryptosystem or a public-key cryptosystem. Most of them, however, have the limitations of high computational and communication overhead in addition to lack of scalability and resilience to node compromising attacks. To address these issues, a polynomial-based scheme was recently introduced. However, this scheme and its extensions all have the weakness of a built-in threshold determined by the degree of the polynomial: when the number of messages transmitted is larger than this threshold, the adversary can fully recover the polynomial. In this paper, we propose a scalable authentication scheme based on elliptic curve cryptography (ECC). While enabling intermediate nodes authentication, our proposed scheme allows any nodes to transmit an unlimited number of messages without suffering the threshold problem. In addition, our scheme can also provide message source privacy. Both theoretical analysis and simulation results demonstrate that our proposed scheme is more efficient than the polynomial-based approach in terms of computational and communication overhead under comparable security levels while providing message source privacy.
EPPA: An Efficient and Privacy-Preserving Aggregation Scheme for Secure Smart Grid Communications	The concept of smart grid has emerged as a convergence of traditional power system engineering and information and communication technology. It is vital to the success of next generation of power grid, which is expected to be featuring reliable, efficient, flexible, clean, friendly, and secure characteristics. In this paper, we propose an efficient and privacy-preserving aggregation scheme, named EPPA, for smart grid communications. EPPA uses a superincreasing sequence to structure multidimensional data and encrypt the structured data by the homomorphic Paillier cryptosystem technique. For data communications from user to smart grid operation center, data aggregation is performed directly on ciphertext at local gateways without decryption, and the aggregation result of the original data can be obtained at the operation center. EPPA also adopts the batch verification technique to reduce authentication cost. Through extensive analysis, we demonstrate that EPPA resists various security threats and preserve user privacy, and has significantly less computation and communication overhead than existing competing approaches.
Quantitative Measurement and Design of Source-Location Privacy Schemes for Wireless Sensor Networks	Wireless sensor networks (WSNs) have been widely used in many areas for critical infrastructure monitoring and information collection. While confidentiality of the message can be ensured through content encryption, it is much more difficult to adequately address source-location privacy (SLP). For WSNs, SLP service is further complicated by the nature that the sensor nodes generally consist of low-cost and low-power radio devices. Computationally intensive cryptographic algorithms (such as public-key cryptosystems), and large scale broadcasting-based protocols may not be suitable. In this paper, we first propose criteria to quantitatively measure source-location information leakage in routing-based SLP protection schemes for WSNs. Through this model, we identify vulnerabilities of some well-known SLP protection schemes. We then propose a scheme to provide SLP through routing to a randomly selected intermediate node (RSIN) and a network mixing ring (NMR). Our security analysis, based on the proposed criteria, shows that the proposed scheme can provide excellent SLP. The comprehensive simulation results demonstrate that the proposed scheme is very efficient and can achieve a high message delivery ratio. We believe it can be used in many practical applications.
Internet Traffic Privacy Enhancement with Masking: Optimization and Trade-Offs	An increasing number of recent experimental works have demonstrated that the supposedly secure channels in the Internet are prone to privacy breaking under many respects, due to packet traffic features leaking information on the user activity and traffic content. We aim at understanding if and how complex it is to obfuscate the information leaked by packet traffic features, namely packet lengths, directions, times: we call this technique traffic masking. We define a security model that points out what the ideal target of masking is, and then define the optimized traffic masking algorithm that removes any leaking (full masking). Further, we investigate the trade-off between traffic privacy protection and masking cost, namely required amount of overhead and realization complexity/feasibility. Numerical results are based on measured Internet traffic traces. Major findings are that: i) optimized full masking achieves similar overhead values with padding only and in case fragmentation is allowed; ii) if practical realizability is accounted for, optimized statistical masking attains only moderately better overhead than simple fixed pattern masking does, while still leaking correlation information that can be exploited by the adversary.
EPPDR: An Efficient Privacy-Preserving Demand Response Scheme with Adaptive Key Evolution in Smart Grid	Smart grid has recently emerged as the next generation of power grid due to its distinguished features, such as distributed energy control, robust to load fluctuations, and close user-grid interactions. As a vital component of smart grid, demand response can maintain supply-demand balance and reduce users&amp;#x2019; electricity bills. Furthermore, it is also critical to preserve user privacy and cyber security in smart grid. In this paper, we propose an efficient privacy-preserving demand response (EPPDR) scheme which employs a homomorphic encryption to achieve privacy-preserving demand aggregation and efficient response. In addition, an adaptive key evolution technique is further investigated to ensure the users&amp;#x2019; session keys to be forward secure. Security analysis indicates that EPPDR can achieve privacy-preservation of electricity demand, forward secrecy of users&amp;#x2019; session keys, and evolution of users&amp;#x2019; private keys. In comparison with an existing scheme which also achieves forward secrecy, EPPDR has better efficiency in terms of computation and communication overheads, and can adaptively control the key evolution to balance the trade-off between the communication efficiency and security level.
Scalable RFID Systems: A Privacy-Preserving Protocol with Constant-Time Identification	In RFID literature, most ΓÇ£privacy-preservingΓÇ¥ protocols require the reader to search all tags in the system in order to identify a single tag. In another class of protocols, the search complexity is reduced to be logarithmic in the number of tags, but it comes with two major drawbacks: it requires a large communication overhead over the fragile wireless channel, and the compromise of a tag in the system reveals secret information about other, uncompromised, tags in the same system. In this work, we take a different approach to address time complexity of private identification in large-scale RFID systems. We utilize the special architecture of RFID systems to propose a symmetric-key privacy-preserving authentication protocol for RFID systems with constant-time identification. Instead of increasing communication overhead, the existence of a large storage device in RFID systems, the database, is utilized for improving the time efficiency of tag identification.
Towards Providing Scalable and Robust Privacy in Vehicular Networks	The first main contribution of this work is to take a nontrivial step towards providing a robust and scalable solution to privacy in vehicular networks. We employ two strategies. First, we view vehicular networks as consisting of non-overlapping subnetworks, each local to a geographic area referred to as a cell. Each cell has a server that maintains a list of pseudonyms that are valid for use in the cell. Each pseudonym has two components: the cell's ID and a random number as host ID. Instead of issuing pseudonyms to vehicles proactively (as virtually all existing schemes do) we issue pseudonyms only to those vehicles that request them. This strategy is suggested by the fact that, in a typical scenario, only a fraction of the vehicles in an area will engage in communication with other vehicles and/or with the infrastructure and, therefore, do not need pseudonyms. Our second main contribution is to model analytically the time-varying request for pseudonyms in a given cell. This is important for capacity planning purposes since it allows system managers to predict, by taking into account the time-varying attributes of the traffic, the probability that a given number of pseudonyms will be required at a certain time as well as the expected number of pseudonyms in use in a cell at a certain time. Empirical results obtained by detailed simulation confirmed the accuracy of our analytical predictions.
LocaWard: A Security and Privacy Aware Location-Based Rewarding System	The proliferation of mobile devices has driven the mobile marketing to surge in the past few years. Emerging as a new type of mobile marketing, mobile location-based services (MLBSs) have attracted intense attention recently. Unfortunately, current MLBSs have a lot of limitations and raise many concerns, especially about system security and users' privacy. In this paper, we propose a new kind of location-based rewarding system, called LocaWard, where mobile users can collect location-based tokens from token distributors, and then redeem their gathered tokens at token collectors for beneficial rewards. Tokens act as virtual currency. The token distributors and collectors can be any commercial entities or merchants that wish to attract customers through such a promotion system, such as stores, restaurants, and car rental companies. We develop a security and privacy aware location-based rewarding protocol for the LocaWard system, and prove the correctness and completeness of the protocol. Moreover, we show that the system is resilient to various attacks and mobile users' privacy can be well protected in the meantime. We finally implement the system and conduct extensive experiments to validate the system efficiency in terms of computation cost, communication cost, energy consumption, and storage space.
Privacy Preserving Back-Propagation Neural Network Learning Made Practical with Cloud Computing	To improve the accuracy of learning result, in practice multiple parties may collaborate through conducting joint Back-propagation neural network learning on the union of their respective data sets. During this process no party wants to disclose her/his private data to others. Existing schemes supporting this kind of collaborative learning are either limited in the way of data partition or just consider two parties. There lacks a solution that allows two or more parties, each with an arbitrarily partitioned data set, to collaboratively conduct the learning. This paper solves this open problem by utilizing the power of cloud computing. In our proposed scheme, each party encrypts his/her private data locally and uploads the ciphertexts into the cloud. The cloud then executes most of the operations pertaining to the learning algorithms over ciphertexts without knowing the original private data. By securely offloading the expensive operations to the cloud, we keep the computation and communication costs on each party minimal and independent to the number of participants. To support flexible operations over ciphertexts, we adopt and tailor the BGN`doubly homomorphic' encryption algorithm for the multi-party setting. Numerical analysis and experiments on commodity cloud show that our scheme is secure, efficient and accurate.
Privacy-Preserving Multiparty Collaborative Mining with Geometric Data Perturbation	In multiparty collaborative data mining, participants contribute their own data sets and hope to collaboratively mine a comprehensive model based on the pooled data set. How to efficiently mine a quality model without breaching each party's privacy is the major challenge. In this paper, we propose an approach based on geometric data perturbation and data mining service-oriented framework. The key problem of applying geometric data perturbation in multiparty collaborative mining is to securely unify multiple geometric perturbations that are preferred by different parties, respectively. We have developed three protocols for perturbation unification. Our approach has three unique features compared to the existing approaches: with geometric data perturbation, these protocols can work for many existing popular data mining algorithms, while most of other approaches are only designed for a particular mining algorithm; both the two major factors: data utility and privacy guarantee are well preserved, compared to other perturbation-based approaches; and two of the three proposed protocols also have great scalability in terms of the number of participants, while many existing cryptographic approaches consider only two or a few more participants. We also study different features of the three protocols and show the advantages of different protocols in experiments.
An Identity-Based Security System for User Privacy in Vehicular Ad Hoc Networks	Vehicular ad hoc network (VANET) can offer various services and benefits to users and thus deserves deployment effort. Attacking and misusing such network could cause destructive consequences. It is therefore necessary to integrate security requirements into the design of VANETs and defend VANET systems against misbehavior, in order to ensure correct and smooth operations of the network. In this paper, we propose a security system for VANETs to achieve privacy desired by vehicles and traceability required by law enforcement authorities, in addition to satisfying fundamental security requirements including authentication, nonrepudiation, message integrity, and confidentiality. Moreover, we propose a privacy-preserving defense technique for network authorities to handle misbehavior in VANET access, considering the challenge that privacy provides avenue for misbehavior. The proposed system employs an identity-based cryptosystem where certificates are not needed for authentication. We show the fulfillment and feasibility of our system with respect to the security goals and efficiency.
Time-Based Privacy Protection for Multi-attribute Data in WSNs	Wireless sensor networks become ubiquitous to collect people's information in many people-centric applications, such as, health care, smart space and public safety. Because any misusage of these personal data might result in the leakage of privacy, it is expected that the data requesters can only access to the data what they are entitled to read. Based on a revised hash chain technique, we proposed a novel time-based privacy protection (TPP) scheme for multi-attribute data in WSNs. In the scheme, all the personal data are divided into 2-D subspaces representing data attribute and generation time. Data in each subspace is encrypted with a sub-key before its transmission to the sink. Anyone who wants to read data attribute at a particular time must get the corresponding sub-key from the sender node. TPP can generate a sub-key for data in each subspace in an efficient manner in terms of less sub-key generation time and low memory space usage. The simulation results show that the schemes can be applied to the resource limited WSNs efficiently.
Privacy-preserving logical vector clocks using secure computation techniques	Systems of logical clocks are commonly found in distributed systems for establishing causality between events occurring in concurrent communicating processes. Vector clocks are a popular type of logical clocks which require processes to attach to each message a logical timestamp that contains information about the sender process's view of the state of the distributed computation at the time of message sending. Causality between two events can then be determined by comparing their two logical timestamps. However, by doing so, processes leak potentially sensitive information about the advancement of their computation and the computations performed by the processes they communicate with. The contribution presented in this paper is a protocol, based on secure computation techniques, which preserves the privacy of each process's local logical clock while being strictly equivalent to regular vector clocks.
Privacy-Aware Multi-Keyword Top-k Search over Untrust Data Cloud	In this paper, we focus on data privacy of searchable symmetric encryption (SSE) in cloud computing. For the first time, we formulate the privacy issue from the aspect of similarity relevance and scheme robustness and then prove server-side ranking based on order-preserving encryption (OPE) inevitably leaks data privacy. In order to solve this problem, we propose a two round searchable encryption (TRSE) scheme, supporting top-k multi-keyword search, in which novel technologies, i.e., homomorphic encryption and vector space model, are employed. Vector space model helps to provide sufficient search accuracy, and homomorphic encryption enables users involve in the ranking while majority of computing work is still done on server-side by operations only on ciphertext. In this way, information leakage can be eliminated and data security is ensured. Thorough security analysis and performance analysis show that the proposed scheme guarantees high security and practical efficiency.
Demonstration of Damson: Differential Privacy for Analysis of Large Data	We demonstrate Damson, a novel and powerful tool for publishing the results of biomedical research with strong privacy guarantees. Damson is developed based on the theory of differential privacy, which ensures that the adversary cannot infer the presence or absence of any individual from the published results, even with substantial background knowledge. Damson supports a variety of analysis tasks that are common in biomedical studies, including histograms, marginals, data cubes, classification, regression, clustering, and ad-hoc selection-counts. Additionally, Damson contains an effective query optimization engine, which obtains high accuracy for analysis results, while minimizing the privacy costs of performing such analysis.
BEST: A Bidirectional Efficiency-Privacy Transferable Authentication Protocol for RFID-Enabled Supply Chain	Radio Frequency Identification (RFID) technique is gaining increasing popularity in supply chain for the product management. By attaching a tag to each product, a reader can employ an authentication protocol to interrogate the tag's information for verification, which facilitates the automatic processing and monitoring of products in many applications. However, most current solutions cannot be directly used as they cannot balance the tradeoff between the privacy and efficiency for individual parties. In this paper, we design a bidirectional efficiency-privacy transferable (BEST) authentication protocol to address this issue. In a relatively secure domain, BEST works in an efficient manner to authenticate batches of tags with less privacy guarantee. Once the tags flow into open environment, BEST can migrate to provide stronger privacy protection to the tags with moderate efficiency degradation. The analytic result shows that BEST can well adapt to the RFID-enabled supply chain.
Complete Bipartite Anonymity: Confusing Anonymous Mobility Traces for Location Privacy	Using mobile devices, people can easily obtain their location information, and access a wide range of location based services (LBSs). Many existing LBSs rely in accurate, continuous, and real-time streams of location information to provide quality of service guarantees. In this case, even if an user accesses LBSs anonymously, the identity of the user can still be revealed by analyzing the mobility trace. To protect user privacy, existing work sacrifice the quality of LBSs by degrading spatial and temporal accuracy. To achieve a better tradeoff between user privacy and the quality of service, we present a novel approach, Complete Bipartite Anonymity (CBA), to confuse the paths of nearby users by connecting different users' real traces with fake ones. CBA protects user privacy as users become indistinguishable after their paths are confused, the quality of service of LBSs is also guaranteed since users are able to report their accurate locations. We evaluate CBA by comparing the system and privacy performance with existing techniques such as Path Confusion or Query Obfuscation using a real-world data set, the results show that our scheme increases the chance for a user joining an anonymity group by 10 times in low user density areas, and reduces the resources consumed by about 90% for achieving the same anonymity degree.
Privacy Preservation in Streaming Data Collection	Big data management and analysis has become a hot topic in academic and industrial research. In fact, a large portion of big data in service today are initially streaming data. To preserve the privacy of such data that are collected from data streams, the most efficient way is to control the process of data collection according to corresponding privacy polices. In this paper, we design a framework to support data stream management with privacy-preserving capabilities. In particular, we focus on two premier principles of data privacy, limited disclosure and limited collection. With these two principles guaranteed, the archived data will not necessarily be checked for privacy protection, before analysis and other operations can be done.
Privacy Preserving for Continuous Query in Location Based Services	Location-based services (LBSs) have become a popular and important way to provide real-time information and guidance. The abuse of mobile users' location data, which may violate their sensitive and private personal information, is one of the major challenges faced by LBS. On the other hand, the query launched by mobile users should not be linked to them even if they are required to expose their location information to attain some services. However, many location based systems (e.g., mobile social networks, store finders) are lacking of users' private preserving consideration. In this paper, we focuse-focus on the issues related to query linking privacy. Particularly, we aim to preserve mobile users' privacy in location based mobile systems where their location information may be available, furthermore, while facing attacks, the sensitive data of a specific mobile user launching the query should not be disclosed to an adversary. We present a new query linking privacy preserving algorithm (V-DCA) for continuous LBS by taking the user's velocity and acceleration similarity into consideration. The consecutive generated cloaked sets are used to create the new cloaked region, which decreases the complexity of the algorithm while fulfilling the privacy requirement. The simulation results show that V-DCA can preserve mobile user's privacy as well as provide better Quality of Service (QoS).
Ad-hoc Anonymity: Privacy Preservation for Location-based Services in Mobile Networks	Location-based Service (LBS) becomes increasingly important for wireless and mobile networks. In current LBS schemes, Service Providers (SPs) require users report their accurate locations, which can be illegally used by adversaries to infer sensitive information of users. Privacy disclosure raises serious concerns and limits the application of LBS. Previous solutions either rely on pre-installed centralized intermediary or assume cooperative users. Other distributed solutions, lacking of user obligation, only provide relatively poor anonymity. In this study, we propose a new solution of pseudonym change, which works for non-cooperative users and in the absence of intermediary. The basic idea behind our solution is ad-hoc anonymity. The proposed solution allows users to decide whether or not participating according to their own wills. In addition, artificially generated dummies mix up all the users who have participated in pseudonym changes at different times. Theoretical analysis demonstrates that asynchronous pseudonym change and dummy participation notably enhance privacy protection. We implement our solution on a real-world dataset of mobile phone users, which is collected at Boston, MA, and by the Reality Mining, MIT. The simulation results show that our approach significantly outperforms existing solutions.
Secure Communication Scheme of VANET with Privacy Preserving	This paper proposes a secure communication and privacy preserving scheme of Vehicular ad-hoc network (VANET). VANET improves road safety and traffic conditions via the vehicle exchange the traffic information with other vehicles and some infrastructures immediately. Ensuring that exchange messages are secure, trustworthy and protect user privacy are important issues. The transmission message must be well protected to ensure the integrity, confidentiality, anonymity and unlink ability. The transmission message must also satisfy trace ability and non-repudiation to guarantee the trusted third party can reveal misbehaving users. This proposed scheme is an efficient self-generated pseudonym mechanism based on Identity-Based Encryption (IBE) to provide privacy preservation. It also provides integrity, confidentiality, anonymity, trace ability and non-repudiation for VANET communications.
Privacy Protection in Participatory Sensing Applications Requiring Fine-Grained Locations	The emerging participatory sensing applications have brought a privacy risk where users expose their location information. Most of the existing solutions preserve location privacy by generalizing a precise user location to a coarse-grained location, and hence they cannot be applied in those applications requiring fine-grained location information. To address this issue, in this paper we propose a novel method to preserve location privacy by anonymizing coarse-grained locations and retaining fine-grained locations using Attribute Based Encryption (ABE). In addition, we do not assume the service provider is an trustworthy entity, making our solution more feasible to practical applications. We present and analyze our security model, and evaluate the performance and scalability of our system.
PicFS: The Privacy-Enhancing Image-Based Collaborative File System	Cloud computing makes available a vast amount of computation and storage resources in the pay-as-you-go manner. However, the users of cloud storage have to trust the providers to ensure the data privacy and confidentiality. In this paper, we present the Privacy-enhancing Image-based Collaborative File System (PicFS), a network file system that steganographically encodes itself into images and provides anonymous uploads and downloads from a media sharing website. PicFS provides plausible deniability by preventing traffic and image analysis by any third party from revealing the existence of PicFS or compromising its data. Because all accesses are anonymized, users of PicFS are dissociated from their data, which protects users against being compelled to release their keys. For further security and ease of use, we develop a method for automatically generating a large set of non-suspicious images to serve as input to the system. Our prototype leverages a number of existing technologies, including the F5 algorithm for steganography, Quick-Flickr for Flickr API access, Tor for anonymization, and FUSE-J for user-level file system calls. We show that the PicFS is indeed practical as the prototype demonstrates satisfactory performance in the real-world environment.
Privacy Reference Monitor - A Computer Model for Law Compliant Privacy Protection	The Internet and computers did not invent or even cause privacy issues. The issues existed long before the creation of computers and Internet. The existence of the Internet, computers and large data storage make it possible to collect, process and transmit large volumes of data, including personal data. In this paper, we shall study the privacy from following two different views, namely legal framework and computer security model, and attempt to identify the difference between them. Because of the difference, we further argue that the current computer security model is not sufficient to support the privacy requirements in the legal framework. We propose a computer model ├é┬┐privacy reference monitor├é┬┐ to handle those unsupported requirements. The design of the privacy reference monitor is privacy policy neutral with a small number of functions. With minimal functionalities, we believe that it is possible to implement a verifiable privacy reference monitor.
Privacy Protection in Service Discovery for Large-Scale Distributed Computing Systems	Service discovery is one of the integral tasks of the system running in distributed computing environment. Even though numerous researches on service discovery have been conducted, the security and privacy issue have not yet been addressed adequately. Here letting only legitimate user and service provider for service discovery is a challenging problem. In this paper we present a scheme for secure service discovery by employing an incremental progressive exposure approach, where the user and service provider exchange only partial encrypted information at each step. They compare the information sent from the other party with their own information. The exchange operation continues until a mismatch occurs or the required service is found finally. Computer simulation reveals that the proposed approach significantly reduces the number of message exchanges compared to the existing progressive exposure scheme.
A Case Study: File Access Privacy Control Using Filter Hook Driver	Sandbox security model is extremely useful for secure execution of untrusted applications. Many sandbox model based security systems proposed so far provide security by intercepting system calls invoked by applications and controlling their execution. However, a problem in existing sandbox based systems is the amount of overhead required for security checks performed after system call interception. In addition, it is difficult for computer novices to manage their security systems because the system settings are complex. In this paper, a function was proposed and implemented to monitor only the file access in Microsoft Windows environment. Test result shows that this function could protect files from unallowed access and then minimize the overhead of application execution time.
Enhancing Privacy and Security in RFID-Enabled Banknotes	A novel and interesting application of RFID was a banknote attached a tag to determine the authenticity of money and to stop counterfeits. At financial cryptography 2003, Juels and Pappu firstly proposed a practical RFID banknote protection scheme (RBPS) by using the optical and the electrical (RFID) contacts. RFID-enabled notes can be tracked by the legal law agency and verified by the merchant. However, some effective attacks on the Juels-Pappu RBPS were subsequently proposed. In this paper, we enhance the Juels-Pappu RBPS to conquer such attacks.
A New Cloaking Method Supporting both K-anonymity and L-diversity for Privacy Protection in Location-Based Service	In location-based services (LBSs), users send location-based queries to LBS servers along with their exact locations, but the location information of the users can be misused by adversaries. In this regard, there must be a mechanism which can deal with the privacy protection of the users. In this paper, we propose a cloaking method considering both K-anonymity and L-diversity. Our cloaking method creates a minimum cloaking region by finding L number of buildings (L-diversity) and then finds K number of users (K-anonymity). To support it, we use R*-tree based index structures as well as efficient filtering techniques to generate a minimum cloaking region. Finally, we show from our performance analysis that our cloaking method outperforms the existing grid-based cloaking method in terms of the size of cloaking regions and cloaking region creation time.
Privacy Protection in Pervasive Healthcare Monitoring Systems with Active Bundles	The main problem in pervasive healthcare monitoring systems is protection of patient privacy without compromising their safety. Current solutions have two main limitations: (1) they require an extensive exchange of messages among patient's caregivers and devices in order to protect data, and (2) they depend on using data decryption keys that must be provided to specific caregivers. The second limitation compromises safety of patients who need urgent help while their ad hoc caregivers have no access to their health data (since they have no needed decryption keys). This paper proposes an approach for protecting privacy of patients based on active bundles. An active bundle encapsulates sensitive data, metadata, and a virtual machine. In healthcare monitoring systems, "sensitive data" are monitored health data. To avoid compromising of safety of patients who need urgent help, our approach does not depend on the use of decryption keys provided to specific caregivers (which is a commonly used approach). Instead, it combines the use of privacy policies and protection mechanisms included within active bundles, such as evaporation and apoptosis. In our approach, ad hoc caregivers are able to access urgently needed patients' data. Their authorizations are provided via privacy policies encapsulated in metadata of an active bundle including health data.
Affordable Privacy for Home Smart Meters	Smart metering is an essential element of the future smart grid development. However, frequent data collected by home smart meters reveal a wealth of information about residential appliance usage. This gives rise to the smart metering privacy problem. Smart metering data privacy can be protected by using a battery to mask energy usage profiles. However, such a system privately modifies usage consumption patterns and it may induce a cost depending on battery performance and dynamic utility pricing. The aim of this paper is to show a) how information theoretic anonymity metrics can be used to measure the privacy protection offered by a water-filling power transformation algorithm, b) how a good level of protection and a low maintenance cost can be obtained with reasonably sized batteries, and c) what is the impact on the utility and price. Our initial cost analysis results suggest that it is possible to communicate granular smart metering information, protect the consumers' privacy at a low cost, and promote load balancing in the smart grid. That renders our privacy protection system affordable.
Multi-party k-Means Clustering with Privacy Consideration	The k-means clustering algorithm is a widely used scheme to solve the clustering problem which classifies a given set of n data points in m-dimensional space into k clusters, whose centers are obtained by the centroids of the points in the same cluster. The problem with privacy consideration has been studied, when the data is distributed among different parties and the privacy of the distributed data is to be preserved. In this paper, we apply the concept of parallel computing to solve the privacy-preserving multi-party k-means clustering problem, when the data is vertically partitioned and horizontally partitioned respectively among different parties. We present algorithms for solving the problems for these two data partition models that run in O(nk) time and in O(m(k + log(n=k))) time respectively. The time complexities of the algorithms are much better than others without parallel computing.
Scalability in Privacy-Preserving Data Aggregation for Wireless Sensor Networks	In this paper, we propose a new privacy preserving data aggregation scheme for WSNs. Our scheme applies additive property of complex numbers in order to combine sensor data and preserve data privacy during transmission to the sink node. In addition, for supporting scalability, we propose a novel mechanism in which a special set of real numbers are assigned to sensor nodes as their IDs so that a single bit is sufficient to hold ID of a sensor node during transmission of aggregated data to the sink node. For this, we, first, generate fixed size signatures for the IDs of all sensor nodes and then superimpose the signatures during data aggregation phase. By analytical evaluations, we show that our scheme is more scalable and energy efficient than the existing methods to achieve data privacy and transmit IDs of sensor nodes along with the aggregated data to the sink node.
Privacy-aware presence management in instant messaging systems	Information about online presence allows participants of instant messaging (IM) systems to determine whether their prospective communication partners are able to answer their requests in a timely manner, or not. This makes IM more personal and closer than other forms of communication such as e-mail. On the other hand, revelation of presence constitutes a potential of misuse by untrustworthy entities, e.g. generation of presence logs. We argue that current IM systems do not take reasonable precautions to protect presence information. We propose an IM system designed to be robust against attacks to disclose a user's presence. It stores presence information in a distributed hash table (DHT) in a way that is only detectable and applicable for intended users and even not comprehensible for the DHT nodes. We apply an anonymous communication network to protect the users' physical addresses
Preserving source location privacy in monitoring-based wireless sensor networks	While a wireless sensor network is deployed to monitor certain events and pinpoint their locations, the location information is intended only for legitimate users. However, an eavesdropper can monitor the traffic and deduce the approximate location of monitored objects in certain situations. We first describe a successful attack against the flooding-based phantom routing, proposed in the seminal work by Celal Ozturk, Yanyong Zhang, and Wade Trappe. Then, we propose GROW (Greedy Random Walk), a two-way random walk, i.e., from both source and sink, to reduce the chance an eavesdropper can collect the location information. We improve the delivery rate by using local broadcasting and greedy forwarding. Privacy protection is verified under a backtracking attack model. The message delivery time is a little longer than that of the broadcasting-based approach, but it is still acceptable if we consider the enhanced privacy preserving capability of this new approach. At the same time, the energy consumption is less than half the energy consumption of flooding-base phantom routing, which is preferred in a low duty cycle, environmental monitoring sensor network
Coordinate transformation - a solution for the privacy problem of location based services?	Protecting location information of mobile users in location based services (LBS) is a very important but quite difficult and still largely unsolved problem. Location information has to be protected against unauthorized access not only from users but also from service providers storing and processing the location data, without restricting the functionality of the system. This paper discusses why existing privacy enhancing techniques are insufficient to solve this problem and proposes a new approach basing on coordinate transformations. It shows how location information can be rendered illegible in such a way that it is still possible to perform processing operations required by LBS
Using mobile communications to assert privacy from video surveillance	We propose a novel use of mobile communications to permit individuals to assert a preference for privacy from video surveillance. Our system, called Cloak, grants an individual the right to prohibit others from distributing video containing their image. We present our system architecture and operation, and demonstrate how the system enhances privacy while requiring no change to existing surveillance technology. We use analysis and simulation to show that an individual's video privacy can be protected even in the presence of the many sources of error (e.g., unsynchronized clocks, unreliable communications, location error) we anticipate in a deployed system, and argue that there are no insurmountable technical barriers to Cloak's large-scale deployment. Given the threat to privacy posed by the rapid and widespread deployment of camera-phones, we maintain that today's surveillance systems must be urgently augmented with privacy enhancing technology.
Privacy Preserving Techniques for Location Based Services in Mobile Networks	The proliferation of smart phones and handheld mobile devices spurs a variety of personalized information services that utilize users' current location, known as Location-Based Services (LBS). Privacy protection is of great importance for such service users in mobile and wireless networks. However, as mobile devices are highly autonomous and heterogeneous, it is challenging to design generic protection techniques and achieve high level of privacy protection. Our study focuses on both potential privacy threats and privacy preserving mechanisms in mobile ad hoc networks. Preliminary work shows that the proposed system architecture and protection mechanisms exhibit satisfactory performance. The remaining work for completing the PhD dissertation is then presented. The proposed research carries significant intellectual merits and potential broader impacts in the following aspects. (1) We investigate the impact of inferential attacks on LBS users in mobile and wireless networks, and prove the vulnerability of using long-term pseudonyms for camouflaging users' real identities. (2) We propose a novel privacy metric to quantify system's resilience to such attack models. (3) An effective and extensible privacy architecture based on the mix zone model is designed. (4) We conduct rigorous analytical study, and design a privacy protection mechanism under real world constraints, e.g., traffic density and heterogeneity on different roads. (5) This proposal addresses the privacy preservation problem from a novel angle and lays a solid foundation for future research in protecting users' location privacy.
A Practical Privacy-preserving Password Authentication Scheme for Cloud Computing	An era of cloud computing allows users to profit from many privileges. However, there are several new security challenges. In fact, anonymous password authentication in the traditional setting has been suffered from many inherent drawbacks such as ease of exposure to malicious attacks and users registered their passwords in the server. Our scheme proposes the phenomenal context according to three main components: data owner, users, and service provider in cloud where users do not need to register their passwords in the service provider. Moreover, the data owner is contributed to make secure decisions, so that he manages the significant keys to other components distributedly. The proposal enjoys several advantages such as preserving privacy of password, unlink ability, and secrecy of session key. We have given a mechanism to prove the identity of the users authenticated without a need to reveal their passwords. Our approach has been achieved good results of reliability, and validity for cloud password authentication. The experimental results show an effective level of performance.
Privacy Preserving Set Intersection Protocol Secure against Malicious Behaviors	When datasets are distributed on different sources, finding out their intersection while preserving the privacy of the datasets is a widely required task. In this paper, we address the privacy preserving set intersection (PPSI) problem, in which each of the N parties learns no elements other than the intersection of their N private datasets. We propose an efficient protocol in the malicious model, where the adversary may control arbitrary number of parties and execute the protocol for its own benefit. A related work in [12] has a correctness probability of ( v;1)ldquo (f is the size of the encryption scheme's plaintext space), a computation complexity of' 0(N2 S2lgf) (S is the size of each party's data set). Our PPSI protocol in the malicious model has a correctness probability iquest/C a/-1)JV~1 plusmnmiddotd achieves a computation cost of 0{c2S2lgM) (c is the number of malicious parties and c < N eurordquo I).
Monitoring Employees' Emails without Violating Their Privacy Right	The capability of an employee to violate the policy of an organization is a concern for an employer. Monitoring is a measure taken by an employer to discourage an employee from acting inappropriately. However, current monitoring techniques tend to raise privacy issues because they violate the privacy rights of employees. Applying a monitoring technique without violating the privacy of employees is the aim of this paper. We propose a design and a protocol which give an employer the opportunity to monitor employee email in order to detect company policy violations. This can be achieved without violating the privacy of honest employees, while at the same time revealing evidence about the illegal actions of dishonest employees.
Quantitative Association Rules Mining Methods with Privacy-preserving	Considering the different size of quantitative attribute values and categorical attribute values in databases, we present two quantitative association rules mining methods with privacy-preserving respectively, one bases on Boolean association rules, which is suitable for the smaller size of quantitative attribute values and categorical attribute values in databases; the other one bases on partially transforming measures, which is suitable for the larger ones. To each approach, the privacy and accuracy are analyzed, and the correctness and feasibility are proven by experiments.
Privacy Preserving ID3 Algorithm over Horizontally Partitioned Data	For the problem of decision tree classification with privacy concerns, we propose several efficient secure multi-party computation protocols to construct a privacy preserving ID3 algorithm over horizontally partitioned data among multiple parties. Our algorithm presents the first solution to privacy preserving decision tree classification among more than two parties. We also make a performance comparison with the existing solution, which is only applicable to the twoparty case. The result shows that our solution has a significantly better performance.
Personal privacy: an endangered species in the information age?	In mid-September (1996) there was a flurry of angry email messages flying around the Internet, discussing the news that personal information about you could be purchased from the company by just about anyone with a credit card. Many were outraged at the loss of their privacy, and Lexis-Nexis was flooded with requests from netizens demanding removal of their personal data from the database. P-Trak, the company's personal information database product, was introduced last June by Lexis-Nexis. This 300 million name database of public information culled from credit bureau records contains each person's name, maiden/alias name, current and two most recent previous addresses, month and year of birth, and phone number. When the product first came out, it included Social Security numbers as well, but that feature was pulled less than two weeks after the product's initial release. However, if you have a Social Security number, you can still search the database (for a fee, of course) for related data. Compared to many other databases, such as those containing credit or medical histories, P-Trak is relatively tame. Nonetheless, the recent spotlight on Lexis-Nexis made it clear that much personal information is unknowingly gathered and used. Several journalists reported checking personal information in P-Trak, and most found erroneous information. This raises another issue: what inaccurate personal information is floating around in cyberspace and what effect might that have?
New Privacy Threats for Facebook and Twitter Users	With around 1 billion active users, Facebook and Twitter are two of the most famous social networking websites. One particular aspect of these social networks widely discussed in the news and heavily researched in academic circles is the privacy of their users. In this paper we introduce six new privacy leaks in Facebook and Twitter. First, we reveal how an attacker can map users email addresses to their real names using Facebook's account recovery service. This mapping helps an attacker accumulate more information about the holder of an email address which could then be used to launch targeted spam attacks. Second, we introduce how an attacker can reconstruct the friend list of a victim on Facebook, even though that user's privacy setting does not allow the attacker to explicitly view the victim's friend list. Third, we show the additional privacy leaks due to the introduction of Facebook's Timeline. Fourth, we show how the unprecedented connectivity offered by social plugins breaches a user's privacy. Fifth, we introduce the social network relay attacks. Sixth, we show how an attacker can permanently withhold a victim's Facebook account after the first take over. Moreover, we propose solutions for each of these privacy leaks.
Integration of Wireless Hand-Held Devices with the Cloud Architecture: Security and Privacy Issues	Use of wireless hand held devices like mobile, PDA, laptop etc. is increasing rapidly. Many advanced users want more functionality with these wireless devices to manage their daily schedule. But most of the wireless hand-held devices have limited resource capability for robust functionality. Therefore cloud computing environment could be an alternative solution for these devices to support resource consuming applications. If the wireless hand held device is connected with the cloud, user can use more resource consuming applications and private data (stored in the cloud) from those devices. But privacy and security of the personal information and data make the user concern for using the cloud. The aim of the paper is to identify the security and privacy related risks and threats of the mass users as well as corporate users, if the wireless hand-held devices will be integrated with the cloud.
Increasing Security and Privacy in User-centric Identity Management: The IdM Card Approach	In this paper, we describe how security and privacy can be increased in user-centric Identity Management (IdM) by the introduction of a so-called IdM card. This IdM card securely stores and processes identity data of the card owner, an end user. The card represents a trusted device that supports the user in managing its digital identities and also in performing secure and privacy-enhanced service authentication and authorization.
User-controlled Privacy Protection with Attribute-filter Mechanism for a Federated SSO Environment Using Shibboleth	Shibboleth is a well-known software package for web single sign-on (SSO) based on several federated identity standards, including the Organization for the Advancement of Structured Information Standards (OASIS)' security assertion markup language (SAML) version 1.1 and 2.0. This paper describes uApprove.jp, a user consent acquisition system (UCAS) with an attribute-filter mechanism for a Shibboleth-based SSO system. uApprove.jp requests the user's consent for the release of his/her personal information from an identity provider (IdP) to a service provider (SP) and allows him/her to determine which attributes will be sent. uApprove.jp is an extension of approve, a UCAS for Shibboleth. Our development is for universities participating in GakuNin (a Japanese academic federation), but it can be utilized in other Shibboleth-based federations.
Enhanced privacy in broadcast passive optical networks through use of spectral slicing in waveguide grating routers	Recently proposed wavelength-division multiplexed (WDM) passive optical network (PON) architectures utilize a waveguide-grating router (WGR) at the remote node to establish point-to-point or broadcast connections. While the initial push for WGR-based PONs was driven by the flexibility, privacy/security, and high capacity associated with point-to-point architectures, the advantages of providing broadcast delivery over these networks was also apparent. The WGR, when illuminated by a broadband source, mimics the broadcast function of a conventional passive splitter insofar as each output port receives approximately equal optical power
Improving optical steganography transmission privacy by imposing phase masks on stealth signals	Temporal phase modulation of spread stealth signals is proposed to improve optical steganography transmission privacy. It increases an eavesdropper's difficulty of detecting and intercepting the stealth channel hidden under public transmission, even with dispersion compensation.
Achieving Physical Layer Security / Privacy with Self-Wrapped OCDM Transmission	We present a novel transmission system using self-wrapped WHTS OCDM signals to achieve enhanced transmission security. Distributed key is encoded and time-spread to hide under noise in the network. BER of 10-4 is demonstrated experimentally.
The privacy protection framework for biometric information in network based CCTV environment	CCTV is one of the most widely used physical security technologies. A surveillance camera is a video collection device installed at a particular location and utilized for a variety of purposes. As CCTV performance has become enhanced recently, technology is being developed that attempts to perform automated processing through facial recognition using the facial information acquired from a CCTV system. However, if these technologies are exploited maliciously, privacy may be seriously violated. In this paper, we propose a security framework that protects personal information obtained from the detected facial area. We pointed out the security threats within CCTV system, and then propose a countermeasures. The key point of this framework is processing the mosaic or scrambling methods to the facial area, so that the facial information cannot be directly obtained without knowledge of the secret key. When the original facial information is needed, such as crime investigation, it can be obtained through reverse scrambling. This framework will contribute to protect privacy and develop the biometric-based physical security technology area.
Towards a mobile security & privacy simulator	The proliferation and capabilities of mobile, networked devices is increasing rapidly and with this trend new threats to security and privacy are emerging at an alarming rate. The new threats are difficult to study and prepare for, since field studies are costly, limited in scope and have significant security and privacy issues of their own. In this paper, we present a Mobile Security & Privacy Simulator, which enables the simulation of mobile entities and their environment to study security and privacy related issues. Entities act and interact with one another, influenced by personal and world context. Simulation can be used to evaluate privacy threats and countermeasures by numerical analysis and by visualization to better grasp the implications of new devices, services and the threats against them. We also present a brief study on the effects of mono-culture in mobile operating systems when faced with the epidemic spread of mobile malware, which shows how future mobile networks can reach total infection within a short time.
Security in data communication and privacy in conversations for underwater wireless networks using scrambled speech scheme	In this paper, a secure scheme for underwater telecommunication networks has been proposed. The main idea stems from the fact that all telecommunication networks, including underwater networks, have been basically prepared to transfer speech and voice. In our proposed scheme, the input voice is transformed to the bit stream using a low bit rate encoder. Then, the whole bits are mapped to the predefined symbols, which have been originally designed using hi-fi speech records. Symbols are stored in a lookup table in the both sides of channel. At transmitter side, the prepared signal is windowed, filtered and shaped to transfer over underwater link. The overall bit error rates are as low as that have not any significant effect on quality of speech while, on the other hand, the output noises are quite unintelligible for intruders who try to access to the conversations through the channel of telecommunication network. Produced noises are signals including random scrambled speech-based symbols in which make no any sense to the listener. The simulated system was considered to transfer speech to obtain results in an experimental state. The results show that the proposed scheme for underwater telecommunication is reliable.
Secure multiparty computation based privacy preserving smart metering system	Smart metering systems provide high resolution, realtime end user power consumption data for utilities to better monitor and control the system, and for end users to better manage their energy usage and bills. However, the high resolution realtime power consumption data can also be used to extract end user activity details, which could pose a great threat to user privacy. In this work, we propose a secure multi-party computation (SMC) based privacy preserving protocol for smart meter based load management. Using SMC and a proper designed electricity plan, the utility is able to perform real time demand management with individual users, without knowing the actual value of each user's consumption data. Using homomorphic encryption, the billing is secure and verifiable. We have further implemented a demonstration system which includes a graphical user interface and simulates network communication. The demonstration shows that the proposed privacy preserving protocol is feasible for implementation on commodity IT systems.
M-commerce model by enhanced location privacy protocol in GSM	Today, e-commerce transactions continue to impact the global business environment profoundly and its technologies and applications are beginning to focus more on mobile computing and the wireless Web. As the usage of mobile devices becomes pervasive and convenient, the e-commerce through mobile devices is an emerging field. However, most of e-commerce systems do not only support privacy rights for user but also the rights for the merchant provider. A collection and processing of personal data may lead to private and family life violation, thus discouraging the public against the usage of new technologies. In this paper, we propose the enhanced-privacy m-commerce schemes, which are based on the e-commerce model using the GSM user authentication protocol.
Privacy-Friendly Smart Environments	In this paper we describe our approach on protecting user privacy in smart environments, particularly smart homes, which we call eHomes. These are environments with devices such as sensors, computational units, actors, which are seamlessly integrated in the environment, and objects we use in our everyday life. In order to provide more convenience to its users such environments can be personalized. As these environments become ubiquitous, thus supporting mobility of the users, new privacy threats arise. These are based on the digital traces and personal information which is left while visiting different environments. We provide a practical approach to minimize these traces and information disclosure by applying negotiation, identity management, and anonymous credentials. Also, we discuss the protection of eHomes from malicious users.
Social Emergency Alert Service - A Location-Based Privacy-Aware Personal Safety Service	The advanced capabilities for location-based services of smart phones are mostly used for travel applications, navigation or business fleet management. We motivate a social emergency alert service that makes use of the wide availability of smart phones and activates nearby social contacts in cases of emergency. Research has shown, that especially in busy urban districts help from fellow citizens is hard to receive because of the so-called bystander-effect: Nearby people often do not recognize or take responsibility for ongoing emergency situations. A simple and fast mechanism to call for help is necessary. Additional to local authorities as the police or rescue services, assistance from family or acquaintances is a valuable and fast(er) supplement. We describe the architecture of an emergency alert service providing the functionality required for the activation of social contacts and present a prototype. The distribution of tasks between mobile devices and server infrastructure and the underlying communication protocol are designed energy-efficient and privacy preserving. The central tracking of geo-positions is avoided.
Performance Tuning of Steganography Algorithm for Privacy Preserving Association Rule Mining in Heterogeneous Data Base	Privacy and security issues in data mining become an important property in any data mining system. A considerable research has focused on developing new data mining algorithms that incorporate privacy constraints. In this paper, we focus on privately mining association rules in vertically partitioned data where the problem has been reduced to privately computing Boolean scalar products. We propose a modification of steganography-based multiparty protocols for this problem. The proposed modification fine tune the performance to be faster in case of very large database, with acceptable level of reduction in privacy.
Controlling Physical Objects with Privacy using Secure RFID System	Security and privacy threats in technological environment are great hindrances to use latest technologies for our benefits. Such threats also exist in RFID systems which are currently utilized to a great extent in ubiquitous communication. These systems can also work in combination with cellular networks to control user's physical objects in a secure way with sufficient privacy. This paper presents a secure system model which enables a user to control his possessions even sitting remotely from the objects' locations. The limitations of RFID tags are taken into account and it is shown that the system mitigates many threats keeping the privacy of the tags and the user intact.
Improving Trust and Privacy Models in Social Networks	The disclosure and misuse of personal information are two major problems of social networking sites. To address these problems, several models focusing on trust or privacy have been proposed. We propose a privacy model addressing the following issues: What could be private? For whom is it private? When is it private? And how can it be made private? We also propose a trust model covering five aspects related to what could be trusted, when it could be trusted, where it could be trusted, whom to trust, and why to trust someone/something. In addition to leveraging results from current research works on trust and privacy, our models are based on the results of our survey that we have undertaken to analyze the responses of users to friendship requests from unknown individuals and to conduct a comprehensive gender-based analysis of the collected data.
A Model for Privacy and Security Risks Analysis	This article introduces an extended misuse case (EMC) model for privacy and security risks analysis and formally validates the model by means of colored petri nets (CPNs). The EMC model extends the use and misuse cases (UMCs) model with security and privacy requirements. The proposed EMC model and the CPNs instantiation deal with some of the shortcomings of the traditional UMCs which include lack of quality goals and formal validation techniques. The CPNs instantiation enables automatic detection of possible violation of privacy and security goals and can be extended to communicate risk to both technical and non-technical stakeholders. The CPNs and EMC models are illustrated with privacy and security risks contributing factors for identity management systems (IDMSs).
Technical Enforcement of European Privacy Legislation: An Access Control Approach	Until today, the protection of personal data is mainly left to the legislation by means of guidelines. This paper aims to increase the perceived control by users over their data by helping the user's agent to check the service requests conformity to the legislation. To do so, it discusses the main concepts involved in the legislative privacy principles, and deduces a privacy semantic information model. The proposed model focuses on the main concepts involved in legislative privacy principles. For proof of concept, we describe our proposed privacy semantic information model by means of privacy ontology. We use OWL as an implementation basis for defining privacy knowledge base, and SQWRL and the Jess rule engine to dynamically interact with that base and enforce legislative requirements as privacy access control rules.
Ensuring Low Cost Authentication with Privacy Preservation in Federated IMS Environments	Federated Identity Management Systems (IMS) is a promising system where an increasing number of e-services will be made available in the future for users' convenience. However in this environment, users are required to manage several identities (ID cards) and a great number of personal data. As such, simplification of users' involvement is highly needed while increasing the users' confidence, and guaranteeing security. This paper proposes a low-cost authentication solution which leads to a reduction of users' identities, even across several circles of trust, while maintaining high-level security. Also it proposes a privacy preserving technique to automatically control that privacy preferences of the users are satisfied during electronic transactions. This leads to defining new entities in the federated IMS, an innovative privacy policy language XPACML, and a practical-oriented privacy policy comparison middleware.
Protecting Privacy While Discovering and Maintaining Association Rules	The k-anonymity is an efficient model to preserve data privacy. Of late, this model has been applied to the area of privacy-preserving data mining but the state-of-the-arts are still far from practical needs. In this paper, we propose a new approach that preserves privacy and maintains data utility in data mining. Concretely, we use a k-anonymity model to preserve privacy while discovering and maintaining association rules through a novel algorithm, M3AR-member migration technique for maintaining association rules. We do not use the existing generalization and suppression techniques to achieve a k-anonymity model. Instead, we propose a member migration technique that is more appropriate for the requirements of maintaining association rules. Experimental results establish the practical value and theoretical analyses of our new technique.
Towards Usable Client-Centric Privacy Advisory for Mobile Collaborative Applications Based on BDDs	Considering privacy advisory for collaborative settings on mobile devices, this paper presents an innovative approach to simultaneously support dynamically reconfigurable privacy advisory and the usability of providing it. Regarded are interaction design requirements such as user-friendless and non-intrusive advisory as well as restrictions of today's mobile devices like CPU and memory consumption etc. The prototypic implementation of a client-centric privacy advisor based on binary decision diagrams shows that the proposed mechanisms integrated in an iPhone application can be effectively extended and correlated with a usable privacy-enhancing model.
Hidden Anchor: Providing Physical Layer Location Privacy in Hybrid Wireless Sensor Networks	In many hybrid wireless sensor networks (HWSNs) applications, sensor nodes are deployed in hostile environments where trusted and un-trusted nodes co-exist. In such hybrid networks, it becomes important to allow trusted nodes to share information, especially, location information and, at the same time, prevent un-trusted nodes from gaining access to this information. We focus on anchor-based localization algorithms in HWSNs, where a small set of specialized nodes, i.e. anchor nodes, broadcast their location to the network and other nodes can use the broadcast information to estimate their own location. The main challenge is that both trusted and un-trusted nodes can measure the physical signal transmitted from anchor nodes. Thus, un-trusted nodes can use the physical signal transmitted from an anchor node to estimate its location. In this paper, we propose hidden anchor, an algorithm that provides anchor physical layer location privacy. The hidden anchor algorithm exploits the inherently noisy wireless channel and uses identity cloning of neighboring trusted nodes to make anchors unobservable to untrusted nodes while providing complete information to trusted nodes. Evaluation of the hidden anchor algorithm through analysis and simulation shows that it can hide the location and identity of anchor nodes with very low overhead.
Privacy Enforcement of Composed Services in Cellular Networks	In this paper, we study privacy policy issues of composed services in cellular networks. We focus on the two basic services of location and presence provided in cellular networks. Based on our privacy policy model, named PrivOrBAC, we propose a composition methodology for the privacy policy of the resulting service. Our work tends to extend contextual privacy management to take into account the privacy attributes' compliance between the two basic services.
Credentials for privacy and interoperation	We consider the problem of providing secure, private access to applications and data in a world-wide distributed client-server environment such as the Internet of the future. In such a system, the set of potential users of a service may extend far beyond the local community knowable to the application providing the service. Applications will not generally have prior knowledge of the individual making a request upon which an access control decision can be based and furthermore, knowledge of an individual's identity may not be directly useful. We frame our discussion in the context of supporting credentials which are submitted with a request, and propose a list of desiderata for such credentials. We evaluate several well-known proposals for credentials, focusing on issues related to privacy and scalability, and then point out the research issues that remain before such schemes can be deployed in a world-wide environment with strong privacy guarantees
Privacy-Preserving Backpropagation Neural Network Learning	With the development of distributed computing environment , many learning problems now have to deal with distributed input data. To enhance cooperations in learning, it is important to address the privacy concern of each data holder by extending the privacy preservation notion to original learning algorithms. In this paper, we focus on preserving the privacy in an important learning model, multilayer neural networks. We present a privacy-preserving two-party distributed algorithm of backpropagation which allows a neural network to be trained without requiring either party to reveal her data to the other. We provide complete correctness and security analysis of our algorithms. The effectiveness of our algorithms is verified by experiments on various real world data sets.
A Privacy Preserving Probabilistic Neural Network for Horizontally Partitioned Databases	In this paper, we present a version of the probabilistic neural network (PNN) that is capable of operating on a distributed database that is horizontally partitioned. It does so in a way that is privacy-preserving: that is, a test point can be evaluated by the algorithm without any party knowing the data owned by the other parties. We present an analysis of this algorithm from the standpoints of security and computational performance. Finally, we provide performance results of an implementation of this privacy preserving, distributed PNN algorithm.
Multi-GPU based camera network system keeps privacy using growing neural gas	In this work we present a multi-camera surveillance system based on the use of self-organizing neural networks to represent events in video. The objectives include: identifying and tracking persons or objects in the scene or the interpretation of user gestures for interaction with services, devices and systems implemented in the digital home. Additionally, the system process several tasks in parallel using GPUs (Graphic Processor Units). Addressing multiple vision tasks of various levels such as segmentation, representation or characterization, analysis and monitoring of the movement to allow the construction of a robust representation of their environment and interpret the elements of the scene. It is also necessary to integrate the vision module into a global system that operates in a complex environment by receiving images from multiple acquisition devices at video frequency and offering relevant information to higher level systems, monitor and take decisions in real time, and must accomplish a set of requirements such as: time constraints, high availability, robustness, high processing speed and re-configurability. Based on our previous work with Growing Neural Gas (GNG) models, we have built a system able to represent and analyze the motion in several image sequences acquired by a multi-camera network and process multisource data in parallel onto a Multi-GPU architecture. The system is able to keep the privacy of the persons under observation by using the graph representation provided by the GNG. Several experiments are presented that demonstrate the validity of the architecture to manage images from different cameras simultaneously.
A privacy attack that removes the majority of the noise from perturbed data	Data perturbation is a sanitization method that helps restrict the disclosure of sensitive information from published data. We present an attack on the privacy of the published data that has been sanitized using data perturbation. The attack employs data mining to remove some noise from the perturbed sensitive values. Our attack is practical, can be launched by non-expert adversaries, and it does not require any background knowledge. Extensive experiments were performed on four databases derived from UCI's Adult and IPUMS census-based data sets sanitized with noise addition that satisfies ╬╡-differential privacy. The experimental results confirm that our attack presents a significant privacy risk to published perturbed data. The results show that up to 93% of the noise added during perturbation can be effectively removed using general-purpose data miners from the Weka software package. Interestingly, the higher the aimed privacy, the higher the percentage of noise can be removed. This suggests that adding more noise does not always increase the real privacy.
Improved mechanism for mobile location privacy	Location-based services are applications that use information about where a communication device is located, which presents a major new market for the telecommunications industry. On the other hand, if such information falls into the wrong hands, an adversary has the potential to physically locate a person. To address the privacy issue, Qi proposed a special and feasible architecture, using blind signature to generate an authorized anonymous ID that replaces the real ID of a legitimate mobile device. The original purpose of Qi's architecture is that eliminating the relationship of authorized anonymous ID and real ID. Unfortunately we prove that Qi's registration and reconfusion protocol did not indeed work correctly. And then we propose a basic blind signature scheme, which be used to construct our improved registration and re-confusion protocol. Moreover we demonstrate that the administrator can learn no information on the legitimate user's authorized anonymous ID and real ID.
Location privacy in mobile IP	Several security issues arise, due to the design of the mobile IP and its deployment in conjunction with other network protocols. Most of the work on the security of mobile IP has focused on authentication of the control packet and the confidentiality of the content in the protocol, and there are not many proposals in the area of location privacy. In this paper, we propose a method to provide location privacy for mobile IP users. We present two protocols that use an overlay network approach, and designed particularly for mobile IP. We employ universal re-encryption and extend it to n-out-of-n universal re-encryption to achieve our goal. In contrast to other overlay network approaches, where at least n public key encryption are required, our scheme requires only 2 public key encryption operations. Therefore, it is applicable to mobile IP systems, where in most cases the mobile nodes are small devices and have computational limitation.
Session 4A Privacy, security, DOS and defences I	Start of the above-titled section of the conference proceedings record.
Session 5A Privacy, security, DOS and defences II	Start of the above-titled section of the conference proceedings record.
Towards automatic negotiation of privacy contracts for Internet services	Concerns of users about the privacy of their data are becoming more important to providers of online services, as they develop into a major barrier for broad acceptance of applications, that gather data about their users. With P3P there exists a standard that, in the context of Web-based applications, gives users some control over the gathering, use and relaying of their data. However, P3P still lacks a negotiation mechanism. This article outlines basic mechanisms that can be used to implement a privacy negotiation protocol. Our ideas extend the expressiveness of the P3P languages and provide means to improve their negotiation strategy to service users as well as to service providers. We also discuss open issues such as how to make sure that the negotiation will terminate.
Privacy Preserving C4.5 Algorithm over Vertically Distributed Datasets	It is a primary task in the privacy-preserving data mining in the distributed environment how to protect privacy and at the same time acquire accurate data relation. This paper shows how two parties built a decision tree collaboratively without revealing privacy when datasets is vertically distributed, including a PPC4.5 algorithm for privacy preserving via C4.5 over vertically distributed datasets and an algorithm of the best split attribute and the information gain ratio of the node. Further, the secure scalar product protocol and the x ln<sub>(x)</sub> protocol are used in collaborative computing, which can protect privacy effectively.
An Identity Privacy Enhanced Trust Model in Fully Distributed Virtual Computing Environments	Trustworthiness of resources is the foundation of virtual computing environments (VCE). Using identical information of resource is an ordinate method to achieve trustworthiness. However, it may conflict with identity privacy problem, an important security issue in VCE, that tries to make resource anonymous. A trust model is proposed to enhance resourcespsila identity privacy by changing pseudonym in fully distributed VCE, while each resourcepsilas trustworthiness can be evaluated by upper applications. Simulation results show that the model achieves considerably fine performance with measurements of resource trustworthiness evaluation error, resource selection success rate, and message overhead.
A Privacy-Enhanced Access Control Model	Privacy is one of the most important issues in providing high-quality ubiquitous network services to users over the Internet. Although several privacy aware access control models have been proposed in recent years, these models still rely mostly on the traditional access control models designed primarily for security. When privacy becomes a main concern, these models are no longer adequate. In this paper, we propose a three-dimensional access control model enhanced with privacy and show that our model can be used as a general method for defining privacy requirements in systems that respect and protect user privacy. By introducing the notions of privacy-concerning subjects and privacy access rights and enhancing the traditional two-dimensional access control models with a third dimension, we demonstrate that our privacy-enhanced access control model can better describe and support user requirements for protecting private information when access control is used for making access decisions to user information.
Privacy Protection in Secure Database Service	There has been much recent interest in secure database service that provides reliable storage and efficient query execution, while not knowing the contents of the database. Existing proposals for secure database services have typically been founded on encryption. However, our research shows that secure database services based on data encryption is not well-balanced on dealing with the contradiction between data privacy preserving and efficient queries. In this paper, we propose an automatic attributes detection partition method and a new security model which partition data in unencrypted form to distributed secure database servers. The theoretical analysis and experimental results show that our new method is feasible and provide efficient privacy protection and efficient query execution, and support horizontal fragmentation and semantic attribute decomposition.
A Unified Metric Method of Information Loss in Privacy Preserving Data Publishing	Data Publishing generates much concern over the protection of individual privacy. K-anonmization is a technique that prevents linking attacks by generalizing and suppressing portions of the released raw data so that no individual can be uniquely distinguished from a group of size of k. We study generalization for preserving privacy in publishing of sensitive data and metric method for information loss in process of generalization. In this paper, we provide a practical metric framework for implementing one model of k-anonymization, called generalization including suppression metric. We introduce Datafly algorithm for the metric method. Our experiments show that generalizatioin including suppression metric is more precision than those existing methods focusing on generalization.
An Approach for Privacy Protection Based-On Ontology	Privacy protection is one of the important topics in network security. Although a lot of work has been done, there are still some open issues and challenges that need to be addressed. Now, open and dynamic computing environments offer flexible and convenient sharing of information and services for users. Consequently, there exist a lot of different policies for privacy protection to deal with dynamic changes in each application scenario. This raises the issue of privacy policy specification. Although trust can help protect user privacy, the use of unified trust values or a simple trust rank cannot satisfy the requirement for privacy protection because different privacy may need its own trust evidence for the evaluation of trust. To solve this problem, we propose a novel approach for privacy protection based-on ontology in this paper. Our main contributions in this paper include (1) specifying privacy policies in a semantic way and (2) abstracting the policies as trust attributes for privacy ontology. In addition, our method can be used to protect sensitive policies at the same time.
A Distributed Spatial Cloaking Protocol for Location Privacy	In order to protect users' location privacy for Location-based Service (LBS), this paper proposes a spatial cloaking protocol satisfied k-anonymity, to generate a cloak area and guarantee users' privacy. Firstly, it analyzes the present solutions for privacy protection. Then, a distributed model is presented in this paper, which does not rely on the intermediate anonymizer. Furthermore, it elaborates the process of spatial cloaking for location privacy by introducing a communication chain, which updating the current minimum cloak area that covers k users. Finally, it discusses the robustness in two risk scenarios, and demonstrates the spatial cloaking protocol performs better than former method.
PCS privacy and authentication implementation challenge	As PCS evolves in the US, issues relative to the privacy of the user's voice and data and the authentication or validation of the user to the service provider are being addressed. The two principle alternatives being reviewed for US privacy and authentication are the methodologies defined as part of the global system for mobile (GSM) communications and the EIA/TIA interim standard IS-54-B for cellular system dual-mode mobile station-base station compatibility. The paper looks at the key aspects and issues of each alternative and the resulting interworking challenge
Impact of privacy concerns on consumers' acceptance of smart metering in the Netherlands	A number of initiatives are taking place in the European Union and US to roll out the smart metering system, as part of the smart grids in the energy sector. The motivation behind the system, among others, is to meet requirements from the Kyoto protocol and EU Energy Efficiency Directives. Among the obstacles impeding the system roll out is consumers' information security and privacy concerns. In this paper, privacy concerns are presented as social vulnerability and how it negatively impacts the system. The paper concludes with the findings of a predictive logistic regression model that was used to analyze a survey among residential electricity consumers in The Netherlands, which revealed consumers' tendencies to rejecting or accepting the system.
Privacy- and Integrity-Preserving Range Queries in Sensor Networks	The architecture of two-tiered sensor networks, where storage nodes serve as an intermediate tier between sensors and a sink for storing data and processing queries, has been widely adopted because of the benefits of power and storage saving for sensors as well as the efficiency of query processing. However, the importance of storage nodes also makes them attractive to attackers. In this paper, we propose SafeQ, a protocol that prevents attackers from gaining information from both sensor collected data and sink issued queries. SafeQ also allows a sink to detect compromised storage nodes when they misbehave. To preserve privacy, SafeQ uses a novel technique to encode both data and queries such that a storage node can correctly process encoded queries over encoded data without knowing their values. To preserve integrity, we propose two schemesΓÇöone using Merkle hash trees and another using a new data structure called neighborhood chainsΓÇöto generate integrity verification information so that a sink can use this information to verify whether the result of a query contains exactly the data items that satisfy the query. To improve performance, we propose an optimization technique using Bloom filters to reduce the communication cost between sensors and storage nodes.
Privacy Vulnerability of Published Anonymous Mobility Traces	Mobility traces of people and vehicles have been collected and published to assist the design and evaluation of mobile networks, such as large-scale urban sensing networks. Although the published traces are often made anonymous in that the true identities of nodes are replaced by random identifiers, the privacy concern remains. This is because in real life, nodes are open to observations in public spaces, or they may voluntarily or inadvertently disclose partial knowledge of their whereabouts. Thus, snapshots of nodes' location information can be learned by interested third parties, e.g., directly through chance/engineered meetings between the nodes and their observers, or indirectly through casual conversations or other information sources about people. In this paper, we investigate how an adversary, when equipped with a small amount of the snapshot information termed as side information, can infer an extended view of the whereabouts of a victim node appearing in an anonymous trace. Our results quantify the loss of victim nodes' privacy as a function of the nodal mobility, the inference strategies of adversaries, and any noise that may appear in the trace or the side information. Generally, our results indicate that the privacy concern is significant in that a relatively small amount of side information is sufficient for the adversary to infer the true identity (either uniquely or with high probability) of a victim in a set of anonymous traces. For instance, an adversary is able to identify the trace of 30%-50% of the victims when she has collected 10 pieces of side information about a victim.
Cross-Domain Privacy-Preserving Cooperative Firewall Optimization	Firewalls have been widely deployed on the Internet for securing private networks. A firewall checks each incoming or outgoing packet to decide whether to accept or discard the packet based on its policy. Optimizing firewall policies is crucial for improving network performance. Prior work on firewall optimization focuses on either intrafirewall or interfirewall optimization within one administrative domain where the privacy of firewall policies is not a concern. This paper explores interfirewall optimization across administrative domains for the first time. The key technical challenge is that firewall policies cannot be shared across domains because a firewall policy contains confidential information and even potential security holes, which can be exploited by attackers. In this paper, we propose the first cross-domain privacy-preserving cooperative firewall policy optimization protocol. Specifically, for any two adjacent firewalls belonging to two different administrative domains, our protocol can identify in each firewall the rules that can be removed because of the other firewall. The optimization process involves cooperative computation between the two firewalls without any party disclosing its policy to the other. We implemented our protocol and conducted extensive experiments. The results on real firewall policies show that our protocol can remove as many as 49% of the rules in a firewall, whereas the average is 19.4%. The communication cost is less than a few hundred kilobytes. Our protocol incurs no extra online packet processing overhead, and the offline processing time is less than a few hundred seconds.
Applying Modified TAM to Privacy Setting Tools on SNS	The technology acceptance model (TAM) proposes that perceived usefulness and perceived ease of use can predict that whether an information technology will be accepted and used by people. In this research, we were trying to find out dominant factors which could be predictors to the usage of privacy setting tools on Social Networking Sites (SNS) based on TAM. We used a modified TAM to take usefulness antecedents and ease of use antecedents into consideration. 266 subjects responded to a survey about their feelings when using privacy setting tools based on Renren, a widely used SNS in China. The results support TAM. They also demonstrate that four factors -- ease of understanding, ease of finding, reject undesirable contact and control access to one's profile have significant effect on people's acceptance and usage of privacy setting tools on SNS. The results could help developers and managers of SNS to better understand which factors can impact users' decisions on accepting and using privacy setting tools on SNS.
Privacy Improvement through Pseudonymity in Parlay X for Location Based Services	Privacy constitutes a great challenge for the spread of new services. In particular for Next Generation Network (NGN) services, operators and providers hold more sensitive information than traditional networks. NGN implies a new service layer, accessible by third parties through standardized interfaces. This newly proposed service architecture is not protected yet against privacy threat. We demonstrate that pseudonymity is an interesting and feasible solution in Parlay X gateway. Location-Based Services (LBS) make use of user positions, which are sensitive information, to provide more enhanced services. Different alternatives in cellular networks, exist to retrieve this information, they however don't offer the same privacy quality level. Those alternatives may cooperate to provide location information to service providers. The discontinuity of the privacy quality imperils the anonymity of users. In this paper, we propose a novel Privacy Web service added to the Parlay X gateway of the service architecture to ensure user privacy through pseudonymity in location services. The architecture is based on the enhancement of standardized Parlay X Web services. The new proposed web service could enforce the privacy provided by operator networks. A formal model of our approach is investigated.
Privacy Based Access to Parlay X Location Services	Next generation networks (NGN) stipulate an open access of core networks, which were previously closed. Service-oriented architecture (SOA) is a promising way to provide the access to third party providers. So, web services, as the prevalent realisation of SOA, constitute a standard middleware between service providers and cellular networks. However the spread of new innovative services run into the problem of the privacy of personal data. Indeed, service providers will hold more and more sensitive information and users are suspicious for revealing their personal data to unauthorized and unwanted parties. Henceforth, current web service standards lack of a clear solution for providing privacy policy. We suggest that the open access of operator networks to third parties goes with the respect of the privacy policy of users. In this paper, we propose to add to parlay X gateway a novel privacy Web service, which is responsible for managing and ensuring privacy of users. To validate our solution, we apply it to location services (LCS), which is a major capability provided by 2G and 3G cellular networks.
Non-interactive Authentication Scheme Providing Privacy among Drivers in Vehicle-to-Vehicle Networks	In this paper, we present a non-interactive authentication scheme providing privacy among drivers in vehicle-to-vehicle (V2V) communication networks. Where the drivers, who are members of V2V networks, are organized into groups. Each group has a shared public key between members. Additionally, each member has a private key provided by the Third Trusted Party (TTP). In our proposed scheme, we ensure driver's privacy by allowing members to change their own set of public keys frequently using the Digital Signature Algorithm (DSA). The TTP sends to each member a token of his original set of public keys. This member can find non-interactively a new token corresponding to the new set of public keys, and hence vehicles can exchange the safety critical information without requiring a control from the TTP. In case of a malicious behavior, the identity of the signer can be revealed only by the TTP.
A solution to privacy-preserving two-party sign test on vertically partitioned data (P<sup>2</sup>2NST<inf>v</inf>) using data disguising techniques	Statistical hypothesis test is an important data analysis technique that has found applications in a variety of research fields. In this paper, we investigate one of the fundamental test theories: the nonparametric Sign Test (NST) theory, under the privacy-preserving context. In this context, two parties, each with a private dataset, would like to conduct a sign test on their joint dataset, but neither of them is willing to disclose its private dataset to the other party or any other third party. To support this computation, we transform the NST algorithm into a privacy-preserving two-party nonparametric sign test (P<sup>2</sup>2NST) protocol. More specifically, this paper addresses this situation using a vertically partitioned data model. We design five building blocks to address this P<sup>2</sup>2NSTv problem based on data disguising techniques. The performance of the protocol, in terms of security, communication and computation cost is evaluated against the solution where a trusted third party (TTP) is used. This paper proposes an alternative to address the P<sup>2</sup>2NSTv problem: our P<sup>2</sup>2NSTv protocol does not make use of any third party nor cryptographic primitives. Our result shows that, with some more computation and communication efforts, our protocol achieves a similar level of security as the TTP model.
Improving Strict Partition for Privacy Preserving Data Publishing	Publishing the original form of data, typically the kind of data which contains personal information, will violate individual privacy. One challenge problem is how to release privacy preserved data while it is still useful. This paper studies partition-based algorithms for privacy preserving data publishing. Such kind of algorithms sets total orders over each attribute domain of a given table, and maps each tuple into a multidimensional space. Then finding an anonymized form of the original data equals to finding a partition of a corresponding multidimensional rectangular box. If different regions does not intersect with each other, a partition is called a strict partition; Otherwise, it is a called a relaxed partition. This paper proves that the data quality and utility of a given strict partition can be improved by further partitioning it into smaller but intersecting subregions. Then, combining advanced relaxed partition technique and Strict Mondrian Algorithm(the state-of-the-art strict partition-based algorithm), we design a Hybrid Algorithm. Through experiments on the famous adult dataset, we show that the anonymized result of the Hybrid Algorithm is better than the solutions produced by Strict Mondrian and two advanced relaxed partition-based algorithms according to existing quality and utility evaluation metrics.
Privacy Aware Parallel Computation of Skyline Sets Queries from Distributed Databases	A skyline query finds the objects that are not dominated by another object from a given set of objects. Skyline queries help us to filter unnecessary information efficiently and provide us clues for various decision making tasks. However, we have to be aware about the privacy of individual's. In privacy aware environments, we have to hide individual records' values even though there is no ID information in the table. In such situations, it is not possible to use conventional skyline queries. To handle the privacy problem, we consider a skyline query for sets of objects in a database. Let s be the number of objects in each set and n be the number of objects in the database. The number of sets in the database is nCs. Skyline sets query returns all skyline s-sets from nCs sets. We consider an efficient algorithm for computing "convex" skyline of the nCs sets. In this paper, we propose a method for computing skyline sets queries in parallel fashion from distributed databases without disclosing individual records to others. The proposed method utilizes an agent-based parallel computing framework that solves the privacy problems of skyline queries in distributed environments. The computation of skyline sets is performed simultaneously in all databases that increases parallelism and reduces the computation time. We show through intensive experiments that our propose technique is almost independent of the number of servers involved in skyline sets queries, thus becoming an efficient and scalable solution for skyline sets queries in distributed environments.
Random Beacon for Privacy and Group Security	Most contemporary security mechanisms and protocols include exchange of random or time-variant nonces as an essential means of protection against replay and other threats or as a seed for randomness. In many cases, it would be beneficial to have such nonces available from a trusted common source, such as a satellite. The goal of this paper is to present a protocol by which a loosely connected network of devices can agree on a common piece of randomness, and show how it can be applied to improve efficiency of a privacy protection system and group session key exchange for PAN/LAN devices.
Strengthening Privacy Protection in VANETs	In the not so far future, vehicles are expected to be able to communicate with each other and with the road infrastructure, to enhance driving experience and support road safety, among others. Vehicular ad-hoc networks (VANETs) introduce a number of security challenges to the research community, mainly concerning the tradeoff between the privacy of the drivers and the accountability of misbehaving vehicles. Another challenge is how to satisfy privacy in the presence of an adversary that has access to all communication (a global observer), and that can perform traffic analysis in order to link messages and identify vehicles. In this paper we attempt to address such issues and propose a set of cryptographic mechanisms that balance the tradeoff between privacy and accountability in a VANET. Furthermore, we examine techniques for location privacy against adversaries that perform a Bayesian traffic analysis, and propose a strategy to strengthen location privacy in VANETs.
Privacy Respected Ubiquitous Sensor Environment	Recently, research and development of small wireless sensor nodes are active, such as Crossbow Motes and muPart . These are exploited to construct ubiquitous services by attaching on daily objects such as cups or chairs. An example service is a smart coffee maker, which drips coffee when coffee in a sensor attached cup gets cold. The sensor node attached daily object is called Smart Object (SOBJ) and the service is called SOBJ Service. In addition, the environment where SOBJ service works is called SOBJ Environment. We aim to clarify the following three points: 1) who has the access control right, 2) who has the right to see the data, and 3) how to disclose the data.
Preserving Privacy and Assuring Integrity in data aggregation for Wireless Sensor Networks	Many applications require reliable and trustful data aggregation in Wireless Sensor Networks (WSNs). In this paper, we propose a new scheme to achieve data privacy and integrity protection in data aggregation for WSNs, called Preserving Privacy and Assuring Integrity (PPAI) scheme. For this, before data transmission, the PPAI scheme blurs the original sampled data of a sensor node by randomly breaking down the data two times independently into two unequal pieces for each time and combining each of the data pieces with a separate private seed of the sensor node. Through analytical performance evaluations, we show that the PPAI scheme is much more efficient in terms of both communication overhead and data propagation delay than the existing work to achieve data privacy and integrity assurance in data aggregation for WSNs.
Privacy in Location Based Services: Primitives Toward the Solution	Location based services (LBS) are one of the most promising and innovative directions of convergence technologies resulting of emergence of several fields including database systems, mobile communication, Internet technology, and positioning systems. Although being initiated as early as middle of 1990's, it is only recently that the LBS received a systematic profound research interest due to its commercial and technological impact. As the LBS is related to the user's location which can be used to trace the user's activities, a strong privacy concern has been raised. To preserve the user's location, several intelligent works have been introduced though many challenges are still awaiting solutions. This paper introduces a survey on LBS systems considering both localization technologies, model and architectures guaranteeing privacy. We also overview cryptographic primitive to possibly use in preserving LBS's privacy followed by fruitful research directions basically concerned with the privacy issue.
Policy Negotiation System Architecture for Privacy Protection	Data sharing and information exchange have grown exponentially with the information explosion in the last few years. More and more data are being shared among different type of users residing in different places, performing different kinds of tasks for different kinds of services. However, these technological advances pose a serious risk on individuals 'privacy rights. In this paper, we consider a problem of monopolistic information management technologies. Most service providers have an access to any information. Even though the information is really a personal data, service providers can access to it merely with the user's first subscription. In order to limit the disclosure and avoid the misuse of personal data, this paper discusses an architectural proposal for a policy negotiation system. This proposed architecture mediates among the three actors: the users, the service providers and the law. The central unit of the proposed architecture is a policy negotiation engine. A negotiation engine undertakes the enforcement of user's privacy preference, by matching the service provider's disclosure policy and user's privacy policy. Several additional components assigned with supporting functional tasks complement the architecture, while the formal definition of personal data type and services type. This architecture provides more powerful right to each user. Finally, this paper discusses the formalization how users can express their privacy preferences and how regulations can be expressed in this system.
A Data Sanitization Method for Privacy Preserving Data Re-publication	When a table containing personal information is published, sensitive information should not be revealed. Although k-anonymity and l-diversity models are popular approaches to protect privacy, they are limited to one time data publishing. After a dataset is updated with insertions and deletions, a data holder cannot safely release up-to-date information. Recently, m-invariance model has been proposed to support re-publication of dynamic datasets. However, m-invariance model has two drawbacks. First, the m-invariant generalization can cause high information loss. Second, if the adversary already obtained sensitive values of some individuals before accessing released information, m-invariance leads to severe privacy breaches. In this paper, we propose a new data sanitization technique for safely releasing dynamic datasets. The proposed technique prevents two drawbacks of m-invariance and provides a simple and effective method for handling inserted and deleted records.
The role of SaaS privacy and security compliance for continued SaaS use	Software-as-a-service (SaaS) can increase the competence of the small and medium sized enterprises (SMEs) as that of a globally integrated enterprise. However, the SaaS provider has total control over the underlying cloud infrastructure while the customer has little control. As numerous surveys show, security and privacy are the top concerns preventing firms from moving to SaaS. This study applies the Information Systems Continuance Model and adopts privacy and security compliance as a new construct of interest. This research plans to conduct two surveys: one for pilot testing the SaaS Privacy/security compliance and one for testing complete research model. The study aims to contribute to a more sophisticated understanding of the role of privacy and security compliance for customer satisfaction and continued SaaS usage intentions. As an academic contribution, this study enriches existing research models on SaaS continuance by adopting privacy/security compliance construct which existing SaaS continuance models have not addressed. This study will be able to account for whether, and in what way specific privacy/ security compliance construct contributes to explain SaaS satisfaction and continuance intention.
An approach for tracking privacy disclosure	The emergence kinds of Web applications offer flexible and convenient service for users. Though the sites declare they won't disclose users' privacy without user's agreement, users may receive some spam after registered in or interacted with some sites. That is clearly that some sites disclosed user's privacy such as preference with user's email address to the third party by their commerce interests. So find out the privacy disclosure site is meaningful, and then user can change interaction pattern or adjust trust with the site even resort to law. In this paper, we propose a novel approach for tracking privacy disclosure in which we introduce an analysis center with our analysis algorithm to solve this issue. Our main contributions include (1) our method can find out privacy disclosure site easily and (2) the privacy disclosure site is hard to deny that it has disclosed user's privacy. Simulation results show our method can tracking privacy disclosure site well.
Pseudonmization techniques for clinical data: Privacy study in Sultan Ismail Hospital Johor Bahru	Privacy includes the right of individuals and organizations to determine for themselves when, how and to what extent information about them is communicated to others. The growing need of managing large amounts of data in hospital or clinical raises important legal and ethical challenges. This paper introduces and show the testing implementation of the privacy-protection problems, and highlights the relevance of trusted third parties and of privacy-enhancing techniques (PETs) in the context of data collection, e.g., for research. Practical approache on the pseudonymization model for batch data collection are presented. The actual application of the described techniques today proves the possible benefits for medicine that innovative privacy-enhancing techniques can provide. Technical PET solutions can unlock valuable data sources, otherwise not available.
An implementation of privacy security for PHR framework supporting u-healthcare service	PHR is protected from being viewed without your consent or authorization. Therefore the security technology must be used by the system who offers PHRs. Security of health records primarily encompasses privacy and confidentiality. In this paper, we implemented PHR's privacy and confidentiality within the layered components of our PHR framework and then evaluated the performance of our implementation. Our implementation stores securely XML-based personal health records using XML security, created on a local machine and by using the owner's certificate and then placed on a repository server, and permits access to selected records only by the authorized users. According to the experimental result, our effort for the security cost reduction is more required because the security cost is about 73% of the total cost
Privacy Preserving Portable Health Record (P^3HR)	Personal health records (PHRs) offer significant potential to stimulate transformational changes in health care delivery and self-care by patients. There is a gap between today's personal health records (PHRs) and what patients say they want and need from this electronic tool for managing their health information. Current barriers to PHR adoption among patients include cost, concerns that information is not protected or private, inconvenience, design shortcomings, and the inability to share information across organizations. We propose a novel architecture to bridge the gap based on privacy preserving portable health record (P<sup>3</sup>HR), a device that incorporates a smart card into a USB flash drive which provides encrypted flash memory for secure mobile data storage. The salient features of the proposed privacy preserving portable health record (P<sup>3</sup>HR) include: strong multifactor authentication using biometrics, public key infrastructure to verify the credentials of the applicants, SSL based authentication protocol suite for authorization and secure online updates, local backup to store patient data which ensures that the patient will have access to data in case of P<sup>3</sup>HR theft, lost device, hardware failure, software failure or a computer virus.
Improving Efficiency in Privacy-Preserving Automated Trust Negotiation with Conjunctive Policies	Automated Trust Negotiation (ATN) is an approach to allow two participants to automatically verify whether their policies are consistent with each other or not. During the negotiation process, in order to protect privacy, both participants intend to disclose their credentials and policies as little as possible. A previous work(ATN)[14] successfully negotiates with perfect privacy preservation where post-negotiation, neither credentials nor policies were revealed to each other. Unfortunately, in order to negotiate with policy with Γäô conjunctive "and" conditions, consisting of m credentials it requires a large computation cost which is linear to combination(m, Γäô). In our work, we focus on this problem and establish a new scheme to lower the cost in the conjunctive condition policy so that our protocol require only mΓäô which can highly decrease computation and communication costs. The proposed scheme performs in semi-honest model. The new idea is adding a dynamic secret key to verify which credentials match with the requested policies. We also demonstrate that this new approach can improve the efficiency of the previous one by showing a qualitative evaluation using implementation and analysis of computation and communication cost.
Tag-Based Secure Set-Intersection Protocol and Its Application to Privacy-Enhancing Biometrics	The secure set-intersection protocol is a cryptographic protocol that retrieves the intersection of two or more datasets without revealing any additional information apart from the intersection data. In this paper we formalize the secure matching tag, which is frequently used in the existing secure set-intersection protocols, and propose applying the tag to privacy-enhancing biometrics. Due to the index property of the tag, the proposed protocol can efficiently match the biometric data of a certain user from among a large amount of encrypted biometric data of users without entering the user ID.
Participatory privacy: Enabling privacy in participatory sensing	Participatory sensing is an emerging computing paradigm that enables the distributed collection of data by self-selected participants. It allows the increasing number of mobile phone users to share local knowledge acquired by their sensor-equipped devices (e.g., to monitor temperature, pollution level, or consumer pricing information). While research initiatives and prototypes proliferate, their real-world impact is often bounded to comprehensive user participation. If users have no incentive, or feel that their privacy might be endangered, it is likely that they will not participate. In this article, we focus on privacy protection in participatory sensing and introduce a suitable privacy-enhanced infrastructure. First, we provide a set of definitions of privacy requirements for both data producers (i.e., users providing sensed information) and consumers (i.e., applications accessing the data). Then we propose an efficient solution designed for mobile phone users, which incurs very low overhead. Finally, we discuss a number of open problems and possible research directions.
Wireless security and privacy, best practices and design techniques [Book Reviews]	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01220685.png" border="0">
Privacy and security for online social networks: challenges and opportunities	Online social networks such as Facebook, Myspace, and Twitter have experienced exponential growth in recent years. These OSNs offer attractive means of online social interactions and communications, but also raise privacy and security concerns. In this article we discuss the design issues for the security and privacy of OSNs. We find there are inherent design conflicts between these and the traditional design goals of OSNs such as usability and sociability. We present the unique security and privacy design challenges brought by the core functionalities of OSNs and highlight some opportunities of utilizing social network theory to mitigate these design conflicts.
Part Four Trust, Anonymity, and Privacy	No abstract.
Privacy in Electronic Communications	This chapter contains sections titled: <br> Introduction <br> Protection from Third Party: Confidentiality <br> Protection from Communication Partner <br> Invasions of Electronic Private Sphere <br> Balancing Privacy with Other Needs <br> Structure of Privacy <br> Conclusion and Future Trends <br> References
PRISM: Privacy-friendly routing in suspicious MANETs (and VANETs)	Mobile ad-hoc networks (MANETs) are particularly useful and well-suited for critical scenarios, including military, law enforcement as well as emergency rescue and disaster recovery. When operating in hostile or suspicious settings, MANETs require communication security and privacy, especially, in underlying routing protocols. This paper focuses on privacy aspects of mobility. Unlike most networks, where communication is based on long-term identities (addresses), we argue that the location-centric communication paradigm is better-suited for privacy in suspicious MANETs. To this end, we construct an on-demand location-based anonymous MANET routing protocol (PRISM) that achieves privacy and security against both outsider and insider adversaries. We analyze security, privacy and performance of PRISM and compare it to alternative techniques. Results show that PRISM is more computationally efficient and offers better privacy than prior work.
Location Privacy in Sensor Networks Against a Global Eavesdropper	While many protocols for sensor network security provide confidentiality for the content of messages, contextual information usually remains exposed. Such information can be critical to the mission of the sensor network, such as the location of a target object in a monitoring application, and it is often important to protect this information as well as message content. There have been several recent studies on providing location privacy in sensor networks. However, these existing approaches assume a weak adversary model where the adversary sees only local network traffic. We first argue that a strong adversary model, the global eavesdropper, is often realistic in practice and can defeat existing techniques. We then formalize the location privacy issues under this strong adversary model and show how much communication overhead is needed for achieving a given level of privacy. We also propose two techniques that prevent the leakage of location information: periodic collection and source simulation. Periodic collection provides a high level of location privacy, while source simulation provides trade-offs between privacy, communication cost, and latency. Through analysis and simulation, we demonstrate that the proposed techniques are efficient and effective in protecting location information from the attacker.
Efficient and privacy-preserving data aggregation in mobile sensing	The proliferation and ever-increasing capabilities of mobile devices such as smart phones give rise to a variety of mobile sensing applications. This paper studies how an untrusted aggregator in mobile sensing can periodically obtain desired statistics over the data contributed by multiple mobile users, without compromising the privacy of each user. Although there are some existing works in this area, they either require bidirectional communications between the aggregator and mobile users in every aggregation period, or has high computation overhead and cannot support large plaintext spaces. Also, they do not consider the Min aggregate which is quite useful in mobile sensing. To address these problems, we propose an efficient protocol to obtain the Sum aggregate, which employs an additive homomorphic encryption and a novel key management technique to support large plaintext space. We also extend the sum aggregation protocol to obtain the Min aggregate of time-series data. Evaluations show that our protocols are orders of magnitude faster than existing solutions.
Privacy-preserving cross-domain network reachability quantification	Network reachability is one of the key factors for capturing end-to-end network behavior and detecting the violation of security policies. While quantifying network reachability within one administrative domain is already difficult, quantifying network reachability across multiple administrative domains is more difficult because the privacy of security policies becomes a serious concern and needs to be protected through this process. In this paper, we propose the first cross-domain privacy-preserving protocol for quantifying network reachability. Our protocol constructs equivalent representations of the Access Control List (ACL) rules and determines network reachability while preserving the privacy of the individual ACLs. This protocol can accurately determine the network reachability along a network path through different administrative domains. We have implemented and evaluated our protocol on both real and synthetic ACLs. The experimental results show that the online processing time of an ACL with thousands of rules is less than 25 seconds, the comparison time of two ACLs is less than 6 seconds, and the communication cost between two ACLs with thousands of rules is less than 2100 KB.
An ontology for privacy policy management in ubiquitous environments	The SOHand (service oriented handover) architecture supports ubiquitous systems handovers, allowing the user to take control of the session and to migrate, transparently, between wireless technologies and providers (access and content ones). To ensure that the handovers will be done with no problems while users are using services, such architecture uses a set of ontologies called DOHand (domain ontology for handovers). The ontologies will help the negotiation process between the different agents involved. Additionally, as users migrate in their daily duties and activities, they will eventually want to communicate with each other, in an ad-hoc way, to exchange information or to share device/network resources, such as memory, processing, email and bandwidth, in opportunistic ways in a strategy named PSN (pocket switched network). Be it in an infra-structured or ad-hoc way, during the interactions the users need to have a good notion of risk and trust to their partners. They need to define privacy policies that must be negotiated between the parts during the inter-providers handovers; and they need to assess the potential of danger during an opportunistic exchange. In this paper, we describe PrOHand (privacy ontology for handovers), which is an extension of DOHand privacy concept. PrOHand supports privacy policies management, handling information and services used by the SOHand users during infrastructured and PSN interactions. A case study is described in which PrOHand is instantiated for the haggle architecture.
Privacy management service contacts as a new business opportunity for operators	Recognizing the importance of privacy management as a business process and a business support process, this paper proposes the use of service level agreements (SLA's) around privacy features, including qualitative and quantitative ones. Privacy metrics are defined by both parties with boundary values on each feature. Their distribution is relying on stress distributions used in this field .The use of service level agreements also casts privacy management into a business perspective with benefits and costs to either party in a process. This approach is especially relevant for communications operators as brokers and communication channels between content owners (individuals, businesses) and enterprise applications ; in this context, the privacy SLA management would be carried out by the operator, while the terms and conditions of the SLA negotiation reside with the individual and information gatherers .This work was carried out as part of the large EU project PRIME www.prime.project.eu.org on privacy enhancing technologies.
Policy and role based mobile RFID user privacy data management system	Recently, mobile RFID has been studied actively as a primary technology in computing environments. Mobile RFID service is defined as a special type of mobile service using RFID tag packaging objects and RFID readers attached to mobile RFID terminals. While the mobile RFID system has many advantages, it may make new intrusions to the userpsilas privacy. We propose the policy-based dynamic privacy protection framework leveraging globally mobile RFIDs. In this paper, we describe privacy infringements for the mobile RFID service environment and requirements for privacy protection, and develop privacy protection service based on a user privacy policy. The proposed framework provides a means for securing the stability of mobile RFID services by suggesting personal privacy-policy based access control for personalized tags. This means a technical solution to privacy protection for the mobile RFID system.
Multi-observer privacy-preserving Hidden Markov Models	Detection of malicious traffic and network health problems would be much easier if ISPs shared their data. Unfortunately, they are reluctant to share because doing so would either violate privacy legislation or expose business secrets. However, secure distributed computation allows calculations to be made using private data, without leaking this data. This paper presents such a method, allowing multiple parties to jointly infer a Hidden Markov Model (HMM) for traffic and/or user behaviour in order to detect anomalies. We extend prior work on HMMs in network security to include observations from multiple ISPs and develop secure protocols to infer the model parameters without revealing the private data. We implement a prototype of the protocols, and our experiments with the prototype show its has a reasonable computational and communications overhead, making it practical for adoption by ISPs.
Beacon-based trust management for location privacy enhancement VANETs	In recent years more and more studies are focused on trust management of vehicle ad-hoc networks (VANETs). However, little attention has been given to the issue of location privacy of the existing trust methodologies in the literature. Although traffic safety remains to be the most crucial issue in VANETs, location privacy can be just as important for drivers, and neither of them can be ignored. In this paper, we propose a trust scheme which aims to thwart internal attackers in privacy enhanced VANETS. In the proposed scheme a secure broadcast authentication protocol and beacon-based trust management system are being employed to maintain the trustworthiness of vehicles. We adopt Dempster-Shafer Theory to incorporate trustworthiness of event message with vehicle trustworthiness from multiple vehicles. In order to ensure the reliability of the proposed scheme, we evaluate the performance under alteration and denial-of-service attack models. The simulation results show that the proposed system is highly resilient to adversary attacks no matter whether it is under fixed silent period (FSP) scheme or random silent period (RSP) location privacy enhancement scheme.
IPAP: Improved privacy and authentication protocol for passive RFID tags	One of the problems in low-cost passive RFID tags is that they do not provide authentication and privacy. To address this problem Liu et al. proposed the PAP protocol for low-cost passive RFID tag in ICCST 2009. The PAP is has low computation and ensures privacy and authentication between tags and readers, especially designed for SCM (Supply Chain Management) and small shops. We present an IPAP: Improved Privacy and Authentication Protocol. IPAP has 2-bits privacy bit to support refined privacy protection and lower computation overhead compared with the original PAP.
Repeated games for privacy-aware distributed state estimation in interconnected networks	The conflict between cooperation in distributed state estimation and the resulting leakage of private state information (competitive privacy) is studied for a system composed of two interconnected agents. The distributed state estimation problem is studied using an information theoretic rate-distortion-leakage tradeoff model and a repeated non-cooperative game framework. The objective is to investigate the conditions under which the repetition of the agents' interaction enables data sharing among the agents beyond the minimum requirement. In the finite horizon case, similarly to the one-shot interaction, data sharing beyond the minimum requirement is not a credible commitment for either of the agents. However, non-trivial mutual data sharing is sustainable in the long term, i.e., in the infinite horizon case.
Research on Privacy-Preserving Cloud Storage Framework Supporting Ciphertext Retrieval	Privacy security is a key issue for cloud storage. Encryption is a well established technology for protecting sensitive data. But it gives some new problems: how data owner and storage service provider to operate on encrypted data? How to reduce data owner's workload of data management and support data sharing at the same time? If they can't be easy to resolved, encryption will bring a lot of troubles to people. In this paper, we design a privacy-preserving cloud storage framework to solve those problems. We design an interaction protocol among participants, adopt key derivation algorithm to generate and manage keys, use the combination of symmetric and asymmetric encryption to hide the sensitive data of users, and apply Bloom filter to realize cipher text retrieval. A system based on the framework is realized. The paper analyzes the feasibility of the framework from the performance of Bloom filter, the running overhead of the system and the privacy security of the framework. Finally, we summarize our work and introduce the directions of future research.
A New Method on Personalized Privacy Preserving Multi-classification	Privacy-preserving data mining has become important since data mining has been widely used in many fields. Various privacy preserving techniques have been proposed to preserve the sensitive data. In this paper, we address two algorithms which can build classifiers accurately with less privacy disclosure in distributed system. These schemes can satisfy the different privacy disclosure level need of every client, which can meet clients' personalized needs. Besides this, our methods can be used for multi-classification.
A Collusion-Resistant Distributed Scalar Product Protocol with Application to Privacy-Preserving Computation of Trust	Private scalar product protocols have proved to be interesting in various applications such as data mining, data integration, trust computing, etc. In 2007, Yao et al. proposed a distributed scalar product protocol with application to privacy-preserving computation of trust [1]. This protocol is split in two phases: an homorphic encryption computation; and a private multi-party summation protocol. The summation protocol has two drawbacks: first, it generates a non-negligible communication overhead; and second, it introduces a security flaw. The contribution of this present paper is two-fold. We first prove that the protocol of [1] is not secure in the semi-honest model by showing that it is not resistant to collusion attacks and we give an example of a collusion attack, with only four participants. Second, we propose to use a superposed sending round as an alternative to the multi-party summation protocol, which results in better security properties and in a reduction of the communication costs. In particular, regarding security, we show that the previous scheme was vulnerable to collusions of three users whereas in our proposal we can t isin [1..n - 1] and define a protocol resisting to collusions of up to t users.
A Privacy Preserving Intrusion Tolerant Voting Architecture	This paper describes an approach to provide intrusion tolerance and privacy to the replies from a state machine replication system. This new voting architecture provides three important functionalities. First, it filters out any incorrect replies from compromised servers. Second, it prevents leakage of replies to an adversary despite server or voter compromise. Third, it provides support for nondeterminism in the replies by matching semantically similar replies even when they are not identical. A prototype of the proposed architecture has been implemented and its performance has been measured using a microbenchmark. The result demonstrates its feasibility and practicality.
Privacy issues in an insecure world	We all have a notion of privacy and understand that we trade some of it away in order to have normal social interactions and communal security. Networked computer systems are no different. The notion of privacy is running squarely against the need for security in an increasingly networked world. Is it possible to have secure systems that honor privacy? There are two basic ways to secure a network: prevent bad things from happening, and watch closely for bad things and prosecute those who commit them. Since our current preventative measures like authentication and authorization seem to be failing to adequately protect the network, we have turned more toward auditing and monitoring-first as a complement, and now increasingly as a substitute-for prevention. I discuss the impact security concerns is having on privacy, and suggest that today's trend of solving security by detecting intrusions through monitoring is a reaction to institutional paranoia as well as woefully inadequate software development processes. I argue that monitoring alone can't provide sufficient protection, and that in fact the trend of relying increasingly on intrusion detection systems tells us that we are really losing ground-not gaining-on providing computer security.
A Subset Coding Based k-Anonymization Technique to Trade-Off Location Privacy and Data Integrity in Participatory Sensing Systems	Success of participatory sensing system depends on the extent of voluntary participation by users. To increase participation, incentive such as rewards can be used only if reported data has associated user identification. This creates serious threat to participating users' location privacy. Existing techniques tried to solve it with spatial clocking, which suffers from inferior data integrity. In this paper, we present a subset coding based anonymization scheme that can safeguard users' location privacy with k-anonymity while preserving almost lossless data integrity at the destination server. Adversary threats to our scheme are comprehensively analyzed to develop robust strategies and analytical bounds on system parameters for location privacy risk mitigation. Applicability of the proposed scheme is established with extensive simulation results.
Privacy-enhanced identity via browser extensions and linking services	Identity Management systems come with a promise of simpler, centralized, and more secure handling of user data, credentials and authorizations. Service providers can thus be separated from an identity provider (IdP), and users will benefit from single sign on mechanisms. However, identity providers become single points of failure, from a security and trust perspective. In particular, in this paper, we address the protection of user privacy against IdPs profiling. The IdP should not be aware of which services the user will access, or about the details of such service use. This paper discusses the difficulties of this type of privacy protection problem and surveys existing solutions. We then identify a novel solution and improve an existing one: (1) moving part of the access management logic to the client, via a Web Browser extension, and (2) elaborating on previously proposed solutions based on the concept of a linking service, i.e. a server separated from the IdP and from the Service Provider, that will perform some of the authentication steps. Proof of the principle implementations of both solutions are made available to the user.
A privacy-preserving eID based Single Sign-On solution	Single Sign-On (SSO) has become a popular technology allowing users to identify and authenticate once and to gain access to different resources in a distributed computing environment. Austrian e-Government relies on a secure and privacy-preserving sectoral identity management model. Even if a sectoral identifier model improves privacy, it also negatively affects the usability of authentication processes. In Austria, most public sector applications use an open-source identity provider called MOA-ID. However, due to the sectoral identity management MOA-ID has not been Single Sign-On-capable. In this paper we present a security architecture that enables Single Sign-On between different governmental applications using MOA-ID as identity provider while meeting the requirements for sectoral data privacy protection at the same time. We achieve this by transforming unique sectoral identifiers of users with the help of an additional trusted attribute provider.
STORK e-privacy and security	The paper focuses on the legal, data security and privacy issues of the STORK (Secure idenTity acrOss boRders linKed) infrastructure and aims (a) to summarize the main findings and (b) to identify key points that the STORK consortium and stakeholders need to resolve in order to make the STORK security and privacy framework more robust, with the ambition to contribute to more strategic and far-reaching road-mapping and decision making in Europe in the field of electronic identification and authentication. Our findings are based on the roundtable discussion with experts and other stakeholders on the privacy and security legal challenges associated to cross-border use of national authentication solutions within STORK pilot projects.
A Novel Anonymization Technique to Trade Off Location Privacy and Data Integrity in Participatory Sensing Systems	In participatory sensing system community people contribute information to be shared by everybody. However, none would be tolerant enough to contribute voluntarily if her privacy is not protected. This has evoked the idea of research in the area of preserving privacy in participatory sensing system. On the other hand, data integrity is desired imperatively to make the service trustworthy and user-friendly. In this paper, we have investigated the performance of a greedy algorithm and its randomized variant to achieve an acceptable tradeoff between these two orthogonal key parameters. We have also analyzed the ability of a third party adversary to decode privacy-sensitive data by eavesdropping. Our experimental results show that the proposed method is performing satisfactorily as an approach of balancing user privacy and data integrity.
Privacy-Preserving Protocols for String Matching	String matching is a basic problem of string operation, and privacy-preserving string matching, as a special case of secure multi-party computation, has broad applications in auction, bidding and some other commercial areas. In this paper, some protocols are proposed to solve this private matching problem, the security and correctness are analyzed respectively, and the actual efficiency is tested by experiment. A protocol is also designed based on the BMH algorithm which is more efficient and conceals more private information.
Conditional Privacy Using Re-encryption	This paper proposes, for the first time, the use of re-encryption scheme to improve users privacy in a privacy-enhancing system. Firstly, a secure protocol to distribute a re-encryption key from a user A to a service provider B, with the help of n referees, is proposed. Next, this re-encryption key distribution protocol is combined with an existing private credential system to provide a protocol for conditional revocation of private information. This protocol has a strong accountability property with efficient online performance. It does not assume the existence of a single trusted entity. We tolerate up to t dishonest referees (t les n - 1), while A and B are dishonest and do not trust each other.
ROAD: An RFID Offline Authentication, Privacy Preserving Protocol with Dos Resilience	As RFID applications become widespread, different authentication schemes have been proposed to address the security and privacy issues in RFID systems. Most recent protocols have employed a "central server" model. This kind of authentication is vulnerable to Dos attack. In this paper, we present an RFID offline authentication protocol with Dos resilience, ROAD, which provides a more flexible and privacy preserving authentication without the need of a central server. Moreover, we suggest another offline scheme, ROAD<sup>+</sup> for a targeted tag authentication with high search efficiency. We also show that ROAD<sup>+</sup> provides a technical support for an absolutely new application of RFID systems.
A Semiring Privacy Protect Model	Trust management systems support the provision of the required levels of assurance in a flexible and scalable manner by locally discriminating between the entities with which a principal should interact. However, there is a tension between the preservation of privacy and the controlled release of information when an entity submits credentials for establish and verify trust. In this paper, we propose a privacy- protecting trust model, which is based on an ordered semiring framework. In our semiring framework, the credential graph is flexible enough to express trust relationships and it also construct trust model based on privacy protect method. It gives a computing model to describe the trust opinion and privacy opinion, and also provides the minimized privacy disclosure credential search algorithm based on semiring model.
Sensor and Data Privacy in Industrial Wireless Sensor Networks	Over the past years, the deployment of wireless sensor networks (WSNs) into industrial environments attracted a lot of business domains (e.g., defence, public security, energy management and traffic control, and health care). Sensor networks are particularly interesting due to their ability to control and monitor physical environments. Nevertheless, several security challenges deter that integration. In particular, privacy protection is a challenging problem, due to the sensor resources' constrain and the self-organizing nature of WSN architecture. This paper analyses the existing approaches for privacy protection in WSNs and investigates the approaches that aim at supporting the integration of privacy-preserving WSNs into large scale industrial environments. This work is carried out in the recently started EU funded project "TWISNet: Trustworthy Wireless Industrial Sensor Networks".
A Semantic Information Model Based on the Privacy Legislation	Users' concerns regarding their privacy have a negative impact on their confidence into e-services, and tend to slow down the widespread adoption of online services. Until today, the protection of personal data is mainly left to the legislation by means of guidelines. This paper aims to increase the perceived control by users over their data and to bring down into the technological reality the legislative data protection principles. To do so, it discusses the main concepts involved in the legislative privacy principles, and deduces a privacy semantic information model, i.e. a privacy ontology. This model serves to build users' privacy preferences and SP's privacy policies.
A Framework Using IBC Achieving Non-Repudiation and Privacy in Vehicular Network	In vehicular communications, a balance between privacy and anonymity from one side and responsibility and non repudiation from the other side is very important. In this paper, a security framework for VANETs to achieve privacy and non-repudiation is proposed. We present the safety requirements in the context of accident and reporting problem. We build a platform to provide security to safety messages in an accident scenario based on Identity-based cryptography (IBC). An analytical evaluation and performance measurement are achieved to validate this platform. This study confirms that identity-based cryptography and elliptic curves are very useful to make light communications.
Panel: Web Privacy And Anonymity	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00579232.png" border="0">
Do You Talk to Each Poster? Security and Privacy for Interactions with Web Service by Means of Contact Free Tag Readings	The pervasive service interaction (PERCI) application allows interaction with Web services through associated real world objects equipped with contact less tags. The tags are read with a mobile. The read tag content is used to invoke Web service in the back-end system. The case study presented here is identifying in a structured approach security and privacy requirements of an near field communication (NFC) based application. As the application is leaving the technology research stage and is about to enter some system development stage it was indicated to consider security and privacy for R&D risk management purposes. The application is representative for a service, deployable on a mobile using NFC technology and building on Web services taking particularly the stake-holder role-specific situations and the operation of the application as a telecommunication service into account. The contributions of the paper relate to (i) the security discussion that avoids threats where this is possible and mitigates the remaining risks where this is necessary and (ii) the way to structure and organize the different aspects of the security and privacy consideration, which can be applied elsewhere too.
Privacy preserving association rule mining with scalar product	One crucial aspect of distributed data mining is privacy preserving. Secure multiparty computation (SMC) is a useful approach to solve privacy preserving in distributed data mining. When data is vertically partitioned, scalar product is a feasible tool to securely discover frequent itemsets of association rule mining. We first show that several of the private scalar product protocols and analysis their insecurity. Then we develop a new and efficient protocol to perform two-party scalar product with an untrusted third party. The method is described in detail in this paper with complete analysis to demonstrate its effectiveness. Our protocol maintains integrity and high security of the data sets of each party while keeping communication and computation cost low.
Privacy-Preserving SVM Classification on Vertically Partitioned Data without Secure Multi-party Computation	With the development of information science and modern technology, it becomes more important about how to protect privacy information. In this paper, a novel privacy-preserving support vector machine (SVM) classifier is put forward for a vertically partitioned data. The proposed SVM classifier, which is public but does not reveal the privately-held data, has accuracy comparable to that of an ordinary SVM classifier based on the original data. We prove the feasibility of our algorithms by using matrix factorization theory and show the security without using the secure multi-party computation.
Context-Aware Learning Privacy Disclosure Policy from Interaction History	Context-aware applications use personal information to provide appropriate services for people. This personal information is often involved in personal privacy. In order to balance the personal privacy concerns against enjoying context-aware services, we propose a conceptual framework and privacy role to control access personal information. Privacy disclosure policy can be learned from people's interaction history about personal information disclosure using rough set theory. According to deducing from the privacy disclosure policy and context information, a context-aware application is assigned to an adequate privacy role. A case analysis and the initial performance evaluation show that the proposed method is effective.
Security and privacy produced by DHCP unique identifiers	As protection against the current privacy weaknesses of StateLess Address AutoConfiguration (SLAAC) in the Internet Protocol version 6 (IPv6), network administrators may choose to deploy the new Dynamic Host Configuration Protocol for IPv6 (DHCPv6). Similar to the Dynamic Host Configuration Protocol (DHCP) for the Internet Protocol version 4 (IPv4), DHCPv6 uses a client-server model to manage addresses in networks, providing stateful address assignment. While DHCPv6 can be configured to assign randomly distributed addresses to clients, the DHCP Unique Identifier (DUID) was designed to identify uniquely identify clients to servers and remains static to clients as they move between different subnets and networks. Since the DUID is globally unique and exposed in the clear, attackers can geotemporally track clients by sniffing DHCPv6 messages on the local network or by using unauthenticated protocol-valid queries that request systems' DUIDs or leased addresses. DUIDs can also be formed with system-specific information, further compromising the privacy and security of the host. To combat the threat of the static DUID, a dynamic DUID was implemented and analyzed for its effect on privacy and security as well as its computational overhead. The privacy implications of DHCPv6 must be addressed before large-scale IPv6 deployment.
Data-part: A technique for privacy protection in databases	In order to protect individuals' privacy, the technique of k-anonymization has been proposed to de-associate sensitive attributes from the corresponding identifiers. Datafly is one such technique which generalizes the information up to a level in such a way that each individual is hidden among at least k-1 other individuals. But this technique sometimes over distorts the data which may render it useless for statistical and research purposes. In this paper, we present a method called ldquoData-Partrdquo, based on ldquoDataflyrdquo, but with certain modifications, which tries to minimize the distortion of data while still maintaining adequate privacy protection. We prove it through results and experiments at the end of this paper.
Standardizing synthetic information in privacy enforced lure message	A suspect (apriori known) for a given malafide intention has to be lured into Context honeypot using lure messages. The message is generated in a privacy enforced environment in such a way that it can entice him/her into the Context honeypot. Earlier work advocates the formation of message with genuine and synthetic information. The choice of synthetic information should in no way destroy the opaque characteristic of the system. This paper tries to address this need. Here we (a) propose a framework to generate privacy enforced lure message and (b) conduct experiments in a particular domain with set of test users in choosing the synthetic information. The lure message having the synthetic information is used as bait to lure the test user. The response from the user helps the framework in regulating the synthetic information. The best message thus generated is taken as bait to induce the suspected user. The outcome of the result corroborates usefulness/success of the proposed framework.
DWT-based multiple watermarking for privacy and security of digital images in e-commerce	E-commerce has gained a wider popularity among consumers during 20<sup>th</sup> century and is one of the fastest growing segments of Internet today. However, due to openness of information on internet, security becomes an important issue. One of the solutions to this problem is digital watermarking. Multiple watermarking is an advanced digital watermarking which provides increased security and robustness as compared to singular watermarking. The existing multiple watermarking techniques lack the balance of trade off between imperceptibility, robustness and data payload. In this paper, we propose a DWT-based segmented robust spread transform watermarking technique to balance the above mentioned parameters. The use of multiple watermarks increases the embedding capacity of watermark as compared to the singular watermarking technique. Also, the spread transform disperse the watermark over a large number of frequencies providing robustness to volumetric as well as geometric distortions. The imperceptibility of watermark is good in terms of PSNR. Thus, the analytical and experimental results show that the proposed technique balances the trade off between imperceptibility, robustness and data payload.
Special issue on intelligent video surveillance for public security personal privacy	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Privacy Enabled Digital Rights Management Without Trusted Third Party Assumption	Digital rights management systems are required to provide security and accountability without violating the privacy of the entities involved. However, achieving privacy along with accountability in the same framework is hard as these attributes are mutually contradictory. Thus, most of the current digital rights management systems rely on trusted third parties to provide privacy to the entities involved. However, a trusted third party can become malicious and break the privacy protection of the entities in the system. Hence, in this paper, we propose a novel privacy preserving content distribution mechanism for digital rights management without relying on the trusted third party assumption. We use simple primitives such as blind decryption and one way hash chain to avoid the trusted third party assumption. We prove that our scheme is not prone to the ΓÇ£oracle problemΓÇ¥ of the blind decryption mechanism. The proposed mechanism supports access control without degrading user's privacy as well as allows revocation of even malicious users without violating their privacy.
Special issue on privacy and trust management in cloud and distributed systems	Provides notice of upcoming special issue(s) of interest to practitioners and researchers.
Community & Privacy An investigation of two design models of housing in UK and USA by syntactic analysis	This paper examines two cases of housing, which are the most influential design manuals in UK and USA in the post war period. Both of them were based on the intention of creating a good life for ordinary people; both were attempting to give architectural expression to everyday family life patterns. However, by space syntax investigation, the authors find that the solutions given by them are quite different and even opposite to each other. The two plans differ from each other in terms of the layout logic of sequence from public to privacy, the interfaces among family members and visitors, and community life style in housing respectively. This paper proposes that it is the difference of domestic life pattern value in UK and in USA embedded in the plans lead to the contrast of their spatial attributes.
Subjective study of privacy filters in video surveillance	Extensive adoption of video surveillance, affecting many aspects of the daily life, alarms the concerned public about the increasing invasion into personal privacy. Therefore, to address privacy issues, many tools have been proposed for protection of personal privacy in image and video. However, little is understood regarding the effectiveness of such tools and especially their impact on the underlying surveillance tasks. In this paper, we propose a subjective evaluation methodology to analyze the tradeoff between the preservation of privacy offered by these tools and the intelligibility of activities under video surveillance. As an example, the proposed method is used to compare several commonly employed privacy protection techniques, such as blurring, pixelization, and masking applied to indoor surveillance video. The results show that, for the test material under analysis, the pixelization filter provides the best performance in terms of balance between privacy protection and intelligibility.
The privacy challenges of in-depth video analytics	The increasing need for both automated and privacy-respecting CCTV systems adds many challenges to the tasks of Video Analytics. The growing capabilities of automated surveillance systems lead to the automatic extraction and processing of complex and potentially personal data related to individuals who may not even be aware of it. This paper discusses the issues related to the processing of potentially sensitive information extracted from various computer vision algorithms and techniques such as person tracking, soft biometrics, behaviour analysis or multi-modal person identification, and delivers insights regarding technical solutions and guidelines for achieving a higher level of privacy compliance.
Privacy enhancing technologies in video surveillance applied to JPEG2000 codestreams	Privacy enhancing technologies in video surveillance are discussed for JPEG2000 codestreams. Protection accuracy, compression impact, and computational requirements are assessed and compared. Recommendations are given which approach is favourable under certain conditions.
Visual context identification for privacy-respecting video analytics	With the growing need for privacy-aware and privacy-respecting CCTV systems, it becomes crucial to develop workflows and architectures that can support and enhance privacy protection. Recent advances in image processing enable the automation of many surveillance tasks, increasing the risks of privacy infringements. Fortunately, image processing and pattern recognition techniques can also be used for automatically evaluating the context in which video surveillance takes place, and can therefore be employed for applying context-specific privacy rules. This paper describes how Bag-of-Visual-Words algorithms as well as human tracking and gait analysis cane used for recognizing specific sub-contexts that necessitate the application of particular privacy protection rules in usage contexts such as ambient assisted living, public or workspace surveillance We explain how the data of a multi-modal surveillance system should be handled in order to avoid unnecessary processing of sensitive information through Image Quality Descriptors that will support visual classifications by computing reliability measures relating to the image quality such as noise or problems with respect to ambient conditions.
Private content identification: Performance-privacy-complexity trade-off	In light of the recent development of multimedia and networking technologies, an exponentially increasing amount of content is available via various public services. That is why content identification attracts a lot of attention. One possible technology for content identification is based on digital fingerprinting. When trying to establish information-theoretic limits in this application, usually it is assumed that the codewords are of infinite length and that a jointly typical decoder is used in the analysis. These assumptions represent a certain over-generalization for the majority of practical applications. Consequently, the impact of the finite length on the mentioned limits remains an open and largely unexplored problem. Furthermore, leaking of privacy-related information to third parties due to storage, distribution and sharing of fingerprinting data represents an emerging research issue that should be addressed carefully. This paper contains an information-theoretic analysis of finite length digital fingerprinting under privacy constraints. A particular link between the considered setup and Forney's erasure/list decoding [1] is presented. Finally, complexity issues of reliable identification in large databases are addressed.
A Literature Review of Privacy Research on Social Network Sites	With the development of social network sites, security protection of private information online has been a serious and important research topic. Research status quo on privacy of social network sites has been investigated and reviewed in this paper. Two main ways of obtaining private information on social network sites were summarized as based on privacy disclosure and attack technique. In each category, actions to threaten privacy were brought forth. A framework of dangers, which users facing on social network sites, was proposed, and according to privacy risks, protection methods were also discussed. Finally, new topics about privacy research directions on social network sites, privacy-preserving collaborative social network and business model of privacy protection, which need further research, were presented and discussed.
A Remote Anonymous Attestation Scheme with Improved Privacy CA	Trusted computing group developed two solutions to realize remote attestation between platforms, but both of them have drawbacks. Privacy CA defined by trusted computing group needs to be highly available and may collude with verifier to trace user's transactions. direct anonymous attestation proposed in trusted platform module specification v1.2 is not efficient because it adopts many exponential operations and the Issuer may collude with verifier, too. In this paper, we propose a remote anonymous attestation scheme with an improved privacy CA. The Privacy CA issues an anonymous attribute credential for a trusted computing platform and doesn't need to be involved in all attestations. It is also not able to leak the privacy of users. The proposed scheme is high efficient and fulfills the requirements of anonymous credential system very well.
Users' Privacy Issues with E-learning in Library2.0	This article discusses the users' privacy issues when they learn in Libray2.0. The authors classify learners' privacy issues in Library2.0 into four categories: users' personal information, users' seeking behavior privacy, threat from the third party and affiliated links, and leak of users' private documents. In order to protect users' privacy, various privacy-enhancing measures should be adopted. In authors' opinion, privacy protection should not only be approached as a technical concern, but also a social consideration. These measures include privacy protection principle, privacy policy statements, users' anonymity or pseudonymity, technologies methods, and librarians' efforts. Moreover, the authors present that trust is an important concern in e-learning systems in Library2.0. It is of significance for librarians to help users find the appropriate balance between sharing information and protecting privacy. Relevant suggestions are put forward.
A Privacy Policy Conflict Detection Method Based on Sub-graph Isomorphism	Privacy policy plays an important role in the collection and usage of privacy data. Compared with the access control policy, the privacy policy shows three characteristics: (1) the set of privacy policies can offer more semantics; (2) The privacy policy is created by the data owner, whereas the access control policy is created by the database manager; (3) they work in different ways, accurate matching for the privacy and sequence matching for the access control. All of the characteristics make the privacy policy more complex and much easier to produce conflicts. In order to give better solution for the conflicts, this paper proposes a method based on sub-graph isomorphic. This method models the privacy policy and each possible policy conflict pattern as a stratified-directed graph (SDG), and an algorithm is proposed to detect whether the SDG of a privacy conflict mode is isomorphic to that of privacy policies.
Study on Privacy Protection and Anonymous Communication in Peer-to-Peer Networks	While encrypting communication can hide the content of the transaction, the attacker still can invade the users' privacy by flow analysis. Anonymous communication technology is an important method to protect users' privacy. By hiding the participators' identities, or the linkability between sender and receiver, anonymous communication system can guard users' privacy against invasion. The study of anonymous communication techniques was surveyed. In crowds-extended destination routing (C-EDR), all users join a crowd group. Base on these situation, a calable protocol called C-EDR was given, which can be applied to peer-to-peer networks.
Protocol for Privacy-Preserving Set Pattern Matching	Motivated by the demand of databases outsourcing and its security concerns, privacy-preserving set operations have been a research hotspot in distributed scenario. By combining Shamir secret sharing scheme and homomorphic encryption, we propose a protocol for privacy-preserving set pattern matching, this protocol constructed in this paper is provably secure against a semi-honest adversary under the decisional Diffie-Hellman assumption. This is the first specific protocol for privacy-preserving set pattern matching in the cryptographic model at present.
Data Privacy Preserving Mechanism Based on Tenant Customization for SaaS	As a newly software delivery model, software as a service, SaaS for short, is the best way for small and medium enterprise to adopt the newly technology. However trustworthiness is greatest challenge in the wide acceptance of SaaS. In the absence of trustworthiness in SaaS applications, data privacy is the primary and the most important issue for tenants. How to protect the data privacy when software service and database are both hosted at the service provider's client is still an open issue. So based on the customization feature of SaaS applications and shared database shared schema storage model, this paper demonstrates the shared data storage model, defines three kinds of privacy constraints, and then proposes a customizable privacy constraints based approach for data privacy preserving by combing data encryption and information disassociation. This approach is proofed correctly and could be used for privacy preserving in SaaS applications in static scenarios.
Message Passing Based Privacy Preserve in Social Networks	Although a lot of literatures have been proposed on the issue of privacy preserve with relational data, social networks bring new challenges of resisting re-identify attacks. Based on message passing, an approach of privacy preserve in social networks is proposed in this paper. Individuals are assigned to different clusters according to their quasi-identifies and structural similarity measured by message passing. With clusters, k-anonymous mask networks are achieved where any individual is indistinguishable to other k-1 individuals. The experiments show our approach can protect individuals'privacy effectively in social networks with little information loss during generalization.
Privacy Preserving Multiple Keyword Search for Confidential Investigation of Remote Forensics	Remote forensics can help investigators perform investigation without need to ship hard drives or travel to a remote location. With increased use of cloud computing technologies, it is becoming more and more difficult to perform post-event forensic investigation. The difficulty consists in that thousands upon thousands of disparate data from different data owners may be stored on a single storage device (e.g., a remote server). To clone a copy of data from the storage device is a costly and time consuming task and may not be easy due to the huge volume of data. Even if it is possible to make a clone, investigating all the data one by one will inevitably result in exposing irrelevant data to the investigators while data owners may be unwilling to expose it because it may involve their privacy information. The other alternative is to let the server administrator search the relevant information and retrieve the data for the investigators provided a warrant can be provided. However, sometimes, the investigators need to keep the investigation subject confidential due to the confidentiality of the crime or the server administrator may be one of the suspects. In this paper, we address how to solve this problem by multiple keyword search over encrypted data, so that the investigators can obtain the necessary evidence while keeping the investigation subject confidential and at the same time, the irrelevant data can be protected from exposing to the investigators.
A Content Providing System with Privacy Protection	With the development of Internet technology, people can conveniently exchange and share image/video without the limit of time and space. In one image/video, some parts can be open to the public and some cannot or only can be open to specific people because of privacy issue. How to protect privacy information in the image/video has become more and more important. This paper proposes a content (image/video) providing system with privacy protection, which is supposed to make the most of the data and provide varying degrees of privacy/security. We apply fuzzy homomorphic encryption to protect privacy-sensitive area and realize hierarchical access to the data based on Chinese Remainder Theorem. Finally, we conduct the simulation experiments and evaluate the system feasibility.
Factors Affecting Privacy Disclosure on Social Network Sites: An Integrated Model	Users' privacy disclosure behaviors on social network sites (SNSs) have great effects on sound development of websites and harmonious internet. For stealing and abusing privacy information on web enhance people's privacy concern, users refuse to submit necessary information or submit fake information. After a review of TPB model and privacy calculus theory, an integrated model was proposed to explain privacy disclosure behavior on SNSs in this article, to find key factors affecting users' privacy disclosure. According to privacy calculus, perceived benefit was combined into the TPB model. Some modifications were taken in TPB model to fit the scene of SNSs, and an integrated model was gotten. Redefinitions were given to information sensitivity and perceived benefit after literature reviewing. Through a study on mechanism of privacy concern and privacy disclosure, this article aims at reducing privacy concern, keeping order online and stimulating the development of SNSs.
A Novel Anonymous RFID Authentication Protocol Providing Strong Privacy and Security	As the radio frequency identification (RFID) technology continues to evolve and mature, RFID tags can be implemented in a wide range of applications. Due to the shared wireless medium between the RFID reader and the RFID tag, however, adversaries can launch various attacks on the RFID system. The privacy and security issues of RFID are getting more and more important. To thwart different types of attacks, we propose a novel Anonymous RFID Authentication Protocol, termed ARAP, which can accomplish the authentication without disclosing real IDs of the participating tags and provide strong privacy and security protection of the RFID users. ARAP offers the anonymity of tags in addition to tag unlocatability and untrackability. It is also resistant to a wide range of attacks. Compared with the previous researches, the major advantages of ARAP are that ARAP can withstand physical attack, de-synchronization attack, disclosure attack and cloning attack, and also can provide anonymity and mutual authentication. We believe that our protocol is attractive to RFID applications.
Privacy Violations of Video Communications in a Ubiquitous Environment	Media Space is a network application in which video images are continuously sent, received, and shared by coworkers. Therefore, Media Space is considered to have a high risk of giving its users a sense of privacy violation. So far, maintaining reciprocity of the communication is considered to have the most significant effect for perceived risk of privacy violation. In this research, we implemented the cellular-phone-based connection to Media Space. However, because a cellular phone can only act as a viewer of images, the reciprocity cannot be achieved. Therefore, this implementation may increase the risk of computer users' privacy violation by cellular phone users. Seventeen people used this application for nine months, and then a questionnaire survey was conducted. Through a questionnaire survey, we found it phenomenal that the users are less sensitive about their own privacy being violated by others, but are more sensitive about violating other people's privacy.
Criteria for Measuring Information Privacy in Context-Aware Computing Environments	A number of context-aware systems have been developed over the last decade. However, according to the recent studies, concerns of overflowing context information have been increased. Better understanding and classification of information privacy concepts under context-aware computing environments are highly needed. Hence, the purpose of this paper is to develop the measurement criteria for information privacy in context-aware computing environments and then prioritize the criteria. Overall technology characteristics are considered to establish a mutually exclusive set of criteria which measure information privacy in context-aware computing environments in a unique and complete manner. To do so, Delphi method was adopted to obtain the reliable opinion from the experts in information privacy, as well as context-aware systems. Based on this analysis, the panels emphasize context-awareness, tracking, recording, sensors, infrastructure, and hence, they are added to our evaluation model as main criteria.
A Flexible Trust-Based Access Control Mechanism for Security and Privacy Enhancement in Ubiquitous Systems	It is the ubiquity and mobility absolutely necessary for ubiquitous computing environments that raise new challenges for pervasive service provision invisibly. Particularly, mobility of users/devices causes un-predefined and unpredictable changes in physical location and in available resources and services, event at runtime and during the same service session, thus forcing us to consider very dynamic aspects of evaluation when designing an access control mechanism. Alternatively, there is generally no a priori trust relationship among entities interacting in pervasive computing environments which makes it essential to establish trust from scratch. This task becomes extremely challenging when it is simultaneously necessary to protect the privacy of the users involved. In this paper , we first show how trust evaluation process of the user's system can be based on previous accesses and peer recommendations. A solution then relied on trust to control access is proposed that depends upon pre-defined access control security policy. Several tuning parameters and options are suggested so that end-users can customize to meet the security and privacy requirement of a ubiquitous system.
Analysis of Privacy Disclosure in DNS Query	When a DNS (domain name system) client needs to look up a name, it queries DNS servers to resolve the name on the Internet. The query information from the client was passed through one or more DNS servers. While useful, in the whole query transmission, we say it can leak potentially sensitive information: what a client wants to connect to, or what the client is always paying attention to. From the definition, the privacy problem is to prove that none of the private data can be inferred from the information which is made public. We first analyzed the complete DNS query process now in use; then, from each step of the DNS query process, we discussed the privacy disclosure problem in each step of the query: client side, query transmission process and DNS server side. Finally, we proposed a simple and flexible privacy-preserving query scheme "range query", which could maximally decrease privacy disclosure in the whole DNS query process. And we also discuss efficiency and implementation on the range query.
A Real Time Voice Transmission Method for Voice Privacy between CDMA Mobile Network and PSTN	To realize the voice privacy between CDMA mobile phone and TSTN terminal, the voice frames shall be transmitted transparently between the heterogeneous networks. For satisfying this requirement, we propose the method which transmits voice frames by the CDMA circuit data channel in real time. In this paper we analyze the causes of voice delay which occurs during voice transmission by circuit data channel, propose methods which overcome the voice transmission delay and prove proposed methods by the experiment.
Privacy-Preserving DBSCAN Clustering Over Vertically Partitioned Data	Data mining has been a popular research area for more than a decade because of its ability of efficiently extracting statistics and trends from large sets of data. However, in many applications, the data are originally collected at different sites owned by different users. The distributed data mining raises concerns about the privacy of individuals. This paper considers the problem of privacy preserving DBSCAN clustering over vertically partitioned data based on some results of SMC. Each site learns the final results about the clusters, but learns nothing about any other site 's data. An efficient secure intersection protocol is first proposed to implement privacy preserving DBSCAN clustering. The security and complexity of the protocols are also analyzed. The results show that the protocols preserve the privacy of the data and the time complexity as well as the communication complexity is acceptable.
Privacy Aware Recommender Service for IPTV Networks	Providers of the next generation of IPTV services seek to gain competitive advantage over competing providers. In order to attract and satisfy customers, these providers must offer added value e.g. by delivering suitable content according to customers personal interests in a seamless way. This can achieved using recommender services. However, this brings about additional requirement related to the privacy of users' profiles that has to be addressed to make these services widely accepted. The ability to deploy a privacy aware recommender services and in the same time provide accurate recommendations become a key success for the spread of these services. Nevertheless, Current implementations of recommender services are mostly centralized where the users' profiles are stored in single server. This implementation fails to achieve the required privacy guarantee for the users, as it requires collecting accurate private information. In this paper, we present our efforts to build a private centralized recommender service (PRS) using collaborative filtering techniques by introducing an agent based middleware (AMPR) to ensure user profile privacy in the recommendation process. The driving force for using software agents in this work is the autonomic intelligent behaviour that can be achieved using agent technology. AMPR preserve the privacy of its users when using the system and allow private sharing of data among different user in the network. We also introduce two-stage obfuscation process embedded in AMPR that protect user profile privacy and preserve the aggregates in the dataset to maximize the usability of information in order to get accurate recommendations. These processes give the user a complete control on the privacy level of his personal profile. We also provide an IPTV network scenario and experimentation results.
A Privacy-Enhanced Contents Sharing Mechanism with Secure Removable Media(SRM)	In this paper, we propose a privacy-enhanced contents sharing mechanism with SRM. For user anonymity, our approach makes use of anonymously authenticated key exchange based on group signature schemes. In addition, our mechanism not only provides anonymous authentication and key exchange, but also supports a variety of anonymous access control.
Audio-visual privacy protection for video conference	Group video-conferencing systems are routinely used in major corporations, hospitals and universities for meetings, tele-medicine and distance learning among participants from very distant locations. As the use of video-conferencing becomes widely prevalent, the privacy concern's raised by this technology becomes an important issue to be addressed. In this paper we propose a real-time privacy preserving video conferencing system which protects the visual and audio privacy of selected individuals. In our proposed system we differentiate between the general participants and private participants (PP) whose privacy needs to be protected. We further divide the private participants into two different categories and provide a varying level of privacy protection based on the requirements. Specifically, among private participants, we have Active Private Participants (APP) who interactively participate in the meeting and Passive Private Participants (PPP) who play a passive observatory role. The video and audio privacy of the APP are protected by obfuscating their visual information by simple black boxing and real-time pitch modification process respectively. For the PPP, we completely protect their privacy by continuously detecting their presence and erasing them with a real-time adaptive background replacement process.
A Framework for the design of privacy preserving pervasive healthcare	Privacy is an important aspect of pervasive and ubiquitous computing systems, and, in particular, pervasive healthcare. With reference to previous approaches on developing privacy sensitive pervasive healthcare applications, we detail a framework for the design of such systems that aims to minimise the impact of privacy on such systems. In reviewing previous approaches, we extract and combine common elements in order to unify the approaches and create a more formal methodology for designing privacy mechanisms in pervasive healthcare applications. In doing so we also consider the manner in which ubiquitous technologies impact on privacy and methods for reducing this impact. We demonstrate how the framework can be applied by using examples from the previous approaches. In addressing privacy issues, the framework aims to remove a large obstacle to deployment of pervasive healthcare systems, acceptance of the technology.
Compression independent object encryption for ensuring privacy in video surveillance	One of the main concerns of the wide use of video surveillance is the loss of individual privacy. Individuals who are not suspects need not be identified on camera recordings. Mechanisms that protect the identity while ensuring legitimate security needs are necessary. Selectively encrypting objects that reveal identity (e.g., faces or vehicle tags) is necessary to preserve individualspsila right to privacy. This paper presents a compression algorithm independent solution that provides privacy in video surveillance applications. The proposed approach is based on the use of permutation based encryption to hide identity revealing features. The permutation based encryption tolerates lossy compression and allows decryption at a later time. The use of permutation based encryption makes the proposed solution independent of the compression algorithms used. The paper presents the performance of the system when using H.264 video encoding.
Narrowcasting: Implementation of Privacy Control in SIP Conferencing	In traditional conferencing systems, participants' voices might by default be shared with all others. However a VOIP user might want to select a subset of session members to selectively exchange media streams. In this article, we describe an implementation of narrowcasting, a model for limiting such information streams in a multimedia conferences, as a class of policies, prototyping a system using existing standard Session Initiation Protocol (SIP) methods for controlling fine-grained narrowcasting sessions.
Dynamic Privacy in a Smart House Environment	A smart house can be regarded as a surveillance environment in which the person being observed carries out activities that range from intimate to more public. What can be observed depends on the activity, the person observing (e.g. a carer) and policy. In assisted living smart house environments, a single privacy policy, applied throughout, would be either too invasive for an occupant, or too restrictive for an observer, due to the conflicting goals of surveillance and private environments. Hence, we propose a dynamic method for altering the level of privacy in the environment based on the context, the situation within the environment, encompassing factors relevant to ensuring the occupant's safety and privacy. The context is mapped to an appropriate level of privacy, which is implemented by controlling access to data sources (e.g. video) using data hiding techniques. The aim of this work is to decrease the invasiveness of the technology, while retaining the purpose of the system.
People Identification with Limited Labels in Privacy-Protected Video	People identification is an essential task for video content analysis in a surveillance system. To construct a good classifier requires a large amount of training data, which may not be obtained in some scenario. In this paper, we propose an approach to augment insufficient training data by labeling identical video images that have removed people's identities by masking faces. We show user study results that human subjects can perform reasonably well in labeling pairwise constraints from face obscured images. We also present a new discriminative learning algorithm WPKLR to handle uncertainties in pairwise constraints. The effectiveness of the proposed approach is demonstrated using video captured in a nursing home environment. The experiments show that the WPKLR approach can obtain a high accuracy of people identification using limited labeled data and noisy pairwise constraints, and meanwhile minimize the risk of exposing people's identities
A Distance-Sensitive Attribute Based Cryptosystem for Privacy-Preserving Querying	We propose an attribute-based cryptosystem in which decryption is conditional on the distance between attributes. Alice constructs a cipher text that consists of an encrypted message and a hidden attribute vector. Bob is able to decrypt Alice's message if and only if his attribute vector is within a specified maximum distance from Alice's attribute vector. We provide constructions for Euclidean and Hamming distances. The cryptosystem has advantages for privacy preserving querying. In particular, all parties can broadcast their respective cipher texts or store them on a database server. Then, a client -- not necessarily belonging to the original set of parties -- can independently and privately query the database server for cipher texts whose attributes are within some small distance from its own attribute. We describe an application of this cryptosystem in which a customer obtains recommendations from other customers of a movie rental company in a privacy-preserving manner.
A privacy preserving content distribution mechanism for drm without trusted third parties	A content distribution mechanism for DRM needs to satisfy the security and accountability requirements while respecting the privacy of the parties involved. However, achieving privacy along with accountability in the same framework is not easy as the requirement for achieving these attributes are conflicting each other. Most of the current content distribution mechanisms rely on trusted third parties to achieve privacy along with these attributes. In this paper, we propose a privacy preserving content distribution mechanism without requiring trust over any third party by using the mechanisms of blind decryption and one way hash chain. We prove that our scheme is not prone to the ΓÇÿoracle problemΓÇÖ of the blind decryption mechanism. Our mechanism supports revocation of even malicious users without violating their privacy.
Automatic generation of privacy-protected videos using background estimation	Recently, video sharing services such as YouTube and Daily-motion have become popular and many videos taken with mobile video cameras are uploaded to such a video sharing service. However, such videos can infringe on the privacy right of people in the videos because they may contain privacy sensitive information (PSI) of the people, i.e., their appearances. This strongly motivates us to develop a technique to generate privacy-protected videos. In this paper, we propose a novel system for automatic generation of privacy-protected videos based on background estimation. In most conventional techniques, objects that contain PSI are detected and obscured by, e.g., blurring. Conversely, in our system, background pixels are estimated and then substituted with intended human objects that are essential for the camera person's capture intention. We quantitatively evaluate our system to demonstrate its potential applicability.
Security and privacy in online social networks: A survey	Social networking becomes increasingly important due to the recent surge in online interaction. Social network analysis can be used to study the functioning of computer networks, information flow patterns in communities, and emergent behavior of physical and biological systems. In this paper, the mathematical formulation and computational models for security and privacy of social network data are discussed. Several possible ways for an attacker to attack are presented so that the mathematical formulation can take them into account. The metrics for measuring the amount of security and privacy in an online social network (OSN) are discussed so that we have an idea of how good a model is. Based on these current techniques and attack strategies, future directions of research are discussed.
A framework for the validation of privacy protection solutions in video surveillance	The issue of privacy protection in video surveillance has drawn a lot of interest lately. However, thorough performance analysis and validation is still lacking, especially regarding the fulfillment of privacy-related requirements. In this paper, we put forward a framework to assess the capacity of privacy protection solutions to hide distinguishing facial information and to conceal identity. We then conduct rigorous experiments to evaluate the performance of face recognition algorithms applied to images altered by privacy protection techniques. Results show the ineffectiveness of nai╠êve privacy protection techniques such as pixelization and blur. Conversely, they demonstrate the effectiveness of more sophisticated scrambling techniques to foil face recognition.
Privacy-preserving approximation of L1 distance for multimedia applications	Alice and Bob possess sequences x and y respectively and would like to compute the Γäô<sub>1</sub> distance, namely || x - y ||<sub>1</sub> under privacy and communication constraints. The privacy constraint requires that Alice and Bob do not reveal their data to each other. The communication constraint requires that they accomplish the secure distance calculation with a small number of protocol transmissions and key exchanges. This paper describes and analyzes a privacy-preserving approximation protocol for the Γäô<sub>1</sub> distance that keeps the communication overhead manageable by performing a Johnson-Lindethe Γäô<sub>1</sub> distance that keeps the communication overhead manageable by performing a Johnson-Lindenstrauss embedding into the Γäô<sub>2</sub> space. Then, it performs secure two-party computation of Γäô<sub>2</sub> distances using Paillier homomorphic encryption. The protocol is implemented for private querying of face images, while maintaining a low communication overhead between the queryingnstrauss embedding into the Γäô<sub>2</sub> space. Then, it performs secure two-party computation of Γäô<sub>2</sub> distances using Paillier homomorphic encryption. The protocol is implemented for private querying of face images, while maintaining a low communication overhead between the querying party and a remote database of face feature vectors.
Privacy modeling for video data publication	Video cameras are being extensively used in many applications. Huge amounts of video are being recorded and stored everyday by surveillance systems. Any proposed application of this data raises severe privacy concerns. An assessment of privacy loss is necessary before any potential application of the data. In traditional methods of privacy modeling, researchers have focused on explicit means of identity leakage like facial information, etc. However, other implicit inference channels through which individual's an identity can be learned have not been considered. For example, an adversary can observe the behavior, look at the places visited and combine that with the temporal information to infer the identity of the person in the video. In this work, we thoroughly investigate privacy issues involved with the video data considering both implicit and explicit channels. We first establish an analogy with the statistical databases and then propose a model to calculate the privacy loss that might occur due to publication of the video data. The experimental results demonstrate the utility of the proposed model.
A real-time privacy-sensitive data hiding approach based on chaos cryptography	A multimedia surveillance system aims to provide security and safety of people in a monitored space. However, due to the nature of surveillance, privacy-sensitive information, such as face, gait and other physical parameters based on the captured media from multiple sensors, can be revealed without the concern of the people. This is a major concern in recent days. Therefore, it is desirable to have such mechanism that can hide privacy-sensitive information as much as possible, yet supporting effective surveillance tasks. In this paper, we propose a chaos cryptography based data hiding approach that can be applied on selected regions of interest (ROIs) in video camera footage, which contains privacy-sensitive data. Our approach also supports multiple levels of abstraction of data hiding depending on the role of the authorized user. In order to evaluate the suitability of this approach, we applied our algorithm on some video camera footage and observed that our approach is computationally efficient and applicable for real-time video surveillance tasks.
Anonymous subject identification in privacy-aware video surveillance	The widespread deployment of surveillance cameras has raised serious privacy concerns. Many privacy-enhancing schemes have been recently proposed to identify selected individuals and redact their images in the surveillance video. To identify individuals, the best known approach is to use biometric signals as they are immutable and highly discriminative. If misused, these characteristics of biometrics can seriously defeat the goal of privacy protection. In this paper, we propose an anonymous subject identification system based on homo-morphic encryption (HE). It matches the biometric signals in encrypted domain to provide anonymity to users. To make the HE-based protocols computationally scalable, we propose a complexity-privacy tradeoff called k-Anonymous Quantization (kAQ) which narrows the plaintext search to a small cell before running the intensive encrypted-domain processing within the cell. We validate a key assumption in kAQ that privacy is better preserved by grouping biometric patterns far apart into the same cell. We also improve the matching success rate by replacing the original bounding boxes with e-balls as basic units for grouping. Experimental results on a public iris biometric database demonstrate the validity of our framework.
Privacy protection of fingerprint database using lossless data hiding	In this paper, we introduce a fingerprint authentication system for protecting the privacy of the fingerprint template stored in a database. The template, which is a binary fingerprint image after thinning, will be embedded with private personal data in the user enrollment phase. In the user authentication phase, these hidden personal data can be extracted from the stored template for verifying the authenticity of the person who provides the query fingerprint. A novel lossless data hiding scheme is proposed for a thinned fingerprint. By adopting ΓÇ£embeddability criterionΓÇ¥, data is hidden into the template by just adding some boundary pixels in the template. These boundary pixels can be extracted and removed to reconstruct the original thinned fingerprint so that fingerprint matching accuracy is not affected. Compared with using existing binary image data hiding techniques, our scheme has a better performance for a thinned fingerprint.
Privacy in mobile agents	Agent technology gives many promises for future IT-systems, but little privacy related problems in this technology have been resolved. This paper addresses the privacy problems in agent technology and provides several solutions to overcome some of these problems. It is shown that if an encryption algorithm is used in a different form, it can also provide privacy in communication for agents. Second, it is shown how secret computations can be performed when the function to be executed is a polynomial. Finally, an agent digital signature is described that takes into consideration that the agent's private key must be seen as the most privacy sensitive information of an agent.
Identification with privacy protection based on data hiding	In many problems such as biometrics, multimedia search and retrieval, recommendation systems requiring privacy-preserving similarity computations and identification, some binary features are stored in the public domain or outsourced to the third parties that might raise certain privacy concerns about the original data. To avoid this privacy leak, privacy protection is used. In the most cases, the privacy protection is uniformly applied to all binary features resulting in the data degradation and corresponding loss of performance. To avoid this undesirable effect we propose a new privacy amplification technique that is based on data hiding principles and benefits from side information about bit reliability a.k.a. soft fingerprinting. In this paper, we investigate the identification rate vs. privacy-leak trade-off. The analysis is performed for the cause of perfect match between the side information shared between the encoder and decoder as well as for the case of partial side information.
Managing location privacy in cellular networks with femtocell deployments	Femtocell deployments allow for high precision in localizing mobile devices. Many of today's location based services have long been mapping the placements of wireless base stations and using the obtained maps to localize mobile devices. Allowing unauthorized third parties to obtain the locations of femtocell base stations may not be desired by network operators. Localizing mobile devices using the information about femtocell base stations' locations is a service that an investor in a femtocell deployment may want to exploit exclusively. In this work we present a station identity management system that enables preserving femtocell base stations location privacy. Through the use of dynamic base station identifiers, the system ensures that unauthorized third parties are not able to map the locations of the base stations for use in their localization services. We analyze the design tradeoffs of the presented approach for different femtocell technologies. Results indicate that complexity will be limited, and that the presented system creates network dynamics smaller than the existing dynamics due to mobility. Additionally, we present an approach for providing location information to authorized systems at different resolution levels.
A Privacy-Preserving Biometric Matching Protocol for Iris Codes Verification	Biometric-based authentication systems have been widely used in applications that require high reliable scheme. For instance, iris-based authentication systems had received great attention due to its high reliability for personal identification. However, the growing use of biometric systems in real life applications raises more attention and concern about the privacy issues. Unlike PIN or password which provides exact matches, iris-codes recognition provides a degree of probability or confidence that two iris-codes are similar based on some distance measurements. In iris verification, the biometric matching is performed by measuring the Hamming distance between the query feature vector and the template. The computation must not leak any sensitive information because the leakage of such information may allow any malicious party to reconstruct the original feature vector of the user. Once the original features have been revealed, the privacy of the user will be compromised forever. In view of this problem, we design a privacy preserving biometric matching protocol to facilitate the iris-codes matching in a privacy preserved environment. By introducing some chaff features in our computation, the malicious client who outputs an artificially low mismatch score can be easily detected by the server. Hence, our protocol makes it computationally infeasible for malicious client to impersonate as an enrolled user.
Location Privacy Through Users' Collaboration: A Distributed Pseudonymizer	Mobile devices able to locate themselves such as mobile phones and PDAs are virtually everywhere, and they are expected to gain more importance in the near future. Their ability to determine locations opens the door to a new bunch of services: the so-called location-based services (LBS). The commercial sector will highly benefit from LBS. However, they are not without a cost - privacy. In this article we present a (trusted third party)-free, distributed, collaborative method to preserve the location privacy of LBS users.
Methods for Conserving Privacy in Workflow Controlled Smart Environments	In the last years context-aware workflow systems have gained more and more importance. However, in research little emphasis has been put on workplace privacy and humane system design. It is the aim of this paper to give an overview on the effects of combining workflow systems and context-aware systems and to discuss its implications for workplace privacy and human-oriented design. Different methods are to be depicted that help to overcome certain ethical problems thus allowing for the development of acceptable, justified and justifiable technical solutions which are likely to be also adopted by its latter users. Finally a ├é┬┐best practice├é┬┐ prototype is to be presented which implements the introduced methods.
Auditable and Privacy-Preserving Authentication in Vehicular Networks	In vehicular networks, vehicles should be able to authenticate each other to securely communicate with network-based infrastructure, and their locations and identifiers should not be exposed from the communication messages. However, when an accident occurs, the investigating authorities have to trace down its origin. As vehicles communicate not only with RSUs (Road Side Units) but also with other vehicles, it is important to minimize the number of communication flows among the vehicles while the communication satisfies several security properties such as anonymity, authenticity, and traceability. In our paper, when the mutual authentication protocol is working between vehicles and RSUs, the protocol offers the traceability with privacy protection using pseudonyms and MAC (Message Authentication Code) chain. And by using MAC-chainas one-time pseudonyms, our protocol does not need a separate way to manage pseudonyms.
Privacy-Aware Cloaking Technique in Location-Based Services	The explosive growth of location-detection devices, such as GPS (Global Positioning System), continuously increasing users' privacy threat in location-based services (LBSs). However, in order to enjoy such services, the user must precisely disclose his/her exact location to the LBS. So, it is a key challenge to efficiently preserve user's privacy while accessing LBS. For this, the existing method employs a 2PASS cloaking framework that not only hides the actual user location but also reduces bandwidth consumption. However, it suffers from privacy attack. Therefore, we wish to provide the solution which can preserve user privacy by utilizing k-anonymity mechanism. In this paper, we propose a weighted adjacency graph based k -anonymous cloaking technique that can ensure users privacy protection and also reduce bandwidth usages. Our cloaking approach efficiently supports k-nearest neighbor queries without revealing private information of the query initiator. We demonstrate via experimental results that our algorithm yields much better performance than the existing one.
A New K-NN Query Processing Algorithm Enhancing Privacy Protection in Location-Based Services	Location-Based Services (LBSs) are becoming popular due to the advances in mobile networks and positioning capabilities. When a user sends a query with his exact location to the LBS server, the server processes the query and returns Points of Interest (POIs) to the user. Providing user's exact location to the LBS server may lead revealing his private information to unauthorized parties (e.g., adversaries). There exist two main fields of research to overcome this problem. They are cloaking region based query processing method which blurs a user's location into a cloaking region and Private Information Retrieval (PIR) based query processing methods which encrypt location data by using PIR protocol. However, they suffer from high computation and communication overheads. To resolve these problems, we, in this paper, propose a hybrid scheme to process an approximate k-Nearest Neighbor (k-NN) query by combining above two methods. Through performance analysis, we have shown that our hybrid scheme outperforms the existing work in terms of both query processing time and accuracy of the result set.
Managing Privacy in LocationBased Access Control Systems	This chapter contains sections titled: <br> Introduction <br> Related Work <br> Basic Scenario and Concepts <br> Location-Based Access Control <br> Obfuscation Techniques for User-Privacy <br> A Privacy-Aware LBAC System <br> Summary <br> Acknowledgments <br> References
Privacy-Aware Proximity Based Services	Proximity based services are location based services (LBS) in which the service adaptation depends on the comparison between a given threshold value and the distance between a user and other (possibly moving) entities. While privacy preservation in LBS has lately received much attention, very limited work has been done on privacy-aware proximity based services. This paper describes the main privacy threats that the usage of these services can lead to, and proposes original privacy preservation techniques offering different trade-offs between quality of service and privacy preservation. The properties of the proposed algorithms are formally proved, and an extensive experimental work illustrates the practicality of the approach.
Caching as Privacy Enhancing Mechanism in Location-Based Services	A Location-based Service has to protect user's location and query information to alleviate privacy concerns. Several location and query privacy preserving approaches, based on the concept of k-anonymity and l-diversity, have been proposed in the literature. These approaches assume a trusted anonymizer. Caching has been used as the trusted anonymizer to save communication and computation cost and to enhance the privacy of snapshot and continuous user queries. Such cache designs only provide privacy up to a certain limit and are not designed for multiple points of interest (POI) type queries. We propose a novel cache design and a cache event model that provides significantly higher levels of privacy. We also propose a novel privacy preserving metric which measures the privacy offered by different components (caching, k-anonymity, l-diversity) of the anonymizer which is to the best of our knowledge the first comprehensive privacy measuring metric. We perform several experiments on real world data to evaluate the effectiveness of our cache design in terms of privacy enhancements, computation and communication costs.
VeryIDX - A Privacy Preserving Digital Identity Management System for Mobile Devices	The combined use of the Internet and mobile technologies is leading to major changes in how individuals communicate, conduct business transactions and access resources and services. In such a scenario, digital identity management (DIM) technology is fundamental for enabling transactions and interactions across the Internet. In this demo, we demonstrate VeryIDX, a system for the privacy-preserving management of users' identity attributes on mobile devices.
PLOT: Privacy in Location Based Services: An Open-Ended Toolbox	The widespread adoption of location based services (LBSs) coupled with recent advances in location tracking technologies, pose serious concerns to user privacy. As a consequence, privacy preserving approaches have been proposed to protect the location information which is communicated during a request for an LBS. Most existing approaches are centralized as they rely on a trusted server to protect the real location of the user. Although the centralized approaches are commonplace, so far no attempt has been made to integrate them in a unified framework. Such an integration would provide the means for easily implementing and testing new techniques by offering ready-made vanilla system components and allow for both the experimental and analytical evaluation of the implemented techniques.In this paper we propose PLOT, an open-ended toolbox that allows the implementation and the evaluation of privacy-enhancing algorithms for LBSs. PLOT offers a variety of interesting features: (i) it supports both real and synthetic movement data, (ii) it relies on spatial DBMSs to efficiently handle movement data as well as the underlying model of user movement, (iii) it offers tools for mobile data preprocessing, movement reconstruction and segmentation, (iv) it allows the implementation of both network-based and free-terrain solutions to location privacy, (v) it provides the infrastructure for second-chance approaches when the main location privacy approach fails, (vi) it implements strategies for the identification of frequent patterns in user movement, and finally (vii) it offers an extended set of visualization tools that both provide insight on the workings of the implemented solutions and facilitate the qualitative and quantitative evaluation of their behavior.
Privacy-Preserving Techniques for Proximity Based LBS	As location based services (LBS) become more popular, preserving users' privacy is becoming an important task. In this paper we present our findings about the privacy threats related to a particular class of LBS and the techniques we recently developed to protect users from these threats. The class of services we address are the proximity based services, in which a user obtains to know if the distance of other users (or, in general, other entities) from her location is above or below a requested threshold. A popular service belonging to this class is the "friend-finder" service. A user subscribed to this kind of service wants to be alerted when one of her buddies is in the neighborhood, so they can eventually get in contact and meet. Depending on the type of service provided, "buddies" can be either identified by a set of known users (like contact lists in instant messaging services) or by a set of users which meets some criteria requested by the user. More technically, a proximity based service consists of spatial range queries on the database of users' locations, using the desired proximity threshold as range.
AnonTwist: Nearest Neighbor Querying with Both Location Privacy and K-anonymity for Mobile Users	Protecting privacy of mobile users of location-based services is a currently interesting research problem. Most protection techniques can be categorized into either those providing location privacy or those guaranteeing k-anonymity. A mobile user (i) has location privacy if, when he makes an LBS request, adversaries cannot tell his location precise enough to cause privacy concerns, and (ii) has k-anonymity if adversaries cannot distinguish him, among a group of k users, as the definite request issuer. SpaceTwist proposed recently is in the former category, but makes no attempt to provide k-anonymity. The purpose of this paper is to study a method that makes SpaceTwist provide k-anonymity in addition to location privacy. The extended algorithm is called AnonTwist. The major challenge is the ability to make sure that at least k users are in the privacy area given in the SpaceTwist algorithm, i.e., in the so-called "twisted space". AnonTwist contains two technical contributions. The first is a user density map in the form of a Quadtree so that we have an estimate of the number of users in each spatial area. The second is a nontrivial counting mechanism, over the density map, to keep track of the number of users in the twisted space. Comparison of AnonTwist and SpaceTwist is performed via an experimental evaluation. The results show that the performance of AnonTwist is comparable to that of SpaceTwist. With the additional advantage of providing k-anonymity, AnonTwist should be the more favorable algorithm to use in practice.
A Profile Anonymization Model for Privacy in a Personalized Location Based Service Environment	Location based services (LBS) aim at delivering point of need information. Personalization and customization of such services, based on the profiles of mobile users, would significantly increase the value of these services. Since profiles may include sensitive information of mobile users and moreover can help identify a person, customization is allowed only when the security and privacy policies dictated by them are respected. While LBS are often presumed as untrusted entities, the location services that capture and maintain mobile users' location to enable communication are considered trusted, and therefore can capture and manage the profile information. In this paper, we address the problem of privacy preservation via anonymization. Prior research in this area attempts to ensure k-anonymity by generalizing the location. However, a person may still be identified based on his/her profile if the profiles of all k people are not the same. We extend the notion of k-anonymity by proposing a profile based k-anonymization model that guarantees anonymity even when profiles of mobile users are known to untrusted entities. Specifically, our proposed approaches generalize both location and profiles to the extent specified by the user. We support three types of queries - mobile users requesting stationary resources, stationary users requesting mobile resources, and mobile users requesting mobile resources. We propose a novel unified index structure, called the (P<sup>TPR</sup>- tree), which organizes both the locations of mobile users as well as their profiles using a single index, and as a result, offers significant performance gain during anonymization as well as query processing.
Privacy Preservation in the Publication of Trajectories	We study the problem of protecting privacy in the publication of location sequences. Consider a database of trajectories, corresponding to movements of people, captured by their transactions when they use credit or RFID debit cards. We show that, if such trajectories are published exactly (by only hiding the identities of persons that followed them), there is a high risk of privacy breach by adversaries who hold partial information about them (e.g., shop owners). In particular, we show that one can use partial trajectory knowledge as a quasi-identifier for the remaining locations in the sequence. We device a data suppression technique, which prevents this type of breach, while keeping the posted data as accurate as possible.
The International Workshop on Privacy-Aware Location-Based Mobile Services (PALMS 2007)	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04417155.png" border="0">
Privacy (Regimes) Do Not Threaten Location Technology Development	Location technology allows for the tracking and tracing of individuals. Users may increasingly be concerned about the abilities of new technology to keep an eye on ones' private life. There are concerns that the increased privacy awareness among citizens and legislation may hinder the success and further development of these technologies. An analysis of the European legal framework for protecting individual's privacy versus private sector use of location information and public sector use in the intelligence services indicates that individuals should be most aware on intrusions in their privacy by intelligence services. The privacy legislation lets the user be in control of the decision if and when his location information may be used by private sector location based services providers. Users seem often willing to allow this, judging by the increase in available location based services. The privacy legislation is not as protective regarding the use for law enforcement and secret intelligence purposes. Thus the location technology industry is also likely to prosper from the investments of the public intelligence sector.
Privacy-Aware RNN Query Processing on Location-Based Services	This paper addresses how to answer the reversed nearest neighbor (RNN) queries in the location-based services when the privacy of users needs to be protected. We assume that the users' exact locations have been blurred into spatial regions based on user-specified privacy requirements. Inspired by the concept of Voronoi cell of point data, we introduce the concept of Voronoi cell for regions (VCR) and propose the framework to answer the privacy-ware RNN queries based on computing the VCR. We also propose the techniques to compute the VCR under L<sub>1</sub> metric efficiently.
iPDA: Supporting Privacy-Preserving Location-Based Mobile Services	This demonstration presents iPDA, a system to support privacy-preserving data access in location-based mobile services. The iPDA system consists of three main components: 1) a mobility-aware location cloaker that cloaks the user's location with a region and transforms a location- based query to a region-based query, 2) a progressive query processor that efficiently evaluates a result superset for the location-based query and, 3) a result refiner that refines the superset to generate the exact query result for the user. We discuss in detail the architecture and functionalities of our iPDA system. In addition, a tourist information system named iGuide, as an iPDA application, is prototyped for demonstration.
Privacy Preserving Computation of Shortest Path in Presence of a Single Convex Polygonal Obstacle	Shortest path computation has always been a subject of study and research in the history of computer science. In this paper we introduce and initiate the study of the problem of finding the shortest path in a privacy preserving manner, in presence of single convex polygonal obstacle. We also propose an efficient, elegant and simple solution for the problem.
Privacy-Aware Knowledge Discovery from Location Data	Spatio-temporal, geo-referenced datasets are growing rapidly, and will be more in the near future. This phenomenon is mostly due to the daily collection of telecommunication data from mobile phones and other location-aware devices and is expected to enable novel classes of applications based on the extraction of behavioral patterns from mobility data. Such patterns could be used for instance in traffic and sustainable mobility management (e.g., to study the accessibility to services), urban planning, environmental monitoring, and collaborative location-based services. Clearly, in these applications privacy is a concern, since some knowledge may be sensitive, or an over-specific pattern may reveal the behaviour of groups of few individual. In this paper we focus on automated privacy-preserving methods we developed for extracting and sharing user- consumable forms of knowledge from large amounts of raw data referenced in space and in time.
Location Privacy Pricing and Motivation	This paper examines the results of our European-wide study on the price of location privacy of individuals using mobile phones. There were 1200 active participants from five EU countries in our experiment. We used tools from experimental psychology and economics to assess the value that users attach to their location data. This paper extends the results that are provided in [D. Cvrcek et al., 2006]. Our main focus in this paper was the motivation of the participants to take part in the experiment and further investigation of their bids. This paper presents a more detailed view of the motivation and a correlations between the motivation and the bids.
Privacy-Preserving Data Mining on Moving Object Trajectories	The popularity of embedded positioning technologies in mobile devices and the development of mobile communication technology have paved the way for powerful location-based services (LBSs). To make LBSs useful and user- friendly, heavy use is made of context information, including patterns in user location data which are extracted by data mining methods. However, there is a potential conflict of interest: the data mining methods want as precise data as possible, while the users want to protect their privacy by not disclosing their exact movements. This paper aims to resolve this conflict by proposing a general framework that allows user location data to be anonymized, thus preserving privacy, while still allowing interesting patterns to be discovered. The framework allows users to specify individual desired levels of privacy that the data collection and mining system will then meet. Privacy-preserving methods are proposed for a core data mining task, namely finding dense spatio-temporal regions. An extensive set of experiments evaluate the methods, comparing them to their non- privacy-preserving equivalents. The experiments show that the framework still allows most patterns to be found, even when privacy is preserved.
Privacy in Location-Based Services: State-of-the-Art and Research Directions	The explosive growth of location-detection devices (e.g., GPS-like devices and handheld devices) along with wireless communications and mobile databases results in realizing location-based applications that deliver specific information to their users based on their current locations. Examples of such applications include location-based store finder, location-based traffic reports, and location-based advertisements. Although location-based services promise safety and convenience, they threaten the privacy and security of users as such services explicitly require users to share private location information with the service. If a user wants to keep her location information private, she has to turn off her location-aware device and temporarily unsubscribe from the service. Recent studies show that such privacy concerns - ranging from worries over employers snooping on their workers' whereabouts to fears of tracking by potential stalkers - are a serious obstacle to wider adoption of location-based services. This article aims to provide practitioners, researchers, and graduate students with the state of the art and major research issues in the important and practical research area of location privacy. In general, the tutorial is divided into the following five parts: (1) legislative issues and privacy concerns, (2) location privacy in mobile environments, (3) privacy attack models, (4) privacy-aware location query processing; (5) concluding remarks.
Analysis of Security and Privacy Issues in RFID-Based Reference Point Systems	In this paper, we analyze security and privacy issues in RFID-based reference point systems, which seamlessly provide high resolution location information so as to enable innovative mobile applications. Our preliminary analysis revealed the significance of the labor cost in deploying RFID reference points; therefore, we carefully analyze several system architecture candidates in terms of deployment cost and security/privacy threats. Based on the analysis, we select a scalable architecture to avoid the bottleneck in deployment cost even though it can be less secure. Finally, we briefly discuss potential solutions for critical security and privacy issues in the selected architecture.
A Comparison of Spatial Generalization Algorithms for LBS Privacy Preservation	Spatial generalization has been recently proposed as a technique for the anonymization of requests in location based services. This paper presents the results of an extensive experimental study, considering known generalization algorithms as well as new ones proposed by the authors.
Access Control and Privacy in Location-Aware Services forMobile Organizations	In mobile organizations such as enterprises operating on field, healthcare organizations and military and civilian coalitions, individuals, because of the role they have, may need to access common information resources through location-aware applications. To enable a controlled and privacy preserving access to such applications, a comprehensive conceptual framework for an access control system enhanced with location privacy is presented.
Enabling context-aware and privacy-conscious user data sharing	This paper provides detail on two key components of the Houdini framework under development at Bell Labs, that enable context-aware and privacy-conscious user data sharing appropriate for mobile and/or ubiquitous computing. The framework includes an approach for integrating data from diverse sources, for gathering user preferences for what data to share and when to share it, and a policy management infrastructure in the network for enforcing those preferences. The current paper focuses on two components of this infrastructure that are essential for mobile and ubiquitous computing, namely the framework to support self-provisioning of preferences, and the performance of the underlying rules engine.
Context-Based Privacy Protection for Location-Based Mobile Services using Pseudonyms	This paper discusses the combination of a nifty pseudonym generation mechanism that is used to veil the real world identity of users with semantic user context descriptions and policy reasoning to express decisions of users and thus protects their sensitive location information. The expected development of a new class of mobile applications is further fostered by the underlying service architecture that makes use of the privacy protection means and allows the implementation of the highly postulated pay-as-you-go model. Means for privacy protection are not only an ultimate requirement for the development of successful location-based services and applications. It further means an incentive for network service operators to enrich location-based services by making available their localization capabilities to at the same time to open new sources of revenue.
Cache Management Techniques for Privacy Preserving Location-based Services	In order to access location-based services, mobile users have to disclose their exact locations to service providers. However, adversaries could collect the location information for purposes against mobile users' privacy. There are existing solutions for privacy protection by utilizing the K-anonymity model. However, the computational and communication costs are high. This research proposes cache management techniques for further improving user privacy protection, saving computational power, and decreasing communication costs.
How Much Room before you Rely: Balancing Privacy Control and Fidelity in the Location-based Pervasive Applications	Rapid development of innovative location-centric applications promoted through widespread proliferation of wireless technology and availability of small handheld devices have brought about a new era in pervasive computing. Besides, they are constantly challenged by individual privacy protection necessities as the location information are stored and exchanged among entities and service providers. In this paper, we attempt to categorize location-centric pervasive applications based on the utility and flexibility on imposing privacy measures. Our first category of applications "Services based on location constraints" provide less options for privacy protection, while the second one "Location-centric statistical query services" allows more control of privacy on the clients' side. But once again giving away too much control to regulate priva.cy on the client side also undermines the quality and fidelity of the applications. We discuss some of the research issues of the privacy flexible framework for location-centric application, ,the costs incurred upon losing fidelity and wayouts to cope with them without compromising privacy in the first place. The framework introduces an interesting class of applications where users relish on the balance of location privacy protection and fidelity of the application.
p-Sensitivity: A Semantic Privacy-Protection Model for Location-based Services	Several methods have been proposed to support location-based services without revealing mobile users' privacy information. There are two types of privacy concerns in location-based services: location privacy and query privacy. Existing work, based on location k-anonymity, mainly focused on location privacy and are insufficient to protect query privacy. In particular, due to lack of semantics, location k-anonymity suffers from query homogeneity attack. In this paper, we introduce p-sensitivity, a novel privacy-protection model that considers query diversity and semantic information in anonymizing user locations. We propose a PE-tree for implementing the p-sensitivity model. Search algorithms and heuristics are developed to efficiently find the optimal p-sensitivity anonymization in the tree. Preliminary experiments show that p-sensitivity provides high-quality services without compromising users' query privacy.
Generating Virtual Users with Real Path Information to Improve Location Privacy	In this paper, we propose a system to ensure privacy for users of mobile location based services. The system is based on doubles i. e. are virtual users in the vicinity of the real user. In order to camouflage the identity of a user and its movements, we introduce changing zones based on mix zones which exploit the fuzziness of GPS location positioning. The doubles themselves have access to real movement data in order to provide a realistic view of their movements. Whenever the movement of users (no matter if real or double) crosses in a changing zone, new movement pieces, so-called stitches are generated and serve as bases for future movement data of other doubles. We also show a synopsis of a possible architecture and how system subcomponents could interact in order to obtain certain levels of privacy. The proposed system is also able to provide new movement information to doubles in a dynamic manner. In addition, we outline a plan on how to evaluate the system.
SPIRAL: A Scalable Private Information Retrieval Approach to Location Privacy	Protecting users' location information in location-based services, also termed location privacy, has recently garnered significant attention due to its importance in satisfying users' privacy concerns when using location-aware services. Several approaches proposed in the literature blur the user's location in a region by increasing its spatial extent or anonymizing the user among several other users. Such approaches in nature require users to communicate through a trusted anonymizer for all of their queries which can impose unrealistic overall communication/computation overhead between the server and the anonymizer for users with more stringent privacy requirements. We revisit the location privacy problem with the objective of providing significantly more stringent privacy guarantees and propose SPIRAL, a scalable private information retrieval approach to location privacy, which is to the best of our knowledge, the first approach to utilize practical private information retrieval (PIR) as a more fundamental approach to enable blind evaluation of range queries. We perform several experiments on real-world data to evaluate the effectiveness and the feasibility of our approach.
Privacy-Preserving Sharing of Sensitive Semantic Locations under Road-Network Constraints	This paper presents a privacy-preserving framework for the protection of sensitive positions in real time trajectories. We assume a scenario in which the sensitivity of user's positions is space-varying, and so depends on the spatial context, while the user's movement is confined to road networks and places. Typical users are the non-anonymous members of a geo-social network who agree to share their exact position whenever such position does not fall within a sensitive place, e.g. a hospital. Suspending location sharing while the user is inside a sensitive place is not an appropriate solution because the user's stopovers can be easily inferred from the user's trace. In this paper we present an extension of the semantic location cloaking model [1] originally developed for the cloaking of non-correlated positions in an unconstrained space. We investigate different algorithms for the generation of cloaked regions over the graph representing the urban setting. We also integrate methods to prevent velocity-based linkage attacks. Finally we evaluate experimentally the algorithms using a real data set.
Defending Location Privacy Using Zero Knowledge Proof Concept in Location Based Services	The increasing trend of embedding positioning capabilities (e.g., GPS) in mobile devices facilitates the widespread use of Location Based Services. For such applications to succeed, privacy and confidentiality are key issues. Over all privacy will have to be managed through a combination of technology, legislation, corporate policy, and social norms. There are many data privacy schemes including Zero Knowledge Proof (ZKP) those can be used for location privacy. ZKP is also useful for removing the bottleneck problem introduced by use of trusted third party. In the earlier work, authors proposed the concept of middleware architecture in which, request and response are not routed through middleware for every transaction. This has reduced the dependency on middleware. This paper presents correspondence between the authentication techniques used in above said architecture and zero knowledge proof technique. Use of the concept of zero knowledge proof for authentication and authorization in the domain of location based services is also explored.
Privacy-Preserving Data Management in Mobile Environments: A Partial Encryption Approach	With the growing demand for data-sensitive applications employing mobile devices, such as mobile clinics in remote villages and remote sensors collecting sensitive data, there is a need for a new architectural paradigm for mobile data management. Typically, these mobile devices have limited storage and processing capabilities, and operate in unreliable environments leading to possible loss of valuable data, if not properly managed. Often, the collected data is periodically offloaded to a remote server such as a cloud. However, such offloading may lead to violation of privacy if the network/server cannot be fully trusted. While encrypting the data prior to offloading appears to be a solution for this problem, this is computationally intensive and infeasible when mobile devices are employed. In this paper, we propose a partial-encryption scheme that takes into account both the privacy (confidentiality) constraints of the data being collected and the limitations of the mobile devices. The scheme employs vertical and horizontal fragmentation to determine those parts that need to be encrypted and those that can be sent in clear. The privacy constraints are represented in terms of a constraint graph and two-coloring problem solution is applied to identify the portions of the data that need to be encrypted. Any cycles in the constraint graph are handled using heuristics. The approach is effective in integrating unsecured wireless/internet with the untrusted yet cheap cloud storage servers, using the capacity-constrained mobile devices to manage sensitive data.
Towards a Safe Realization of Privacy-Preserving Data Publishing Mechanisms	This article addresses the issue of adapting the traditional model of Privacy-Preserving Data Publishing (PPDP) to an environment composed of a large number of tamper-resistant Secure Portable Tokens (SPTs) containing private personal data. Our model assumes that the SPTs seldom connect to a highly available but untrusted infrastructure. We illustrate the problem by studying the feasability of the simple generalization privacy mechanism to enforce k-anonymity.
Mobility, Data Mining and Privacy Understanding Human Movement Patterns from Trajectory Data	The technologies of mobile communications and ubiquitous computing pervade our society, and wireless net works sense the movement of people and vehicles, generating large volumes of mobility data. This is a scenario of great opportunities and risks. On one side, mining this data can produce useful knowledge. On the other side, individual privacy is at risk, as the mobility data contain sensitive personal information.
Effective Privacy-Preserving Online Route Planning	An online Route Planning Service (RPS) computes a route from one location to another. Current RPSs such as Google Maps require the use of precise locations. However, some users may not want to disclose their source and destination locations due to privacy concerns. An approach that supplies fake locations to an existing service incurs a substantial loss of quality of service, and the service may well return a result that may be not helpful to the user. We propose a solution that is able to return accurate route planning results when source and destination regions are used in order to achieve privacy. The solution re-uses a standard online RPS rather than replicate this functionality, and it needs no trusted third party. The solution is able to compute the exact results without leaking of the exact locations to the RPS or un-trusted parties. In addition, we provide heuristics that reduce the number of times that the RPS needs to be queried, and we also describe how the accuracy and privacy requirements can be relaxed to achieve better performance. An empirical study offers insight into key properties of the approach.
Integrating Identity, Location, and Absence Privacy in Context-Aware Retrieval of Points of Interest	The retrieval of close-by points of interest (POIs) is becoming a popular location-based service (LBS), often integrated with navigational services and geo-social networks. However, the access to POI services is prone to potentially serious privacy issues, since requests for POIs often include sensitive information like the user's location and her personal interests. Many techniques to enforce privacy in LBS have been proposed in the literature, in some cases focusing on anonymizing the requests and in others on obfuscating information in order to decrease its sensitivity. In many cases privacy protection comes at some cost in terms of service precision and performance. In this paper we propose a novel technique that combines the above cited approaches, overcomes some of their limitations in terms of assumptions on adversary knowledge, while still guaranteeing service precision. Our privacy solution has been integrated in an existing distributed system to share and retrieve POIs based not only on the user's current location but also on other (possibly sensitive) context data.
Ensuring Privacy and Security for LBS through Trajectory Partitioning	The concept of location k-anonymity has been proposed to address the privacy issue of location based services (LBS). Under this notion of anonymity, the adversary only has the knowledge that the LBS request originates from a region containing at least k people, and therefore cannot individually distinguish the requestor. However, new types of LBS services such as continuous nearest neighbor searches require the knowledge of the user's trajectory, which can lead to a privacy breach. The longer the adversary can track the user's trajectory, the stronger the possibility that the user's sensitive information is revealed. To alleviate this problem, we propose algorithms to optimally partition a continuous request into multiple LBS requests with shorter trajectories. This results in increased privacy due to the unlinking of different requests over time and has the added benefit of improving the overall quality of service since the anonymized regions are now smaller. Our experimental results show that significant privacy and QoS benefits can be achieved with nominal computational overhead.
Protecting Privacy in Location-Based Services Using K-Anonymity without Cloaked Region	The emerging location-detection devices together with ubiquitous connectivity have enabled a large variety of location-based services (LBS). Unfortunately, LBS may threaten the usersΓÇÖ privacy. K-anonymity cloaking the user location to K-anonymizing spatial region (K-ASR) has been extensively studied to protect privacy in LBS. Traditional K-anonymity method needs complex query processing algorithms at the server side. SpaceTwist [8] rectifies the above shortcoming of traditional K-anonymity since it only requires incremental nearest neighbor (INN) queries processing techniques at the server side. However, Space Twist may fail since it cannot guarantee K-anonymity. In this paper, our proposed framework, called KAWCR (K-anonymity Without Cloaked Region), rectifies the shortcomings and retains the advantages of the above two techniques. KAWCR only needs the server to process INN queries and can guarantee that the users issuing the query is indistinguishable from at least K-1 other users. The extensive experimental results show that the communication cost of KAWCR for kNN queries is lower than that of both traditional K-anonymity and SpaceTwist.
Pcube: A System to Evaluate and Test Privacy-Preserving Proximity Services	Proximity services are a particular class of location-based services (LBS) in which a subscriber is alerted when other participants (called buddies) are nearby. Existing works in the field of privacy preservation in LBS propose techniques specifically designed for this type of service. The objective of this demo is to present the Pcube system that makes it possible to visually show the different performances of these techniques in terms of privacy protection and precision of the service. The system includes a server component providing the proximity service, a web-based client application and a client application for mobile devices. Four different privacy-preserving techniques existing in literature have been implemented and will be compared during the demo, with a particular focus on the evaluation of the recently proposed Longitude protocol.
In-Device Spatial Cloaking for Mobile User Privacy Assisted by the Cloud	Spatial cloaking has been proposed and studied to protect mobile user privacy when using location based services (LBS). Traditional spatial cloaking methods are carried out by a trusted proxy known as location trusted server (LTS) to generate a region that contains at least k users for every request. The LTS is assumed to know the location of all users at all times, and perform the cloaking for all user requests. There are a number of disadvantages of relying on a single service for privacy preservation, including the scalability concern and the appropriate worry that this service ΓÇ£knows too muchΓÇ¥. To ameliorate this single-service problem, in-device spatial cloaking may be more desirable. However, the sticky problem is that the device does not know, at the time of the request, the locations of all other users, which are necessary to obtain an appropriate cloaked region. With cloud services, it may be appropriate to assume that user-density information is available from cloud servers. These servers may collect user location information for different regions, or may use sophisticated method to estimate user densities for different places. When a request needs to be anonymized, the device goes to the cloud to acquire appropriate user density information to perform spatial cloaking. In this operating environment, traditional spatial cloaking methods such as Casper [9] need to be modified in order to guarantee safety. This paper proposes and studies a new algorithm and reports performance evaluation of the new algorithm and its optimized version, aiming at provably safe cloaking with minimized communication cost. Experimental results show that the new algorithms work well in the realistic evaluation environment.
Privacy-Aware Location-Aided Routing in Mobile Ad Hoc Networks	Mobile Ad-hoc Networks (MANETs) enable users in physical proximity to each other to exchange data without the need for expensive communication infrastructures. Each user represents a node in the network, and executes a neighbor discovery Typically, nodes broadcast beacon messages that are received by other participants within the senderΓÇÖs communication range. Routing strategies are computed on-line based on the locations of nearby nodes, and geocasting is employed to deliver data packets to their destinations. However, mobile users may be reluctant to share their exact locations with other participants, since location can disclose private details about a personΓÇÖs lifestyle, religious or political affiliations, etc. A common approach to protect location privacy is to replace exact coordinates with coarser-grained regions, based on the privacy profile of each user. In this paper, we investigate protocols that support MANET routing without disclosing exact positions of nodes. Each node defines its own privacy profile, and reports a cloaked location information to its neighbors. We adopt a novel strategy to advertise beacons, to prevent inference of node locations. We also propose packet forwarding heuristics that rely on cloaking regions, rather than point locations. Our extensive experimental evaluation shows that the proposed routing scheme achieves low delays and high packet delivery ratios, without incurring significant overhead compared to conventional MANET routing protocols.
Protecting Location Privacy with Personalized k-Anonymity: Architecture and Algorithms	Continued advances in mobile networks and positioning technologies have created a strong market push for location-based applications. Examples include location-aware emergency response, location-based advertisement, and location-based entertainment. An important challenge in the wide deployment of location-based services (LBSs) is the privacy-aware management of location information, providing safeguards for location privacy of mobile clients against vulnerabilities for abuse. This paper describes a scalable architecture for protecting the location privacy from various privacy threats resulting from uncontrolled usage of LBSs. This architecture includes the development of a personalized location anonymization model and a suite of location perturbation algorithms. A unique characteristic of our location privacy architecture is the use of a flexible privacy personalization framework to support location k-anonymity for a wide range of mobile clients with context-sensitive privacy requirements. This framework enables each mobile client to specify the minimum level of anonymity that it desires and the maximum temporal and spatial tolerances that it is willing to accept when requesting k-anonymity-preserving LBSs. We devise an efficient message perturbation engine to implement the proposed location privacy framework. The prototype that we develop is designed to be run by the anonymity server on a trusted platform and performs location anonymization on LBS request messages of mobile clients such as identity removal and spatio-temporal cloaking of the location information. We study the effectiveness of our location cloaking algorithms under various conditions by using realistic location data that is synthetically generated from real road maps and traffic volume data. Our experiments show that the personalized location k-anonymity model, together with our location perturbation engine, can achieve high resilience to location privacy threats without introducing any significant- - performance penalty.
Verifiable Privacy-Preserving Sensor Network Storage for Range Query	We consider a hybrid two-tiered sensor network consisting of regular sensors and special sensors with large storage capacity, called storage nodes. In this structure, regular sensors "pushΓÇ¥ their raw data to nearby storage nodes and the sink diffuses queries only to storage nodes and "pullΓÇ¥ the reply from them. We investigate security and privacy threats when the sensor network is deployed in an untrusted or hostile environment. The major concern is that storage nodes might easily become the target for the adversary to compromise due to their important role. A compromised storage node may leak the data stored there to the adversary breaching the data privacy. Also, it may send wrong information as the reply to a query breaking the data integrity. This paper focuses on range query, a fundamental operation in a sensor network. The solution framework includes a privacy-preserving storage scheme which utilizes a bucketing technique to mix the data in a certain range, and a verifiable query protocol which employs encoding numbers to enable the sink to validate the reply. We further study the performance of event detection, an application implemented by range query. Our simulation results illustrate that our schemes are efficient for communication and effective for privacy and security protection.
Local Differential Perturbations: Location Privacy Under Approximate Knowledge Attackers	Location privacy research has received wide attention in the past few years owing to the growing popularity of location-based applications, and the skepticism thereof on the collection of location information. A large section of this research is directed towards mechanisms based on location obfuscation enforced using cloaking regions. The primary motivation for this engagement comes from the relatively well researched area of database privacy. Researchers in this sibling domain have indicated multiple times that any notion of privacy is incomplete without explicit statements on the capabilities of an adversary. As a result, we have started to see some efforts to categorize the various forms of background knowledge that an adversary may possess in the context of location privacy. Along this line, we consider some preliminary forms of attacker knowledge, and explore what implication does a certain form of knowledge has on location privacy. Continuing on, we extend our insights to a form of adversarial knowledge related to the geographic uncertainty that the adversary has in correctly locating a user. We empirically demonstrate that the use of cloaking regions can adversely impact the preservation of privacy in the presence of such approximate location knowledge, and demonstrate how perturbation based mechanisms can instead provide a well-balanced trade-off between privacy and service accuracy.
Toward Privacy Preserving and Collusion Resistance in a Location Proof Updating System	Today's location-sensitive service relies on user's mobile device to determine the current location. This allows malicious users to access a restricted resource or provide bogus alibis by cheating on their locations. To address this issue, we propose A Privacy-Preserving LocAtion proof Updating System (APPLAUS) in which colocated Bluetooth enabled mobile devices mutually generate location proofs and send updates to a location proof server. Periodically changed pseudonyms are used by the mobile devices to protect source location privacy from each other, and from the untrusted location proof server. We also develop user-centric location privacy model in which individual users evaluate their location privacy levels and decide whether and when to accept the location proof requests. In order to defend against colluding attacks, we also present betweenness ranking-based and correlation clustering-based approaches for outlier detection. APPLAUS can be implemented with existing network infrastructure, and can be easily deployed in Bluetooth enabled mobile devices with little computation or power cost. Extensive experimental results show that APPLAUS can effectively provide location proofs, significantly preserve the source location privacy, and effectively detect colluding attacks.
Enhancing Privacy and Accuracy in Probe Vehicle-Based Traffic Monitoring via Virtual Trip Lines	Traffic monitoring using probe vehicles with GPS receivers promises significant improvements in cost, coverage, and accuracy over dedicated infrastructure systems. Current approaches, however, raise privacy concerns because they require participants to reveal their positions to an external traffic monitoring server. To address this challenge, we describe a system based on virtual trip lines and an associated cloaking technique, followed by another system design in which we relax the privacy requirements to maximize the accuracy of real-time traffic estimation. We introduce virtual trip lines which are geographic markers that indicate where vehicles should provide speed updates. These markers are placed to avoid specific privacy sensitive locations. They also allow aggregating and cloaking several location updates based on trip line identifiers, without knowing the actual geographic locations of these trip lines. Thus, they facilitate the design of a distributed architecture, in which no single entity has a complete knowledge of probe identities and fine-grained location information. We have implemented the system with GPS smartphone clients and conducted a controlled experiment with 100 phone-equipped drivers circling a highway segment, which was later extended into a year-long public deployment.
pDCS: Security and Privacy Support for Data-Centric Sensor Networks	The demand for efficient data dissemination/access techniques to find relevant data from within a sensor network has led to the development of data-centric sensor (DCS) networks, where the sensor data instead of sensor nodes are named based on attributes such as event type or geographic location. However, saving data inside a network also creates security problems due to the lack of tamper resistance of the sensor nodes and the unattended nature of the sensor network. For example, an attacker may simply locate and compromise the node storing the event of his interest. To address these security problems, we present pDCS, a privacy-enhanced DCS network which offers different levels of data privacy based on different cryptographic keys. pDCS also includes an efficient key management scheme to facilitate the management of multiple types of keys used in the system. In addition, we propose several query optimization techniques based on Euclidean Steiner tree and keyed bloom filter (KBF) to minimize the query overhead while preserving query privacy. Finally, detailed analysis and simulations show that the KBF scheme can significantly reduce the message overhead with the same level of query delay and maintain a very high level of query privacy.
A Privacy-Preserving Location Monitoring System for Wireless Sensor Networks	Monitoring personal locations with a potentially untrusted server poses privacy threats to the monitored individuals. To this end, we propose a privacy-preserving location monitoring system for wireless sensor networks. In our system, we design two in-network location anonymization algorithms, namely, resource and quality-aware algorithms, that aim to enable the system to provide high-quality location monitoring services for system users, while preserving personal location privacy. Both algorithms rely on the well-established k-anonymity privacy concept, that is, a person is indistinguishable among k persons, to enable trusted sensor nodes to provide the aggregate location information of monitored persons for our system. Each aggregate location is in a form of a monitored area A along with the number of monitored persons residing in A, where A contains at least k persons. The resource-aware algorithm aims to minimize communication and computational cost, while the quality-aware algorithm aims to maximize the accuracy of the aggregate locations by minimizing their monitored areas. To utilize the aggregate location information to provide location monitoring services, we use a spatial histogram approach that estimates the distribution of the monitored persons based on the gathered aggregate location information. Then, the estimated distribution is used to provide location monitoring services through answering range queries. We evaluate our system through simulated experiments. The results show that our system provides high-quality location monitoring services for system users and guarantees the location privacy of the monitored persons.
A Flexible Privacy-Enhanced Location-Based Services System Framework and Practice	Location based services(LBS) are becoming increasingly important to the success and attractiveness of next generation wireless systems. However, a natural tension arises between the need for user privacy and the flexible use of location information. In this paper we present a framework to support privacy enhanced location based services. We classify the services according to several basic criteria and we propose a hierarchical key distribution method to support these services. The key idea behind the system is to hierarchically encrypt location information under different keys, and distribute the appropriate keys only to group members with the necessary permission. Four methods are proposed to deliver hierarchical location information while maintaining privacy. We propose a key tree rebalancing algorithm to maintain the re-keying performance of the group key management. Furthermore, we present a practical LBS system implementation. Hierarchical location information coding offers flexible location information access which enables a rich set of location based services. Our load tests show such a system is highly practical with good efficiency and scalability.
A Gen2-Based RFID Authentication Protocol for Security and Privacy	EPCglobal Class-1 Generation-2 specification (Gen2 in brief) has been approved as ISO18000-6C for global use, but the identity of tag (TID) is transmitted in plaintext which makes the tag traceable and clonable. Several solutions have been proposed based on traditional encryption methods, such as symmetric or asymmetric ciphers, but they are not suitable for low-cost RFID tags. Recently, some lightweight authentication protocols conforming to Gen2 have been proposed. However, the message flow of these protocols is different from Gen2. Existing readers may fail to read new tags. In this paper, we propose a novel authentication protocol based on Gen2, called Gen2<sup>+</sup>, for low-cost RFID tags. Our protocol follows every message flow in Gen2 to provide backward compatibility. Gen2<sup>+</sup> is a multiple round protocol using shared pseudonyms and Cyclic Redundancy Check (CRC) to achieve reader-to-tag authentication. Conversely, Gen2<sup>+</sup> uses the memory read command defined in Gen2 to achieve tag-to-reader authentication. We show that Gen2<sup>+</sup> is more secure under tracing and cloning attacks.
Investigating the Privacy vs. Forwarding Accuracy Tradeoff in Opportunistic Interest-Casting	Many mobile social networking applications are based on a "friend proximity detection" step, according to which two mobile users try to jointly estimate whether they have friends in common. Preserving privacy while performing "friend proximity detection" is fundamental to achieve widespread acceptance of mobile social networking applications. However, the need of privacy preservation is often at odds with application-level performance of the mobile social networking application, since only obfuscated information about the other user's profile is available for optimizing performance. In this paper, we study the fundamental tradeoff between privacy preservation and application-level performance in mobile social networks. We consider a mobile social networking application for opportunistic networks called interest-casting, where a user wants to deliver a piece of information to other users sharing similar interests ("friends"). In this paper, we propose a privacy-preserving friend proximity detection scheme based on a protocol for solving the Yao's "Millionaire's Problem", and we introduce three interest-casting protocols achieving different tradeoffs between privacy and accuracy of the information forwarding process. The privacy vs. accuracy tradeoff is analyzed both theoretically and through simulations. Our results demonstrate that privacy preservation is at odds with forwarding accuracy, and that the best tradeoff should be identified based on the application-level requirements.
Preserving Location Privacy in Geo-Social Applications	Using geo-social applications, such as FourSquare, millions of people interact with their surroundings through their friends and their recommendations. Without adequate privacy protection, however, these systems can be easily misused, e.g., to track users or target them for home invasion. In this paper, we introduce LocX, a novel alternative that provides significantly-improved location privacy without adding uncertainty into query results or relying on strong assumptions about server security. Our key insight is to apply secure user-specific, distance-preserving coordinate transformations to all location data shared with the server. The friends of a user share this user&amp;#8217;s secrets so they can apply the same transformation. This allows all location queries to be evaluated correctly by the server, but our privacy mechanisms guarantee that servers are unable to see or infer the actual location data from the transformed data or from the data access. We show that LocX provides privacy even against a powerful adversary model, and we use prototype measurements to show that it provides privacy with very little performance overhead, making it suitable for today's mobile devices.
Privacy-friendly Authentication in RFID Systems: On Sub-linear Protocols based on Symmetric-key Cryptography	In this paper, we provide a comprehensive analysis of privacy-friendly authentication protocols devoted to RFID that: (1) are based on well-established symmetric-key cryptographic building blocks; (2) require a reader complexity lower than O(N) where N is the number of provers in the system. These two properties are sine qua non conditions for deploying privacy-friendly authentication protocols in large-scale applications, e.g., access control in mass transportation. We describe existing protocols fulfilling these requirements and point out their drawbacks and weaknesses. We especially introduce attacks on CHT, CTI, YA-TRAP*, and the variant of OSK/AO with mutual authentication. We also raise that some protocols, such as O-RAP, O-FRAP and OSK/BF are not resistant to timing attacks. Finally, we select some candidates that are, according to our criteria, the most appropriate ones for practical uses.
Protecting Location Privacy in Sensor Networks against a Global Eavesdropper	While many protocols for sensor network security provide confidentiality for the content of messages, contextual information usually remains exposed. Such contextual information can be exploited by an adversary to derive sensitive information such as the locations of monitored objects and data sinks in the field. Attacks on these components can significantly undermine any network application. Existing techniques defend the leakage of location information from a limited adversary who can only observe network traffic in a small region. However, a stronger adversary, the global eavesdropper, is realistic and can defeat these existing techniques. This paper first formalizes the location privacy issues in sensor networks under this strong adversary model and computes a lower bound on the communication overhead needed for achieving a given level of location privacy. The paper then proposes two techniques to provide location privacy to monitored objects (source-location privacy)-periodic collection and source simulation-and two techniques to provide location privacy to data sinks (sink-location privacy)-sink simulation and backbone flooding. These techniques provide trade-offs between privacy, communication cost, and latency. Through analysis and simulation, we demonstrate that the proposed techniques are efficient and effective for source and sink-location privacy in sensor networks.
User-Controllable Security and Privacy for Pervasive Computing	We describe our current work in developing novel mechanisms for managing security and privacy in pervasive computing environments. More specifically, we have developed and evaluated three different applications, including a contextual instant messenger, a people finder application, and a phone-based application for access control. We also draw out some themes we have learned thus far for user-controllable security and privacy.
A Method Providing Identity Privacy to Mobile Users During Authentication	The increasing development of mobile networks raises new security requirements and concerns. In addition to the basic need of authentification, confidentiality and key distribution services, a new problem involving privacy is the unauthorized tracking of users migration. In other words, accessing any information related to the mobile user's location data without his consent, is a serious violation of his privacy. Moreover, if no care is taken, the disclosure of the mobile user real identity may appear during the authentication process. The basic solution to this problem is the usc of aliases which insure non-traceability by hiding the user's real identity and also his relationship with domain authorities. In this paper we provide a classification of the different degrees of non-traceability and present a new efficient method for the computation of aliases. This technique can be used during authentification of mobile users and thus avoids the drawbacks of existing solutions such as GSM and CDPD.
A method providing identity privacy to mobile users during authentication	The increasing development of mobile networks raises new security requirements and concerns. In addition to the basic need for authentication, confidentiality and key distribution services, a new problem involving privacy is the unauthorized tracking of users' migration. In other words, accessing any information related to the mobile user's location data without his consent, is a serious violation of his privacy. Moreover, if no care is taken, the disclosure of the mobile user's real identity may appear during the authentication process. The basic solution to this problem is the use of aliases which insure non-traceability by hiding the user's real identity and also his relationship with domain authorities. We provide a classification of the different degrees of non-traceability and present a new efficient method for the computation of aliases. This technique can be used during authentication of mobile users and thus avoids the drawbacks of existing solutions such as GSM and CDPD
Effectiveness of Privacy Assurance Approaches in Location-Based Services: A Study of India and the United States	The increasing commercial potential and rapid growth of location based services (LBS) have been accompanied by concerns over the collection and use of personal information by LBS providers. In this paper we study the influence of three privacy assurance approaches that might be used to ensure privacy in location-based services. With the usage context included as a covariate, we examine the influence of privacy assurance approaches in individualist and collectivist cultures. The results reveal how culture may moderate the effects of privacy assurance approaches on influencing users' privacy risk and information control perceptions. Implications for theory and practice are discussed.
The Impact of Perceived Emergency and Essentiality on Perceived Privacy Risk, Privacy Concern and Intention to Use in Mobile LBS Environment: An Example of China Mobile and Unicom	With the popularization of mobile devices and the rapidly development of LBS, users concern on privacy aroused by services depending on personal location information needed. To strengthen the current research in LBS, combine time management theory and rational choice theory, this paper aims to explore the effect of situational antecedent factors-perceived emergency and perceived essentiality on perceived privacy risk, privacy concern and intention to use. The experimental study was conducted and the findings indicate that perception of emergency and essentiality of a Website characteristics have positive effect on intention to use not but on perceived privacy risk and privacy concern. Privacy concern has significant negative effect on intention to use. However, does not consistent with prior literature, the perceived privacy risk has significant direct effect on privacy concern not but on intention to use.
Security, Privacy and Legal Issues in Pervasive eHealth Monitoring Systems	In this paper we analyze the security and privacy requirements of eHealth monitoring systems which use wireless sensor networks. Based on our experience developing our eHealth system, ReMoteCare, we have devised a model of such systems which we use to discuss threats and attacks, address security requirements and give guidelines for security mechanisms. The contentious issues of privacy of medical data are canvassed - especially as there are legal ramifications if personal health information is compromised.
Privacy, Value and Control Issues in Four Mobile Business Applications	This paper presents four case studies that explore the adoption and acceptance of mobile technologies and services within the context of the privacy-value-control (PVC) trichotomy. The technologies studied include: the mobile phone, electronic toll payment tags, e-passports, and loyalty card programs. The study shows that despite the potential barriers to adoption in each of the depicted cases, the applications were embraced with great success soon after their introduction. An understanding of why these mobile innovations succeeded in spite of the concerns surrounding them will serve to help practitioners understand other issues currently plaguing emerging technologies like radio-frequency identification (RFID) tags and transponders. The contribution of this paper is not only in its usage of secondary sources to support case development and subsequent cross-case analysis but on the importance of emphasizing the value proposition to the consumer to ensure the success of an innovation. The PVC trichotomy emphasizes the need to harmonize privacy, value and control.
Location Privacy-An Overview	Location-based services (LBS) are mobile services which evaluate knowledge about a user's location. In most cases this is done to provide the user with personalized information, e.g. to list point of interests in his nearer surrounding. But users have concerns when their whereabouts are tracked and their location information is disclosedto external service providers. So it is no wonder that a lot of publications deal with the specific privacy issues of LBS usage. The aim of this article is to give an overview about the most relevant works in this field: we first discuss different attack scenarios where location information is misused. Afterwards we present a classification of technical approaches to prevent such misuse of location information. We also summarize some results from pertinent empirical studies.
Personality Traits and Privacy Perceptions: An Empirical Study in the Context of Location-Based Services	Location-based services (LBS) are services that take into account the geographic location of a user. While LBS promise efficiency and effectiveness gains, their use also raises fundamental privacy issues. In this study we propose the development of a theoretical model for examining the role of personality traits in perceptions of privacy in reference to LBS. More specifically, we will develop a model that incorporates the Big Five personality traits (agreeableness, extraversion, emotional stability, openness to experience, conscientiousness), the most widely accepted framework for personality research in psychology, as well as perceptions of privacy, usefulness, risk, and trust as mediators in our model to explain behavioral intentions towards adopting LBS. We empirically test our model using a survey-based approach sampling 470 undergraduate business students.
Charged location aware services - a privacy analysis	In this paper we investigate privacy issues in location based services (LBS). We first introduce the components needed to realize such a service. Then we discuss design issues of the components as well as of the overall architecture. We also provide cross check of our own system for charged LBS against the design issues presented in this paper.
A framework of privacy shield in organizational information systems	Preserving privacy and the protection of personally identifiable information (PH) has been of increasing interest over the last few years. Many privacy advocates, and a significant portion of the general public, feared that the new initiatives used in an attempt to fight terrorism, would have a serious impact on an individual's right and ability to protect their privacy. This paper proposes a new framework for preserving privacy for individuals along with the protection of personally identifiable information. We have termed it privacy shield. Through the application of anonymity and privacy principles in design, the privacy protecting separation of data, the use of public key infrastructure, and the application of our information system Hippocratic policies, we provide a framework of privacy shield to protect an information system user's personal data.
A Framework for Adapting Services' Design and Execution to Privacy Regulations	The potential impact of contemporary Information and Communication Technologies on users' privacy rights is regarded as being among their most evident negative effects. In fact, the recent advances in mobile communications, location and sensing technologies as well as data processing, are boosting the deployment of context-aware personalized services and the creation of smart environments, but at the same time, they pose a serious risk on individuals' privacy rights. In order to address this issue, this paper provides a framework for settling the services privacy friendly. The presented approach focuses on specifying a methodology for adapting services to operate on top of a middleware system that incorporates and thus, enforces the privacy regulations, preventing to a great extent the disclosure of personal data to the service providers even if personal data is collected and services are used through pervasive, ubiquitous and wireless devices.
P-DIBS: Pseudonymised DIstributed Billing System for Improved Privacy Protection	The deployment of payment systems protective of the customer privacy is an hard challenge. Accountability and payment seem to require a direct link to the customer credentials (e.g. his credit card number or bank account), this exposes the user to be profiled on his habits. Static and uniquely identified mappings to user credentials, hold by a trusted third party, may vanish all the parallel anonymization/pseudonymisation efforts done to avoid disclosure of the user identity to the provider of the service. This paper proposes P-DIBS (pseudonymised distributed billing system), a billing framework devised to protect user privacy. P-DIBS is developed as an extension of a previously proposed pseudonymization mechanism. It relies on an intermediate brokerage entity, referred to as "Accounting Server", operating between the bank and the service provider on behalf of the end user, yet having no knowledge neither about his real identity nor about his real account number. A fundamental novelty of the proposed approach is the possibility, through a distributed procedure involving mutual interaction across the various system components, to guarantee linkability upon improper user behavior (e.g. misuses) without requiring a single trusted third party in the system to possess all the knowledge necessary to disclose the user.
Privacy Challenges in Context-sensitive Access Control for Pervasive Computing Environment	The widespread prevalence of pervasive devices and applications has raised the concerns of privacy. Granting Access to Resources and Context sensitive information causes information leakage through inference or obfuscation. Again, the open and dynamic collaborative environment of pervasive computing has rendered the traditional access control models like Role based models to be unfit. Even though Trust based models came to rescue in such circumstances, privacy is mostly compromised in the big picture. In this paper, we have drawn examples from pervasive computing environment and illustrated some scenarios of privacy violation. We have presented a trust based access control model for pervasive healthcare environment to prevent information leakage on accessing constraint information that yields privacy violation in the end. We have addressed information leak from three perspectives of constraint information satisfaction to grant access to the resources. They are satisfy any, satisfy all and hierarchical constraints. Furthermore, the model eliminates requirements for maintaining any keys or access rights certificates for privacy protection. This lightweight model helps ensure the resource constrained small pervasive devices like PDA, cell phones use the access control model effectively and efficiently with privacy of the individuals preserved in the first place.
Privacy-Preserving Detection of Sybil Attacks in Vehicular Ad Hoc Networks	Vehicular ad hoc networks (VANETs) are being advocated for traffic control, accident avoidance, and a variety of other applications. Security is an important concern in VANETs because a malicious user may deliberately mislead other vehicles and vehicular agencies. One type of malicious behavior is called a Sybil attack, wherein a malicious vehicle pretends to be multiple other vehicles. Reported data from a Sybil attacker will appear to arrive from a large number of distinct vehicles, and hence will be credible. This paper proposes a light-weight and scalable framework to detect Sybil attacks. Importantly, the proposed scheme does not require any vehicle in the network to disclose its identity, hence privacy is preserved at all times. Simulation results demonstrate the efficacy of our protocol.
Privacy Infusion in Ubiquitous Computing	In recent years, ubiquitous computing applications span such areas as telemedicine, banking, and transportation that require user privacy protection. The realization of context-aware ubiquitous computing exasperates existing privacy concerns. Ubiquitous computing applications demand new privacy enhancing technologies for the information and communication environments where the users are equipped with flexible and portable applications to support the capture, communication, recall, organization and reuse of diverse information. In this paper, we develop a novel scheme for the infusion of privacy into context-aware ubiquitous computing. We present Precision, a system for privacy enhanced context-aware information fusion in ubiquitous computing environments. In our scheme, privacy is defined as a set of parameters encapsulated in composite data entities called privons, through which, we aim at infusing privacy into Precision. We evaluate our proposed scheme through real interactions in implementation of privons.
Location Privacy of Users in Location-based Services	In this paper, we introduce location traceability as an indicator for evaluating time-series location privacy for users on location-based services (LBS). The location traceability of a user is calculated with a formalized tree structure that represents all possible paths of a moving user. Through the results of the simulation experiments, we validated the effectiveness of this proposed indicator
Bridging the Gap between Privacy and Security in Multi-Domain Federations with Identity Tokens	In this paper we introduce the concept of identity tokens in multi-domain service environments and show how it is used to bridge between authentication/authorization and users' privacy. This token provides, together with further authentication and authorization techniques, a high level of privacy without anonymity
Bridging the Gap between Privacy and Security in Multi-Domain Federations with Identity Tokens	In this paper we introduce the concept of identity tokens in multi-domain service environments and show how it is used to bridge between authentication/authorization and users' privacy. This token provides, together with further authentication and authorization techniques, a high level of privacy without anonymity
Location Privacy of Users in Location-based Services	In this paper, we introduce location traceability as an indicator for evaluating time-series location privacy for users on location-based services (LBS). The location traceability of a user is calculated with a formalized free structure that represents all possible paths of a moving user. Through the results of the simulation experiments, we validated the effectiveness of this proposed indicator
Providing source privacy in mobile ad hoc networks	Communication privacy is becoming an essential security requirement for mission critical communications and communication infrastructure protection. This is especially true for mobile ad hoc networks (MANETs) due to mobility of the communication nodes and the nature of wireless communications. Existing research in privacy-preserving communications can largely be divided into two categories: cryptosystem-based techniques and broadcasting-based techniques. The cryptosystem-based techniques include mix-based systems and secure multiparty computation-based systems, originating from mixnet and DC-net respectively. All mix-based approaches require a trusted third party to provide the mix and are not quite feasible in MANET. However, DC-net based approaches suffer from transmission collision problem that cannot be easily resolved practically. Broadcasting based schemes provide communication privacy by mixing the real messages with dummy packets so that it is infeasible for the adversaries to identify the real packets and track the message source. However, the transmission of dummy messages not only increases the energy consumption significantly, but also increases the network collisions and decreases the packet delivery ratio. In this paper, we first propose a novel unconditionally secure source anonymous message authentication scheme (SAMAS) that enables messages to be released without relying on any trusted third parties. While providing source privacy, the proposed scheme can also provide message content authenticity. We then propose a novel communication protocol for MANET that can ensure communication privacy of both communication parties and their end-to-end routing. The proposed protocol can be used for critical infrastructure protection and secure file sharing. The security analysis demonstrates that the proposed protocol is secure against various attacks. The theoretical analysis and simulation show that the proposed scheme is efficient and can ensure high message- delivery ratio.
Measuring location privacy in V2X communication systems with accumulated information	Vehicle-to-vehicle/vehicle-to-infrastructure (V2X) communication systems are envisioned to greatly improve road safety, traffic efficiency, and driver convenience. However, many V2X applications rely on continuous and detailed location information, which raises location privacy concerns. A multitude of privacy-protection mechanisms have been proposed in recent years. However, few efforts have been made to develop privacy metrics, which can provide a rigorous way to assess the privacy risk, evaluate the effectiveness of a given mechanism, and exploit the full possibilities of protection methods in V2X systems. Therefore, in this paper we present a trip-based location privacy metric for measuring user location privacy in V2X systems. The most distinguishable aspect of the metric is to take into account the accumulated information, which is the privacy-related information acquired by an adversary for an extended period of time, e.g., days or weeks. We develop methods to model and process the accumulated information, and reflect the impact on the privacy level in the metric. We further prove the viability and correctness of the metric by various case studies. Our simulations find out that under certain conditions, accumulated information can significantly decrease the level of user location privacy. The metric and our findings in this paper give some valuable insights into location privacy, which can contribute to the development of effective privacy-protection mechanisms for the users of V2X systems.
A low-frequency RFID to challenge security and privacy concerns	This paper presents a practical realization of a secure passive (battery-less) RFID tag. The tag consists of an off the shelf front end combined with a bespoke 0.18 mum ASIC assembled as a credit card sized prototype. The ASIC integrates the authors' ultra low power novel AES design together with a novel random number generator and a novel protocol which provides both security and privacy. The analysis presented shows a security of 64-bits against many attack methods. Both modeled and measured power results are presented. The measured average core power consumed during continuous normal operation is 1.36 muW.
Detecting privacy infractions in applications: A framework and methodology	We describe a framework and methodology for managing the privacy policy of an enterprise, including creation (based on factors like legislation and consumer preferences), validation and verification, deployment and enforcement, and compliance testing for business processes and software. To evaluate this approach, one module of our framework (compliance testing) is implemented for an existing prominent electronic commerce software application. Our unique approach monitors the personal information sent and received by the software application and converts it to a standardized representation. At defined points in the electronic commerce workflow, the transmissions are compared to a set of privacy rules (extracted from a privacy policy) to ascertain compliance. Non-compliant transmissions of personal information are labeled `potential privacy infractions' and are reported. Though presently implemented for software testing, ultimately the methodology is intended to halt or alter a workflow to avoid privacy infractions.
VIPER: A vehicle-to-infrastructure communication privacy enforcement protocol	Privacy-related issues are crucial for the wide diffusion of Vehicular Communications (VC). In particular, traffic analysis is one of the subtler threats to privacy in VC. In this paper we first briefly review current work in literature addressing privacy issues. Then we present VIPER: a Vehicle-to-infrastructure communication Privacy Enforcement pRotocol. VIPER is inspired to solutions provided for the Internet -mix- and cryptography-universal re- encryption. The protocol is shown to be resilient to traffic analysis attacks and analytical results suggest that it also performs well with respect to two key performance indicators: queue occupancy and message delivery time. Finally, simulation results support our analytical findings.
Improved mechanism for mobile location privacy	Location-based services are using information about where a mobile device is located. Such services bring convenience to mobile user but also provide criminals with powerful weapons to compromise the privacy of mobile user. To address the location privacy issue, much architecture for location privacy control was presented and experimented. Qi He proposed a special and feasible architecture, using blind signature to generate an authorized anonymous ID that replaces the real ID of a legitimate mobile device. The original purpose of Qi's architecture is that eliminating the relationship of authorized anonymous ID and real ID. Unfortunately we prove that Qi's registration protocol did not indeed delete the linkability of authorized anonymous ID and real ID. Furthermore we propose an improved registration protocol adapted the same cryptographic technique based on bilinear pairings. Moreover we demonstrate that the administrator can learn no information on the legitimate user's authorized anonymous ID and real ID
Enhancing wireless communication privacy with artificial fading	This paper addresses the problem of anti-eavesdropping in wireless network physical layer. The main contribution of this paper is twofold. First, we propose a novel concept of artificial fading that is produced by double-beam switching of smart antenna array to intentionally corrupt unwanted wireless communication links. Second, we develop a physical layer anti-eavesdropping scheme to minimize the unnecessary coverage area, and hence, lower the chance of being eavesdropped. Our anti-eavesdropping scheme employs smart antenna with two synthesized radiation patterns, which are optimized to provide good signal quality to the intended receiver, while their overlap apart from the intended direction is minimized. During the transmission, the transmitter periodically alternates between the two optimized patterns at a high frequency, which produces severe fading to the received signal in undesired directions. Since such signals are corrupted and cannot be decoded, eavesdropping is prevented. Simulation experiments show that our anti-eavesdropping scheme outperforms single pattern beamforming in reducing the unnecessary coverage area exposed to eavesdroppers.
Credit routing for source-location privacy protection in wireless sensor networks	Source-location privacy became one of major issues due to the open nature of wireless sensor networks. The adversary can eavesdrop and trace the message movements so as to capture the source. In the paper, first we propose Credit routing to provide the source-location privacy protection. Credit routing is able to route the message within the assigned credit at each message and randomize the routing path. Unlike other location privacy protection schemes in WSN, Credit routing not only can provide strong protection but also precisely control the transmission cost of each message. Then, we propose Hybrid credit routing, which routes the message to the receiver through three phases: totally random walk, forwarding random walk and credit random walk. These phases provide tri-fold protection to prevent the source from being captured by the adversary. We evaluate our proposed schemes based on several metrics including safe period, latency and protection efficiency. The simulation results show that Credit is able to provide the strong and efficient protection compared with other schemes including Phantom, LPR and RRIN. It is also shown Hybrid improves the protection strength and efficiency even further. The performance of Credit and Hybrid can be tuned by the assigned credit. For real application, the credit can be the real power consumption for forwarding the message from the source to the sink. So both Credit and Hybrid can be used to precisely control the power consumption for source-location protection.
Collaborative Location Privacy	Location-aware smart phones support various location-based services (LBSs): users query the LBS server and learn on the fly about their surroundings. However, such queries give away private information, enabling the LBS to identify and track users. We address this problem by proposing the first, to the best of our knowledge, user-collaborative privacy preserving approach for LBSs. Our solution, MobiCrowd, is simple to implement, it does not require changing the LBS server architecture, and it does not assume third party privacy-protection servers; still, MobiCrowd significantly improves user location-privacy. The gain stems from the collaboration of MobiCrowd-ready mobile devices: they keep their context information in a buffer, until it expires, and they pass it to other users seeking such information. Essentially, the LBS does not need to be contacted unless all the collaborative peers in the vicinity lack the sought information. Hence, the user can remain hidden from the server, unless it absolutely needs to expose herself through a query. Our results show that MobiCrowd hides a high fraction of location-based queries, thus significantly enhancing user location-privacy. To study the effects of various parameters, such as the collaboration level and contact rate between mobile users, we develop an epidemic model. Our simulations with real mobility datasets corroborate our model-based findings. Finally, our implementation of MobiCrowd on Nokia platforms indicates that it is lightweight and the collaboration cost is negligible.
Content-Aware Data Dissemination for Enhancing Privacy and Availability in Wireless Sensor Networks	Wireless sensor networks are vulnerable to various attacks and network dynamics that can breach data privacy and harm data availability. Since those threats cannot be addressed purely by cryptography-based methods, this paper presents a data dissemination scheme that can enhance two goals: data privacy and data availability, leveraging the node location diversity presented in typical wireless sensor networks rather than relying on cryptographic techniques. We demonstrate that the message content is important to quantify the uncertainty associated with data privacy and data availability, and provide content-based definitions utilizing information states. Further, to strike the balance between two conflicting goals in an energy efficient way, we construct a spatial privacy graph based on the locations of network nodes, and use a distributed coloring scheme to ensure that any pairs of nodes whose combined data provide too much information should not send their sensed data to the same storage node. Additionally, sensor nodes selectively send data to multiple storage nodes to achieve higher availability. Our experimental results show that our scheme can achieve better data privacy and a higher level of data availability at smaller energy cost than other baseline data dissemination schemes.
Privacy-Preserving Collaborative Path Hiding for Participatory Sensing Applications	The presence of multimodal sensors on current mobile phones enables a broad range of novel mobile applications including, e.g., monitoring noise pollution or traffic and road conditions in urban environments. Data of unprecedented quantity and quality can be collected and reported by a possible user base of billions of mobile phone subscribers worldwide. The collection of detailed sensor and location data may however compromise user privacy. In this paper, we present a decentralized mechanism to preserve location privacy during the collection of sensor readings. As most sensor readings are geotagged, we propose to exchange them between users in physical proximity in order to jumble the paths followed by the users. We evaluate different strategies to exchange and report the sensor readings to the application using real-world GPS traces of mobile users. The results demonstrate the feasibility and efficacy of our proposed scheme, which can obfuscate up to 100% of the visited locations in the best instances.
Privacy aware localization in VANET	Positioning or tracking in VANET is currently based on GPS. However, GPS is known to be prone to failure in case of emergencies. In addition, the current market penetration rate of GPS devices is low. Vehicles with built-in cellular communication capability are expected to be a part of the near future. Therefore, it is reasonable to assume that any vehicle possesses the functionality of a mobile unit (MU). The principal contribution of this paper is the proposed novel concept that employs the existing cellular RSS measurements as the basis for position estimation in VANET in situations where GPS services are unavailable. The proposed localization technique involves sampling the signal beacons received from three base stations surrounding the mobile unit for a very small time duration. Each of the RSS samples are then mapped to a sample of distance estimates based on shadowing radio propagation model. The medians of the generated distance sets are then used by a state of the art technique to produce a final location estimate. One of the important contributions of this work is justifying the selection of median over mean. An extremely small sampling duration negates the impact of mobile unit movement while the median selection neutralizes the deviation caused by time varying radio channel characteristics. All computation is restricted to mobile unit, thereby ensuring privacy. Simulation results demonstrate the efficiency of the proposed algorithm.
Enhanced Location Privacy Protection of Base Station in Wireless Sensor Networks	Location privacy in wireless sensor networks has gained a wide concern. Particularly, the location privacy of base station requires ultimate protection due to its crucial position in wireless sensor networks. In this paper, we propose an efficient scheme, consisting of anonymous topology discovery and intelligent fake packet injection (IFPI), to protect the location privacy of base station. Anonymous topology discovery eliminates the potential threats against base station within topology discovery period. On the other hand, IFPI enhances privacy protection strength during data transmission period. Under given conditions, comprehensive simulations demonstrate that our scheme significantly improves privacy strength compared with existing strategies.
On-Demand Anonymous Routing with Distance Vector Protecting Traffic Privacy in Wireless Multi-hop Networks	Because of easy accessible medium in wireless networks, use of these wireless networks in military applications poses several security issues. Likewise, in the business field, despite the emerging static wireless Internet access, the same security issues remains. On example is the passive attack in which attackers attempt to overhear network communications from the outside. Confidentiality can be further divided into two categories, namely, data confidentiality and traffic confidentiality. In this paper, for improving traffic confidentiality, we propose two anonymous routing algorithms, called randomized routing algorithm and probabilistic penalty-based routing algorithm. Both algorithms aim to differentiate routing paths to the same destination enhancing anonymity of the network traffic. We provide simulation results and demonstrate how much these two algorithm disperse routing paths in a network.
Location Privacy with Road Network Mix-Zones	Mix-zones are recognized as an alternative and complementary approach to spatial cloaking based approach to location privacy protection. Mix-zones break the continuity of location exposure by ensuring that users' movements cannot be traced while they reside in a mix-zone. In this paper we provide an overview of various known attacks that make mix-zones on road networks vulnerable and illustrate a set of counter measures to make road network mix-zones attack resilient. Concretely, we categorize the vulnerabilities of road network mix-zones into two classes: one due to the road network characteristics and user mobility, and the other due to the temporal, spatial and semantic correlations of location queries. For instance, the timing information of users' entry and exit into a mix-zone provides information to launch a timing attack. The non-uniformity in the transitions taken at the road intersection may lead to transition attack. An example query correlation attack is the basic continual query (CQ) attacks, which attempt to break the anonymity of road network aware mix-zones by performing query correlation based inference. The CQ-timing attacks carry out inference attacks based on both query correlation and timing correlation, and the CQ-transition attacks execute inference attacks based on both query correlation and transition correlation. We study the factors that impact on the effectiveness of each of these attacks and evaluate the efficiency of the counter measures, such as non-rectangle mix-zones and delay tolerant mix-zones, through extensive experiments on traces produced by GTMobiSim at different scales of geographic maps.
The role of perceived privacy and perceived security in online market	Individuals mostly hesitate to use services offered via Internet due to their suspicions regarding the level of offered (1) protection of their privacy and (2) security of performing online transactions. Privacy is mostly concerned with the identifiable user data and users' rights to have control over their data. On the other hand, security provides the physical, logical, and procedural safeguards that are needed to keep the data private. Privacy cannot be achieved without obtaining security practice, nor will the usage of security mechanisms guarantee protection of privacy. Despite being closely linked in practice, privacy and security are perceived as separate issues by online users. Therefore, in this article the relationship between various privacy factors (factors that influence users' privacy concerns) and the perception of security protection during users' online activities is discussed. The role that perceived privacy and perceived security have in the e-service users' evaluation of a service is investigated.
Privacy preserving OLAP: Models, issues, algorithms	The problem of computing privacy preserving OLAP data cubes is gaining momentum in the Data Mining and Warehousing research community, due to the large spectrum of application scenarios where OLAP and, under a larger vision, Business Intelligence (BI) are exploited successfully. Following this emerging trend, several privacy preserving OLAP techniques have been proposed recently, with alternate fortune. This research proposes an excerpt of two significant state-of-the-art contributions in the contexts of centralized and distributed privacy preserving OLAP research, by providing several case studies showing challenges and achievements of these contributions, along with directions for future efforts in these fields.
Students and privacy in the networked environment	The continuing adoption of new emerging technologies is not only changing the educational environment but also raises concerns in terms of students' digital media literacy and their sense of privacy in online environments. Despite the widespread agreement of its importance the lack of formal training in information and media literacy across the curriculum actually forces students to acquire necessary skills through informal learning. This lack of systematic education potentially leads to differences in student competencies. Authors present the results of the study on students' attitude towards information privacy their private online environment (inside their chosen social network), as well as their professional environment (inside their e-learning system). The research was conducted in December of 2010 where a total of 397 students from the Faculty of Humanities and Social Sciences (FHSS) at the University of Zagreb and Accredited College of Business and Management "Baltazar Adam Krc╠îelic╠ü" (ACBM) responded to an online survey. The results showed significant differences between the samples, where the students from FHSS were more aware of the importance of protecting their private data inside their social network, as well as inside their educational environment. The study confirmed the original assumption that the lack of formal guidance through student education resulted in significant differences between the students.
The influence of users' attitudes regarding trust, privacy and control on the adoption of mobile advertising	The mobile device (cellular phone, smartphone, PDA phone) is considered as a primary personal mass media channel that, from the marketing perspective, considerably differs from traditional media like television and the press. For most users, the mobile device is an interactive channel that is always open to receive messages, is carried almost everywhere with the user, and receives their considerable attention regarding incoming messages. The main research goal of this paper was to investigate the potential of the mobile medium as a marketing channel with the focus on the use of the Short Message Service (SMS). A synthesis of recent research on the adoption of mobile and SMS marketing was performed to develop a theoretical model that is presented in the paper, along with the results of an empirical evaluation of this model on a group of 129 college students. The theoretical model was used to create a comprehensive survey that was applied before and after a two-week SMS marketing campaign among the subjects in our study. The data collected in the survey was analyzed with factor analysis, regression analysis, and structural equation modeling (SEM). Finally, an empirically tested model is proposed that is based on the impact of users' attitudes regarding trust, privacy and control on the adoption of SMS/mobile advertising.
Managing base station location privacy	Many of today's location services map locations of wireless base stations and use them to localize mobile devices. Severe security and privacy risks exist when unauthorized third-party location services are able to localize mobile devices. In this work we examine a software module that helps network operators to prevent third parties from aggregating wireless base station identifiers by making the identifiers dynamic. This software operates in the infrastructure and does not require any changes of handsets nor any modification of air interface standards. We also examine another software module that provides authorized mobile devices with the ability to locate themselves at different accuracy levels depending on their permission levels. This module operates in the infrastructure with any air interface and does not require standardization. We analyze the effect of the proposed modules on malicious third-party location services, examine their performance, and analyze potential location service countermeasures.
Multi-node coordinated jamming for location privacy protection	In wireless sensor networks, adversaries can easily threaten the location privacy of sensor nodes using ordinary localization techniques. By collecting basic physical layer information, such as signal strength and time of arrival, adversaries can precisely locate the target nodes. Although basic anti-localization techniques based on power control and directional antennas are believed to mitigate such localization attacks in the radio physical layer, there has been little research on location privacy protection techniques by obfuscating physical layer information. In this paper, we propose a novel jamming technique that prevents adversaries from locating target nodes by mixing the jamming signal from neighboring nodes. We introduce this beneficial use of jamming technique, which uses single- or multiple- jammers, to improve location privacy while providing similar link throughputs. In addition, we introduce the Multi Cooperator Power Control (MCPC) algorithm to control jamming noise power, which further increases location privacy by actively controlling the strength of jamming noise.
Achieving configural location privacy in location based routing for MANET	Research shows that location based routing can improve the performance and efficiency of communication in mobile ad hoc networks. From another point of view, disclosure of location information can cause a serious privacy risk, especially in environments where different groups of nodes cannot fully trust each other. In this paper, we propose a protocol through which a wireless node can achieve configurable location privacy by distributing location information with different levels of perturbations to different groups of nodes. To achieve this goal, polynomial based personal keys are deployed for group based location information access. A modified location based routing protocol with privacy awareness features is introduced. Authentication mechanisms are designed to protect the genuineness of location information and prevent impersonation attacks. The efficiency and safety of the proposed approach are investigated.
Achieving Physical Layer Security / Privacy with Self-Wrapped OCDM Transmission	We present a novel transmission system using self-wrapped WHTS OCDM signals to achieve enhanced transmission security. Distributed key is encoded and time-spread to hide under noise in the network. BER of 10<sup>-4</sup> is demonstrated experimentally.
PPBR: Privacy-Aware Position-Based Routing in Mobile Ad Hoc Networks	Position-based routing for Mobile Ad-Hoc Networks is a promising approach to reduce route overhead by using the location information of each node. However, in most of the previously reported position-based routing protocols, a node has to periodically broadcast its current position coordinates and identifiers to its one-hop neighbors. Such information could be easily eavesdropped on by an adversary if it is not protected, and consequently, location privacy would be violated. In this paper, we propose a novel privacy-aware position-based routing protocol (PPBR), in which a node takes dynamic pseudo identifiers instead of its real identity in advertising its position. Furthermore, PPBR provides end-to-end anonymity to any intermediate nodes along the route. The theoretical analysis shows that the probability of tracking a node under PPBR through traffic analysis would be very small. We compare the performance of PPBR with that by GPSR and AODV through extensive simulation, which demonstrates the effectiveness and efficiency of the proposed scheme. We also show that frequent update of the pseudo identifier of each node yields an insignificant impact on routing performance and overhead.
An ID-based Framework Achieving Privacy and Non-Repudiation in Vehicular Ad Hoc Networks	Security requirements should be integrated into the design of vehicular ad hoc networks (VANETs), which bear unique features like road-safety and life-critical message dissemination. In this paper, we propose a security framework for VANETs to achieve privacy desired by vehicles and non-repudiation required by authorities, in addition to satisfying fundamental security requirements including authentication, message integrity and confidentiality. The proposed framework employs an ID-based cryptosystem where certificates are not needed for authentication. It increases the communication efficiency for VANET applications where the real-time constraint on message delivery should be guaranteed. We also briefly review the requirements for VANET security and verify the fulfillment of our proposed framework against these requirements.
A Privacy-preserving Lightweight Authentication Protocol for Low-Cost RFID Tags	Radio frequency identification (RFID) is an emerging technology for automatic object identification. For successful deployment of tags, a RFID system should provide effective protection over security and privacy. In particular, traceability is the main concern for user privacy. To address these issues, mutual authentication between the reader and tags is required when deploying a RFID system. Unfortunately, because low-cost RFID tags are highly resource constrained, they are not able to carry out expensive cryptographic primitives to achieve strong authentication. This paper introduces a lightweight authentication protocol for low-cost RFID tags. Compared with previous work, our solution provides better traceability protection while keeping the system efficient in terms of computation and communication. Our scheme also maintains comparable strength regarding other security aspects.
Mobile phones as traffic sensors with map matching and privacy considerations	In the recent years, it has become readily more accepted that smart mobile phones with GPS or A-GPS enabled device, or even Cell-ID enabled, among the commuters, can be used as traffic sensor, which complements other traditional sensors. This development is pursued in the efforts of reducing or avoiding traffic jams. Consequently, this paper attempts to find a novel way to map match 2D local map with actual GPS traces from mobile phones. From a number of experiments, it has been found that Virtual Detection Zone method can be used to obtain 100% map matching, as it ensures matching by comparing the GPS data to a set of pre-determined check points (circular VDZ, preferably with a radius of 50-185m). Furthermore, from this study, it is proposed to increase privacy, firstly by using OTP to doubly-lock the sensor's data. Secondly, by ensuring that valid data is only delivered from a significant distance of the user's private locations, and thirdly, by splitting the data to two parts before using OTP.
IEEE Security & Privacy Silver Bullet Security Podcast	
Proceedings-1983 Symposium on Security and Privacy	
IEEE Security & Privacy Subscription Offer	
Security and Privacy Issues in Medical Devices - The Provider/Manufacturer Partnership	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04375400.png" border="0">
Notice of Violation of IEEE Publication Principles<BR>Privacy protection in outsourced database services	Technical considerations and many significant commercial and legal regulations demand that privacy guarantees be provided whenever sensitive information is stored, processed, or communicated to external partied. In this paper, we propose a solution to enforce data confidentiality, data privacy and accountable user privacy in outsourced database services. The approach starts from a flexible definition of privacy constraints, applies encryption on information in a parsimonious way and mostly relies on attribute partition to protect sensitive information. Based on the approximation algorithm for the minimal encryption attribute partition, the approach allows storing the outsourced data on un-trusted database server and minimizing the amount of encrypted data. By combining cryptographic with auxiliary random server, the approach can reduce the computational and communication complexity of private information retrieval to provide user privacy protection. By introducing verifiable encryption and revocation of decryption based on event capsule, the approach obtains accountability when the user misbehaves. The theoretical analysis shows that our new approach can provide efficient data privacy, efficient accountable user privacy protection with lower computational complexity and not increase the cost of communication complexity simultaneously.
A VLSI implementation and analysis of cryptographic algorithms for security and privacy in communication networks	In an age of technological advancements, security and privacy plays an important role in the day to day communications. With the advent of the internet, data security has become a topic of utmost importance. Through this project we wish to address this concern by carrying out a comparative analytical study of the feasibility of different cryptographic algorithms. The design is done using Verilog HDL and simulated using Modelsim. Synthesis, implementation and power analysis is done using Xilinx ISE 10.1 and the companion software Xilinx XPower Analyzer. It has been implemented in different device models that are provided by the software Xilinx ISE 10.1 and experimental results have been recorded. The results obtained have been used to carry out a comparative analysis of different factors like memory usage, power consumed, number of input / outputs, speed and frequency of operation.
Architecture for Preserving Privacy During Data Mining by Hybridization of Partitioning on Medical Data	Abstract- Data mining technique, classification and prediction has improved and used in medical domain to helping medical practitioner in making their decisions. As medical data is highly sensitive to personal information of human being, so it is desired to keep private. There are many approaches for classification which have been adapted for privacy preserving in medical data which are based on data separation technique for privacy preserving. There are two scenarios, one is centralized and other is distributed data where several approaches have been developed. In this paper, we propose architecture for privacy preserving in data mining by combining horizontal data distribution and vertical data distribution for breast cancer data set.
Distributed Model Based Sampling Technique for Privacy Preserving Clustering	The sharing of data has been proven beneficial in data mining applications. However, privacy regulations and other privacy concerns may prevent data owners from sharing information for data analysis. To resolve this challenging problem, data owners must design a solution that meets privacy requirements and guarantees valid data clustering results. To achieve this dual goal, we introduce a new method for privacy-preserving clustering based on the probability distributed model for clustering. This paper proposes square wave-based clustering model, gauss distribution-based clustering model and the multivariate normal distribution-based clustering model based on the information provided by the K-means clustering result separately. And we mainly show the correctness and feasibility of the sampled data for clustering by experiment. This new preserving technique can be used not only for distributed clustering, but also for simultaneous clustering rule and data hiding.
Privacy Preserving Data Mining Algorithms by Data Distortion	Recently, a new class of data mining methods, known as privacy preserving data mining (PPDM) algorithms, has been developed by the research community working on security and knowledge discovery. The aim of these algorithms is the extraction of relevant knowledge from large amount of data, while protecting sensitive information simultaneously. In this paper, we present a generic PPDM framework and a classification scheme for centralized database, adopted from early studies, to guide the review process. Frequencies of different techniques/algorithms used are tableau and analyzed. A set of metrics and a theoretical framework are also proposed for assessing the relative performance of selected PPDM algorithms. Finally, we share directions for future research
A Secure Protocol of Reverse Discriminatory Auction with Bid Privacy	The recent focus on auction field has been to multiple item auctions where bidders are not restricted to buying only one item of the merchandize. In this paper, we concentrate on the use of the multi-item auction and propose a novel PRDA auction protocol to solve problems of bid privacy in multi-item auction. A verifiable technique of shared key chain is used to find the winners without revealing the losing bids and unnecessary information. Through analysis, our new scheme is robust against cheating bidders.
Perceived Privacy and Perceived Security and Their Effects on Trust, Risk, and User Intentions	This article seeks to review and consolidate existing research modeling the relationships between perceived privacy, security, and consumer intention to use Web-based services such as on-line shopping. This is a crucial area to understand since many consumers are still reluctant to use on-line services due to perceived risk and trust issues. Recent headlines highlighting major privacy and security breaches by firms such as Winners have further inflamed concerns. Past research, however, has focused only on narrowly defined components of the overall picture, such as the link between security and trust. This paper therefore seeks to consolidate their models, creating a single overarching model, which is proposed as a starting point for future research.
Analysis of the Use of Privacy-Enhancing Technologies to Achieve PIPEDA Compliance in a B2C e-Business Model	The advanced computing power and reduced acquisition cost of information technology have facilitated the collection, storage, and processing of information in a short amount of time. Privacy legislation has been enacted to ensure that governments and businesses secure such collections in their systems and implement solutions to comply with the law. One such legislation in Canada is the personal information protection and electronic documents act (PIPEDA), intended as a technology- neutral data protection law, where the principles are general and do not require organizations to use a specific vendor or technological tool. In this paper, we give a detailed analysis and taxonomy of use of several privacy-enhancing technologies (PET) to assist business-to-consumer (B2C) organizations to comply with PIPEDA. Our analysis indicates that a combination of PETs can assist in complying with the ten PIPEDA privacy principles, with selection of the PETs to be determined by the organization's privacy handling practices.
Addressing Privacy in a Federated Identity Management Network for EHealth	E-health networks can provide integrated services to patients and health care workers that are more broadly accessible by leveraging Internet technology and electronic health records. However, issues of security and privacy must be addressed. In particular, compliance with relevant privacy legislation must be established. Federated identity management can enable users and service providers to securely and systematically manage identities and user profiles in a single sign on framework that controls access to personal information. In this paper, we use a simple ePrescription scenario to analyze the business and technical issues that need to be addressed in a Liberty Alliance federated identity management framework. We look at the potential impact of privacy compliance on three existing components of the framework (Discovery Service, Identity Mapping Service, Interaction Service) as well as a fourth component (Audit Service) that has been proposed to address potential privacy breeches in Liberty Alliance.
Analyze and Prevent the Security Risks of E-Commerce Privacy	This paper introduces the concepts of e-commerce privacy, security risk of e-commerce privacy, and present status of security risk of e-commerce privacy, analyzes the causes of security risks of e-commerce privacy in six aspects: humanity, environment, infrastructure, logical entities, security mechanisms, security services and applications, and gives the corresponding preventive strategies for e-commerce privacy.
An Anonymization Method Based on Tradeoff between Utility and Privacy for Data Publishing	Privacy preserving is an important issue in data publishing. Many anonymization algorithms are available in meeting the privacy requirements of the privacy models such as k-anonymity, l-diversity and t-closeness. In this paper, we discuss the requirements that anonymized data should meet and propose a new data anonymization approach based on tradeoff between utility and privacy to resist probabilistic inference attacks. To evaluate the quality of anonymized results, a method of measuring the utility loss and privacy gain of anonymized data is brought out which can be used to find the optimal anonymization solution. The result of the experiments validates the availability of the approach.
U-Commerce Product Adoption: An Economic Model for Personalization and Privacy Concerns	U-commerce is considered as the ultimate form of commerce. Highly advanced in technologies, u-commerce can provide various unique personalized products and services based on customers' identities and preferences. However, customers have to give up part of their personal information in order to get the personalization benefits. Therefore, privacy concerns have become a major obstacle to the adoption of u-commerce products. This study uses a simple economic model to explore how the value of personalization, privacy concerns, cost of information collection and additional value of information can impact the adoption of u-commerce products and services. The results show that the value of personalization to consumer and the additional value of personal information to firm have positive correlation to personalized product adoption, and consumer's privacy concerns, price and cost of information collection negatively affected the adoption of personalized products.
A Novel Graph-Based Privacy Policy Management System	Privacy and data protection have become a critical issue in recent years. Not surprisingly, many technologies have been proposed to support privacy data management. The widely used access control model, role based access control (RBAC), significantly simplifies the specification and management of data. In this paper we proposed a privacy-aware system to improve the performance in RBAC, which properly expresses the relationship between data elements. As some vulnerabilities may be raised after certain sensitive data are disclosed, our privacy data graph successfully solved this problem by reducing disclosure of data minimizing overhead. We extend our previous work by refining the definition of roles, thus results in low storage overhead. A full detailed view of the role-based privacy management with experimental results is provided.
Privacy-Preserving Skyline Queries in LBS	Skyline query is widely used in many applications, such as multi-criteria decision making, data mining and visualization, as well as Location-Based Services (LBS). The previous works about skyline mainly focuses on static attributes, such as Branch and Bound Skyline and Probabilistic Skyline. However, due to the requirements in the privacy-protection as protecting individual position and individual information in LBS, a cloaking region of a user instead of his exact position should be cared. To protect privacy of usersΓÇÖ location, dynamic attribute such as uncertain user position should be introduced to skyline. In this paper, two novel skylines query, Range to Ranges Skyline Query (R2R Skyline Query) and Point to Ranges Skyline Query (P2R Skyline Query), are introduced to deal with the privacy problems in LBS. Firstly we propose a R2RSQ algorithm, based on effectiveness pruning mechanism, to answer R2R skyline query, where the spatial attributes of data are all dynamic. Then, R2RSQ algorithm is extended to solve P2R skyline query by its generality. Lastly, extensive experiments using real data sets demonstrate the efficiency and effectiveness of our proposed algorithms in answering R2R skyline query. Our experimental results show that Privacy-Preserving skylines are significant and useful, and R2RSQ algorithm can efficiently support Privacy-Preserving skylines, especially, R2RSQ is efficient on large datasets with dynamic attributes.
Privacy protection in trust management	As pervasive computing leading to an increased collection of information in the computational world as well as the real world, privacy leaking becomes a serious issue. Although privacy protection has drawn great attention in recent years, the privacy-preserving trust management has not been brought forward. Credential chain discovery problem is the key issue in trust management, and traditionally credentials are full open in the whole system. This could expose userspsila access control policies as well as other private information, and leads to a great risk of being cheated by malicious users. This paper advocates a privacy-preserving credential chain discovery mechanism, in which credentials are no longer available to everyone. By merely learning credentials of onepsilas logic neighbors, this mechanism still achieves good results. The simulations show that this mechanism is practical.
An Aspect-Oriented Approach to Privacy-Aware Access Control	This paper concerns the problem of enhancing enterprise applications with a modular mechanism for enforcing privacy policies on personal data. We propose to use aspect-oriented programming and address the involved issues from the perspective of extending fine-grained access control with privacy concerns. An aspect framework for enforcing access control in Struts-based Web applications is extended with fine-grained privacy protection mechanisms that make the aspects privacy aware. The proposed mechanisms are loosely coupled with the underlying application. It is thus easy to adapt them and employ them to migrate existing applications.
A Proposal Towards Customers' Privacy Preference Policy	Increasingly, companies hold more and more data about their customers. This data is seen as useful for the company, although often customers do not wish to share their personal data. Methods such as P3P for verifying a company's privacy policy are available, however, they do not provide much choice to the customer, and they provide an all-or-nothing approach. We explore the privacy preference policy approach which attempts to align the privacy preferences of the individual with that of a company. We further critique this method and develop it to incorporate levels of importance and priority.
Privacy Preserving Sequential Pattern Mining Based on Data Perturbation	Data mining is to discover previously unknown, potentially useful and nontrivial knowledge, patterns or rules. Because databases may have some sensitive information which should not be leaked out, it is nontrivial to study data mining techniques without neglecting sensitive information, i.e., privacy-preserving data mining. In this paper, a new technique has been proposed for privacy-preserving mining of sequential patterns based on data perturbation. Experimental results show that the reconstructing support of frequent sequences can achieve a rather high level of accuracy.
Adapting US Privacy Laws to the Internet: Is Patching Enough?	The current laws addressing privacy in the United States (US) vary greatly both in number and in level of government to which they are applied and enforced. As new technologies are created existing laws are modified to address these technologies, and when a law cannot be modified new laws are created. This modification of older laws and creation of situation specific laws has resulted in a patchwork of privacy laws, which both protect and harm the citizen's privacy. This paper examines the US federal laws which address two different Internet technologies (websites and email). These laws are examined for their effects on privacy both positive and negative. This paper seeks to show that the current privacy laws and their patchwork nature are not effective, and will present the steps towards repairing this system.
Privacy Preserving Sequential Pattern Mining Based on Secure Two-Party Computation	Privacy-preserving data mining in distributed or grid environment is an important hot research topic in recent years. We focus on the privacy-preserving sequential pattern mining in the following situation: two parties, each having a private data set, wish to collaboratively discover sequential patterns on the union of the two private data sets without disclosing their private data to each other. Therefore, we put forward a novel approach to discover privacy-preserving sequential patterns based on secure two-party computation using homomorphic encryption technology
An Incremental Algorithm for Mining Privacy-Preserving Frequent Itemsets	Privacy preserving data mining is a novel research direction in data mining and statistical database, where data mining algorithms are analyzed for the side-effects they incur in data privacy. There have been many studies on efficient discovery of frequent itemsets in privacy preserving data mining. However, it is nontrivial to maintain such discovered frequent itemsets because a database may allow frequent itemsets updates and such frequent itemsets may be turned into infrequent itemsets. In this paper, an incremental updating algorithm IPPFIM is proposed for efficient maintenance of discovered frequent itemsets when new transaction data are added to a transaction database in privacy preserving. The algorithm makes use of previous mining results to cut down the cost of finding new frequent itemsets in an updated database, the performance evaluation shows the efficiency of this method
Android privacy	Due to technological progress, today's mobile phones have evolved into technically and functionally sophisticated smartphones which have more in common with computers than with the conventional phones. As a result of their popularity and functionality, smartphones are a burgeoning target for malicious activities In Android privacy; we undertake two aspects such as user and developer. For users, a known fact in Android mobile, any app can be downloaded from Android Market without accessing a significant quantity of personal data which is different in App Store. For app developers, the App Store's method acquires developed app need to be signed using a private encryption key. Furthermore, several privacy related data such as personal information, IMEI, and location which are leaks already existing in Android Smartphone for a while. In this paper, we explain what kind of data is at risk and how to acquire them programmatically without the user's permission. We will focus on how to obtain the data illicitly which are of Android privacy concerns and the categorization of these Android privacy issues. For example, mobile number, email accounts, keyboard cache entries, browser searches and the most recent location are sensitive data attractive to the attackers. This paper also shows how we use the Android API to perform our Spyware to obtain the sensitive information. Some attack scenarios and recommendations are also presented.
Interval valued fuzzy rough classifier and its application on privacy protection	Currently, most works on interval valued problems mainly focus on attribute reduction (i.e., feature selection) by using rough set technologies. However, less research work on classifier building on interval-valued problems has been conducted. It is promising to propose an approach to build classifier for interval-valued problems. In this paper, we propose a classification approach based on interval valued fuzzy rough sets. First, the concept of interval valued fuzzy granules are proposed, which is the crucial notion to build the reduction framework for the interval-valued databases. Second, the idea to keep the critical value invariant before and after reduction is selected. Third, the structure of reduction rule is completely studied by using the discernibility vector approach. After the description of rule inference system, a set of rules covering all the objects can be obtained, which is used as a rule based classifier for future classification. Finally, numerical examples are presented to illustrate feasibility and affectivity of the proposed method in the application of privacy protection.
An encryption-based approach for protecting privacy in network-based location systems	Since the privacy of the users can be threatened by location-based services (LBS), many privacy preserving approaches have been proposed to protect the user location information during a request for LBS. Nevertheless, the user's location information may still be exposed during positioning because of the nature of the unreliable wireless environment. This paper presents a secure network-based positioning system that can protect the privacy of the users by encrypting the location estimation. To preserve privacy, the proposed method exposes only an encrypted version of the user location based on asymmetric encryption schemes. When a network of base stations sends back the estimated result, it uses the public key to encrypt the data. The device will then use its private key to decrypt the location information. This intelligent scheme prevents the exposure of location information in the radio transmission and thus, protects the location privacy. Our experimental results show that, although the encryption in mobile device results in extra energy consumption, the computational time is acceptable in current high-level devices. The positioning accuracy is also comparable to the unencrypted results with a suitable choice of the scaling factor in the adopted RSA encryption techniques.
Protecting Privacy in case based reasoning by disordered PCA on one class data	Protecting Privacy has attracted more and more attention in data mining. Case based reasoning(CBR) is very important task in data mining. This paper presents method that protects the privacy by disordered principal component analysis(PCA) on one class data. In order to be ensure the security of the CBR, we first disorder the PCA to select the principal component confusedly. Further we transform the sensitive attribution into principal component space using disordered PCA, thus the sensitive attributes are encrypted and protected. Because the PCA method is disordered, this algorithm is very secure. In addition, PCA can keep the main character of dataset, so the precision change of CBR after encryption can be controlled in a small scope. The experiment show that if we select appropriate parameters, then nearest neighbors of every point may be high consistent. The present algorithm can guarantee that the security and the precision both achieve the requirements.
Distributed Privacy Preserving Decision Support System for Predicting Hospitalization Risk in Hospitals with Insufficient Data	Building prediction models for suggestive knowledge from multiple sources dynamically is of great interest from a clinical decision support point of view. This is valuable in situations where the local clinical data repository does not have sufficient number of records to draw conclusions from. However, due to privacy concerns, hospitals are reluctant to divulge patient records. Consequently, a distributed model building mechanism that can use just the statistics from multiple hospitals' databases is valuable. Our DIDT algorithm builds a model in that fashion. In this study, using National Inpatient Sample (NIS) data for 2009, we demonstrate that DIDT algorithm can be used to help collaboratively build a better decision-making model in situations where hospitals have small number of records that are insufficient to make good local models. Based on 262 attributes used for model building, we showed that 9 collaborating hospitals each with less than 100 cases of hospitalizations related to diabetes were able to achieve 9.9% improvement in accuracies of hospitalization prediction collectively using a distributed model as compared to relying on local models developed on their own. When relying on local risk prediction models for diabetes at these 9 hospitals, 159 of 357 patients were misclassified and prediction was impossible for another 16 patients. Our integrated model reduced the misclassification to 138 effectively providing accurate early diagnostics to 37 additional patients. We also introduce the concept of banding to improve DIDT algorithm so as to logically combine multiple hospitals when large number of hospitals is involved for reduction in cross-validation folds.
Tradeoff between energy savings and privacy protection in computation offloading	Offloading can save energy on mobile systems for computation-intensive applications. The mobile systems send programs and data to grid-powered servers where computation is performed. Offloading, however, causes privacy concerns because sensitive data may be sent to servers. This paper investigates how to protect privacy in computation offloading. We use steganography to hide data before sending them to servers. This paper evaluates the tradeoff between energy savings and privacy protection for content-based image retrieval with different steganographic techniques. We implement these methods on a PDA and compare their energy consumption, performance, and effectiveness of protecting privacy.
An Improved RFID Privacy Protection Scheme Based on Hash-Chain	Radio Frequency Identification (RFID) is a new automatic identification technology. Widespread application of RFID may leak user's privacy. To solve this problem, an improved RFID privacy protection scheme based on Hash-chain is proposed, in which a database identifier field is introduced in RFID tag. When a RFID tag is identified by a reader, by using of the database identifier field, the reader can quickly decide whether the RFID tag belongs to the database system that the reader is associated with. Further treatment is not required if the RFID tag doesn't belong to the database system, thus the privacy of any RFID that isn't relevant with the database is protected. The identification load will be reduced remarkably and the efficiency will be improved evidently in the new authentication scheme.
Privacy, Anonymity, and Accountability in Ad-Supported Services	In this talk, I will address three aspects of user privacy in advertiser-supported, online services. First, I present the design of a novel browser plug-in that enables anonymous search. Next, I consider economic aspects of user privacy from the point of view of the operator of an advertiser-supported website. Finally, I present recent work on "accountability" in online activity, where the goal is to hold website operators responsible for appropriate handling of users' sensitive information rather than to prevent users from ever providing information that might be misused.
Privacy-Preserving Quick Authentication in Fast Roaming Networks	Vehicular networks will become an important component for information accesses in one's daily life. A vehicular network provides a vehicular user not only chances to communicate with peer vehicles but also to use Internet through roadside access points (APs). During a trip a vehicular user could roam across multiple APs either belong to their home wireless domain or to domains owned by different authorities. This poses challenges on privacy and network performance to the current public wireless network access protocols. In this paper we explore an idea that shifts the paradigm of authentication that goes back to home networks to a paradigm of authentication that performs at the APs. We propose three authentication schemes in realizing the idea. These schemes are designed for preserving user's identity and location privacy. They also greatly reduce response time for authentication when roaming. The paper then analyzes the security and privacy properties of these schemes as well as the efficiency of them
A privacy-preserving reputation system for participatory sensing	Participatory sensing is a revolutionary paradigm in which volunteers collect and share information from their local environment using mobile phones. The design of a successful participatory sensing application is met with two challenges - (1) user privacy and (2) data trustworthiness. Addressing these challenges concurrently is a non-trivial task since they result in conflicting system requirements. User privacy is often achieved by removing the links between successive user contributions while such links are essential in establishing trust. In this work, we present a way to transfer reputation values (which is a proxy for assessing trustworthiness) between anonymous contributions. We also propose a reputation anonymization scheme that prevents the inadvertent leakage of privacy due to the inherent relationship between reputation information. We conduct extensive simulations using real-world mobility traces and practical application. The results show that our solution reduces the probabilities of users being tracked via successive contributions by as much as 80%. Moreover, this improvement has no discernible impact on the normal operation of the application.
Security and privacy for WLAN roaming with per-connection tariff negotiation	In this paper, we propose a novel protocol suite for roaming WLAN devices. It supports authentication, key agreement, and secure payment between roaming devices and network operators. This is achieved with the help of an integrated tick payment scheme. Our protocol suite allows operators to quickly change tariffs depending on current demand and allows users to choose between different operators and select from different tariff options on a per-connection basis. In addition, our protocol suite offers a very high degree of privacy protection by revealing only strictly required information to the participating parties.
Privacy protection and authentication for medical images with record-based watermarking	In this paper, we propose a practical scheme for privacy protection and authentication of medical images with the aid of EXIF metadata and associated records of the patients. By using watermarking, the goals mentioned above can be reached. Application for robust watermarking is one of the major branches in digital rights management (DRM) systems. With robust watermarking, it generally alters selected coefficients in the transform domain to accomplish the embedding process. We consider not only the image contents itself, but we also employ the EXIF metadata, which contains the patients' records and serves as the role of watermark, to be integrated into our scheme. By doing so, the false negative probability for obtaining the record can be reduced. Moreover, taking the information that the medical doctor recorded in the EXIF metadata into account, conventional watermarking techniques can be applied to medical images, and watermarked images with good quality can be produced. Even when the marked image has been intentionally modified, the original EXIF with selected information can mostly be recovered from the decoding process. Simulation results present the effectiveness of such an implementation.
Integrity preservation and privacy protection for medical images with histogram-based reversible data hiding	For medical treatments, the integrity of the medical images, the authenticity of corresponding medical records, and the privacy of the patients are crucial requirements for the diagnosis of patient's disease. Therefore, how to retain the validity between images and medical records is an important topic for researches and real applications. In this paper, we apply the concept and implementation in digital rights management (DRM) systems, and propose a functional scheme for the above-mentioned goals. We employ the reversible data hiding scheme, a newly developed branch in DRM researches, for combating the goals. With the term of reversibility, it means that data, including patients' private information and the diagnosis data, can be hidden into the medical image by some means. Later on, the medical image containing data might be retrieved while necessary, and both the original image and the hidden data can be perfectly recovered. Data can be authenticated for enhanced privacy protection. Simulation results present the applicability of such an implementation.
Facilitating Trust in Privacy-Preserving E-Learning Environments	This research explores a new model for facilitating trust in online e-learning activities. We begin by protecting the privacy of learners through identity management (IM), where personal information can be protected through some degree of participant anonymity or pseudonymity. In order to expect learners to trust other pseudonymous participants, we realize that a reliable mechanism is needed for managing participants' reputations and assuring that such reputations are legitimately obtained. Further, because participants can hold multiple identities or can adopt new pseudonymous personas, a reliable and trustworthy mechanism for reputation transfer (RT) from one persona to another is required. Such a reputation transfer model must preserve privacy and at the same time prevent linkability of learners' identities and personas. In this paper, we present a privacy-preserving reputation management (RM) system which allows secure transfer of reputation. A prototypical implementation of our reputation transfer protocol and the successful experimental deployment of our reputation management solution in an e-learning discussion forum serve as a proof of concept.
Privacy risks and challenges for the mobile internet	<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01514380.png" border="0">
Privacy Mechanism for Applications in Cloud Computing	Applications stored in the cloud enable users to access and perform tasks in real time, reducing costs in the acquisition of computer resources. Although there are benefits, this paradigm also brings security and privacy risks to users, such as theft of information or identity. This paper proposes a mechanism able to provide privacy protection for users to use applications that address issues of identity, confidentiality and user preferences.
Improving Transmission Privacy Using Optical Layer XOR	We built novel "dual code" OCDMA transmitter and receiver with optical layer XOR, thus achieving data privacy approaching one-time pad security. Enhanced secure communication among users was demonstrated at OC-24 with raw BER < 10<sup>-12</sup>.
Privacy Preserving Attribute Reduction Based on Rough Set	Attribute reduction, as a part of preprocesses, plays an important role in data mining. Privacy ought to be preserved while conducting attribute reduction on distributed data. However, to the best of our knowledge, there exists no algorithm about attribute reduction for the present. In this paper, we represent two privacy preserving attribute reduction algorithms based on rough set. One is on the vertically partitioned data. We develop secure sum of matrices and secure set intersection for it. The other is on the horizontally partitioned data, mainly using secure set union. The correctness and security of the two algorithms are also analyzed. The results show that both of the two algorithms are correct and secure.
Three New Approaches to Privacy-preserving Add to Multiply Protocol and its Application	Privacy-preserving data mining aims at securely extracting knowledge from two or more parties' private data. Secure multi-party computation is the paramount approach to it. In this paper, we study privacy-preserving add and multiply exchanging technology and present three new different approaches to privacy-preserving add to multiply protocol. After that, we analyze and compare the three different approaches about the communication overheads, the computation efforts and the security. In addition, we extend privacy-preserving add to multiply protocol to privacy-preserving adding to scalar product protocol, which is more secure and more useful in the high security situations of privacy-preserving data mining. Meantime, we present a solution for the new protocol.
A Distributed Solution for Privacy Preserving Outlier Detection	In this paper, we study some parties - each has a private data set - want to conduct the outlier detection on their joint data set, but none of them want to disclose its private data to the other parties. We propose a linear transformation technique to design protocols of secure multivariate outlier detection in both horizontally and vertically distributed data models. While different from the most of previous techniques in a privacy preserving fashion for distance-based outliers detection, our focus is the technique in statistics for detecting outliers.
Privacy Preserving Classification in Two-Dimension Distributed Data	Within the context of privacy preserving data mining, several solutions for privacy-preserving classification rules learning such as association rules mining have been proposed. Each solution was provided for horizontally or vertically distributed scenario. The aim of this work is to study privacy-preserving classification rules learning in two-dimension distributed data, which is a generalisation of both horizontally and vertically distributed data. In this paper, we develop a cryptographic solution for classification rules learning methods. The crucial step in the proposed solution is the privacy-preserving computation of frequencies of a tuple of values, which can ensure each participant's privacy without loss of accuracy. We illustrate the applicability of the method by using it to build the privacy preserving protocol for association rules mining and ID3 decision tree learning.
Privacy Preserving Decision Tree Learning Using Unrealized Data Sets	Privacy preservation is important for machine learning and data mining, but measures designed to protect private information often result in a trade-off: reduced utility of the training samples. This paper introduces a privacy preserving approach that can be applied to decision tree learning, without concomitant loss of accuracy. It describes an approach to the preservation of the privacy of collected data samples in cases where information from the sample database has been partially lost. This approach converts the original sample data sets into a group of unreal data sets, from which the original samples cannot be reconstructed without the entire group of unreal data sets. Meanwhile, an accurate decision tree can be built directly from those unreal data sets. This novel approach can be applied directly to the data storage as soon as the first sample is collected. The approach is compatible with other privacy preserving approaches, such as cryptography, for extra protection.
On the Design and Analysis of the Privacy-Preserving SVM Classifier	The support vector machine (SVM) is a widely used tool in classification problems. The SVM trains a classifier by solving an optimization problem to decide which instances of the training data set are support vectors, which are the necessarily informative instances to form the SVM classifier. Since support vectors are intact tuples taken from the training data set, releasing the SVM classifier for public use or shipping the SVM classifier to clients will disclose the private content of support vectors. This violates the privacy-preserving requirements for some legal or commercial reasons. The problem is that the classifier learned by the SVM inherently violates the privacy. This privacy violation problem will restrict the applicability of the SVM. To the best of our knowledge, there has not been work extending the notion of privacy preservation to tackle this inherent privacy violation problem of the SVM classifier. In this paper, we exploit this privacy violation problem, and propose an approach to postprocess the SVM classifier to transform it to a privacy-preserving classifier which does not disclose the private content of support vectors. The postprocessed SVM classifier without exposing the private content of training data is called Privacy-Preserving SVM Classifier (abbreviated as PPSVC). The PPSVC is designed for the commonly used Gaussian kernel function. It precisely approximates the decision function of the Gaussian kernel SVM classifier without exposing the sensitive attribute values possessed by support vectors. By applying the PPSVC, the SVM classifier is able to be publicly released while preserving privacy. We prove that the PPSVC is robust against adversarial attacks. The experiments on real data sets show that the classification accuracy of the PPSVC is comparable to the original SVM classifier.
Privacy-Preserving OLAP: An Information-Theoretic Approach	We address issues related to the protection of private information in Online Analytical Processing (OLAP) systems, where a major privacy concern is the adversarial inference of private information from OLAP query answers. Most previous work on privacy-preserving OLAP focuses on a single aggregate function and/or addresses only exact disclosure, which eliminates from consideration an important class of privacy breaches where partial information, but not exact values, of private data is disclosed (i.e., partial disclosure). We address privacy protection against both exact and partial disclosure in OLAP systems with mixed aggregate functions. In particular, we propose an information-theoretic inference control approach that supports a combination of common aggregate functions (e.g., COUNT, SUM, MIN, MAX, MEDIAN) and guarantees the level of privacy disclosure not to exceed thresholds pre-determined by the data owners. We demonstrate that our approach is efficient and can be implemented in existing OLAP systems with little modification. It also satisfies the simulatable auditing model and leaks no private information through query rejections. Through performance analysis, we show that compared with previous approaches, our approach provides more effective privacy protection while maintaining a higher level of query-answer availability. Furthermore, our approach can be readily integrated with perturbation-based privacy protection mechanisms to improve the performance of both.
Privacy-preserving distributed mining of association rules on horizontally partitioned data	Data mining can extract important knowledge from large data collections ut sometimes these collections are split among various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. We address secure mining of association rules over horizontally partitioned data. The methods incorporate cryptographic techniques to minimize the information shared, while adding little overhead to the mining task.
Distributed Autonomous Online Learning: Regrets and Intrinsic Privacy-Preserving Properties	Online learning has become increasingly popular on handling massive data. The sequential nature of online learning, however, requires a centralized learner to store data and update parameters. In this paper, we consider online learning with distributed data sources. The autonomous learners update local parameters based on local data sources and periodically exchange information with a small subset of neighbors in a communication network. We derive the regret bound for strongly convex functions that generalizes the work by Ram et al. [2010] for convex functions. More importantly, we show that our algorithm has intrinsic privacy-preserving properties, and we prove the sufficient and necessary conditions for privacy preservation in the network. These conditions imply that for networks with greater-than-one connectivity, a malicious learner cannot reconstruct the subgradients (and sensitive raw data) of other learners, which makes our algorithm appealing in privacy sensitive applications.
Privacy Protection Against Malicious Adversaries in Distributed Information Sharing Systems	We address issues related to sharing information in a distributed system consisting of autonomous entities, each of which holds a private database. We consider threats from malicious adversaries that can deviate from the designated protocol and change their input databases. We classify malicious adversaries into two widely existing subclasses, namely weakly and strongly malicious adversaries, and propose protocols that can effectively and efficiently protect privacy against malicious adversaries.
Privacy Preserving Policy Based Content Sharing in Public Clouds	An important problem in public clouds is how to selectively share documents based on fine-grained attribute based access control policies. An approach is to encrypt documents satisfying different policies with different keys using a public key crytosystem such as attribute based encryption (ABE), and/or proxy re-encryption (PRE). However, such an approach has some weaknesses. A direct application of a symmetric key cryptosystem also has similar weaknesses. We observe that, without utilizing public key cryptography and by allowing users to dynamically derive the symmetric keys at the time of decryption, one can address the above weaknesses. Based on this idea, we formalize a new key management scheme called broadcast group key management (BGKM) and then give a secure construction of a BGKM scheme called ACV-BGKM. The idea is to give some secrets to users based on the identity attributes they have and later allow them to derive actual symmetric keys based on their secrets and some public information. A key advantage of the BGKM scheme is that adding users/revoking users or updating access control policies can be performed efficiently by updating only some public information. Using our BGKM construct, we propose an efficient approach for fine-grained encryption based access control for documents stored in an untrusted cloud file storage.
Privacy-Preserving OLAP: An Information-Theoretic Approach	We address issues related to the protection of private information in Online Analytical Processing (OLAP) systems, where a major privacy concern is the adversarial inference of private information from OLAP query answers. Most previous work on privacy-preserving OLAP focuses on a single aggregate function and/or addresses only exact disclosure, which eliminates from consideration an important class of privacy breaches where partial information, but not exact values, of private data is disclosed (i.e., partial disclosure). We address privacy protection against both exact and partial disclosure in OLAP systems with mixed aggregate functions. In particular, we propose an information-theoretic inference control approach that supports a combination of common aggregate functions (e.g., COUNT, SUM, MIN, MAX, and MEDIAN) and guarantees the level of privacy disclosure not to exceed thresholds predetermined by the data owners. We demonstrate that our approach is efficient and can be implemented in existing OLAP systems with little modification. It also satisfies the simulatable auditing model and leaks no private information through query rejections. Through performance analysis, we show that compared with previous approaches, our approach provides more effective privacy protection while maintaining a higher level of query-answer availability.
A Tree-Based Data Perturbation Approach for Privacy-Preserving Data Mining	Due to growing concerns about the privacy of personal information, organizations that use their customers' records in data mining activities are forced to take actions to protect the privacy of the individuals. A frequently used disclosure protection method is data perturbation. When used for data mining, it is desirable that perturbation preserves statistical relationships between attributes, while providing adequate protection for individual confidential data. To achieve this goal, we propose a kd-tree based perturbation method, which recursively partitions a data set into smaller subsets such that data records within each subset are more homogeneous after each partition. The confidential data in each final subset are then perturbed using the subset average. An experimental study is conducted to show the effectiveness of the proposed method
Incentive Compatible Privacy-Preserving Data Analysis	In many cases, competing parties who have private data may collaboratively conduct privacy-preserving distributed data analysis (PPDA) tasks to learn beneficial data models or analysis results. Most often, the competing parties have different incentives. Although certain PPDA techniques guarantee that nothing other than the final analysis result is revealed, it is impossible to verify whether participating parties are truthful about their private input data. Unless proper incentives are set, current PPDA techniques cannot prevent participating parties from modifying their private inputs. This raises the question of how to design incentive compatible privacy-preserving data analysis techniques that motivate participating parties to provide truthful inputs. In this paper, we first develop key theorems, then base on these theorems, we analyze certain important privacy-preserving data analysis tasks that could be conducted in a way that telling the truth is the best choice for any participating party.
Random projection-based multiplicative data perturbation for privacy preserving distributed data mining	This paper explores the possibility of using multiplicative random projection matrices for privacy preserving distributed data mining. It specifically considers the problem of computing statistical aggregates like the inner product matrix, correlation coefficient matrix, and Euclidean distance matrix from distributed privacy sensitive data possibly owned by multiple parties. This class of problems is directly related to many other data-mining problems such as clustering, principal component analysis, and classification. This paper makes primary contributions on two different grounds. First, it explores independent component analysis as a possible tool for breaching privacy in deterministic multiplicative perturbation-based models such as random orthogonal transformation and random rotation. Then, it proposes an approximate random projection-based technique to improve the level of privacy protection while still preserving certain statistical characteristics of the data. The paper presents extensive theoretical analysis and experimental results. Experiments demonstrate that the proposed technique is effective and can be successfully used for different types of privacy-preserving data mining applications.
Privacy-Preserving Enhanced Collaborative Tagging	Collaborative tagging is one of the most popular services available online, and it allows end user to loosely classify either online or offline resources based on their feedback, expressed in the form of free-text labels (i.e., tags). Although tags are not per se sensitive information, the wide use of collaborative tagging services increases the risk of cross referencing, thereby seriously compromising user privacy. In this paper, we make a first contribution in this direction by showing how a specific privacy-enhancing technology, namely tag suppression, can be used to protect end-user privacy. Moreover, we analyze how our approach can affect the effectiveness of a policy-based collaborative tagging system which supports enhanced Web access functionalities, like content filtering and discovery, based on preferences specified by end users.
Achieving Data Privacy through Secrecy Views and Null-Based Virtual Updates	We may want to keep sensitive information in a relational database hidden from a user or group thereof. We characterize sensitive data as the extensions of secrecy views. The database, before returning the answers to a query posed by a restricted user, is updated to make the secrecy views empty or a single tuple with null values. Then, a query about any of those views returns no meaningful information. Since the database is not supposed to be physically changed for this purpose, the updates are only virtual, and also minimal. Minimality makes sure that query answers, while being privacy preserving, are also maximally informative. The virtual updates are based on null values as used in the SQL standard. We provide the semantics of secrecy views, virtual updates, and secret answers (SAs) to queries. The different instances resulting from the virtually updates are specified as the models of a logic program with stable model semantics, which becomes the basis for computation of the SAs.
ANGEL: Enhancing the Utility of Generalization for Privacy Preserving Publication	Generalization is a well-known method for privacy preserving data publication. Despite its vast popularity, it has several drawbacks such as heavy information loss, difficulty of supporting marginal publication, and so on. To overcome these drawbacks, we develop ANGEL,1 a new anonymization technique that is as effective as generalization in privacy protection, but is able to retain significantly more information in the microdata. ANGEL is applicable to any monotonic principles (e.g., l-diversity, t-closeness, etc.), with its superiority (in correlation preservation) especially obvious when tight privacy control must be enforced. We show that ANGEL lends itself elegantly to the hard problem of marginal publication. In particular, unlike generalization that can release only restricted marginals, our technique can be easily used to publish any marginals with strong privacy guarantees.
m-Privacy for Collaborative Data Publishing	In this paper, we consider the collaborative data publishing problem for anonymizing horizontally partitioned data at multiple data providers. We consider a new type of "insider attack" by colluding data providers who may use their own data records (a subset of the overall data) to infer the data records contributed by other data providers. The paper addresses this new threat, and makes several contributions. First, we introduce the notion of m-privacy, which guarantees that the anonymized data satisfies a given privacy constraint against any group of up to m colluding data providers. Second, we present heuristic algorithms exploiting the monotonicity of privacy constraints for efficiently checking m-privacy given a group of records. Third, we present a data provider-aware anonymization algorithm with adaptive m-privacy checking strategies to ensure high utility and m-privacy of anonymized data with efficiency. Finally, we implement the m-privacy anonymization and verification algorithms with a trusted third party (TTP), and propose secure multiparty computation protocols for scenarios without TTP. All protocols are extensively analyzed and their security and efficiency are formally proved. Experiments on real-life datasets suggest that our approach achieves better or comparable utility and efficiency than existing and baseline algorithms while satisfying m-privacy.
Differential Privacy via Wavelet Transforms	Privacy-preserving data publishing has attracted considerable research interest in recent years. Among the existing solutions, Γêê-differential privacy provides the strongest privacy guarantee. Existing data publishing methods that achieve Γêê-differential privacy, however, offer little data utility. In particular, if the output data set is used to answer count queries, the noise in the query answers can be proportional to the number of tuples in the data, which renders the results useless. In this paper, we develop a data publishing technique that ensures Γêê-differential privacy while providing accurate answers for range-count queries, i.e., count queries where the predicate on each attribute is a range. The core of our solution is a framework that applies wavelet transforms on the data before adding noise to it. We present instantiations of the proposed framework for both ordinal and nominal data, and we provide a theoretical analysis on their privacy and utility guarantees. In an extensive experimental study on both real and synthetic data, we show the effectiveness and efficiency of our solution.
The Context and the SitBAC Models for Privacy PreservationΓÇöAn Experimental Comparison of Model Comprehension and Synthesis	Situation-Based Access Control (SitBAC) is a conceptual model for representing access control policies of healthcare organizations by characterizing situations of access to patient data. The SitBAC model enables formal representation of access situations as an ontology of concepts (Patient, Data Requestor, EHR, Task, and Response) along with their attributes and relationships. A competing access control model is the Contextual Role-Based Access Control (Context) model. The Context model uses logical expressions (rules) that specify contextual authorizations (i.e., characteristics of access requests that are available at access time). Open questions that relate to formal representation of scenarios involving access to patient data are: 1) which of the two models yields a formal representation that is easier to comprehend; 2) which of the two models facilitates the synthesis of correct models, and how does the task complexity affect the performance of comprehension and synthesis. In this study, we address these questions through a controlled experiment. The results of the experiment suggest that while there are no differences between the two models when it comes to comprehending or synthesizing simple scenarios of data access, for complex scenarios, there is a significant advantage to the SitBAC model in terms of both comprehension and synthesis.
An Adaptive Approach to Real-Time Aggregate Monitoring with Differential Privacy	Sharing real-time aggregate statistics of private data is of great value to the public to perform data mining for understanding important phenomena, such as Influenza outbreaks and traffic congestion. However, releasing time-series data with standard differential privacy mechanism has limited utility due to high correlation between data values. We propose FAST, a novel framework to release real-time aggregate statistics under differential privacy based on filtering and adaptive sampling. To minimize the overall privacy cost, FAST adaptively samples long time-series according to the detected data dynamics. To improve the accuracy of data release per time stamp, FAST predicts data values at non-sampling points and corrects noisy observations at sampling points. Our experiments with real-world as well as synthetic data sets confirm that FAST improves the accuracy of released aggregates even under small privacy cost and can be used to enable a wide range of monitoring applications.
Towards Efficient Privacy-Aware Content-Based Pub/Sub Systems	In recent years, the content-based publish/subscribe [11], [19] has become a popular paradigm to decouple information producers and consumers with the help of brokers. Unfortunately, when users register their personal interests to the brokers, the privacy pertaining to subscribers could be easily exposed by untrusted brokers and the collusion attack between untrusted brokers and compromised subscribers. To protect subscriber privacy, we propose to separate the roles of brokers into two parts by introducing an anonymizer engine and adapting the k-anonymity and l-diversity models to the content-based pub/sub.When the anonymizationmodel is applied to protect subscriber privacy, there is an inherent trade-off between the anonymization level and the publication redundancy. We then leverage partial-order-based generalization of filters to track filters satisfying k-anonymity and `-diversity, and design an approximation algorithm to minimize the forwarding cost. Our experiments show the proposed scheme, when compared with two counterparts, spends less forwarding cost and achieve comparable attack resilience.
Privacy-Preserving Kth Element Score over Vertically Partitioned Data	Given a large integer data set shared vertically by two parties, we consider the problem of securely computing a score separating the kth and the (k + 1) to compute such a score while revealing little additional information. The proposed protocol is implemented using the Fairplay system and experimental results are reported. We show a real application of this protocol as a component used in the secure processing of top-k queries over vertically partitioned data.
Protecting Location Privacy against Location-Dependent Attacks in Mobile Services	Privacy protection has recently received considerable attention in location-based services. A large number of location cloaking algorithms have been proposed for protecting the location privacy of mobile users. In this paper, we consider the scenario where different location-based query requests are continuously issued by mobile users while they are moving. We show that most of the existing k-anonymity location cloaking algorithms are concerned with snapshot user locations only and cannot effectively prevent location-dependent attacks when users' locations are continuously updated. Therefore, adopting both the location k-anonymity and cloaking granularity as privacy metrics, we propose a new incremental clique-based cloaking algorithm, called ICliqueCloak, to defend against location-dependent attacks. The main idea is to incrementally maintain maximal cliques needed for location cloaking in an undirected graph that takes into consideration the effect of continuous location updates. Thus, a qualified clique can be quickly identified and used to generate the cloaked region when a new request arrives. The efficiency and effectiveness of the proposed ICliqueCloak algorithm are validated by a series of carefully designed experiments. The experimental results also show that the price paid for defending against location-dependent attacks is small.
Slicing: A New Approach for Privacy Preserving Data Publishing	Several anonymization techniques, such as generalization and bucketization, have been designed for privacy preserving microdata publishing. Recent work has shown that generalization loses considerable amount of information, especially for high-dimensional data. Bucketization, on the other hand, does not prevent membership disclosure and does not apply for data that do not have a clear separation between quasi-identifying attributes and sensitive attributes. In this paper, we present a novel technique called slicing, which partitions the data both horizontally and vertically. We show that slicing preserves better data utility than generalization and can be used for membership disclosure protection. Another important advantage of slicing is that it can handle high-dimensional data. We show how slicing can be used for attribute disclosure protection and develop an efficient algorithm for computing the sliced data that obey the Γäô-diversity requirement. Our workload experiments confirm that slicing preserves better utility than generalization and is more effective than bucketization in workloads involving the sensitive attribute. Our experiments also demonstrate that slicing can be used to prevent membership disclosure.
Accuracy-Constrained Privacy-Preserving Access Control Mechanism for Relational Data	Access control mechanisms protect sensitive information from unauthorized users. However, when sensitive information is shared and a Privacy Protection Mechanism (PPM) is not in place, an authorized user can still compromise the privacy of a person leading to identity disclosure. A PPM can use suppression and generalization of relational data to anonymize and satisfy privacy requirements, e.g., k-anonymity and l-diversity, against identity and attribute disclosure. However, privacy is achieved at the cost of precision of authorized information. In this paper, we propose an accuracy-constrained privacy-preserving access control framework. The access control policies define selection predicates available to roles while the privacy requirement is to satisfy the k-anonymity or l-diversity. An additional constraint that needs to be satisfied by the PPM is the imprecision bound for each selection predicate. The techniques for workload-aware anonymization for selection predicates have been discussed in the literature. However, to the best of our knowledge, the problem of satisfying the accuracy constraints for multiple roles has not been studied before. In our formulation of the aforementioned problem, we propose heuristics for anonymization algorithms and show empirically that the proposed approach satisfies imprecision bounds for more permissions and has lower total imprecision than the current state of the art.
Anonymizing Classification Data for Privacy Preservation	Classification is a fundamental problem in data analysis. Training a classifier requires accessing a large collection of data. Releasing person-specific data, such as customer data or patient records, may pose a threat to an individual's privacy. Even after removing explicit identifying information such as Name and SSN, it is still possible to link released records back to their identities by matching some combination of nonidentifying attributes such as {Sex, Zip, Birthdate}. A useful approach to combat such linking attacks, called k-anonymization, is anonymizing the linking attributes so that at least k released records match each value combination of the linking attributes. Previous work attempted to find an optimal k-anonymization that minimizes some data distortion metric. We argue that minimizing the distortion to the training data is not relevant to the classification goal that requires extracting the structure of predication on the "future" data. In this paper, we propose a k-anonymization solution for classification. Our goal is to find a k-anonymization, not necessarily optimal in the sense of minimizing data distortion, which preserves the classification structure. We conducted intensive experiments to evaluate the impact of anonymization on the classification on future data. Experiments on real-life data show that the quality of classification can be preserved even for highly restrictive anonymity requirements
From t-Closeness-Like Privacy to Postrandomization via Information Theory	t-Closeness is a privacy model recently defined for data anonymization. A data set is said to satisfy t-closeness if, for each group of records sharing a combination of key attributes, the distance between the distribution of a confidential attribute in the group and the distribution of the attribute in the entire data set is no more than a threshold t. Here, we define a privacy measure in terms of information theory, similar to t-closeness. Then, we use the tools of that theory to show that our privacy measure can be achieved by the postrandomization method (PRAM) for masking in the discrete case, and by a form of noise addition in the general case.
Privacy-Preserving and Content-Protecting Location Based Queries	In this paper we present a solution to one of the location-based query problems. This problem is defined as follows: (i) a user wants to query a database of location data, known as Points Of Interest (POIs), and does not want to reveal his/her location to the server due to privacy concerns; (ii) the owner of the location data, that is, the location server, does not want to simply distribute its data to all users. The location server desires to have some control over its data, since the data is its asset. We propose a major enhancement upon previous solutions by introducing a two stage approach, where the first step is based on Oblivious Transfer and the second step is based on Private Information Retrieval, to achieve a secure solution for both parties. The solution we present is efficient and practical in many scenarios. We implement our solution on a desktop machine and a mobile device to assess the efficiency of our protocol. We also introduce a security model and analyse the security in the context of our protocol. Finally, we highlight a security weakness of our previous work and present a solution to overcome it.
PAM: An Efficient and Privacy-Aware Monitoring Framework for Continuously Moving Objects	Efficiency and privacy are two fundamental issues in moving object monitoring. This paper proposes a privacy-aware monitoring (PAM) framework that addresses both issues. The framework distinguishes itself from the existing work by being the first to holistically address the issues of location updating in terms of monitoring accuracy, efficiency, and privacy, particularly, when and how mobile clients should send location updates to the server. Based on the notions of safe region and most probable result, PAM performs location updates only when they would likely alter the query results. Furthermore, by designing various client update strategies, the framework is flexible and able to optimize accuracy, privacy, or efficiency. We develop efficient query evaluation/reevaluation and safe region computation algorithms in the framework. The experimental results show that PAM substantially outperforms traditional schemes in terms of monitoring accuracy, CPU cost, and scalability while achieving close-to-optimal communication cost.
Preserving privacy by de-identifying face images	In the context of sharing video surveillance data, a significant threat to privacy is face recognition software, which can automatically identify known people, such as from a database of drivers' license photos, and thereby track people regardless of suspicion. This paper introduces an algorithm to protect the privacy of individuals in video surveillance data by deidentifying faces such that many facial characteristics remain but the face cannot be reliably recognized. A trivial solution to deidentifying faces involves blacking out each face. This thwarts any possible face recognition, but because all facial details are obscured, the result is of limited use. Many ad hoc attempts, such as covering eyes, fail to thwart face recognition because of the robustness of face recognition methods. This work presents a new privacy-enabling algorithm, named k-Same, that guarantees face recognition software cannot reliably recognize deidentified faces, even though many facial details are preserved. The algorithm determines similarity between faces based on a distance metric and creates new faces by averaging image components, which may be the original image pixels (k-Same-Pixel) or eigenvectors (k-Same-Eigen). Results are presented on a standard collection of real face images with varying k.
Privacy-Preserving Tuple Matching in Distributed Databases	We address the problems of privacy-preserving duplicate tuple matching (PPDTM) and privacy-preserving threshold attributes matching (PPTAM) in the scenario of a horizontally partitioned database among N parties, where each party holds a private share of the database's tuples and all tuples have the same set of attributes. In PPDTM, each party determines whether its tuples have any duplicate on other parties' private databases. In PPTAM, each party determines whether all attribute values of each tuple appear at least a threshold number of times in the attribute unions. We propose protocols for the two problems using additive homomorphic cryptosystem based on the subgroup membership assumption, e.g., Paillier's and ElGamal's schemes. By analysis on the total numbers of modular exponentiations, modular multiplications and communication bits, with a reduced computation cost which dominates the total cost, by trading off communication cost, our PPDTM protocol for the semihonest model is superior to the solution derivable from existing techniques in total cost. Our PPTAM protocol is superior in both computation and communication costs. The efficiency improvements are achieved mainly by using random numbers instead of random polynomials as existing techniques for perturbation, without causing successful attacks by polynomial interpolations. We also give detailed constructions on the required zero-knowledge proofs and extend our two protocols to the malicious model, which were previously unknown.
TrustedDB: A Trusted Hardware Based Database with Privacy and Data Confidentiality	Traditionally, as soon as confidentiality becomes a concern, data is encrypted before outsourcing to a service provider. Any software-based cryptographic constructs then deployed, for server-side query processing on the encrypted data, inherently limit query expressiveness. Here, we introduce TrustedDB, an outsourced database prototype that allows clients to execute SQL queries with privacy and under regulatory compliance constraints by leveraging server-hosted, tamper-proof trusted hardware in critical query processing stages, thereby removing any limitations on the type of supported queries. Despite the cost overhead and performance limitations of trusted hardware, we show that the costs per query are orders of magnitude lower than any (existing or) potential future software-only mechanisms. TrustedDB is built and runs on actual hardware, and its performance and costs are evaluated here.
Supporting Privacy Protection In Personalized Web Search	Personalized Web Search (PWS) has demonstrated its effectiveness in improving the quality of various search services on the Internet. However, evidences show that users' reluctance to disclose their private information during search has become a major barrier for the wide proliferation of PWS. We study privacy protection in PWS applications which model user preferences as hierarchical user profiles. We propose a PWS framework called UPS that can adaptively generalize profiles by queries while respecting user-specified privacy requirements. Our run-time generalization aims at striking a balance between two predictive metrics which evaluate the utility of personalization and the privacy risk of exposing the generalized profile. We present two greedy algorithms, namely GreedyDP and GreedyIL, for run-time generalization. We also provide an online prediction mechanism for deciding whether personalizing a query is beneficial. Extensive experiments demonstrate the effectiveness of our framework. The experimental results also reveal that GreedyIL significantly outperforms GreedyDP in terms of efficiency.
Privacy-Preserving Gradient-Descent Methods	Gradient descent is a widely used paradigm for solving many optimization problems. Gradient descent aims to minimize a target function in order to reach a local minimum. In machine learning or data mining, this function corresponds to a decision model that is to be discovered. In this paper, we propose a preliminary formulation of gradient descent with data privacy preservation. We present two approaches-stochastic approach and least square approach-under different assumptions. Four protocols are proposed for the two approaches incorporating various secure building blocks for both horizontally and vertically partitioned data. We conduct experiments to evaluate the scalability of the proposed secure building blocks and the accuracy and efficiency of the protocols for four different scenarios. The excremental results show that the proposed secure building blocks are reasonably scalable and the proposed protocols allow us to determine a better secure protocol for the applications for each scenario.
Privacy Preserving Delegated Access Control in Public Clouds	Current approaches to enforce fine-grained access control on confidential data hosted in the cloud are based on fine-grained encryption of the data. Under such approaches, data owners are in charge of encrypting the data before uploading them on the cloud and re-encrypting the data whenever user credentials change. Data owners thus incur high communication and computation costs. A better approach should delegate the enforcement of fine-grained access control to the cloud, so to minimize the overhead at the data owners, while assuring data confidentiality from the cloud. We propose an approach, based on two layers of encryption, that addresses such requirement. Under our approach, the data owner performs a coarse-grained encryption, whereas the cloud performs a fine-grained encryption on top of the owner encrypted data. A challenging issue is how to decompose access control policies (ACPs) such that the two layer encryption can be performed.We show that this problem is NP-complete and propose novel optimization algorithms. We utilize an efficient group key management scheme that supports expressive ACPs. Our system assures the confidentiality of the data and preserves the privacy of users from the cloud while delegating most of the access control enforcement to the cloud.
Enhancing Access Privacy of Range Retrievals over $({rm B}^+)$-Trees	Users of databases that are hosted on shared servers cannot take for granted that their queries will not be disclosed to unauthorized parties. Even if the database is encrypted, an adversary who is monitoring the I/O activity on the server may still be able to infer some information about a user query. For the particular case of a $({rm B}^+)$-tree that has its nodes encrypted, we identify properties that enable the ordering among the leaf nodes to be deduced. These properties allow us to construct adversarial algorithms to recover the $({rm B}^+)$-tree structure from the I/O traces generated by range queries. Combining this structure with knowledge of the key distribution (or the plaintext database itself), the adversary can infer the selection range of user queries. To counter the threat, we propose a privacy-enhancing $({rm PB}^+)$-tree index which ensures that there is high uncertainty about what data the user has worked on, even to a knowledgeable adversary who has observed numerous query executions. The core idea in $({rm PB}^+)$-tree is to conceal the order of the leaf nodes in an encrypted $({rm B}^+)$-tree. In particular, it groups the nodes of the tree into buckets, and employs homomorphic encryption techniques to prevent the adversary from pinpointing the exact nodes retrieved by range queries. $({rm PB}^+)$-tree can be tuned to balance its privacy strength with the computational and I/O overheads incurred. Moreover, it can be adapted to protect access privacy in cases where the attacker additionally knows a priori the access frequencies of key values. Experiments demonstrate that $({rm PB}^+)$-tree effectively impairs the adversary's ability to recover the $({rm B}^+)$-tree structure and deduce the query ranges in all considered scenarios.
Enabling Multilevel Trust in Privacy Preserving Data Mining	Privacy Preserving Data Mining (PPDM) addresses the problem of developing accurate models about aggregated data without access to precise information in individual data record. A widely studied perturbation-based PPDM approach introduces random perturbation to individual values to preserve privacy before data are published. Previous solutions of this approach are limited in their tacit assumption of single-level trust on data miners. In this work, we relax this assumption and expand the scope of perturbation-based PPDM to Multilevel Trust (MLT-PPDM). In our setting, the more trusted a data miner is, the less perturbed copy of the data it can access. Under this setting, a malicious data miner may have access to differently perturbed copies of the same data through various means, and may combine these diverse copies to jointly infer additional information about the original data that the data owner does not intend to release. Preventing such diversity attacks is the key challenge of providing MLT-PPDM services. We address this challenge by properly correlating perturbation across copies at different trust levels. We prove that our solution is robust against diversity attacks with respect to our privacy goal. That is, for data miners who have access to an arbitrary collection of the perturbed copies, our solution prevent them from jointly reconstructing the original data more accurately than the best effort using any individual copy in the collection. Our solution allows a data owner to generate perturbed copies of its data for arbitrary trust levels on-demand. This feature offers data owners maximum flexibility.
Privacy-Preserving Computation of Bayesian Networks on Vertically Partitioned Data	Traditionally, many data mining techniques have been designed in the centralized model in which all data is collected and available in one central site. However, as more and more activities are carried out using computers and computer networks, the amount of potentially sensitive data stored by business, governments, and other parties increases. Different parties often wish to benefit from cooperative use of their data, but privacy regulations and other privacy concerns may prevent the parties from sharing their data. Privacy-preserving data mining provides a solution by creating distributed data mining algorithms in which the underlying data need not be revealed. In this paper, we present privacy-preserving protocols for a particular data mining task: learning a Bayesian network from a database vertically partitioned among two parties. In this setting, two parties owning confidential databases wish to learn the Bayesian network on the combination of their databases without revealing anything else about their data to each other. We present an efficient and privacy-preserving protocol to construct a Bayesian network on the parties' joint data
Closeness: A New Privacy Measure for Data Publishing	The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain ΓÇ£identifyingΓÇ¥ attributes) contains at least k records. Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure. The notion of Γäô-diversity has been proposed to address this; Γäô-diversity requires that each equivalence class has at least Γäô well-represented (in Section 2) values for each sensitive attribute. In this paper, we show that Γäô-diversity has a number of limitations. In particular, it is neither necessary nor sufficient to prevent attribute disclosure. Motivated by these limitations, we propose a new notion of privacy called ΓÇ£closeness.ΓÇ¥ We first present the base model t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t). We then propose a more flexible privacy model called (n,t)-closeness that offers higher utility. We describe our desiderata for designing a distance measure between two probability distributions and present two distance measures. We discuss the rationale for using closeness as a privacy measure and illustrate its advantages through examples and experiments.
A Privacy-Preserving Remote Data Integrity Checking Protocol with Data Dynamics and Public Verifiability	Remote data integrity checking is a crucial technology in cloud computing. Recently, many works focus on providing data dynamics and/or public verifiability to this type of protocols. Existing protocols can support both features with the help of a third-party auditor. In a previous work, Sebe╠ü et al. propose a remote data integrity checking protocol that supports data dynamics. In this paper, we adapt Sebe╠ü et al.'s protocol to support public verifiability. The proposed protocol supports public verifiability without help of a third-party auditor. In addition, the proposed protocol does not leak any private information to third-party verifiers. Through a formal analysis, we show the correctness and security of the protocol. After that, through theoretical analysis and experimental results, we demonstrate that the proposed protocol has a good performance.
Privacy: a machine learning view	The problem of disseminating a data set for machine learning while controlling the disclosure of data source identity is described using a commuting diagram of functions. This formalization is used to present and analyze an optimization problem balancing privacy and data utility requirements. The analysis points to the application of a generalization mechanism for maintaining privacy in view of machine learning needs. We present new proofs of NP-hardness of the problem of minimizing information loss while satisfying a set of privacy requirements, both with and without the addition of a particular uniform coding requirement. As an initial analysis of the approximation properties of the problem, we show that the cell suppression problem with a constant number of attributes can be approximated within a constant. As a side effect, proofs of NP-hardness of the minimum k-union, maximum k-intersection, and parallel versions of these are presented. Bounded versions of these problems are also shown to be approximable within a constant.
Publishing Search LogsΓÇöA Comparative Study of Privacy Guarantees	Search engine companies collect the ΓÇ£database of intentions,ΓÇ¥ the histories of their users' search queries. These search logs are a gold mine for researchers. Search engine companies, however, are wary of publishing search logs in order not to disclose sensitive information. In this paper, we analyze algorithms for publishing frequent keywords, queries, and clicks of a search log. We first show how methods that achieve variants of k-anonymity are vulnerable to active attacks. We then demonstrate that the stronger guarantee ensured by ╬╡-differential privacy unfortunately does not provide any utility for this problem. We then propose an algorithm ZEALOUS and show how to set its parameters to achieve (╬╡, ╬┤)-probabilistic privacy. We also contrast our analysis of ZEALOUS with an analysis by Korolova et al. [17] that achieves (╬╡',╬┤')-indistinguishability. Our paper concludes with a large experimental study using real applications where we compare ZEALOUS and previous work that achieves k-anonymity in search log publishing. Our results show that ZEALOUS yields comparable utility to k-anonymity while at the same time achieving much stronger privacy guarantees.
An efficient scheme to protect privacy in Probe Vehicle Information system	The Probe Vehicle Information system is as system that collects information from cars equipped with sensors. Usually, various information is collected and transferred to a server, at frequent intervals. The information includes when and where the information was collected, which could lead to privacy problems. One way to solve these problems, is to use cryptographic anonymous authentication protocols. However, although the computational and network resource on cars are limited, anonymous authentication protocols tend to consume both heavily. In this article, we propose a new protocol using the combination cryptographic anonymous authentication and symmetric-key cryptographic authentication. This protocol can protect the users├é┬┐ privacy, while is efficient enough to be used for probe vehicle information systems. We also have conducted an experiment on a simulator with 5,000 virtual cars, and showed that this protocol is efficient enough for real use.
CANE: A Controlled Application Environment for privacy protection in ITS	Many of the applications proposed for intelligent transportation systems (ITS) need to process and communicate detailed personal identifiable information. Examples are detailed location traces or unique identifiers for authentication towards paid services. Existing applications often run as monolithic black boxes inside users' cars. Hence, users cannot verify that applications behave as expected. We propose CANE, an application sandboxing approach that enhances user control over privacy properties while, at the same time, supporting common application requirements. CANE makes privacy-relevant application properties explicit and allows their analysis and enforcement during application runtime. We evaluate CANE using a common ITS use case and demonstrate feasibility with a proof-of-concept implementation.
Privacy considerations for cloud-based positioning	Cloud-based positioning provides better support for resource-constrained mobile devices; however, the user's location information is exposed during positioning when the computation is performed on the cloud. The improper exposure of location information could result in severe consequences that make users the target of fraudulent attacks. This study proposes a privacy-preserving localization scheme based on homomorphic encryption techniques in order to protect user privacy from both imminent attackers and untrusted cloud servers. The proposed algorithm exposes unreliable cloud only an encrypted version of the measurements and allows positioning to be performed in an encrypted domain. This scheme prevents cloud servers from understanding the computed results and avoid an adversary monitoring the transmission to log user behavior. On-site experiments show the feasibility of our approach. The results show that positioning in an encrypted domain would not affect accuracy. Experimental results also show that the proposed algorithm requires less computational overhead and achieves higher privacy level simultaneously compared to traditional encryption approaches.
Using cooperation among peers and interest mixing to protect privacy in targeted mobile advertisement	Organizations are starting to realize the significant value of advertising on mobile devices, and a number of systems have been developed to exploit this opportunity. We propose a system for delivering location and preference-aware advertisements to vehicles and to mobile devices using a novel architecture for preserving privacy. Our model assumes the main adversary is the server distributing the ads trying to identify users and track them. It also considers other peers in the network as potential threats who may disclose information to third parties. When a node wants an ad, it forms a group of nearby nodes seeking ads and willing to cooperate to achieve privacy. Peers combine their interests using a mixing mechanism using an ad-hoc network and send them through a primary peer to the ad server. In this way, preferences are masqueraded to request custom ads which are then distributed by the primary peer. Another mechanism is proposed to implement the billing process without disclosing user identities.
Addressing new security and privacy challenges	Now that Y2K is behind us, IT professionals have been tempted to rest on their laurels particularly because the economic recession has significantly slowed spending on IT equipment and services. However, the tragic events of 11 September and a series of serious worms and denial-of-service attacks should serve as an urgent wake-up call that society is indeed vulnerable to threats against critical infrastructure. These critical systems include those for telecommunications, transportation, energy, banking and finance, government, and emergency services systems vital to the world's normal functioning and well being. Incapacitating any one or multiple portions of these infrastructures could compromise economies and public safety
Security and Privacy Advertisement	
Privacy and/or Security: Take Your Pick	The concepts of privacy and security are distinct, but they're often considered synonymously when applied to computational systems. This article explores the conceptual differences between computational privacy and security and suggests four mutually exclusive models that define four different fundamental approaches to privacy and security during design. It's crucial that developers make a conscious and explicit decision how the two concepts should be approached early during system design.